{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bba2de81-0660-4c45-9370-401a61ba41fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "        .appName(\"MyApp\") \\\n",
    "        .config(\"spark.jars\", \"/opt/jars/hadoop-aws-3.3.1.jar,/opt/jars/aws-java-sdk-bundle-1.12.375.jar,/opt/jars/delta-spark_2.12-3.2.1.jar,/opt/jars/delta-storage-3.2.1.jar,/opt/jars/delta-kernel-api-3.2.1.jar,/opt/jars/mysql-connector-j-8.3.0.jar\") \\\n",
    "        .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\\\n",
    "        .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\\\n",
    "        .config(\"spark.hadoop.fs.s3a.access.key\", \"NJ3L4SVUPNXQG3Q8G467\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.secret.key\", \"xJwXJYnzpsIDlDpFGOPspi8ryChaBJJ94XMFICwj\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.endpoint\", \"https://rgw.nau.fccn.pt\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90c42c69-58d4-4a82-b634-7f76482701ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/13 15:52:56 INFO BlockManagerInfo: Removed broadcast_17_piece0 on jupyter-spark-758b7c86d8-7j77n:32921 in memory (size: 37.1 KiB, free: 1048.6 MiB)\n",
      "25/11/13 15:52:56 INFO BlockManagerInfo: Removed broadcast_16_piece0 on jupyter-spark-758b7c86d8-7j77n:32921 in memory (size: 164.5 KiB, free: 1048.7 MiB)\n",
      "25/11/13 15:52:56 INFO BlockManagerInfo: Removed broadcast_18_piece0 on jupyter-spark-758b7c86d8-7j77n:32921 in memory (size: 11.1 KiB, free: 1048.7 MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- meta: string (nullable = true)\n",
      " |-- courseware: string (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- year_of_birth: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- level_of_education: string (nullable = true)\n",
      " |-- mailing_address: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- goals: string (nullable = true)\n",
      " |-- bio: string (nullable = true)\n",
      " |-- profile_image_uploaded_at: timestamp (nullable = true)\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- phone_number: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- ingestion_date: timestamp (nullable = true)\n",
      " |-- source_name: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/13 15:52:56 INFO PrepareDeltaScan: DELTA: Filtering files for query\n",
      "25/11/13 15:52:56 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128\n",
      "25/11/13 15:52:56 INFO DAGScheduler: Got job 12 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions\n",
      "25/11/13 15:52:56 INFO DAGScheduler: Final stage: ResultStage 20 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)\n",
      "25/11/13 15:52:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)\n",
      "25/11/13 15:52:56 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 15:52:56 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[50] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents\n",
      "25/11/13 15:52:56 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 721.9 KiB, free 1047.6 MiB)\n",
      "25/11/13 15:52:56 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 164.5 KiB, free 1047.5 MiB)\n",
      "25/11/13 15:52:56 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 164.5 KiB, free: 1048.6 MiB)\n",
      "25/11/13 15:52:56 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 15:52:56 INFO DAGScheduler: Submitting 50 missing tasks from ResultStage 20 (MapPartitionsRDD[50] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n",
      "25/11/13 15:52:56 INFO TaskSchedulerImpl: Adding task set 20.0 with 50 tasks resource profile 0\n",
      "25/11/13 15:52:56 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 257) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:56 INFO TaskSetManager: Starting task 1.0 in stage 20.0 (TID 258) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 1, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:56 INFO Executor: Running task 0.0 in stage 20.0 (TID 257)\n",
      "25/11/13 15:52:56 INFO Executor: Running task 1.0 in stage 20.0 (TID 258)\n",
      "25/11/13 15:52:56 INFO BlockManager: Found block rdd_18_0 locally\n",
      "25/11/13 15:52:56 INFO BlockManager: Found block rdd_18_1 locally\n",
      "25/11/13 15:52:56 INFO Executor: Finished task 0.0 in stage 20.0 (TID 257). 4336 bytes result sent to driver\n",
      "25/11/13 15:52:56 INFO Executor: Finished task 1.0 in stage 20.0 (TID 258). 4336 bytes result sent to driver\n",
      "25/11/13 15:52:56 INFO TaskSetManager: Starting task 2.0 in stage 20.0 (TID 259) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 2, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:56 INFO Executor: Running task 2.0 in stage 20.0 (TID 259)\n",
      "25/11/13 15:52:56 INFO TaskSetManager: Starting task 3.0 in stage 20.0 (TID 260) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 3, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:56 INFO TaskSetManager: Finished task 1.0 in stage 20.0 (TID 258) in 73 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/50)\n",
      "25/11/13 15:52:56 INFO Executor: Running task 3.0 in stage 20.0 (TID 260)\n",
      "25/11/13 15:52:56 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 257) in 75 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (2/50)\n",
      "25/11/13 15:52:56 INFO BlockManager: Found block rdd_18_2 locally\n",
      "25/11/13 15:52:56 INFO Executor: Finished task 2.0 in stage 20.0 (TID 259). 4336 bytes result sent to driver\n",
      "25/11/13 15:52:56 INFO TaskSetManager: Starting task 4.0 in stage 20.0 (TID 261) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 4, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:56 INFO TaskSetManager: Finished task 2.0 in stage 20.0 (TID 259) in 59 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (3/50)\n",
      "25/11/13 15:52:56 INFO Executor: Running task 4.0 in stage 20.0 (TID 261)\n",
      "25/11/13 15:52:56 INFO BlockManager: Found block rdd_18_3 locally\n",
      "25/11/13 15:52:56 INFO Executor: Finished task 3.0 in stage 20.0 (TID 260). 4336 bytes result sent to driver\n",
      "25/11/13 15:52:56 INFO TaskSetManager: Starting task 5.0 in stage 20.0 (TID 262) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 5, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:56 INFO Executor: Running task 5.0 in stage 20.0 (TID 262)\n",
      "25/11/13 15:52:56 INFO TaskSetManager: Finished task 3.0 in stage 20.0 (TID 260) in 94 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (4/50)\n",
      "25/11/13 15:52:56 INFO BlockManager: Found block rdd_18_4 locally\n",
      "25/11/13 15:52:56 INFO BlockManager: Found block rdd_18_5 locally\n",
      "25/11/13 15:52:56 INFO Executor: Finished task 4.0 in stage 20.0 (TID 261). 4336 bytes result sent to driver\n",
      "25/11/13 15:52:56 INFO TaskSetManager: Starting task 6.0 in stage 20.0 (TID 263) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 6, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:56 INFO Executor: Running task 6.0 in stage 20.0 (TID 263)\n",
      "25/11/13 15:52:56 INFO Executor: Finished task 5.0 in stage 20.0 (TID 262). 4336 bytes result sent to driver\n",
      "25/11/13 15:52:56 INFO TaskSetManager: Finished task 4.0 in stage 20.0 (TID 261) in 89 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (5/50)\n",
      "25/11/13 15:52:56 INFO TaskSetManager: Starting task 7.0 in stage 20.0 (TID 264) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 7, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:56 INFO Executor: Running task 7.0 in stage 20.0 (TID 264)\n",
      "25/11/13 15:52:56 INFO TaskSetManager: Finished task 5.0 in stage 20.0 (TID 262) in 57 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (6/50)\n",
      "25/11/13 15:52:56 INFO BlockManager: Found block rdd_18_6 locally\n",
      "25/11/13 15:52:56 INFO Executor: Finished task 6.0 in stage 20.0 (TID 263). 4336 bytes result sent to driver\n",
      "25/11/13 15:52:56 INFO TaskSetManager: Starting task 8.0 in stage 20.0 (TID 265) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 8, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:56 INFO Executor: Running task 8.0 in stage 20.0 (TID 265)\n",
      "25/11/13 15:52:56 INFO TaskSetManager: Finished task 6.0 in stage 20.0 (TID 263) in 54 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (7/50)\n",
      "25/11/13 15:52:56 INFO BlockManager: Found block rdd_18_7 locally\n",
      "25/11/13 15:52:56 INFO Executor: Finished task 7.0 in stage 20.0 (TID 264). 4530 bytes result sent to driver\n",
      "25/11/13 15:52:56 INFO TaskSetManager: Starting task 9.0 in stage 20.0 (TID 266) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 9, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:56 INFO Executor: Running task 9.0 in stage 20.0 (TID 266)\n",
      "25/11/13 15:52:56 INFO TaskSetManager: Finished task 7.0 in stage 20.0 (TID 264) in 85 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (8/50)\n",
      "25/11/13 15:52:56 INFO BlockManager: Found block rdd_18_8 locally\n",
      "25/11/13 15:52:56 INFO Executor: Finished task 8.0 in stage 20.0 (TID 265). 4336 bytes result sent to driver\n",
      "25/11/13 15:52:56 INFO TaskSetManager: Starting task 10.0 in stage 20.0 (TID 267) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 10, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:56 INFO Executor: Running task 10.0 in stage 20.0 (TID 267)\n",
      "25/11/13 15:52:56 INFO TaskSetManager: Finished task 8.0 in stage 20.0 (TID 265) in 53 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (9/50)\n",
      "25/11/13 15:52:56 INFO BlockManager: Found block rdd_18_9 locally\n",
      "25/11/13 15:52:56 INFO Executor: Finished task 9.0 in stage 20.0 (TID 266). 4336 bytes result sent to driver\n",
      "25/11/13 15:52:56 INFO TaskSetManager: Starting task 11.0 in stage 20.0 (TID 268) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 11, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:56 INFO Executor: Running task 11.0 in stage 20.0 (TID 268)\n",
      "25/11/13 15:52:56 INFO TaskSetManager: Finished task 9.0 in stage 20.0 (TID 266) in 29 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (10/50)\n",
      "25/11/13 15:52:57 INFO BlockManager: Found block rdd_18_10 locally\n",
      "25/11/13 15:52:57 INFO Executor: Finished task 10.0 in stage 20.0 (TID 267). 4336 bytes result sent to driver\n",
      "25/11/13 15:52:57 INFO BlockManager: Found block rdd_18_11 locally\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Starting task 12.0 in stage 20.0 (TID 269) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 12, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:57 INFO Executor: Running task 12.0 in stage 20.0 (TID 269)\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Finished task 10.0 in stage 20.0 (TID 267) in 105 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (11/50)\n",
      "25/11/13 15:52:57 INFO Executor: Finished task 11.0 in stage 20.0 (TID 268). 4336 bytes result sent to driver\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Starting task 13.0 in stage 20.0 (TID 270) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 13, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:57 INFO Executor: Running task 13.0 in stage 20.0 (TID 270)\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Finished task 11.0 in stage 20.0 (TID 268) in 101 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (12/50)\n",
      "25/11/13 15:52:57 INFO BlockManager: Found block rdd_18_12 locally\n",
      "25/11/13 15:52:57 INFO Executor: Finished task 12.0 in stage 20.0 (TID 269). 4336 bytes result sent to driver\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Starting task 14.0 in stage 20.0 (TID 271) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 14, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:57 INFO Executor: Running task 14.0 in stage 20.0 (TID 271)\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Finished task 12.0 in stage 20.0 (TID 269) in 54 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (13/50)\n",
      "25/11/13 15:52:57 INFO BlockManager: Found block rdd_18_13 locally\n",
      "25/11/13 15:52:57 INFO Executor: Finished task 13.0 in stage 20.0 (TID 270). 4293 bytes result sent to driver\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Starting task 15.0 in stage 20.0 (TID 272) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 15, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:57 INFO Executor: Running task 15.0 in stage 20.0 (TID 272)\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Finished task 13.0 in stage 20.0 (TID 270) in 77 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (14/50)\n",
      "25/11/13 15:52:57 INFO BlockManager: Found block rdd_18_14 locally\n",
      "25/11/13 15:52:57 INFO Executor: Finished task 14.0 in stage 20.0 (TID 271). 4293 bytes result sent to driver\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Starting task 16.0 in stage 20.0 (TID 273) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 16, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:57 INFO Executor: Running task 16.0 in stage 20.0 (TID 273)\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Finished task 14.0 in stage 20.0 (TID 271) in 42 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (15/50)\n",
      "25/11/13 15:52:57 INFO BlockManager: Found block rdd_18_15 locally\n",
      "25/11/13 15:52:57 INFO Executor: Finished task 15.0 in stage 20.0 (TID 272). 4293 bytes result sent to driver\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Starting task 17.0 in stage 20.0 (TID 274) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 17, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:57 INFO Executor: Running task 17.0 in stage 20.0 (TID 274)\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Finished task 15.0 in stage 20.0 (TID 272) in 51 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (16/50)\n",
      "25/11/13 15:52:57 INFO BlockManager: Found block rdd_18_16 locally\n",
      "25/11/13 15:52:57 INFO Executor: Finished task 16.0 in stage 20.0 (TID 273). 4336 bytes result sent to driver\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Starting task 18.0 in stage 20.0 (TID 275) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 18, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:57 INFO Executor: Running task 18.0 in stage 20.0 (TID 275)\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Finished task 16.0 in stage 20.0 (TID 273) in 67 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (17/50)\n",
      "25/11/13 15:52:57 INFO BlockManager: Found block rdd_18_17 locally\n",
      "25/11/13 15:52:57 INFO Executor: Finished task 17.0 in stage 20.0 (TID 274). 4293 bytes result sent to driver\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Starting task 19.0 in stage 20.0 (TID 276) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 19, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:57 INFO Executor: Running task 19.0 in stage 20.0 (TID 276)\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Finished task 17.0 in stage 20.0 (TID 274) in 71 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (18/50)\n",
      "25/11/13 15:52:57 INFO BlockManager: Found block rdd_18_18 locally\n",
      "25/11/13 15:52:57 INFO Executor: Finished task 18.0 in stage 20.0 (TID 275). 4293 bytes result sent to driver\n",
      "25/11/13 15:52:57 INFO BlockManager: Found block rdd_18_19 locally\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Starting task 20.0 in stage 20.0 (TID 277) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 20, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:57 INFO Executor: Running task 20.0 in stage 20.0 (TID 277)\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Finished task 18.0 in stage 20.0 (TID 275) in 47 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (19/50)\n",
      "25/11/13 15:52:57 INFO Executor: Finished task 19.0 in stage 20.0 (TID 276). 4336 bytes result sent to driver\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Starting task 21.0 in stage 20.0 (TID 278) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 21, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:57 INFO Executor: Running task 21.0 in stage 20.0 (TID 278)\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Finished task 19.0 in stage 20.0 (TID 276) in 30 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (20/50)\n",
      "25/11/13 15:52:57 INFO BlockManager: Found block rdd_18_21 locally(20 + 2) / 50]\n",
      "25/11/13 15:52:57 INFO Executor: Finished task 21.0 in stage 20.0 (TID 278). 4293 bytes result sent to driver\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Starting task 22.0 in stage 20.0 (TID 279) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 22, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:57 INFO TaskSetManager: Finished task 21.0 in stage 20.0 (TID 278) in 71 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (21/50)\n",
      "25/11/13 15:52:57 INFO Executor: Running task 22.0 in stage 20.0 (TID 279)\n",
      "25/11/13 15:52:57 INFO BlockManager: Found block rdd_18_20 locally\n",
      "25/11/13 15:52:57 INFO Executor: Finished task 20.0 in stage 20.0 (TID 277). 4293 bytes result sent to driver\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Starting task 23.0 in stage 20.0 (TID 280) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 23, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:57 INFO Executor: Running task 23.0 in stage 20.0 (TID 280)\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Finished task 20.0 in stage 20.0 (TID 277) in 83 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (22/50)\n",
      "25/11/13 15:52:57 INFO BlockManager: Found block rdd_18_22 locally\n",
      "25/11/13 15:52:57 INFO BlockManager: Found block rdd_18_23 locally\n",
      "25/11/13 15:52:57 INFO Executor: Finished task 22.0 in stage 20.0 (TID 279). 4336 bytes result sent to driver\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Starting task 24.0 in stage 20.0 (TID 281) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 24, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:57 INFO Executor: Running task 24.0 in stage 20.0 (TID 281)\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Finished task 22.0 in stage 20.0 (TID 279) in 46 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (23/50)\n",
      "25/11/13 15:52:57 INFO Executor: Finished task 23.0 in stage 20.0 (TID 280). 4336 bytes result sent to driver\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Starting task 25.0 in stage 20.0 (TID 282) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 25, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:57 INFO Executor: Running task 25.0 in stage 20.0 (TID 282)\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Finished task 23.0 in stage 20.0 (TID 280) in 31 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (24/50)\n",
      "25/11/13 15:52:57 INFO BlockManager: Found block rdd_18_24 locally\n",
      "25/11/13 15:52:57 INFO BlockManager: Found block rdd_18_25 locally\n",
      "25/11/13 15:52:57 INFO Executor: Finished task 24.0 in stage 20.0 (TID 281). 4336 bytes result sent to driver\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Starting task 26.0 in stage 20.0 (TID 283) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 26, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:57 INFO Executor: Running task 26.0 in stage 20.0 (TID 283)\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Finished task 24.0 in stage 20.0 (TID 281) in 78 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (25/50)\n",
      "25/11/13 15:52:57 INFO Executor: Finished task 25.0 in stage 20.0 (TID 282). 4336 bytes result sent to driver\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Starting task 27.0 in stage 20.0 (TID 284) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 27, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:57 INFO Executor: Running task 27.0 in stage 20.0 (TID 284)\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Finished task 25.0 in stage 20.0 (TID 282) in 79 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (26/50)\n",
      "25/11/13 15:52:57 INFO BlockManager: Found block rdd_18_26 locally\n",
      "25/11/13 15:52:57 INFO Executor: Finished task 26.0 in stage 20.0 (TID 283). 4379 bytes result sent to driver\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Starting task 28.0 in stage 20.0 (TID 285) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 28, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:57 INFO Executor: Running task 28.0 in stage 20.0 (TID 285)\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Finished task 26.0 in stage 20.0 (TID 283) in 69 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (27/50)\n",
      "25/11/13 15:52:57 INFO BlockManager: Found block rdd_18_27 locally\n",
      "25/11/13 15:52:57 INFO Executor: Finished task 27.0 in stage 20.0 (TID 284). 4336 bytes result sent to driver\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Starting task 29.0 in stage 20.0 (TID 286) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 29, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:57 INFO Executor: Running task 29.0 in stage 20.0 (TID 286)\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Finished task 27.0 in stage 20.0 (TID 284) in 72 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (28/50)\n",
      "25/11/13 15:52:57 INFO BlockManager: Found block rdd_18_28 locally\n",
      "25/11/13 15:52:57 INFO Executor: Finished task 28.0 in stage 20.0 (TID 285). 4293 bytes result sent to driver\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Starting task 30.0 in stage 20.0 (TID 287) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 30, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:57 INFO Executor: Running task 30.0 in stage 20.0 (TID 287)\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Finished task 28.0 in stage 20.0 (TID 285) in 50 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (29/50)\n",
      "25/11/13 15:52:57 INFO BlockManager: Found block rdd_18_29 locally\n",
      "25/11/13 15:52:57 INFO Executor: Finished task 29.0 in stage 20.0 (TID 286). 4336 bytes result sent to driver\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Starting task 31.0 in stage 20.0 (TID 288) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 31, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:57 INFO Executor: Running task 31.0 in stage 20.0 (TID 288)\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Finished task 29.0 in stage 20.0 (TID 286) in 87 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (30/50)\n",
      "25/11/13 15:52:57 INFO BlockManager: Found block rdd_18_30 locally\n",
      "25/11/13 15:52:57 INFO Executor: Finished task 30.0 in stage 20.0 (TID 287). 4336 bytes result sent to driver\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Starting task 32.0 in stage 20.0 (TID 289) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 32, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:57 INFO Executor: Running task 32.0 in stage 20.0 (TID 289)\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Finished task 30.0 in stage 20.0 (TID 287) in 85 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (31/50)\n",
      "25/11/13 15:52:57 INFO BlockManager: Found block rdd_18_31 locally\n",
      "25/11/13 15:52:57 INFO Executor: Finished task 31.0 in stage 20.0 (TID 288). 4336 bytes result sent to driver\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Starting task 33.0 in stage 20.0 (TID 290) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 33, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:57 INFO Executor: Running task 33.0 in stage 20.0 (TID 290)\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Finished task 31.0 in stage 20.0 (TID 288) in 53 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (32/50)\n",
      "25/11/13 15:52:57 INFO BlockManager: Found block rdd_18_32 locally\n",
      "25/11/13 15:52:57 INFO Executor: Finished task 32.0 in stage 20.0 (TID 289). 4336 bytes result sent to driver\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Starting task 34.0 in stage 20.0 (TID 291) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 34, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:57 INFO TaskSetManager: Finished task 32.0 in stage 20.0 (TID 289) in 74 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (33/50)\n",
      "25/11/13 15:52:57 INFO Executor: Running task 34.0 in stage 20.0 (TID 291)\n",
      "25/11/13 15:52:57 INFO BlockManager: Found block rdd_18_33 locally\n",
      "25/11/13 15:52:57 INFO Executor: Finished task 33.0 in stage 20.0 (TID 290). 4336 bytes result sent to driver\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Starting task 35.0 in stage 20.0 (TID 292) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 35, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:57 INFO Executor: Running task 35.0 in stage 20.0 (TID 292)\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Finished task 33.0 in stage 20.0 (TID 290) in 90 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (34/50)\n",
      "25/11/13 15:52:57 INFO BlockManager: Found block rdd_18_34 locally\n",
      "25/11/13 15:52:57 INFO Executor: Finished task 34.0 in stage 20.0 (TID 291). 4293 bytes result sent to driver\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Starting task 36.0 in stage 20.0 (TID 293) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 36, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:57 INFO Executor: Running task 36.0 in stage 20.0 (TID 293)\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Finished task 34.0 in stage 20.0 (TID 291) in 52 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (35/50)\n",
      "25/11/13 15:52:57 INFO BlockManager: Found block rdd_18_35 locally\n",
      "25/11/13 15:52:57 INFO Executor: Finished task 35.0 in stage 20.0 (TID 292). 4293 bytes result sent to driver\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Starting task 37.0 in stage 20.0 (TID 294) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 37, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:57 INFO Executor: Running task 37.0 in stage 20.0 (TID 294)\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Finished task 35.0 in stage 20.0 (TID 292) in 66 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (36/50)\n",
      "25/11/13 15:52:57 INFO BlockManager: Found block rdd_18_36 locally\n",
      "25/11/13 15:52:57 INFO BlockManager: Found block rdd_18_37 locally\n",
      "25/11/13 15:52:57 INFO Executor: Finished task 36.0 in stage 20.0 (TID 293). 4293 bytes result sent to driver\n",
      "25/11/13 15:52:57 INFO Executor: Finished task 37.0 in stage 20.0 (TID 294). 4293 bytes result sent to driver\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Starting task 38.0 in stage 20.0 (TID 295) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 38, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:57 INFO Executor: Running task 38.0 in stage 20.0 (TID 295)\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Starting task 39.0 in stage 20.0 (TID 296) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 39, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:57 INFO TaskSetManager: Finished task 36.0 in stage 20.0 (TID 293) in 91 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (37/50)\n",
      "25/11/13 15:52:57 INFO Executor: Running task 39.0 in stage 20.0 (TID 296)\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Finished task 37.0 in stage 20.0 (TID 294) in 49 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (38/50)\n",
      "25/11/13 15:52:57 INFO BlockManager: Found block rdd_18_39 locally(38 + 2) / 50]\n",
      "25/11/13 15:52:57 INFO BlockManager: Found block rdd_18_38 locally\n",
      "25/11/13 15:52:57 INFO Executor: Finished task 38.0 in stage 20.0 (TID 295). 4293 bytes result sent to driver\n",
      "25/11/13 15:52:57 INFO Executor: Finished task 39.0 in stage 20.0 (TID 296). 4336 bytes result sent to driver\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Starting task 40.0 in stage 20.0 (TID 297) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 40, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:57 INFO Executor: Running task 40.0 in stage 20.0 (TID 297)\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Starting task 41.0 in stage 20.0 (TID 298) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 41, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:57 INFO Executor: Running task 41.0 in stage 20.0 (TID 298)\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Finished task 38.0 in stage 20.0 (TID 295) in 92 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (39/50)\n",
      "25/11/13 15:52:57 INFO TaskSetManager: Finished task 39.0 in stage 20.0 (TID 296) in 92 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (40/50)\n",
      "25/11/13 15:52:57 INFO BlockManager: Found block rdd_18_41 locally\n",
      "25/11/13 15:52:57 INFO BlockManager: Found block rdd_18_40 locally\n",
      "25/11/13 15:52:57 INFO Executor: Finished task 40.0 in stage 20.0 (TID 297). 4293 bytes result sent to driver\n",
      "25/11/13 15:52:57 INFO Executor: Finished task 41.0 in stage 20.0 (TID 298). 4293 bytes result sent to driver\n",
      "25/11/13 15:52:58 INFO TaskSetManager: Starting task 42.0 in stage 20.0 (TID 299) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 42, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:58 INFO Executor: Running task 42.0 in stage 20.0 (TID 299)\n",
      "25/11/13 15:52:58 INFO TaskSetManager: Starting task 43.0 in stage 20.0 (TID 300) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 43, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:58 INFO Executor: Running task 43.0 in stage 20.0 (TID 300)\n",
      "25/11/13 15:52:58 INFO TaskSetManager: Finished task 40.0 in stage 20.0 (TID 297) in 64 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (41/50)\n",
      "25/11/13 15:52:58 INFO TaskSetManager: Finished task 41.0 in stage 20.0 (TID 298) in 65 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (42/50)\n",
      "25/11/13 15:52:58 INFO BlockManager: Found block rdd_18_43 locally\n",
      "25/11/13 15:52:58 INFO BlockManager: Found block rdd_18_42 locally\n",
      "25/11/13 15:52:58 INFO Executor: Finished task 43.0 in stage 20.0 (TID 300). 4336 bytes result sent to driver\n",
      "25/11/13 15:52:58 INFO TaskSetManager: Starting task 44.0 in stage 20.0 (TID 301) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 44, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:58 INFO Executor: Finished task 42.0 in stage 20.0 (TID 299). 4336 bytes result sent to driver\n",
      "25/11/13 15:52:58 INFO Executor: Running task 44.0 in stage 20.0 (TID 301)\n",
      "25/11/13 15:52:58 INFO TaskSetManager: Starting task 45.0 in stage 20.0 (TID 302) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 45, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:58 INFO TaskSetManager: Finished task 43.0 in stage 20.0 (TID 300) in 218 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (43/50)\n",
      "25/11/13 15:52:58 INFO Executor: Running task 45.0 in stage 20.0 (TID 302)\n",
      "25/11/13 15:52:58 INFO TaskSetManager: Finished task 42.0 in stage 20.0 (TID 299) in 271 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (44/50)\n",
      "25/11/13 15:52:58 INFO BlockManager: Found block rdd_18_44 locally\n",
      "25/11/13 15:52:58 INFO BlockManager: Found block rdd_18_45 locally\n",
      "25/11/13 15:52:58 INFO Executor: Finished task 44.0 in stage 20.0 (TID 301). 4336 bytes result sent to driver\n",
      "25/11/13 15:52:58 INFO Executor: Finished task 45.0 in stage 20.0 (TID 302). 4336 bytes result sent to driver\n",
      "25/11/13 15:52:58 INFO TaskSetManager: Starting task 46.0 in stage 20.0 (TID 303) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 46, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:58 INFO Executor: Running task 46.0 in stage 20.0 (TID 303)\n",
      "25/11/13 15:52:58 INFO TaskSetManager: Starting task 47.0 in stage 20.0 (TID 304) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 47, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:58 INFO Executor: Running task 47.0 in stage 20.0 (TID 304)\n",
      "25/11/13 15:52:58 INFO TaskSetManager: Finished task 44.0 in stage 20.0 (TID 301) in 98 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (45/50)\n",
      "25/11/13 15:52:58 INFO TaskSetManager: Finished task 45.0 in stage 20.0 (TID 302) in 93 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (46/50)\n",
      "25/11/13 15:52:58 INFO BlockManager: Found block rdd_18_47 locally\n",
      "25/11/13 15:52:58 INFO Executor: Finished task 47.0 in stage 20.0 (TID 304). 4293 bytes result sent to driver\n",
      "25/11/13 15:52:58 INFO TaskSetManager: Starting task 48.0 in stage 20.0 (TID 305) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 48, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:58 INFO Executor: Running task 48.0 in stage 20.0 (TID 305)\n",
      "25/11/13 15:52:58 INFO TaskSetManager: Finished task 47.0 in stage 20.0 (TID 304) in 46 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (47/50)\n",
      "25/11/13 15:52:58 INFO BlockManager: Found block rdd_18_46 locally\n",
      "25/11/13 15:52:58 INFO Executor: Finished task 46.0 in stage 20.0 (TID 303). 4293 bytes result sent to driver\n",
      "25/11/13 15:52:58 INFO TaskSetManager: Starting task 49.0 in stage 20.0 (TID 306) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 49, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:52:58 INFO Executor: Running task 49.0 in stage 20.0 (TID 306)\n",
      "25/11/13 15:52:58 INFO TaskSetManager: Finished task 46.0 in stage 20.0 (TID 303) in 59 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (48/50)\n",
      "25/11/13 15:52:58 INFO BlockManager: Found block rdd_18_48 locally\n",
      "25/11/13 15:52:58 INFO Executor: Finished task 48.0 in stage 20.0 (TID 305). 4293 bytes result sent to driver\n",
      "25/11/13 15:52:58 INFO TaskSetManager: Finished task 48.0 in stage 20.0 (TID 305) in 61 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (49/50)\n",
      "25/11/13 15:52:58 INFO BlockManager: Found block rdd_18_49 locally\n",
      "25/11/13 15:52:58 INFO Executor: Finished task 49.0 in stage 20.0 (TID 306). 4293 bytes result sent to driver\n",
      "25/11/13 15:52:58 INFO TaskSetManager: Finished task 49.0 in stage 20.0 (TID 306) in 94 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (50/50)\n",
      "25/11/13 15:52:58 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool \n",
      "25/11/13 15:52:58 INFO DAGScheduler: ResultStage 20 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 1.860 s\n",
      "25/11/13 15:52:58 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/11/13 15:52:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished\n",
      "25/11/13 15:52:58 INFO DAGScheduler: Job 12 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 1.879379 s\n",
      "25/11/13 15:52:58 INFO FileSourceStrategy: Pushed Filters:                      \n",
      "25/11/13 15:52:58 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/11/13 15:52:58 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 208.2 KiB, free 1047.3 MiB)\n",
      "25/11/13 15:52:58 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 37.1 KiB, free 1047.2 MiB)\n",
      "25/11/13 15:52:58 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 37.1 KiB, free: 1048.5 MiB)\n",
      "25/11/13 15:52:58 INFO SparkContext: Created broadcast 20 from showString at NativeMethodAccessorImpl.java:0\n",
      "25/11/13 15:52:58 INFO FileSourceScanExec: Planning scan with bin packing, max size: 10926151 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/11/13 15:52:58 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "25/11/13 15:52:58 INFO DAGScheduler: Got job 13 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/11/13 15:52:58 INFO DAGScheduler: Final stage: ResultStage 21 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/11/13 15:52:58 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/11/13 15:52:58 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 15:52:58 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[54] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/11/13 15:52:58 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 34.2 KiB, free 1047.2 MiB)\n",
      "25/11/13 15:52:58 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 11.1 KiB, free 1047.2 MiB)\n",
      "25/11/13 15:52:58 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 11.1 KiB, free: 1048.5 MiB)\n",
      "25/11/13 15:52:58 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 15:52:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[54] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/11/13 15:52:58 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks resource profile 0\n",
      "25/11/13 15:52:58 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 307) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 9679 bytes) \n",
      "25/11/13 15:52:58 INFO Executor: Running task 0.0 in stage 21.0 (TID 307)\n",
      "25/11/13 15:52:58 INFO FileScanRDD: Reading File path: s3a://nau-local-analytics-bronze/auth_userprofile/part-00000-130fc9e9-8dc1-4d6a-b4e7-714542eff639-c000.snappy.parquet, range: 0-10926151, partition values: [empty row]\n",
      "25/11/13 15:52:58 INFO S3AInputStream: Switching to Random IO seek policy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+----+----------+--------+--------+-------------+------+------------------+---------------+----+-------+-----+----+-------------------------+-------+------------+-----+--------------------+----------------+\n",
      "| id|name|meta|courseware|language|location|year_of_birth|gender|level_of_education|mailing_address|city|country|goals| bio|profile_image_uploaded_at|user_id|phone_number|state|      ingestion_date|     source_name|\n",
      "+---+----+----+----------+--------+--------+-------------+------+------------------+---------------+----+-------+-----+----+-------------------------+-------+------------+-----+--------------------+----------------+\n",
      "|  1|    |    |course.xml|        |        |         NULL|  NULL|              NULL|           NULL|NULL|   NULL| NULL|NULL|                     NULL|      1|        NULL| NULL|2025-11-04 18:27:...|auth_userprofile|\n",
      "|  2|    |    |course.xml|        |        |         NULL|  NULL|              NULL|           NULL|NULL|   NULL| NULL|NULL|                     NULL|      2|        NULL| NULL|2025-11-04 18:27:...|auth_userprofile|\n",
      "|  3|    |    |course.xml|        |        |         NULL|  NULL|              NULL|           NULL|NULL|   NULL| NULL|NULL|                     NULL|      3|        NULL| NULL|2025-11-04 18:27:...|auth_userprofile|\n",
      "|  4|    |    |course.xml|        |        |         NULL|  NULL|              NULL|           NULL|NULL|   NULL| NULL|NULL|                     NULL|      4|        NULL| NULL|2025-11-04 18:27:...|auth_userprofile|\n",
      "|  5|    |    |course.xml|        |        |         NULL|  NULL|              NULL|           NULL|NULL|   NULL| NULL|NULL|                     NULL|      6|        NULL| NULL|2025-11-04 18:27:...|auth_userprofile|\n",
      "+---+----+----+----------+--------+--------+-------------+------+------------------+---------------+----+-------+-----+----+-------------------------+-------+------------+-----+--------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/13 15:52:59 INFO Executor: Finished task 0.0 in stage 21.0 (TID 307). 2215 bytes result sent to driver\n",
      "25/11/13 15:52:59 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 307) in 588 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/1)\n",
      "25/11/13 15:52:59 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool \n",
      "25/11/13 15:52:59 INFO DAGScheduler: ResultStage 21 (showString at NativeMethodAccessorImpl.java:0) finished in 0.600 s\n",
      "25/11/13 15:52:59 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/11/13 15:52:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 21: Stage finished\n",
      "25/11/13 15:52:59 INFO DAGScheduler: Job 13 finished: showString at NativeMethodAccessorImpl.java:0, took 0.608187 s\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_auth_userprofile_bronze = spark.read.format(\"delta\").load(\"s3a://nau-local-analytics-bronze/auth_userprofile\")\n",
    "df_auth_userprofile_bronze.printSchema()\n",
    "df_auth_userprofile_bronze.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d518dba3-41e6-419a-85e9-7c95473f9c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/13 16:15:14 INFO DelegatingLogStore: LogStore `LogStoreAdapter(io.delta.storage.S3SingleDriverLogStore)` is used for scheme `s3a`\n",
      "25/11/13 16:15:14 INFO DeltaLog: Creating initial snapshot without metadata, because the directory is empty\n",
      "25/11/13 16:15:14 INFO InitialSnapshot: [tableId=153cb307-46e6-48c9-8558-36f05025fa14] Created snapshot InitialSnapshot(path=s3a://nau-local-analytics-silver/dim_user_profile/_delta_log, version=-1, metadata=Metadata(8331b31f-065d-44ac-ab7f-d88f606cf74a,null,null,Format(parquet,Map()),null,List(),Map(),Some(1763050514238)), logSegment=LogSegment(s3a://nau-local-analytics-silver/dim_user_profile/_delta_log,-1,List(),org.apache.spark.sql.delta.EmptyCheckpointProvider$@2b65c581,-1), checksumOpt=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> [dim_user_profile] Silver Delta table does not exist yet (first load).\n",
      ">> [dim_user_profile] Preview of df_user_profile_silver (with profile_sk):\n",
      "root\n",
      " |-- profile_sk: integer (nullable = false)\n",
      " |-- profile_id: integer (nullable = true)\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- year_of_birth: integer (nullable = true)\n",
      " |-- age_band: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- level_of_education: string (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- courseware: string (nullable = true)\n",
      " |-- phone_number: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- ingestion_date: timestamp (nullable = true)\n",
      " |-- source_name: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/13 16:15:14 INFO PrepareDeltaScan: DELTA: Filtering files for query\n",
      "25/11/13 16:15:15 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128\n",
      "25/11/13 16:15:15 INFO DAGScheduler: Got job 16 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions\n",
      "25/11/13 16:15:15 INFO DAGScheduler: Final stage: ResultStage 26 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)\n",
      "25/11/13 16:15:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)\n",
      "25/11/13 16:15:15 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 16:15:15 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[62] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents\n",
      "25/11/13 16:15:15 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 684.9 KiB, free 1047.7 MiB)\n",
      "25/11/13 16:15:15 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 154.5 KiB, free 1047.5 MiB)\n",
      "25/11/13 16:15:15 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 154.5 KiB, free: 1048.6 MiB)\n",
      "25/11/13 16:15:15 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 16:15:15 INFO DAGScheduler: Submitting 50 missing tasks from ResultStage 26 (MapPartitionsRDD[62] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n",
      "25/11/13 16:15:15 INFO TaskSchedulerImpl: Adding task set 26.0 with 50 tasks resource profile 0\n",
      "25/11/13 16:15:15 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 359) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:15 INFO TaskSetManager: Starting task 1.0 in stage 26.0 (TID 360) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 1, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:15 INFO Executor: Running task 0.0 in stage 26.0 (TID 359)\n",
      "25/11/13 16:15:15 INFO Executor: Running task 1.0 in stage 26.0 (TID 360)\n",
      "25/11/13 16:15:15 INFO BlockManager: Found block rdd_14_1 locally\n",
      "25/11/13 16:15:15 INFO Executor: Finished task 1.0 in stage 26.0 (TID 360). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:15 INFO TaskSetManager: Starting task 2.0 in stage 26.0 (TID 361) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 2, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:15 INFO BlockManager: Found block rdd_14_0 locally\n",
      "25/11/13 16:15:15 INFO Executor: Running task 2.0 in stage 26.0 (TID 361)\n",
      "25/11/13 16:15:15 INFO TaskSetManager: Finished task 1.0 in stage 26.0 (TID 360) in 73 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/50)\n",
      "25/11/13 16:15:15 INFO Executor: Finished task 0.0 in stage 26.0 (TID 359). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:15 INFO TaskSetManager: Starting task 3.0 in stage 26.0 (TID 362) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 3, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:15 INFO Executor: Running task 3.0 in stage 26.0 (TID 362)\n",
      "25/11/13 16:15:15 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 359) in 80 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (2/50)\n",
      "25/11/13 16:15:15 INFO BlockManager: Found block rdd_14_2 locally\n",
      "25/11/13 16:15:15 INFO Executor: Finished task 2.0 in stage 26.0 (TID 361). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:15 INFO BlockManager: Found block rdd_14_3 locally\n",
      "25/11/13 16:15:15 INFO TaskSetManager: Starting task 4.0 in stage 26.0 (TID 363) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 4, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:15 INFO Executor: Running task 4.0 in stage 26.0 (TID 363)\n",
      "25/11/13 16:15:15 INFO TaskSetManager: Finished task 2.0 in stage 26.0 (TID 361) in 65 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (3/50)\n",
      "25/11/13 16:15:15 INFO Executor: Finished task 3.0 in stage 26.0 (TID 362). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:15 INFO TaskSetManager: Starting task 5.0 in stage 26.0 (TID 364) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 5, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:15 INFO Executor: Running task 5.0 in stage 26.0 (TID 364)\n",
      "25/11/13 16:15:15 INFO TaskSetManager: Finished task 3.0 in stage 26.0 (TID 362) in 62 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (4/50)\n",
      "25/11/13 16:15:15 INFO BlockManager: Found block rdd_14_4 locally\n",
      "25/11/13 16:15:15 INFO BlockManager: Found block rdd_14_5 locally\n",
      "25/11/13 16:15:15 INFO Executor: Finished task 4.0 in stage 26.0 (TID 363). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:15 INFO TaskSetManager: Starting task 6.0 in stage 26.0 (TID 365) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 6, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:15 INFO Executor: Finished task 5.0 in stage 26.0 (TID 364). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:15 INFO Executor: Running task 6.0 in stage 26.0 (TID 365)\n",
      "25/11/13 16:15:15 INFO TaskSetManager: Starting task 7.0 in stage 26.0 (TID 366) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 7, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:15 INFO TaskSetManager: Finished task 4.0 in stage 26.0 (TID 363) in 49 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (5/50)\n",
      "25/11/13 16:15:15 INFO Executor: Running task 7.0 in stage 26.0 (TID 366)\n",
      "25/11/13 16:15:15 INFO TaskSetManager: Finished task 5.0 in stage 26.0 (TID 364) in 47 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (6/50)\n",
      "25/11/13 16:15:15 INFO BlockManager: Found block rdd_14_7 locally\n",
      "25/11/13 16:15:15 INFO BlockManager: Found block rdd_14_6 locally\n",
      "25/11/13 16:15:15 INFO Executor: Finished task 7.0 in stage 26.0 (TID 366). 4392 bytes result sent to driver\n",
      "25/11/13 16:15:15 INFO TaskSetManager: Starting task 8.0 in stage 26.0 (TID 367) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 8, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:15 INFO Executor: Finished task 6.0 in stage 26.0 (TID 365). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:15 INFO Executor: Running task 8.0 in stage 26.0 (TID 367)\n",
      "25/11/13 16:15:15 INFO TaskSetManager: Starting task 9.0 in stage 26.0 (TID 368) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 9, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:15 INFO Executor: Running task 9.0 in stage 26.0 (TID 368)\n",
      "25/11/13 16:15:15 INFO TaskSetManager: Finished task 7.0 in stage 26.0 (TID 366) in 87 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (7/50)\n",
      "25/11/13 16:15:15 INFO TaskSetManager: Finished task 6.0 in stage 26.0 (TID 365) in 96 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (8/50)\n",
      "25/11/13 16:15:15 INFO BlockManager: Found block rdd_14_8 locally\n",
      "25/11/13 16:15:15 INFO BlockManager: Found block rdd_14_9 locally\n",
      "25/11/13 16:15:15 INFO Executor: Finished task 9.0 in stage 26.0 (TID 368). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:15 INFO TaskSetManager: Starting task 10.0 in stage 26.0 (TID 369) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 10, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:15 INFO Executor: Running task 10.0 in stage 26.0 (TID 369)\n",
      "25/11/13 16:15:15 INFO Executor: Finished task 8.0 in stage 26.0 (TID 367). 4267 bytes result sent to driver\n",
      "25/11/13 16:15:15 INFO TaskSetManager: Finished task 9.0 in stage 26.0 (TID 368) in 106 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (9/50)\n",
      "25/11/13 16:15:15 INFO TaskSetManager: Starting task 11.0 in stage 26.0 (TID 370) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 11, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:15 INFO TaskSetManager: Finished task 8.0 in stage 26.0 (TID 367) in 110 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (10/50)\n",
      "25/11/13 16:15:15 INFO Executor: Running task 11.0 in stage 26.0 (TID 370)\n",
      "25/11/13 16:15:15 INFO BlockManager: Found block rdd_14_10 locally\n",
      "25/11/13 16:15:15 INFO BlockManager: Found block rdd_14_11 locally\n",
      "25/11/13 16:15:15 INFO Executor: Finished task 11.0 in stage 26.0 (TID 370). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:15 INFO Executor: Finished task 10.0 in stage 26.0 (TID 369). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:15 INFO TaskSetManager: Starting task 12.0 in stage 26.0 (TID 371) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 12, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:15 INFO Executor: Running task 12.0 in stage 26.0 (TID 371)\n",
      "25/11/13 16:15:15 INFO TaskSetManager: Starting task 13.0 in stage 26.0 (TID 372) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 13, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:15 INFO TaskSetManager: Finished task 11.0 in stage 26.0 (TID 370) in 55 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (11/50)\n",
      "25/11/13 16:15:15 INFO Executor: Running task 13.0 in stage 26.0 (TID 372)\n",
      "25/11/13 16:15:15 INFO TaskSetManager: Finished task 10.0 in stage 26.0 (TID 369) in 59 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (12/50)\n",
      "25/11/13 16:15:15 INFO BlockManager: Found block rdd_14_12 locally\n",
      "25/11/13 16:15:15 INFO Executor: Finished task 12.0 in stage 26.0 (TID 371). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:15 INFO BlockManager: Found block rdd_14_13 locally\n",
      "25/11/13 16:15:15 INFO TaskSetManager: Starting task 14.0 in stage 26.0 (TID 373) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 14, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:15 INFO Executor: Running task 14.0 in stage 26.0 (TID 373)\n",
      "25/11/13 16:15:15 INFO TaskSetManager: Finished task 12.0 in stage 26.0 (TID 371) in 39 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (13/50)\n",
      "25/11/13 16:15:15 INFO Executor: Finished task 13.0 in stage 26.0 (TID 372). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:15 INFO TaskSetManager: Starting task 15.0 in stage 26.0 (TID 374) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 15, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:15 INFO Executor: Running task 15.0 in stage 26.0 (TID 374)\n",
      "25/11/13 16:15:15 INFO TaskSetManager: Finished task 13.0 in stage 26.0 (TID 372) in 40 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (14/50)\n",
      "25/11/13 16:15:15 INFO BlockManager: Found block rdd_14_14 locally\n",
      "25/11/13 16:15:15 INFO BlockManager: Found block rdd_14_15 locally\n",
      "25/11/13 16:15:15 INFO Executor: Finished task 14.0 in stage 26.0 (TID 373). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:15 INFO Executor: Finished task 15.0 in stage 26.0 (TID 374). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:15 INFO TaskSetManager: Starting task 16.0 in stage 26.0 (TID 375) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 16, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:15 INFO TaskSetManager: Starting task 17.0 in stage 26.0 (TID 376) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 17, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:15 INFO Executor: Running task 16.0 in stage 26.0 (TID 375)\n",
      "25/11/13 16:15:15 INFO Executor: Running task 17.0 in stage 26.0 (TID 376)\n",
      "25/11/13 16:15:15 INFO TaskSetManager: Finished task 15.0 in stage 26.0 (TID 374) in 55 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (15/50)\n",
      "25/11/13 16:15:15 INFO TaskSetManager: Finished task 14.0 in stage 26.0 (TID 373) in 59 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (16/50)\n",
      "25/11/13 16:15:15 INFO BlockManager: Found block rdd_14_16 locally(16 + 2) / 50]\n",
      "25/11/13 16:15:15 INFO Executor: Finished task 16.0 in stage 26.0 (TID 375). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:15 INFO BlockManager: Found block rdd_14_17 locally\n",
      "25/11/13 16:15:15 INFO TaskSetManager: Starting task 18.0 in stage 26.0 (TID 377) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 18, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:15 INFO Executor: Running task 18.0 in stage 26.0 (TID 377)\n",
      "25/11/13 16:15:15 INFO Executor: Finished task 17.0 in stage 26.0 (TID 376). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:15 INFO TaskSetManager: Starting task 19.0 in stage 26.0 (TID 378) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 19, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:15 INFO Executor: Running task 19.0 in stage 26.0 (TID 378)\n",
      "25/11/13 16:15:15 INFO TaskSetManager: Finished task 16.0 in stage 26.0 (TID 375) in 77 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (17/50)\n",
      "25/11/13 16:15:15 INFO TaskSetManager: Finished task 17.0 in stage 26.0 (TID 376) in 78 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (18/50)\n",
      "25/11/13 16:15:15 INFO BlockManager: Found block rdd_14_18 locally\n",
      "25/11/13 16:15:15 INFO BlockManager: Found block rdd_14_19 locally\n",
      "25/11/13 16:15:15 INFO Executor: Finished task 18.0 in stage 26.0 (TID 377). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:15 INFO Executor: Finished task 19.0 in stage 26.0 (TID 378). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:15 INFO TaskSetManager: Starting task 20.0 in stage 26.0 (TID 379) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 20, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:15 INFO Executor: Running task 20.0 in stage 26.0 (TID 379)\n",
      "25/11/13 16:15:15 INFO TaskSetManager: Starting task 21.0 in stage 26.0 (TID 380) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 21, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:15 INFO Executor: Running task 21.0 in stage 26.0 (TID 380)\n",
      "25/11/13 16:15:15 INFO TaskSetManager: Finished task 18.0 in stage 26.0 (TID 377) in 98 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (19/50)\n",
      "25/11/13 16:15:15 INFO TaskSetManager: Finished task 19.0 in stage 26.0 (TID 378) in 99 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (20/50)\n",
      "25/11/13 16:15:15 INFO BlockManager: Found block rdd_14_21 locally\n",
      "25/11/13 16:15:15 INFO Executor: Finished task 21.0 in stage 26.0 (TID 380). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:15 INFO TaskSetManager: Starting task 22.0 in stage 26.0 (TID 381) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 22, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:15 INFO Executor: Running task 22.0 in stage 26.0 (TID 381)\n",
      "25/11/13 16:15:15 INFO BlockManager: Found block rdd_14_20 locally\n",
      "25/11/13 16:15:16 INFO TaskSetManager: Finished task 21.0 in stage 26.0 (TID 380) in 79 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (21/50)\n",
      "25/11/13 16:15:16 INFO Executor: Finished task 20.0 in stage 26.0 (TID 379). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:16 INFO TaskSetManager: Starting task 23.0 in stage 26.0 (TID 382) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 23, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:16 INFO Executor: Running task 23.0 in stage 26.0 (TID 382)\n",
      "25/11/13 16:15:16 INFO TaskSetManager: Finished task 20.0 in stage 26.0 (TID 379) in 87 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (22/50)\n",
      "25/11/13 16:15:16 INFO BlockManager: Found block rdd_14_23 locally(22 + 2) / 50]\n",
      "25/11/13 16:15:16 INFO BlockManager: Found block rdd_14_22 locally\n",
      "25/11/13 16:15:16 INFO Executor: Finished task 23.0 in stage 26.0 (TID 382). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:16 INFO TaskSetManager: Starting task 24.0 in stage 26.0 (TID 383) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 24, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:16 INFO Executor: Running task 24.0 in stage 26.0 (TID 383)\n",
      "25/11/13 16:15:16 INFO TaskSetManager: Finished task 23.0 in stage 26.0 (TID 382) in 93 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (23/50)\n",
      "25/11/13 16:15:16 INFO Executor: Finished task 22.0 in stage 26.0 (TID 381). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:16 INFO TaskSetManager: Starting task 25.0 in stage 26.0 (TID 384) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 25, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:16 INFO Executor: Running task 25.0 in stage 26.0 (TID 384)\n",
      "25/11/13 16:15:16 INFO TaskSetManager: Finished task 22.0 in stage 26.0 (TID 381) in 154 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (24/50)\n",
      "25/11/13 16:15:16 INFO BlockManager: Found block rdd_14_24 locally\n",
      "25/11/13 16:15:16 INFO BlockManager: Found block rdd_14_25 locally\n",
      "25/11/13 16:15:16 INFO Executor: Finished task 24.0 in stage 26.0 (TID 383). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:16 INFO TaskSetManager: Starting task 26.0 in stage 26.0 (TID 385) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 26, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:16 INFO TaskSetManager: Finished task 24.0 in stage 26.0 (TID 383) in 98 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (25/50)\n",
      "25/11/13 16:15:16 INFO Executor: Running task 26.0 in stage 26.0 (TID 385)\n",
      "25/11/13 16:15:16 INFO Executor: Finished task 25.0 in stage 26.0 (TID 384). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:16 INFO TaskSetManager: Starting task 27.0 in stage 26.0 (TID 386) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 27, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:16 INFO Executor: Running task 27.0 in stage 26.0 (TID 386)\n",
      "25/11/13 16:15:16 INFO TaskSetManager: Finished task 25.0 in stage 26.0 (TID 384) in 100 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (26/50)\n",
      "25/11/13 16:15:16 INFO BlockManager: Found block rdd_14_27 locally(26 + 2) / 50]\n",
      "25/11/13 16:15:16 INFO BlockManager: Found block rdd_14_26 locally\n",
      "25/11/13 16:15:16 INFO Executor: Finished task 27.0 in stage 26.0 (TID 386). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:16 INFO TaskSetManager: Starting task 28.0 in stage 26.0 (TID 387) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 28, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:16 INFO Executor: Running task 28.0 in stage 26.0 (TID 387)\n",
      "25/11/13 16:15:16 INFO Executor: Finished task 26.0 in stage 26.0 (TID 385). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:16 INFO TaskSetManager: Finished task 27.0 in stage 26.0 (TID 386) in 51 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (27/50)\n",
      "25/11/13 16:15:16 INFO TaskSetManager: Starting task 29.0 in stage 26.0 (TID 388) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 29, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:16 INFO Executor: Running task 29.0 in stage 26.0 (TID 388)\n",
      "25/11/13 16:15:16 INFO TaskSetManager: Finished task 26.0 in stage 26.0 (TID 385) in 104 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (28/50)\n",
      "25/11/13 16:15:16 INFO BlockManager: Found block rdd_14_29 locally\n",
      "25/11/13 16:15:16 INFO BlockManager: Found block rdd_14_28 locally\n",
      "25/11/13 16:15:16 INFO Executor: Finished task 28.0 in stage 26.0 (TID 387). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:16 INFO TaskSetManager: Starting task 30.0 in stage 26.0 (TID 389) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 30, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:16 INFO Executor: Finished task 29.0 in stage 26.0 (TID 388). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:16 INFO Executor: Running task 30.0 in stage 26.0 (TID 389)\n",
      "25/11/13 16:15:16 INFO TaskSetManager: Starting task 31.0 in stage 26.0 (TID 390) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 31, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:16 INFO TaskSetManager: Finished task 28.0 in stage 26.0 (TID 387) in 86 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (29/50)\n",
      "25/11/13 16:15:16 INFO Executor: Running task 31.0 in stage 26.0 (TID 390)\n",
      "25/11/13 16:15:16 INFO TaskSetManager: Finished task 29.0 in stage 26.0 (TID 388) in 83 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (30/50)\n",
      "25/11/13 16:15:16 INFO BlockManager: Found block rdd_14_30 locally\n",
      "25/11/13 16:15:16 INFO BlockManager: Found block rdd_14_31 locally\n",
      "25/11/13 16:15:16 INFO Executor: Finished task 30.0 in stage 26.0 (TID 389). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:16 INFO TaskSetManager: Starting task 32.0 in stage 26.0 (TID 391) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 32, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:16 INFO Executor: Running task 32.0 in stage 26.0 (TID 391)\n",
      "25/11/13 16:15:16 INFO Executor: Finished task 31.0 in stage 26.0 (TID 390). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:16 INFO TaskSetManager: Finished task 30.0 in stage 26.0 (TID 389) in 70 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (31/50)\n",
      "25/11/13 16:15:16 INFO TaskSetManager: Starting task 33.0 in stage 26.0 (TID 392) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 33, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:16 INFO Executor: Running task 33.0 in stage 26.0 (TID 392)\n",
      "25/11/13 16:15:16 INFO TaskSetManager: Finished task 31.0 in stage 26.0 (TID 390) in 71 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (32/50)\n",
      "25/11/13 16:15:16 INFO BlockManager: Found block rdd_14_32 locally(32 + 2) / 50]\n",
      "25/11/13 16:15:16 INFO BlockManager: Found block rdd_14_33 locally\n",
      "25/11/13 16:15:16 INFO Executor: Finished task 32.0 in stage 26.0 (TID 391). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:16 INFO Executor: Finished task 33.0 in stage 26.0 (TID 392). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:16 INFO TaskSetManager: Starting task 34.0 in stage 26.0 (TID 393) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 34, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:16 INFO Executor: Running task 34.0 in stage 26.0 (TID 393)\n",
      "25/11/13 16:15:16 INFO TaskSetManager: Starting task 35.0 in stage 26.0 (TID 394) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 35, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:16 INFO TaskSetManager: Finished task 33.0 in stage 26.0 (TID 392) in 105 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (33/50)\n",
      "25/11/13 16:15:16 INFO TaskSetManager: Finished task 32.0 in stage 26.0 (TID 391) in 107 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (34/50)\n",
      "25/11/13 16:15:16 INFO Executor: Running task 35.0 in stage 26.0 (TID 394)\n",
      "25/11/13 16:15:16 INFO BlockManager: Found block rdd_14_35 locally\n",
      "25/11/13 16:15:16 INFO Executor: Finished task 35.0 in stage 26.0 (TID 394). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:16 INFO BlockManager: Found block rdd_14_34 locally\n",
      "25/11/13 16:15:16 INFO Executor: Finished task 34.0 in stage 26.0 (TID 393). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:16 INFO TaskSetManager: Starting task 36.0 in stage 26.0 (TID 395) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 36, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:16 INFO Executor: Running task 36.0 in stage 26.0 (TID 395)\n",
      "25/11/13 16:15:16 INFO TaskSetManager: Starting task 37.0 in stage 26.0 (TID 396) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 37, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:16 INFO Executor: Running task 37.0 in stage 26.0 (TID 396)\n",
      "25/11/13 16:15:16 INFO TaskSetManager: Finished task 34.0 in stage 26.0 (TID 393) in 90 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (35/50)\n",
      "25/11/13 16:15:16 INFO TaskSetManager: Finished task 35.0 in stage 26.0 (TID 394) in 88 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (36/50)\n",
      "25/11/13 16:15:16 INFO BlockManager: Found block rdd_14_36 locally\n",
      "25/11/13 16:15:16 INFO BlockManager: Found block rdd_14_37 locally\n",
      "25/11/13 16:15:16 INFO Executor: Finished task 36.0 in stage 26.0 (TID 395). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:16 INFO Executor: Finished task 37.0 in stage 26.0 (TID 396). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:16 INFO TaskSetManager: Starting task 38.0 in stage 26.0 (TID 397) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 38, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:16 INFO Executor: Running task 38.0 in stage 26.0 (TID 397)\n",
      "25/11/13 16:15:16 INFO TaskSetManager: Starting task 39.0 in stage 26.0 (TID 398) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 39, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:16 INFO Executor: Running task 39.0 in stage 26.0 (TID 398)\n",
      "25/11/13 16:15:16 INFO TaskSetManager: Finished task 37.0 in stage 26.0 (TID 396) in 94 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (37/50)\n",
      "25/11/13 16:15:16 INFO TaskSetManager: Finished task 36.0 in stage 26.0 (TID 395) in 97 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (38/50)\n",
      "25/11/13 16:15:17 INFO BlockManager: Found block rdd_14_39 locally(38 + 2) / 50]\n",
      "25/11/13 16:15:17 INFO BlockManager: Found block rdd_14_38 locally\n",
      "25/11/13 16:15:17 INFO Executor: Finished task 39.0 in stage 26.0 (TID 398). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:17 INFO Executor: Finished task 38.0 in stage 26.0 (TID 397). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:17 INFO TaskSetManager: Starting task 40.0 in stage 26.0 (TID 399) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 40, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:17 INFO Executor: Running task 40.0 in stage 26.0 (TID 399)\n",
      "25/11/13 16:15:17 INFO TaskSetManager: Starting task 41.0 in stage 26.0 (TID 400) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 41, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:17 INFO Executor: Running task 41.0 in stage 26.0 (TID 400)\n",
      "25/11/13 16:15:17 INFO TaskSetManager: Finished task 39.0 in stage 26.0 (TID 398) in 362 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (39/50)\n",
      "25/11/13 16:15:17 INFO TaskSetManager: Finished task 38.0 in stage 26.0 (TID 397) in 383 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (40/50)\n",
      "25/11/13 16:15:17 INFO BlockManager: Found block rdd_14_41 locally\n",
      "25/11/13 16:15:17 INFO Executor: Finished task 41.0 in stage 26.0 (TID 400). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:17 INFO BlockManager: Found block rdd_14_40 locally\n",
      "25/11/13 16:15:17 INFO TaskSetManager: Starting task 42.0 in stage 26.0 (TID 401) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 42, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:17 INFO Executor: Finished task 40.0 in stage 26.0 (TID 399). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:17 INFO Executor: Running task 42.0 in stage 26.0 (TID 401)\n",
      "25/11/13 16:15:17 INFO TaskSetManager: Starting task 43.0 in stage 26.0 (TID 402) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 43, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:17 INFO TaskSetManager: Finished task 41.0 in stage 26.0 (TID 400) in 39 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (41/50)\n",
      "25/11/13 16:15:17 INFO Executor: Running task 43.0 in stage 26.0 (TID 402)\n",
      "25/11/13 16:15:17 INFO TaskSetManager: Finished task 40.0 in stage 26.0 (TID 399) in 44 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (42/50)\n",
      "25/11/13 16:15:17 INFO BlockManager: Found block rdd_14_42 locally\n",
      "25/11/13 16:15:17 INFO BlockManager: Found block rdd_14_43 locally\n",
      "25/11/13 16:15:17 INFO Executor: Finished task 42.0 in stage 26.0 (TID 401). 4267 bytes result sent to driver\n",
      "25/11/13 16:15:17 INFO Executor: Finished task 43.0 in stage 26.0 (TID 402). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:17 INFO TaskSetManager: Starting task 44.0 in stage 26.0 (TID 403) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 44, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:17 INFO Executor: Running task 44.0 in stage 26.0 (TID 403)\n",
      "25/11/13 16:15:17 INFO TaskSetManager: Starting task 45.0 in stage 26.0 (TID 404) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 45, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:17 INFO Executor: Running task 45.0 in stage 26.0 (TID 404)\n",
      "25/11/13 16:15:17 INFO TaskSetManager: Finished task 43.0 in stage 26.0 (TID 402) in 85 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (43/50)\n",
      "25/11/13 16:15:17 INFO TaskSetManager: Finished task 42.0 in stage 26.0 (TID 401) in 87 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (44/50)\n",
      "25/11/13 16:15:17 INFO BlockManager: Found block rdd_14_44 locally\n",
      "25/11/13 16:15:17 INFO Executor: Finished task 44.0 in stage 26.0 (TID 403). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:17 INFO TaskSetManager: Starting task 46.0 in stage 26.0 (TID 405) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 46, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:17 INFO Executor: Running task 46.0 in stage 26.0 (TID 405)\n",
      "25/11/13 16:15:17 INFO TaskSetManager: Finished task 44.0 in stage 26.0 (TID 403) in 40 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (45/50)\n",
      "25/11/13 16:15:17 INFO BlockManager: Found block rdd_14_45 locally\n",
      "25/11/13 16:15:17 INFO Executor: Finished task 45.0 in stage 26.0 (TID 404). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:17 INFO TaskSetManager: Starting task 47.0 in stage 26.0 (TID 406) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 47, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:17 INFO Executor: Running task 47.0 in stage 26.0 (TID 406)\n",
      "25/11/13 16:15:17 INFO BlockManager: Found block rdd_14_46 locally\n",
      "25/11/13 16:15:17 INFO TaskSetManager: Finished task 45.0 in stage 26.0 (TID 404) in 69 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (46/50)\n",
      "25/11/13 16:15:17 INFO Executor: Finished task 46.0 in stage 26.0 (TID 405). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:17 INFO TaskSetManager: Starting task 48.0 in stage 26.0 (TID 407) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 48, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:17 INFO Executor: Running task 48.0 in stage 26.0 (TID 407)\n",
      "25/11/13 16:15:17 INFO TaskSetManager: Finished task 46.0 in stage 26.0 (TID 405) in 62 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (47/50)\n",
      "25/11/13 16:15:17 INFO BlockManager: Found block rdd_14_47 locally\n",
      "25/11/13 16:15:17 INFO Executor: Finished task 47.0 in stage 26.0 (TID 406). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:17 INFO TaskSetManager: Starting task 49.0 in stage 26.0 (TID 408) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 49, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:17 INFO Executor: Running task 49.0 in stage 26.0 (TID 408)\n",
      "25/11/13 16:15:17 INFO TaskSetManager: Finished task 47.0 in stage 26.0 (TID 406) in 52 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (48/50)\n",
      "25/11/13 16:15:17 INFO BlockManager: Found block rdd_14_48 locally\n",
      "25/11/13 16:15:17 INFO Executor: Finished task 48.0 in stage 26.0 (TID 407). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:17 INFO TaskSetManager: Finished task 48.0 in stage 26.0 (TID 407) in 54 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (49/50)\n",
      "25/11/13 16:15:17 INFO BlockManager: Found block rdd_14_49 locally\n",
      "25/11/13 16:15:17 INFO Executor: Finished task 49.0 in stage 26.0 (TID 408). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:17 INFO TaskSetManager: Finished task 49.0 in stage 26.0 (TID 408) in 54 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (50/50)\n",
      "25/11/13 16:15:17 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool \n",
      "25/11/13 16:15:17 INFO DAGScheduler: ResultStage 26 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 2.069 s\n",
      "25/11/13 16:15:17 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/11/13 16:15:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 26: Stage finished\n",
      "25/11/13 16:15:17 INFO DAGScheduler: Job 16 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 2.082189 s\n",
      "25/11/13 16:15:17 INFO PrepareDeltaScan: DELTA: Done                            \n",
      "25/11/13 16:15:17 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/11/13 16:15:17 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/11/13 16:15:17 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/11/13 16:15:17 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/11/13 16:15:17 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/11/13 16:15:17 INFO CodeGenerator: Code generated in 33.707654 ms\n",
      "25/11/13 16:15:17 INFO CodeGenerator: Code generated in 7.430999 ms\n",
      "25/11/13 16:15:17 INFO CodeGenerator: Code generated in 14.784831 ms\n",
      "25/11/13 16:15:17 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 206.9 KiB, free 1047.3 MiB)\n",
      "25/11/13 16:15:17 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 1047.3 MiB)\n",
      "25/11/13 16:15:17 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 36.8 KiB, free: 1048.5 MiB)\n",
      "25/11/13 16:15:17 INFO SparkContext: Created broadcast 26 from showString at NativeMethodAccessorImpl.java:0\n",
      "25/11/13 16:15:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 10926151 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/11/13 16:15:17 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "25/11/13 16:15:17 INFO DAGScheduler: Registering RDD 67 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 2\n",
      "25/11/13 16:15:17 INFO DAGScheduler: Got job 17 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/11/13 16:15:17 INFO DAGScheduler: Final stage: ResultStage 28 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/11/13 16:15:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 27)\n",
      "25/11/13 16:15:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 27)\n",
      "25/11/13 16:15:17 INFO DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[67] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/11/13 16:15:17 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 52.6 KiB, free 1047.2 MiB)\n",
      "25/11/13 16:15:17 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 20.4 KiB, free 1047.2 MiB)\n",
      "25/11/13 16:15:17 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 20.4 KiB, free: 1048.5 MiB)\n",
      "25/11/13 16:15:17 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 16:15:17 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[67] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))\n",
      "25/11/13 16:15:17 INFO TaskSchedulerImpl: Adding task set 27.0 with 2 tasks resource profile 0\n",
      "25/11/13 16:15:17 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 409) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 9668 bytes) \n",
      "25/11/13 16:15:17 INFO TaskSetManager: Starting task 1.0 in stage 27.0 (TID 410) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 1, PROCESS_LOCAL, 9668 bytes) \n",
      "25/11/13 16:15:17 INFO Executor: Running task 0.0 in stage 27.0 (TID 409)\n",
      "25/11/13 16:15:17 INFO Executor: Running task 1.0 in stage 27.0 (TID 410)\n",
      "25/11/13 16:15:17 INFO CodeGenerator: Code generated in 7.230482 ms\n",
      "25/11/13 16:15:17 INFO CodeGenerator: Code generated in 19.952683 ms\n",
      "25/11/13 16:15:17 INFO FileScanRDD: Reading File path: s3a://nau-local-analytics-bronze/auth_userprofile/part-00000-130fc9e9-8dc1-4d6a-b4e7-714542eff639-c000.snappy.parquet, range: 10926151-17657998, partition values: [empty row]\n",
      "25/11/13 16:15:17 INFO FileScanRDD: Reading File path: s3a://nau-local-analytics-bronze/auth_userprofile/part-00000-130fc9e9-8dc1-4d6a-b4e7-714542eff639-c000.snappy.parquet, range: 0-10926151, partition values: [empty row]\n",
      "25/11/13 16:15:17 INFO S3AInputStream: Switching to Random IO seek policy\n",
      "25/11/13 16:15:17 INFO S3AInputStream: Switching to Random IO seek policy\n",
      "25/11/13 16:15:17 INFO Executor: Finished task 1.0 in stage 27.0 (TID 410). 3444 bytes result sent to driver\n",
      "25/11/13 16:15:17 INFO TaskSetManager: Finished task 1.0 in stage 27.0 (TID 410) in 253 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/2)\n",
      "25/11/13 16:15:19 INFO Executor: Finished task 0.0 in stage 27.0 (TID 409). 3616 bytes result sent to driver\n",
      "25/11/13 16:15:19 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 409) in 2264 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (2/2)\n",
      "25/11/13 16:15:19 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool \n",
      "25/11/13 16:15:19 INFO DAGScheduler: ShuffleMapStage 27 (showString at NativeMethodAccessorImpl.java:0) finished in 2.281 s\n",
      "25/11/13 16:15:19 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/11/13 16:15:19 INFO DAGScheduler: running: Set()\n",
      "25/11/13 16:15:19 INFO DAGScheduler: waiting: Set(ResultStage 28)\n",
      "25/11/13 16:15:19 INFO DAGScheduler: failed: Set()\n",
      "25/11/13 16:15:19 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[72] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/11/13 16:15:19 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 50.4 KiB, free 1047.2 MiB)\n",
      "25/11/13 16:15:19 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 21.0 KiB, free 1047.1 MiB)\n",
      "25/11/13 16:15:19 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 21.0 KiB, free: 1048.5 MiB)\n",
      "25/11/13 16:15:19 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 16:15:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[72] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/11/13 16:15:19 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks resource profile 0\n",
      "25/11/13 16:15:19 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 411) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, NODE_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:19 INFO Executor: Running task 0.0 in stage 28.0 (TID 411)\n",
      "25/11/13 16:15:20 INFO ShuffleBlockFetcherIterator: Getting 1 (539.0 B) non-empty blocks including 1 (539.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:15:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/11/13 16:15:20 INFO CodeGenerator: Code generated in 19.114195 ms\n",
      "25/11/13 16:15:20 INFO CodeGenerator: Code generated in 8.891422 ms\n",
      "25/11/13 16:15:20 INFO CodeGenerator: Code generated in 6.123227 ms\n",
      "25/11/13 16:15:20 INFO CodeGenerator: Code generated in 6.011673 ms\n",
      "25/11/13 16:15:20 INFO CodeGenerator: Code generated in 15.986681 ms\n",
      "25/11/13 16:15:20 INFO Executor: Finished task 0.0 in stage 28.0 (TID 411). 5039 bytes result sent to driver\n",
      "25/11/13 16:15:20 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 411) in 142 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/1)\n",
      "25/11/13 16:15:20 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool \n",
      "25/11/13 16:15:20 INFO DAGScheduler: ResultStage 28 (showString at NativeMethodAccessorImpl.java:0) finished in 0.153 s\n",
      "25/11/13 16:15:20 INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/11/13 16:15:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 28: Stage finished\n",
      "25/11/13 16:15:20 INFO DAGScheduler: Job 17 finished: showString at NativeMethodAccessorImpl.java:0, took 2.470332 s\n",
      "25/11/13 16:15:20 INFO CodeGenerator: Code generated in 13.164562 ms            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-------+-------------+--------+------+-------+----+--------+------------------+--------+----------+------------+-----+--------------------------+----------------+\n",
      "|profile_sk|profile_id|user_id|year_of_birth|age_band|gender|country|city|location|level_of_education|language|courseware|phone_number|state|ingestion_date            |source_name     |\n",
      "+----------+----------+-------+-------------+--------+------+-------+----+--------+------------------+--------+----------+------------+-----+--------------------------+----------------+\n",
      "|1         |1         |1      |NULL         |NULL    |NULL  |NULL   |NULL|        |NULL              |        |course.xml|NULL        |NULL |2025-11-04 18:27:24.809743|auth_userprofile|\n",
      "|2         |2         |2      |NULL         |NULL    |NULL  |NULL   |NULL|        |NULL              |        |course.xml|NULL        |NULL |2025-11-04 18:27:24.809743|auth_userprofile|\n",
      "|3         |3         |3      |NULL         |NULL    |NULL  |NULL   |NULL|        |NULL              |        |course.xml|NULL        |NULL |2025-11-04 18:27:24.809743|auth_userprofile|\n",
      "|4         |4         |4      |NULL         |NULL    |NULL  |NULL   |NULL|        |NULL              |        |course.xml|NULL        |NULL |2025-11-04 18:27:24.809743|auth_userprofile|\n",
      "|5         |5         |6      |NULL         |NULL    |NULL  |NULL   |NULL|        |NULL              |        |course.xml|NULL        |NULL |2025-11-04 18:27:24.809743|auth_userprofile|\n",
      "|6         |6         |7      |1976         |30_54   |m     |NULL   |NULL|        |NULL              |        |course.xml|NULL        |NULL |2025-11-04 18:27:24.809743|auth_userprofile|\n",
      "|7         |7         |8      |2017         |UNDER_18|o     |PT     |    |        |other             |        |course.xml|NULL        |NULL |2025-11-04 18:27:24.809743|auth_userprofile|\n",
      "|8         |8         |10     |NULL         |NULL    |NULL  |PT     |    |        |NULL              |        |course.xml|NULL        |NULL |2025-11-04 18:27:24.809743|auth_userprofile|\n",
      "|9         |9         |11     |NULL         |NULL    |NULL  |PT     |    |        |NULL              |        |course.xml|NULL        |NULL |2025-11-04 18:27:24.809743|auth_userprofile|\n",
      "|10        |10        |12     |NULL         |NULL    |NULL  |PT     |    |        |NULL              |        |course.xml|NULL        |NULL |2025-11-04 18:27:24.809743|auth_userprofile|\n",
      "+----------+----------+-------+-------------+--------+------+-------+----+--------+------------------+--------+----------+------------+-----+--------------------------+----------------+\n",
      "only showing top 10 rows\n",
      "\n",
      ">> [dim_user_profile] Writing initial Silver Delta table (overwrite).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/13 16:15:20 INFO DeltaLog: Creating initial snapshot without metadata, because the directory is empty\n",
      "25/11/13 16:15:20 INFO InitialSnapshot: [tableId=8331b31f-065d-44ac-ab7f-d88f606cf74a] Created snapshot InitialSnapshot(path=s3a://nau-local-analytics-silver/dim_user_profile/_delta_log, version=-1, metadata=Metadata(8b0029bd-d62f-406f-9cab-5818b29ae118,null,null,Format(parquet,Map()),null,List(),Map(),Some(1763050520311)), logSegment=LogSegment(s3a://nau-local-analytics-silver/dim_user_profile/_delta_log,-1,List(),org.apache.spark.sql.delta.EmptyCheckpointProvider$@2b65c581,-1), checksumOpt=None)\n",
      "25/11/13 16:15:20 INFO BlockManagerInfo: Removed broadcast_27_piece0 on jupyter-spark-758b7c86d8-7j77n:32921 in memory (size: 20.4 KiB, free: 1048.5 MiB)\n",
      "25/11/13 16:15:20 INFO BlockManagerInfo: Removed broadcast_28_piece0 on jupyter-spark-758b7c86d8-7j77n:32921 in memory (size: 21.0 KiB, free: 1048.5 MiB)\n",
      "25/11/13 16:15:20 INFO OptimisticTransaction: [tableId=8b0029bd,txnId=e34d9523] Updated metadata from - to Metadata(cecff036-318c-4ebc-be9d-1081081bfefa,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"profile_sk\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"profile_id\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"user_id\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"year_of_birth\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{\"isSigned\":true,\"scale\":0}},{\"name\":\"age_band\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"gender\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(6)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"country\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(2)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"city\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"isSigned\":false,\"scale\":0}},{\"name\":\"location\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(255)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"level_of_education\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(6)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"language\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(255)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"courseware\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(255)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"phone_number\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(50)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"state\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(2)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"ingestion_date\",\"type\":\"timestamp\",\"nullable\":true,\"metadata\":{}},{\"name\":\"source_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1763050520365))\n",
      "25/11/13 16:15:21 INFO PrepareDeltaScan: DELTA: Filtering files for query\n",
      "25/11/13 16:15:21 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128\n",
      "25/11/13 16:15:21 INFO DAGScheduler: Got job 18 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions\n",
      "25/11/13 16:15:21 INFO DAGScheduler: Final stage: ResultStage 30 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)\n",
      "25/11/13 16:15:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 29)\n",
      "25/11/13 16:15:21 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 16:15:21 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[74] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents\n",
      "25/11/13 16:15:21 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 684.9 KiB, free 1046.6 MiB)\n",
      "25/11/13 16:15:21 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 154.5 KiB, free 1046.5 MiB)\n",
      "25/11/13 16:15:21 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 154.5 KiB, free: 1048.4 MiB)\n",
      "25/11/13 16:15:21 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 16:15:21 INFO DAGScheduler: Submitting 50 missing tasks from ResultStage 30 (MapPartitionsRDD[74] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n",
      "25/11/13 16:15:21 INFO TaskSchedulerImpl: Adding task set 30.0 with 50 tasks resource profile 0\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 412) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:21 INFO TaskSetManager: Starting task 1.0 in stage 30.0 (TID 413) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 1, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:21 INFO Executor: Running task 0.0 in stage 30.0 (TID 412)\n",
      "25/11/13 16:15:21 INFO Executor: Running task 1.0 in stage 30.0 (TID 413)\n",
      "25/11/13 16:15:21 INFO BlockManager: Found block rdd_14_1 locally\n",
      "25/11/13 16:15:21 INFO BlockManager: Found block rdd_14_0 locally\n",
      "25/11/13 16:15:21 INFO Executor: Finished task 0.0 in stage 30.0 (TID 412). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:21 INFO Executor: Finished task 1.0 in stage 30.0 (TID 413). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Starting task 2.0 in stage 30.0 (TID 414) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 2, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:21 INFO Executor: Running task 2.0 in stage 30.0 (TID 414)\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Starting task 3.0 in stage 30.0 (TID 415) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 3, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:21 INFO Executor: Running task 3.0 in stage 30.0 (TID 415)\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Finished task 1.0 in stage 30.0 (TID 413) in 32 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/50)\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 412) in 33 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (2/50)\n",
      "25/11/13 16:15:21 INFO BlockManager: Found block rdd_14_3 locally\n",
      "25/11/13 16:15:21 INFO BlockManager: Found block rdd_14_2 locally\n",
      "25/11/13 16:15:21 INFO Executor: Finished task 3.0 in stage 30.0 (TID 415). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Starting task 4.0 in stage 30.0 (TID 416) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 4, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:21 INFO Executor: Running task 4.0 in stage 30.0 (TID 416)\n",
      "25/11/13 16:15:21 INFO Executor: Finished task 2.0 in stage 30.0 (TID 414). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Finished task 3.0 in stage 30.0 (TID 415) in 32 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (3/50)\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Starting task 5.0 in stage 30.0 (TID 417) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 5, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:21 INFO Executor: Running task 5.0 in stage 30.0 (TID 417)\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Finished task 2.0 in stage 30.0 (TID 414) in 35 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (4/50)\n",
      "25/11/13 16:15:21 INFO BlockManager: Found block rdd_14_4 locally\n",
      "25/11/13 16:15:21 INFO Executor: Finished task 4.0 in stage 30.0 (TID 416). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:21 INFO BlockManager: Found block rdd_14_5 locally\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Starting task 6.0 in stage 30.0 (TID 418) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 6, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:21 INFO Executor: Running task 6.0 in stage 30.0 (TID 418)\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Finished task 4.0 in stage 30.0 (TID 416) in 24 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (5/50)\n",
      "25/11/13 16:15:21 INFO Executor: Finished task 5.0 in stage 30.0 (TID 417). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Starting task 7.0 in stage 30.0 (TID 419) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 7, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:21 INFO Executor: Running task 7.0 in stage 30.0 (TID 419)\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Finished task 5.0 in stage 30.0 (TID 417) in 52 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (6/50)\n",
      "25/11/13 16:15:21 INFO BlockManager: Found block rdd_14_6 locally\n",
      "25/11/13 16:15:21 INFO Executor: Finished task 6.0 in stage 30.0 (TID 418). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Starting task 8.0 in stage 30.0 (TID 420) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 8, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:21 INFO Executor: Running task 8.0 in stage 30.0 (TID 420)\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Finished task 6.0 in stage 30.0 (TID 418) in 40 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (7/50)\n",
      "25/11/13 16:15:21 INFO BlockManager: Found block rdd_14_7 locally\n",
      "25/11/13 16:15:21 INFO BlockManager: Found block rdd_14_8 locally\n",
      "25/11/13 16:15:21 INFO Executor: Finished task 8.0 in stage 30.0 (TID 420). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:21 INFO Executor: Finished task 7.0 in stage 30.0 (TID 419). 4392 bytes result sent to driver\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Starting task 9.0 in stage 30.0 (TID 421) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 9, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:21 INFO Executor: Running task 9.0 in stage 30.0 (TID 421)\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Starting task 10.0 in stage 30.0 (TID 422) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 10, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:21 INFO Executor: Running task 10.0 in stage 30.0 (TID 422)\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Finished task 8.0 in stage 30.0 (TID 420) in 59 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (8/50)\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Finished task 7.0 in stage 30.0 (TID 419) in 96 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (9/50)\n",
      "25/11/13 16:15:21 INFO BlockManager: Found block rdd_14_10 locally\n",
      "25/11/13 16:15:21 INFO Executor: Finished task 10.0 in stage 30.0 (TID 422). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Starting task 11.0 in stage 30.0 (TID 423) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 11, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:21 INFO Executor: Running task 11.0 in stage 30.0 (TID 423)\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Finished task 10.0 in stage 30.0 (TID 422) in 40 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (10/50)\n",
      "25/11/13 16:15:21 INFO BlockManager: Found block rdd_14_9 locally\n",
      "25/11/13 16:15:21 INFO Executor: Finished task 9.0 in stage 30.0 (TID 421). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Starting task 12.0 in stage 30.0 (TID 424) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 12, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:21 INFO Executor: Running task 12.0 in stage 30.0 (TID 424)\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Finished task 9.0 in stage 30.0 (TID 421) in 50 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (11/50)\n",
      "25/11/13 16:15:21 INFO BlockManager: Found block rdd_14_11 locally\n",
      "25/11/13 16:15:21 INFO Executor: Finished task 11.0 in stage 30.0 (TID 423). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Starting task 13.0 in stage 30.0 (TID 425) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 13, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:21 INFO Executor: Running task 13.0 in stage 30.0 (TID 425)\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Finished task 11.0 in stage 30.0 (TID 423) in 46 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (12/50)\n",
      "25/11/13 16:15:21 INFO BlockManager: Found block rdd_14_12 locally\n",
      "25/11/13 16:15:21 INFO Executor: Finished task 12.0 in stage 30.0 (TID 424). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Starting task 14.0 in stage 30.0 (TID 426) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 14, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:21 INFO TaskSetManager: Finished task 12.0 in stage 30.0 (TID 424) in 44 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (13/50)\n",
      "25/11/13 16:15:21 INFO Executor: Running task 14.0 in stage 30.0 (TID 426)\n",
      "25/11/13 16:15:21 INFO BlockManager: Found block rdd_14_13 locally\n",
      "25/11/13 16:15:21 INFO Executor: Finished task 13.0 in stage 30.0 (TID 425). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Starting task 15.0 in stage 30.0 (TID 427) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 15, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:21 INFO Executor: Running task 15.0 in stage 30.0 (TID 427)\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Finished task 13.0 in stage 30.0 (TID 425) in 53 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (14/50)\n",
      "25/11/13 16:15:21 INFO BlockManager: Found block rdd_14_14 locally\n",
      "25/11/13 16:15:21 INFO Executor: Finished task 14.0 in stage 30.0 (TID 426). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Starting task 16.0 in stage 30.0 (TID 428) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 16, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:21 INFO TaskSetManager: Finished task 14.0 in stage 30.0 (TID 426) in 58 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (15/50)\n",
      "25/11/13 16:15:21 INFO Executor: Running task 16.0 in stage 30.0 (TID 428)\n",
      "25/11/13 16:15:21 INFO BlockManager: Found block rdd_14_15 locally\n",
      "25/11/13 16:15:21 INFO Executor: Finished task 15.0 in stage 30.0 (TID 427). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Starting task 17.0 in stage 30.0 (TID 429) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 17, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:21 INFO Executor: Running task 17.0 in stage 30.0 (TID 429)\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Finished task 15.0 in stage 30.0 (TID 427) in 45 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (16/50)\n",
      "25/11/13 16:15:21 INFO BlockManager: Found block rdd_14_16 locally\n",
      "25/11/13 16:15:21 INFO Executor: Finished task 16.0 in stage 30.0 (TID 428). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Starting task 18.0 in stage 30.0 (TID 430) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 18, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:21 INFO Executor: Running task 18.0 in stage 30.0 (TID 430)\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Finished task 16.0 in stage 30.0 (TID 428) in 43 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (17/50)\n",
      "25/11/13 16:15:21 INFO BlockManager: Found block rdd_14_17 locally\n",
      "25/11/13 16:15:21 INFO Executor: Finished task 17.0 in stage 30.0 (TID 429). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Starting task 19.0 in stage 30.0 (TID 431) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 19, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:21 INFO Executor: Running task 19.0 in stage 30.0 (TID 431)\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Finished task 17.0 in stage 30.0 (TID 429) in 64 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (18/50)\n",
      "25/11/13 16:15:21 INFO BlockManager: Found block rdd_14_18 locally\n",
      "25/11/13 16:15:21 INFO Executor: Finished task 18.0 in stage 30.0 (TID 430). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Starting task 20.0 in stage 30.0 (TID 432) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 20, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:21 INFO Executor: Running task 20.0 in stage 30.0 (TID 432)\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Finished task 18.0 in stage 30.0 (TID 430) in 79 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (19/50)\n",
      "25/11/13 16:15:21 INFO BlockManager: Found block rdd_14_19 locally\n",
      "25/11/13 16:15:21 INFO Executor: Finished task 19.0 in stage 30.0 (TID 431). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Starting task 21.0 in stage 30.0 (TID 433) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 21, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:21 INFO Executor: Running task 21.0 in stage 30.0 (TID 433)\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Finished task 19.0 in stage 30.0 (TID 431) in 44 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (20/50)\n",
      "25/11/13 16:15:21 INFO BlockManager: Found block rdd_14_20 locally\n",
      "25/11/13 16:15:21 INFO Executor: Finished task 20.0 in stage 30.0 (TID 432). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Starting task 22.0 in stage 30.0 (TID 434) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 22, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:21 INFO Executor: Running task 22.0 in stage 30.0 (TID 434)\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Finished task 20.0 in stage 30.0 (TID 432) in 41 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (21/50)\n",
      "25/11/13 16:15:21 INFO BlockManager: Found block rdd_14_21 locally\n",
      "25/11/13 16:15:21 INFO Executor: Finished task 21.0 in stage 30.0 (TID 433). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Starting task 23.0 in stage 30.0 (TID 435) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 23, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:21 INFO Executor: Running task 23.0 in stage 30.0 (TID 435)\n",
      "25/11/13 16:15:21 INFO TaskSetManager: Finished task 21.0 in stage 30.0 (TID 433) in 17 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (22/50)\n",
      "25/11/13 16:15:22 INFO BlockManager: Found block rdd_14_22 locally(22 + 2) / 50]\n",
      "25/11/13 16:15:22 INFO Executor: Finished task 22.0 in stage 30.0 (TID 434). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:22 INFO BlockManager: Found block rdd_14_23 locally\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Starting task 24.0 in stage 30.0 (TID 436) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 24, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:22 INFO Executor: Running task 24.0 in stage 30.0 (TID 436)\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Finished task 22.0 in stage 30.0 (TID 434) in 79 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (23/50)\n",
      "25/11/13 16:15:22 INFO Executor: Finished task 23.0 in stage 30.0 (TID 435). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Starting task 25.0 in stage 30.0 (TID 437) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 25, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:22 INFO TaskSetManager: Finished task 23.0 in stage 30.0 (TID 435) in 75 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (24/50)\n",
      "25/11/13 16:15:22 INFO Executor: Running task 25.0 in stage 30.0 (TID 437)\n",
      "25/11/13 16:15:22 INFO BlockManager: Found block rdd_14_24 locally\n",
      "25/11/13 16:15:22 INFO Executor: Finished task 24.0 in stage 30.0 (TID 436). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:22 INFO BlockManager: Found block rdd_14_25 locally\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Starting task 26.0 in stage 30.0 (TID 438) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 26, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:22 INFO Executor: Running task 26.0 in stage 30.0 (TID 438)\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Finished task 24.0 in stage 30.0 (TID 436) in 43 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (25/50)\n",
      "25/11/13 16:15:22 INFO Executor: Finished task 25.0 in stage 30.0 (TID 437). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Starting task 27.0 in stage 30.0 (TID 439) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 27, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:22 INFO Executor: Running task 27.0 in stage 30.0 (TID 439)\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Finished task 25.0 in stage 30.0 (TID 437) in 131 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (26/50)\n",
      "25/11/13 16:15:22 INFO BlockManagerInfo: Removed broadcast_25_piece0 on jupyter-spark-758b7c86d8-7j77n:32921 in memory (size: 154.5 KiB, free: 1048.5 MiB)\n",
      "25/11/13 16:15:22 INFO BlockManager: Found block rdd_14_26 locally\n",
      "25/11/13 16:15:22 INFO Executor: Finished task 26.0 in stage 30.0 (TID 438). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Starting task 28.0 in stage 30.0 (TID 440) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 28, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:22 INFO BlockManager: Found block rdd_14_27 locally\n",
      "25/11/13 16:15:22 INFO Executor: Running task 28.0 in stage 30.0 (TID 440)\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Finished task 26.0 in stage 30.0 (TID 438) in 156 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (27/50)\n",
      "25/11/13 16:15:22 INFO Executor: Finished task 27.0 in stage 30.0 (TID 439). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Starting task 29.0 in stage 30.0 (TID 441) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 29, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:22 INFO Executor: Running task 29.0 in stage 30.0 (TID 441)\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Finished task 27.0 in stage 30.0 (TID 439) in 181 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (28/50)\n",
      "25/11/13 16:15:22 INFO BlockManager: Found block rdd_14_28 locally\n",
      "25/11/13 16:15:22 INFO Executor: Finished task 28.0 in stage 30.0 (TID 440). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Starting task 30.0 in stage 30.0 (TID 442) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 30, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:22 INFO BlockManager: Found block rdd_14_29 locally\n",
      "25/11/13 16:15:22 INFO Executor: Running task 30.0 in stage 30.0 (TID 442)\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Finished task 28.0 in stage 30.0 (TID 440) in 46 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (29/50)\n",
      "25/11/13 16:15:22 INFO Executor: Finished task 29.0 in stage 30.0 (TID 441). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Starting task 31.0 in stage 30.0 (TID 443) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 31, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:22 INFO Executor: Running task 31.0 in stage 30.0 (TID 443)\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Finished task 29.0 in stage 30.0 (TID 441) in 19 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (30/50)\n",
      "25/11/13 16:15:22 INFO BlockManager: Found block rdd_14_30 locally\n",
      "25/11/13 16:15:22 INFO BlockManager: Found block rdd_14_31 locally\n",
      "25/11/13 16:15:22 INFO Executor: Finished task 30.0 in stage 30.0 (TID 442). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Starting task 32.0 in stage 30.0 (TID 444) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 32, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:22 INFO TaskSetManager: Finished task 30.0 in stage 30.0 (TID 442) in 60 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (31/50)\n",
      "25/11/13 16:15:22 INFO Executor: Running task 32.0 in stage 30.0 (TID 444)\n",
      "25/11/13 16:15:22 INFO Executor: Finished task 31.0 in stage 30.0 (TID 443). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Starting task 33.0 in stage 30.0 (TID 445) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 33, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:22 INFO Executor: Running task 33.0 in stage 30.0 (TID 445)\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Finished task 31.0 in stage 30.0 (TID 443) in 78 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (32/50)\n",
      "25/11/13 16:15:22 INFO BlockManager: Found block rdd_14_32 locally\n",
      "25/11/13 16:15:22 INFO BlockManager: Found block rdd_14_33 locally\n",
      "25/11/13 16:15:22 INFO Executor: Finished task 32.0 in stage 30.0 (TID 444). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:22 INFO Executor: Finished task 33.0 in stage 30.0 (TID 445). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Starting task 34.0 in stage 30.0 (TID 446) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 34, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:22 INFO Executor: Running task 34.0 in stage 30.0 (TID 446)\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Starting task 35.0 in stage 30.0 (TID 447) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 35, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:22 INFO Executor: Running task 35.0 in stage 30.0 (TID 447)\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Finished task 33.0 in stage 30.0 (TID 445) in 17 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (33/50)\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Finished task 32.0 in stage 30.0 (TID 444) in 37 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (34/50)\n",
      "25/11/13 16:15:22 INFO BlockManager: Found block rdd_14_35 locally\n",
      "25/11/13 16:15:22 INFO BlockManager: Found block rdd_14_34 locally(34 + 2) / 50]\n",
      "25/11/13 16:15:22 INFO Executor: Finished task 35.0 in stage 30.0 (TID 447). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Starting task 36.0 in stage 30.0 (TID 448) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 36, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:22 INFO Executor: Running task 36.0 in stage 30.0 (TID 448)\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Finished task 35.0 in stage 30.0 (TID 447) in 99 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (35/50)\n",
      "25/11/13 16:15:22 INFO Executor: Finished task 34.0 in stage 30.0 (TID 446). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Starting task 37.0 in stage 30.0 (TID 449) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 37, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:22 INFO Executor: Running task 37.0 in stage 30.0 (TID 449)\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Finished task 34.0 in stage 30.0 (TID 446) in 102 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (36/50)\n",
      "25/11/13 16:15:22 INFO BlockManager: Found block rdd_14_36 locally\n",
      "25/11/13 16:15:22 INFO BlockManager: Found block rdd_14_37 locally\n",
      "25/11/13 16:15:22 INFO Executor: Finished task 37.0 in stage 30.0 (TID 449). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:22 INFO Executor: Finished task 36.0 in stage 30.0 (TID 448). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Starting task 38.0 in stage 30.0 (TID 450) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 38, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:22 INFO TaskSetManager: Starting task 39.0 in stage 30.0 (TID 451) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 39, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:22 INFO Executor: Running task 38.0 in stage 30.0 (TID 450)\n",
      "25/11/13 16:15:22 INFO Executor: Running task 39.0 in stage 30.0 (TID 451)\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Finished task 36.0 in stage 30.0 (TID 448) in 19 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (37/50)\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Finished task 37.0 in stage 30.0 (TID 449) in 51 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (38/50)\n",
      "25/11/13 16:15:22 INFO BlockManager: Found block rdd_14_38 locally\n",
      "25/11/13 16:15:22 INFO BlockManager: Found block rdd_14_39 locally\n",
      "25/11/13 16:15:22 INFO Executor: Finished task 38.0 in stage 30.0 (TID 450). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:22 INFO Executor: Finished task 39.0 in stage 30.0 (TID 451). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Starting task 40.0 in stage 30.0 (TID 452) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 40, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:22 INFO Executor: Running task 40.0 in stage 30.0 (TID 452)\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Starting task 41.0 in stage 30.0 (TID 453) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 41, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:22 INFO TaskSetManager: Finished task 38.0 in stage 30.0 (TID 450) in 71 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (39/50)\n",
      "25/11/13 16:15:22 INFO Executor: Running task 41.0 in stage 30.0 (TID 453)\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Finished task 39.0 in stage 30.0 (TID 451) in 72 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (40/50)\n",
      "25/11/13 16:15:22 INFO BlockManager: Found block rdd_14_40 locally\n",
      "25/11/13 16:15:22 INFO Executor: Finished task 40.0 in stage 30.0 (TID 452). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:22 INFO BlockManager: Found block rdd_14_41 locally\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Starting task 42.0 in stage 30.0 (TID 454) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 42, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:22 INFO TaskSetManager: Finished task 40.0 in stage 30.0 (TID 452) in 20 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (41/50)\n",
      "25/11/13 16:15:22 INFO Executor: Running task 42.0 in stage 30.0 (TID 454)\n",
      "25/11/13 16:15:22 INFO Executor: Finished task 41.0 in stage 30.0 (TID 453). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Starting task 43.0 in stage 30.0 (TID 455) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 43, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:22 INFO Executor: Running task 43.0 in stage 30.0 (TID 455)\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Finished task 41.0 in stage 30.0 (TID 453) in 22 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (42/50)\n",
      "25/11/13 16:15:22 INFO BlockManager: Found block rdd_14_42 locally\n",
      "25/11/13 16:15:22 INFO Executor: Finished task 42.0 in stage 30.0 (TID 454). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:22 INFO BlockManager: Found block rdd_14_43 locally\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Starting task 44.0 in stage 30.0 (TID 456) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 44, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:22 INFO Executor: Running task 44.0 in stage 30.0 (TID 456)\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Finished task 42.0 in stage 30.0 (TID 454) in 50 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (43/50)\n",
      "25/11/13 16:15:22 INFO Executor: Finished task 43.0 in stage 30.0 (TID 455). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Starting task 45.0 in stage 30.0 (TID 457) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 45, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:22 INFO Executor: Running task 45.0 in stage 30.0 (TID 457)\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Finished task 43.0 in stage 30.0 (TID 455) in 51 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (44/50)\n",
      "25/11/13 16:15:22 INFO BlockManager: Found block rdd_14_45 locally\n",
      "25/11/13 16:15:22 INFO Executor: Finished task 45.0 in stage 30.0 (TID 457). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Starting task 46.0 in stage 30.0 (TID 458) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 46, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:22 INFO Executor: Running task 46.0 in stage 30.0 (TID 458)\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Finished task 45.0 in stage 30.0 (TID 457) in 63 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (45/50)\n",
      "25/11/13 16:15:22 INFO BlockManager: Found block rdd_14_44 locally\n",
      "25/11/13 16:15:22 INFO Executor: Finished task 44.0 in stage 30.0 (TID 456). 4224 bytes result sent to driver\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Starting task 47.0 in stage 30.0 (TID 459) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 47, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:22 INFO Executor: Running task 47.0 in stage 30.0 (TID 459)\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Finished task 44.0 in stage 30.0 (TID 456) in 72 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (46/50)\n",
      "25/11/13 16:15:22 INFO BlockManager: Found block rdd_14_46 locally\n",
      "25/11/13 16:15:22 INFO Executor: Finished task 46.0 in stage 30.0 (TID 458). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Starting task 48.0 in stage 30.0 (TID 460) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 48, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:22 INFO Executor: Running task 48.0 in stage 30.0 (TID 460)\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Finished task 46.0 in stage 30.0 (TID 458) in 37 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (47/50)\n",
      "25/11/13 16:15:22 INFO BlockManager: Found block rdd_14_47 locally\n",
      "25/11/13 16:15:22 INFO Executor: Finished task 47.0 in stage 30.0 (TID 459). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Starting task 49.0 in stage 30.0 (TID 461) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 49, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:22 INFO Executor: Running task 49.0 in stage 30.0 (TID 461)\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Finished task 47.0 in stage 30.0 (TID 459) in 39 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (48/50)\n",
      "25/11/13 16:15:22 INFO BlockManager: Found block rdd_14_48 locally\n",
      "25/11/13 16:15:22 INFO Executor: Finished task 48.0 in stage 30.0 (TID 460). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Finished task 48.0 in stage 30.0 (TID 460) in 43 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (49/50)\n",
      "25/11/13 16:15:22 INFO BlockManager: Found block rdd_14_49 locally\n",
      "25/11/13 16:15:22 INFO Executor: Finished task 49.0 in stage 30.0 (TID 461). 4181 bytes result sent to driver\n",
      "25/11/13 16:15:22 INFO TaskSetManager: Finished task 49.0 in stage 30.0 (TID 461) in 42 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (50/50)\n",
      "25/11/13 16:15:22 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool \n",
      "25/11/13 16:15:22 INFO DAGScheduler: ResultStage 30 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 1.288 s\n",
      "25/11/13 16:15:22 INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/11/13 16:15:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 30: Stage finished\n",
      "25/11/13 16:15:22 INFO DAGScheduler: Job 18 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 1.297572 s\n",
      "25/11/13 16:15:22 INFO PrepareDeltaScan: DELTA: Done                            \n",
      "25/11/13 16:15:22 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/11/13 16:15:22 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/11/13 16:15:22 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/11/13 16:15:22 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/11/13 16:15:22 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/11/13 16:15:22 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "25/11/13 16:15:23 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 206.9 KiB, free 1047.1 MiB)\n",
      "25/11/13 16:15:23 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 1047.0 MiB)\n",
      "25/11/13 16:15:23 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 36.8 KiB, free: 1048.5 MiB)\n",
      "25/11/13 16:15:23 INFO SparkContext: Created broadcast 30 from save at NativeMethodAccessorImpl.java:0\n",
      "25/11/13 16:15:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 10926151 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/11/13 16:15:23 INFO DAGScheduler: Registering RDD 78 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 3\n",
      "25/11/13 16:15:23 INFO DAGScheduler: Got map stage job 19 (save at NativeMethodAccessorImpl.java:0) with 2 output partitions\n",
      "25/11/13 16:15:23 INFO DAGScheduler: Final stage: ShuffleMapStage 31 (save at NativeMethodAccessorImpl.java:0)\n",
      "25/11/13 16:15:23 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/11/13 16:15:23 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 16:15:23 INFO DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[78] at save at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/11/13 16:15:23 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 36.0 KiB, free 1047.0 MiB)\n",
      "25/11/13 16:15:23 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 12.9 KiB, free 1047.0 MiB)\n",
      "25/11/13 16:15:23 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 12.9 KiB, free: 1048.5 MiB)\n",
      "25/11/13 16:15:23 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 16:15:23 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[78] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))\n",
      "25/11/13 16:15:23 INFO TaskSchedulerImpl: Adding task set 31.0 with 2 tasks resource profile 0\n",
      "25/11/13 16:15:23 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 462) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 9668 bytes) \n",
      "25/11/13 16:15:23 INFO TaskSetManager: Starting task 1.0 in stage 31.0 (TID 463) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 1, PROCESS_LOCAL, 9668 bytes) \n",
      "25/11/13 16:15:23 INFO Executor: Running task 1.0 in stage 31.0 (TID 463)\n",
      "25/11/13 16:15:23 INFO Executor: Running task 0.0 in stage 31.0 (TID 462)\n",
      "25/11/13 16:15:23 INFO FileScanRDD: Reading File path: s3a://nau-local-analytics-bronze/auth_userprofile/part-00000-130fc9e9-8dc1-4d6a-b4e7-714542eff639-c000.snappy.parquet, range: 10926151-17657998, partition values: [empty row]\n",
      "25/11/13 16:15:23 INFO FileScanRDD: Reading File path: s3a://nau-local-analytics-bronze/auth_userprofile/part-00000-130fc9e9-8dc1-4d6a-b4e7-714542eff639-c000.snappy.parquet, range: 0-10926151, partition values: [empty row]\n",
      "25/11/13 16:15:23 INFO S3AInputStream: Switching to Random IO seek policy\n",
      "25/11/13 16:15:23 INFO S3AInputStream: Switching to Random IO seek policy\n",
      "25/11/13 16:15:23 INFO Executor: Finished task 1.0 in stage 31.0 (TID 463). 1841 bytes result sent to driver\n",
      "25/11/13 16:15:23 INFO TaskSetManager: Finished task 1.0 in stage 31.0 (TID 463) in 163 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/2)\n",
      "25/11/13 16:15:24 INFO BlockManagerInfo: Removed broadcast_29_piece0 on jupyter-spark-758b7c86d8-7j77n:32921 in memory (size: 154.5 KiB, free: 1048.6 MiB)\n",
      "25/11/13 16:15:25 INFO Executor: Finished task 0.0 in stage 31.0 (TID 462). 2056 bytes result sent to driver\n",
      "25/11/13 16:15:25 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 462) in 2362 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (2/2)\n",
      "25/11/13 16:15:25 INFO DAGScheduler: ShuffleMapStage 31 (save at NativeMethodAccessorImpl.java:0) finished in 2.371 s\n",
      "25/11/13 16:15:25 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/11/13 16:15:25 INFO DAGScheduler: running: Set()\n",
      "25/11/13 16:15:25 INFO DAGScheduler: waiting: Set()\n",
      "25/11/13 16:15:25 INFO DAGScheduler: failed: Set()\n",
      "25/11/13 16:15:25 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool \n",
      "25/11/13 16:15:25 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/11/13 16:15:25 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/11/13 16:15:25 INFO CodeGenerator: Code generated in 7.314864 ms\n",
      "25/11/13 16:15:25 INFO CodeGenerator: Code generated in 31.200471 ms\n",
      "25/11/13 16:15:25 INFO SparkContext: Starting job: save at NativeMethodAccessorImpl.java:0\n",
      "25/11/13 16:15:25 INFO DAGScheduler: Got job 20 (save at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/11/13 16:15:25 INFO DAGScheduler: Final stage: ResultStage 33 (save at NativeMethodAccessorImpl.java:0)\n",
      "25/11/13 16:15:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 32)\n",
      "25/11/13 16:15:25 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 16:15:25 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[83] at save at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/11/13 16:15:25 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 393.7 KiB, free 1047.4 MiB)\n",
      "25/11/13 16:15:25 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 140.5 KiB, free 1047.3 MiB)\n",
      "25/11/13 16:15:25 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 140.5 KiB, free: 1048.5 MiB)\n",
      "25/11/13 16:15:25 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 16:15:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[83] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/11/13 16:15:25 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks resource profile 0\n",
      "25/11/13 16:15:25 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 464) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, NODE_LOCAL, 8999 bytes) \n",
      "25/11/13 16:15:25 INFO Executor: Running task 0.0 in stage 33.0 (TID 464)\n",
      "25/11/13 16:15:25 INFO ShuffleBlockFetcherIterator: Getting 1 (20.2 MiB) non-empty blocks including 1 (20.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:15:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:15:26 INFO CodeGenerator: Code generated in 11.822377 ms\n",
      "25/11/13 16:15:26 INFO CodeGenerator: Code generated in 14.289971 ms\n",
      "25/11/13 16:15:26 INFO BlockManagerInfo: Removed broadcast_31_piece0 on jupyter-spark-758b7c86d8-7j77n:32921 in memory (size: 12.9 KiB, free: 1048.5 MiB)\n",
      "25/11/13 16:15:27 INFO CodeGenerator: Code generated in 8.196366 ms (0 + 1) / 1]\n",
      "25/11/13 16:15:27 INFO CodeGenerator: Code generated in 24.567558 ms\n",
      "25/11/13 16:15:27 INFO CodeGenerator: Code generated in 18.734894 ms\n",
      "25/11/13 16:15:27 INFO CodeGenerator: Code generated in 60.375806 ms\n",
      "25/11/13 16:15:27 INFO CodeGenerator: Code generated in 13.154168 ms\n",
      "25/11/13 16:15:27 INFO CodecConfig: Compression: SNAPPY\n",
      "25/11/13 16:15:27 INFO CodecConfig: Compression: SNAPPY\n",
      "25/11/13 16:15:27 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]\n",
      "25/11/13 16:15:27 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"profile_sk\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"profile_id\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"user_id\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"year_of_birth\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"isSigned\" : true,\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"age_band\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"gender\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(6)\",\n",
      "      \"isSigned\" : false,\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"country\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(2)\",\n",
      "      \"isSigned\" : false,\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"isSigned\" : false,\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"location\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(255)\",\n",
      "      \"isSigned\" : false,\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"level_of_education\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(6)\",\n",
      "      \"isSigned\" : false,\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"language\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(255)\",\n",
      "      \"isSigned\" : false,\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"courseware\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(255)\",\n",
      "      \"isSigned\" : false,\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"phone_number\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(50)\",\n",
      "      \"isSigned\" : false,\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"state\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(2)\",\n",
      "      \"isSigned\" : false,\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"ingestion_date\",\n",
      "    \"type\" : \"timestamp\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"source_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional int32 profile_sk;\n",
      "  optional int32 profile_id;\n",
      "  optional int32 user_id;\n",
      "  optional int32 year_of_birth;\n",
      "  optional binary age_band (STRING);\n",
      "  optional binary gender (STRING);\n",
      "  optional binary country (STRING);\n",
      "  optional binary city (STRING);\n",
      "  optional binary location (STRING);\n",
      "  optional binary level_of_education (STRING);\n",
      "  optional binary language (STRING);\n",
      "  optional binary courseware (STRING);\n",
      "  optional binary phone_number (STRING);\n",
      "  optional binary state (STRING);\n",
      "  optional int96 ingestion_date;\n",
      "  optional binary source_name (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "25/11/13 16:15:27 INFO CodecPool: Got brand-new compressor [.snappy]\n",
      "25/11/13 16:15:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter\n",
      "25/11/13 16:15:30 INFO BlockManagerInfo: Removed broadcast_26_piece0 on jupyter-spark-758b7c86d8-7j77n:32921 in memory (size: 36.8 KiB, free: 1048.6 MiB)\n",
      "25/11/13 16:15:36 INFO Executor: Finished task 0.0 in stage 33.0 (TID 464). 7622 bytes result sent to driver\n",
      "25/11/13 16:15:36 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 464) in 10928 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/1)\n",
      "25/11/13 16:15:36 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool \n",
      "25/11/13 16:15:36 INFO DAGScheduler: ResultStage 33 (save at NativeMethodAccessorImpl.java:0) finished in 11.008 s\n",
      "25/11/13 16:15:36 INFO DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/11/13 16:15:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 33: Stage finished\n",
      "25/11/13 16:15:36 INFO DAGScheduler: Job 20 finished: save at NativeMethodAccessorImpl.java:0, took 11.024605 s\n",
      "25/11/13 16:15:36 INFO DeltaFileFormatWriter: Start to commit write Job 1e56a242-44ad-4645-b07d-484ec5310c44.\n",
      "25/11/13 16:15:36 INFO DeltaFileFormatWriter: Write Job 1e56a242-44ad-4645-b07d-484ec5310c44 committed. Elapsed time: 1 ms.\n",
      "25/11/13 16:15:36 INFO DeltaFileFormatWriter: Finished processing stats for write job 1e56a242-44ad-4645-b07d-484ec5310c44.\n",
      "25/11/13 16:15:37 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128\n",
      "25/11/13 16:15:37 INFO DAGScheduler: Job 21 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.000377 s\n",
      "25/11/13 16:15:37 INFO OptimisticTransaction: [tableId=8b0029bd,txnId=e34d9523] Attempting to commit version 0 with 4 actions with Serializable isolation level\n",
      "25/11/13 16:15:38 INFO DeltaLog: Creating a new snapshot v0 for commit version 0\n",
      "25/11/13 16:15:38 INFO DeltaLog: Loading version 0.\n",
      "25/11/13 16:15:38 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(JSON, numFilesInSegment: 1, totalFileSize: 3824)\n",
      "25/11/13 16:15:38 INFO DataSourceStrategy: Pruning directories with: \n",
      "25/11/13 16:15:38 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/11/13 16:15:38 INFO FileSourceStrategy: Post-Scan Filters: ((isnotnull(protocol#2881.minReaderVersion) OR isnotnull(metaData#2880.id)) OR (isnotnull(commitInfo#2882.inCommitTimestamp) AND (version#2883L = 0)))\n",
      "25/11/13 16:15:38 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 202.9 KiB, free 1047.4 MiB)\n",
      "25/11/13 16:15:38 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 35.5 KiB, free 1047.3 MiB)\n",
      "25/11/13 16:15:38 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 35.5 KiB, free: 1048.5 MiB)\n",
      "25/11/13 16:15:38 INFO SparkContext: Created broadcast 33 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128\n",
      "25/11/13 16:15:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/11/13 16:15:38 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128\n",
      "25/11/13 16:15:38 INFO DAGScheduler: Got job 22 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions\n",
      "25/11/13 16:15:38 INFO DAGScheduler: Final stage: ResultStage 34 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)\n",
      "25/11/13 16:15:38 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/11/13 16:15:38 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 16:15:38 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[91] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents\n",
      "25/11/13 16:15:38 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 55.2 KiB, free 1047.3 MiB)\n",
      "25/11/13 16:15:38 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1047.3 MiB)\n",
      "25/11/13 16:15:38 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 17.1 KiB, free: 1048.5 MiB)\n",
      "25/11/13 16:15:38 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 16:15:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[91] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))\n",
      "25/11/13 16:15:38 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks resource profile 0\n",
      "25/11/13 16:15:38 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 465) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 9699 bytes) \n",
      "25/11/13 16:15:38 INFO Executor: Running task 0.0 in stage 34.0 (TID 465)\n",
      "25/11/13 16:15:38 INFO FileScanRDD: Reading File path: s3a://nau-local-analytics-silver/dim_user_profile/_delta_log/00000000000000000000.json, range: 0-3824, partition values: [0]\n",
      "25/11/13 16:15:38 INFO Executor: Finished task 0.0 in stage 34.0 (TID 465). 2181 bytes result sent to driver\n",
      "25/11/13 16:15:38 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 465) in 103 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/1)\n",
      "25/11/13 16:15:38 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool \n",
      "25/11/13 16:15:38 INFO DAGScheduler: ResultStage 34 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.134 s\n",
      "25/11/13 16:15:38 INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/11/13 16:15:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 34: Stage finished\n",
      "25/11/13 16:15:38 INFO DAGScheduler: Job 22 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.143599 s\n",
      "25/11/13 16:15:38 INFO Snapshot: [tableId=8b0029bd-d62f-406f-9cab-5818b29ae118] Created snapshot Snapshot(path=s3a://nau-local-analytics-silver/dim_user_profile/_delta_log, version=0, metadata=Metadata(cecff036-318c-4ebc-be9d-1081081bfefa,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"profile_sk\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"profile_id\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"user_id\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"year_of_birth\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{\"isSigned\":true,\"scale\":0}},{\"name\":\"age_band\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"gender\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(6)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"country\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(2)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"city\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"isSigned\":false,\"scale\":0}},{\"name\":\"location\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(255)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"level_of_education\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(6)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"language\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(255)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"courseware\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(255)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"phone_number\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(50)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"state\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(2)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"ingestion_date\",\"type\":\"timestamp\",\"nullable\":true,\"metadata\":{}},{\"name\":\"source_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1763050520365)), logSegment=LogSegment(s3a://nau-local-analytics-silver/dim_user_profile/_delta_log,0,List(S3AFileStatus{path=s3a://nau-local-analytics-silver/dim_user_profile/_delta_log/00000000000000000000.json; isDirectory=false; length=3824; replication=1; blocksize=33554432; modification_time=1763050538000; access_time=0; owner=spark; group=spark; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=f40b41965d0cb0f3e3972264b65ca069 versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@2b65c581,1763050538000), checksumOpt=None)\n",
      "25/11/13 16:15:38 INFO DeltaLog: Updated snapshot to Snapshot(path=s3a://nau-local-analytics-silver/dim_user_profile/_delta_log, version=0, metadata=Metadata(cecff036-318c-4ebc-be9d-1081081bfefa,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"profile_sk\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"profile_id\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"user_id\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"year_of_birth\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{\"isSigned\":true,\"scale\":0}},{\"name\":\"age_band\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"gender\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(6)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"country\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(2)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"city\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"isSigned\":false,\"scale\":0}},{\"name\":\"location\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(255)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"level_of_education\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(6)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"language\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(255)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"courseware\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(255)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"phone_number\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(50)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"state\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(2)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"ingestion_date\",\"type\":\"timestamp\",\"nullable\":true,\"metadata\":{}},{\"name\":\"source_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1763050520365)), logSegment=LogSegment(s3a://nau-local-analytics-silver/dim_user_profile/_delta_log,0,List(S3AFileStatus{path=s3a://nau-local-analytics-silver/dim_user_profile/_delta_log/00000000000000000000.json; isDirectory=false; length=3824; replication=1; blocksize=33554432; modification_time=1763050538000; access_time=0; owner=spark; group=spark; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=f40b41965d0cb0f3e3972264b65ca069 versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@2b65c581,1763050538000), checksumOpt=None)\n",
      "25/11/13 16:15:39 INFO BlockManagerInfo: Removed broadcast_32_piece0 on jupyter-spark-758b7c86d8-7j77n:32921 in memory (size: 140.5 KiB, free: 1048.6 MiB)\n",
      "25/11/13 16:15:39 INFO OptimisticTransaction: [tableId=8b0029bd,txnId=e34d9523] Committed delta #0 to s3a://nau-local-analytics-silver/dim_user_profile/_delta_log\n",
      "25/11/13 16:15:39 INFO DeltaLog: Loading version 0.\n",
      "25/11/13 16:15:39 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(JSON, numFilesInSegment: 1, totalFileSize: 3824)\n",
      "25/11/13 16:15:39 INFO DataSourceStrategy: Pruning directories with: \n",
      "25/11/13 16:15:39 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/11/13 16:15:39 INFO FileSourceStrategy: Post-Scan Filters: ((isnotnull(protocol#2927.minReaderVersion) OR isnotnull(metaData#2926.id)) OR (isnotnull(commitInfo#2928.inCommitTimestamp) AND (version#2929L = 0)))\n",
      "25/11/13 16:15:39 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 202.9 KiB, free 1047.6 MiB)\n",
      "25/11/13 16:15:39 INFO BlockManagerInfo: Removed broadcast_34_piece0 on jupyter-spark-758b7c86d8-7j77n:32921 in memory (size: 17.1 KiB, free: 1048.7 MiB)\n",
      "25/11/13 16:15:39 INFO BlockManagerInfo: Removed broadcast_33_piece0 on jupyter-spark-758b7c86d8-7j77n:32921 in memory (size: 35.5 KiB, free: 1048.7 MiB)\n",
      "25/11/13 16:15:39 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 35.5 KiB, free 1047.9 MiB)\n",
      "25/11/13 16:15:39 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 35.5 KiB, free: 1048.7 MiB)\n",
      "25/11/13 16:15:39 INFO SparkContext: Created broadcast 35 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128\n",
      "25/11/13 16:15:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> [dim_user_profile] Load/MERGE finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/13 16:15:39 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128\n",
      "25/11/13 16:15:39 INFO DAGScheduler: Got job 23 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions\n",
      "25/11/13 16:15:39 INFO DAGScheduler: Final stage: ResultStage 35 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)\n",
      "25/11/13 16:15:39 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/11/13 16:15:39 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 16:15:39 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[95] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents\n",
      "25/11/13 16:15:39 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 55.2 KiB, free 1047.8 MiB)\n",
      "25/11/13 16:15:39 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1047.8 MiB)\n",
      "25/11/13 16:15:39 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 17.1 KiB, free: 1048.6 MiB)\n",
      "25/11/13 16:15:39 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 16:15:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[95] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))\n",
      "25/11/13 16:15:39 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks resource profile 0\n",
      "25/11/13 16:15:39 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 466) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 9699 bytes) \n",
      "25/11/13 16:15:39 INFO Executor: Running task 0.0 in stage 35.0 (TID 466)\n",
      "25/11/13 16:15:39 INFO FileScanRDD: Reading File path: s3a://nau-local-analytics-silver/dim_user_profile/_delta_log/00000000000000000000.json, range: 0-3824, partition values: [0]\n",
      "25/11/13 16:15:39 INFO Executor: Finished task 0.0 in stage 35.0 (TID 466). 2181 bytes result sent to driver\n",
      "25/11/13 16:15:39 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 466) in 109 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/1)\n",
      "25/11/13 16:15:39 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool \n",
      "25/11/13 16:15:39 INFO DAGScheduler: ResultStage 35 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.151 s\n",
      "25/11/13 16:15:39 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/11/13 16:15:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 35: Stage finished\n",
      "25/11/13 16:15:39 INFO DAGScheduler: Job 23 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.156066 s\n",
      "25/11/13 16:15:39 INFO Snapshot: [tableId=cecff036-318c-4ebc-be9d-1081081bfefa] Created snapshot Snapshot(path=s3a://nau-local-analytics-silver/dim_user_profile/_delta_log, version=0, metadata=Metadata(cecff036-318c-4ebc-be9d-1081081bfefa,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"profile_sk\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"profile_id\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"user_id\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"year_of_birth\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{\"isSigned\":true,\"scale\":0}},{\"name\":\"age_band\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"gender\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(6)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"country\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(2)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"city\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"isSigned\":false,\"scale\":0}},{\"name\":\"location\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(255)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"level_of_education\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(6)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"language\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(255)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"courseware\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(255)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"phone_number\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(50)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"state\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(2)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"ingestion_date\",\"type\":\"timestamp\",\"nullable\":true,\"metadata\":{}},{\"name\":\"source_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1763050520365)), logSegment=LogSegment(s3a://nau-local-analytics-silver/dim_user_profile/_delta_log,0,WrappedArray(S3AFileStatus{path=s3a://nau-local-analytics-silver/dim_user_profile/_delta_log/00000000000000000000.json; isDirectory=false; length=3824; replication=1; blocksize=33554432; modification_time=1763050538184; access_time=0; owner=spark; group=spark; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=f40b41965d0cb0f3e3972264b65ca069 versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@2b65c581,1763050538184), checksumOpt=None)\n",
      "25/11/13 16:15:39 INFO DeltaLog: Updated snapshot to Snapshot(path=s3a://nau-local-analytics-silver/dim_user_profile/_delta_log, version=0, metadata=Metadata(cecff036-318c-4ebc-be9d-1081081bfefa,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"profile_sk\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"profile_id\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"user_id\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"year_of_birth\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{\"isSigned\":true,\"scale\":0}},{\"name\":\"age_band\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"gender\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(6)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"country\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(2)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"city\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"isSigned\":false,\"scale\":0}},{\"name\":\"location\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(255)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"level_of_education\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(6)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"language\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(255)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"courseware\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(255)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"phone_number\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(50)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"state\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(2)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"ingestion_date\",\"type\":\"timestamp\",\"nullable\":true,\"metadata\":{}},{\"name\":\"source_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1763050520365)), logSegment=LogSegment(s3a://nau-local-analytics-silver/dim_user_profile/_delta_log,0,WrappedArray(S3AFileStatus{path=s3a://nau-local-analytics-silver/dim_user_profile/_delta_log/00000000000000000000.json; isDirectory=false; length=3824; replication=1; blocksize=33554432; modification_time=1763050538184; access_time=0; owner=spark; group=spark; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=f40b41965d0cb0f3e3972264b65ca069 versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@2b65c581,1763050538184), checksumOpt=None)\n",
      "25/11/13 16:15:39 INFO CreateDeltaTableCommand: Table is path-based table: false. Update catalog with mode: Create\n",
      "25/11/13 16:15:40 INFO BlockManagerInfo: Removed broadcast_30_piece0 on jupyter-spark-758b7c86d8-7j77n:32921 in memory (size: 36.8 KiB, free: 1048.7 MiB)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "\n",
    "silver_profile_path = \"s3a://nau-local-analytics-silver/dim_user_profile\"\n",
    "dim_profile_table_name = \"dim_user_profile\"\n",
    "\n",
    "PROFILE_BUSINESS_COLUMNS = [\n",
    "    \"profile_id\",\n",
    "    \"user_id\",\n",
    "    \"year_of_birth\",\n",
    "    \"age_band\",\n",
    "    \"gender\",\n",
    "    \"country\",\n",
    "    \"city\",\n",
    "    \"location\",\n",
    "    \"level_of_education\",\n",
    "    \"language\",\n",
    "    \"courseware\",\n",
    "    \"phone_number\",\n",
    "    \"state\",\n",
    "    \"ingestion_date\",\n",
    "    \"source_name\",\n",
    "]\n",
    "\n",
    "# ============================================================\n",
    "# 1. Check if Silver Delta table already exists\n",
    "# ============================================================\n",
    "try:\n",
    "    df_dim_profile_current = (\n",
    "        spark.read\n",
    "             .format(\"delta\")\n",
    "             .load(silver_profile_path)\n",
    "             .select(\"profile_id\", \"profile_sk\")\n",
    "    )\n",
    "    dim_profile_exists = True\n",
    "    print(\">> [dim_user_profile] Existing Silver Delta table found.\")\n",
    "except AnalysisException:\n",
    "    dim_profile_exists = False\n",
    "    df_dim_profile_current = None\n",
    "    print(\">> [dim_user_profile] Silver Delta table does not exist yet (first load).\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. Build df_user_profile_silver with stable profile_sk\n",
    "# ============================================================\n",
    "if dim_profile_exists:\n",
    "    max_sk = df_dim_profile_current.agg(F.max(\"profile_sk\")).collect()[0][0]\n",
    "    max_sk = max_sk if max_sk is not None else 0\n",
    "\n",
    "    df_joined_profile = (\n",
    "        df_user_profile_source.alias(\"s\")\n",
    "        .join(\n",
    "            df_dim_profile_current.alias(\"t\"),\n",
    "            on=\"profile_id\",\n",
    "            how=\"left\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Existing profiles -> reuse profile_sk\n",
    "    df_profile_existing = (\n",
    "        df_joined_profile\n",
    "        .filter(F.col(\"t.profile_sk\").isNotNull())\n",
    "        .select(\n",
    "            F.col(\"t.profile_sk\").alias(\"profile_sk\"),\n",
    "            *[F.col(f\"s.{c}\").alias(c) for c in PROFILE_BUSINESS_COLUMNS]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # New profiles -> generate new SKs\n",
    "    df_profile_new = df_joined_profile.filter(F.col(\"t.profile_sk\").isNull())\n",
    "\n",
    "    w_new_profiles = Window.orderBy(F.col(\"s.profile_id\"))\n",
    "\n",
    "    df_profile_new_with_sk = (\n",
    "        df_profile_new\n",
    "        .withColumn(\n",
    "            \"profile_sk\",\n",
    "            F.row_number().over(w_new_profiles) + F.lit(max_sk)\n",
    "        )\n",
    "        .select(\n",
    "            F.col(\"profile_sk\"),\n",
    "            *[F.col(f\"s.{c}\").alias(c) for c in PROFILE_BUSINESS_COLUMNS]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    df_user_profile_silver = df_profile_existing.unionByName(df_profile_new_with_sk)\n",
    "\n",
    "else:\n",
    "    w_initial_profiles = Window.orderBy(\"profile_id\")\n",
    "\n",
    "    df_user_profile_silver = (\n",
    "        df_user_profile_source\n",
    "        .withColumn(\"profile_sk\", F.row_number().over(w_initial_profiles))\n",
    "        .select(\n",
    "            \"profile_sk\",\n",
    "            *PROFILE_BUSINESS_COLUMNS\n",
    "        )\n",
    "    )\n",
    "\n",
    "print(\">> [dim_user_profile] Preview of df_user_profile_silver (with profile_sk):\")\n",
    "df_user_profile_silver.printSchema()\n",
    "df_user_profile_silver.show(10, truncate=False)\n",
    "\n",
    "# ============================================================\n",
    "# 3. Upsert into Silver using Delta MERGE (SQL)\n",
    "# ============================================================\n",
    "if dim_profile_exists:\n",
    "    print(\">> [dim_user_profile] Registering staging view and running MERGE...\")\n",
    "\n",
    "    df_user_profile_silver.createOrReplaceTempView(\"stg_dim_user_profile\")\n",
    "\n",
    "    spark.sql(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {dim_profile_table_name}\n",
    "        USING delta\n",
    "        LOCATION '{silver_profile_path}'\n",
    "    \"\"\")\n",
    "\n",
    "    spark.sql(f\"\"\"\n",
    "        MERGE INTO {dim_profile_table_name} AS t\n",
    "        USING stg_dim_user_profile AS s\n",
    "        ON t.profile_id = s.profile_id\n",
    "        WHEN MATCHED THEN UPDATE SET\n",
    "            t.user_id            = s.user_id,\n",
    "            t.year_of_birth      = s.year_of_birth,\n",
    "            t.age_band           = s.age_band,\n",
    "            t.gender             = s.gender,\n",
    "            t.country            = s.country,\n",
    "            t.city               = s.city,\n",
    "            t.location           = s.location,\n",
    "            t.level_of_education = s.level_of_education,\n",
    "            t.language           = s.language,\n",
    "            t.courseware         = s.courseware,\n",
    "            t.phone_number       = s.phone_number,\n",
    "            t.state              = s.state,\n",
    "            t.ingestion_date     = s.ingestion_date,\n",
    "            t.source_name        = s.source_name\n",
    "        WHEN NOT MATCHED THEN INSERT (\n",
    "            profile_sk,\n",
    "            profile_id,\n",
    "            user_id,\n",
    "            year_of_birth,\n",
    "            age_band,\n",
    "            gender,\n",
    "            country,\n",
    "            city,\n",
    "            location,\n",
    "            level_of_education,\n",
    "            language,\n",
    "            courseware,\n",
    "            phone_number,\n",
    "            state,\n",
    "            ingestion_date,\n",
    "            source_name\n",
    "        )\n",
    "        VALUES (\n",
    "            s.profile_sk,\n",
    "            s.profile_id,\n",
    "            s.user_id,\n",
    "            s.year_of_birth,\n",
    "            s.age_band,\n",
    "            s.gender,\n",
    "            s.country,\n",
    "            s.city,\n",
    "            s.location,\n",
    "            s.level_of_education,\n",
    "            s.language,\n",
    "            s.courseware,\n",
    "            s.phone_number,\n",
    "            s.state,\n",
    "            s.ingestion_date,\n",
    "            s.source_name\n",
    "        )\n",
    "    \"\"\")\n",
    "else:\n",
    "    print(\">> [dim_user_profile] Writing initial Silver Delta table (overwrite).\")\n",
    "\n",
    "    (\n",
    "        df_user_profile_silver\n",
    "            .write\n",
    "            .format(\"delta\")\n",
    "            .mode(\"overwrite\")\n",
    "            .option(\"overwriteSchema\", \"true\")\n",
    "            .save(silver_profile_path)\n",
    "    )\n",
    "\n",
    "    spark.sql(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {dim_profile_table_name}\n",
    "        USING delta\n",
    "        LOCATION '{silver_profile_path}'\n",
    "    \"\"\")\n",
    "\n",
    "print(\">> [dim_user_profile] Load/MERGE finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a6d3644-546a-401b-b26e-a039a59f601f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> [dim_user_profile] Reading Silver Delta table from path:\n",
      "   s3a://nau-local-analytics-silver/dim_user_profile\n",
      "\n",
      ">> [dim_user_profile] Schema:\n",
      "root\n",
      " |-- profile_sk: integer (nullable = true)\n",
      " |-- profile_id: integer (nullable = true)\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- year_of_birth: integer (nullable = true)\n",
      " |-- age_band: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- level_of_education: string (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- courseware: string (nullable = true)\n",
      " |-- phone_number: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- ingestion_date: timestamp (nullable = true)\n",
      " |-- source_name: string (nullable = true)\n",
      "\n",
      ">> [dim_user_profile] Sample rows:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/13 16:17:30 INFO PrepareDeltaScan: DELTA: Filtering files for query\n",
      "25/11/13 16:17:30 INFO Snapshot: [tableId=cecff036-318c-4ebc-be9d-1081081bfefa] DELTA: Compute snapshot for version: 0\n",
      "25/11/13 16:17:30 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 202.5 KiB, free 1047.8 MiB)\n",
      "25/11/13 16:17:30 INFO BlockManagerInfo: Removed broadcast_35_piece0 on jupyter-spark-758b7c86d8-7j77n:32921 in memory (size: 35.5 KiB, free: 1048.7 MiB)\n",
      "25/11/13 16:17:30 INFO BlockManagerInfo: Removed broadcast_36_piece0 on jupyter-spark-758b7c86d8-7j77n:32921 in memory (size: 17.1 KiB, free: 1048.7 MiB)\n",
      "25/11/13 16:17:30 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 35.5 KiB, free 1048.1 MiB)\n",
      "25/11/13 16:17:30 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 35.5 KiB, free: 1048.7 MiB)\n",
      "25/11/13 16:17:30 INFO SparkContext: Created broadcast 37 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128\n",
      "25/11/13 16:17:31 INFO DataSourceStrategy: Pruning directories with: \n",
      "25/11/13 16:17:31 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/11/13 16:17:31 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/11/13 16:17:31 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 202.9 KiB, free 1047.9 MiB)\n",
      "25/11/13 16:17:31 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 35.5 KiB, free 1047.9 MiB)\n",
      "25/11/13 16:17:31 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 35.5 KiB, free: 1048.7 MiB)\n",
      "25/11/13 16:17:31 INFO SparkContext: Created broadcast 38 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128\n",
      "25/11/13 16:17:31 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/11/13 16:17:31 INFO DAGScheduler: Registering RDD 99 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 4\n",
      "25/11/13 16:17:31 INFO DAGScheduler: Got map stage job 24 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions\n",
      "25/11/13 16:17:31 INFO DAGScheduler: Final stage: ShuffleMapStage 36 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)\n",
      "25/11/13 16:17:31 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/11/13 16:17:31 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 16:17:31 INFO DAGScheduler: Submitting ShuffleMapStage 36 (MapPartitionsRDD[99] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents\n",
      "25/11/13 16:17:31 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 105.9 KiB, free 1047.8 MiB)\n",
      "25/11/13 16:17:31 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 32.7 KiB, free 1047.7 MiB)\n",
      "25/11/13 16:17:31 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 32.7 KiB, free: 1048.6 MiB)\n",
      "25/11/13 16:17:31 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 16:17:31 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[99] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))\n",
      "25/11/13 16:17:31 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks resource profile 0\n",
      "25/11/13 16:17:31 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 467) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 9688 bytes) \n",
      "25/11/13 16:17:31 INFO Executor: Running task 0.0 in stage 36.0 (TID 467)\n",
      "25/11/13 16:17:31 INFO FileScanRDD: Reading File path: s3a://nau-local-analytics-silver/dim_user_profile/_delta_log/00000000000000000000.json, range: 0-3824, partition values: [0]\n",
      "25/11/13 16:17:31 INFO Executor: Finished task 0.0 in stage 36.0 (TID 467). 1897 bytes result sent to driver\n",
      "25/11/13 16:17:31 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 467) in 175 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/1)\n",
      "25/11/13 16:17:31 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool \n",
      "25/11/13 16:17:31 INFO DAGScheduler: ShuffleMapStage 36 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.191 s\n",
      "25/11/13 16:17:31 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/11/13 16:17:31 INFO DAGScheduler: running: Set()\n",
      "25/11/13 16:17:31 INFO DAGScheduler: waiting: Set()\n",
      "25/11/13 16:17:31 INFO DAGScheduler: failed: Set()\n",
      "25/11/13 16:17:32 INFO DAGScheduler: Registering RDD 109 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 5\n",
      "25/11/13 16:17:32 INFO DAGScheduler: Got map stage job 25 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions\n",
      "25/11/13 16:17:32 INFO DAGScheduler: Final stage: ShuffleMapStage 38 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)\n",
      "25/11/13 16:17:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 37)\n",
      "25/11/13 16:17:32 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 16:17:32 INFO DAGScheduler: Submitting ShuffleMapStage 38 (MapPartitionsRDD[109] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents\n",
      "25/11/13 16:17:32 INFO BlockManagerInfo: Removed broadcast_39_piece0 on jupyter-spark-758b7c86d8-7j77n:32921 in memory (size: 32.7 KiB, free: 1048.7 MiB)\n",
      "25/11/13 16:17:32 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 603.3 KiB, free 1047.3 MiB)\n",
      "25/11/13 16:17:32 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 138.2 KiB, free 1047.1 MiB)\n",
      "25/11/13 16:17:32 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 138.2 KiB, free: 1048.5 MiB)\n",
      "25/11/13 16:17:32 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 16:17:32 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[109] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n",
      "25/11/13 16:17:32 INFO TaskSchedulerImpl: Adding task set 38.0 with 50 tasks resource profile 0\n",
      "25/11/13 16:17:32 INFO TaskSetManager: Starting task 20.0 in stage 38.0 (TID 468) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 20, NODE_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:32 INFO TaskSetManager: Starting task 42.0 in stage 38.0 (TID 469) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 42, NODE_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:32 INFO Executor: Running task 20.0 in stage 38.0 (TID 468)\n",
      "25/11/13 16:17:32 INFO Executor: Running task 42.0 in stage 38.0 (TID 469)\n",
      "25/11/13 16:17:32 INFO ShuffleBlockFetcherIterator: Getting 1 (717.0 B) non-empty blocks including 1 (717.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 21 ms\n",
      "25/11/13 16:17:32 INFO ShuffleBlockFetcherIterator: Getting 1 (1051.0 B) non-empty blocks including 1 (1051.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:32 INFO MemoryStore: Block rdd_106_20 stored as values in memory (estimated size 777.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:32 INFO BlockManagerInfo: Added rdd_106_20 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 777.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:32 INFO MemoryStore: Block rdd_106_42 stored as values in memory (estimated size 775.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:32 INFO BlockManagerInfo: Added rdd_106_42 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 775.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:32 INFO Executor: Finished task 20.0 in stage 38.0 (TID 468). 5364 bytes result sent to driver\n",
      "25/11/13 16:17:32 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 470) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:32 INFO TaskSetManager: Finished task 20.0 in stage 38.0 (TID 468) in 272 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/50)\n",
      "25/11/13 16:17:32 INFO Executor: Running task 0.0 in stage 38.0 (TID 470)\n",
      "25/11/13 16:17:32 INFO Executor: Finished task 42.0 in stage 38.0 (TID 469). 5321 bytes result sent to driver\n",
      "25/11/13 16:17:32 INFO TaskSetManager: Starting task 1.0 in stage 38.0 (TID 471) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 1, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:32 INFO Executor: Running task 1.0 in stage 38.0 (TID 471)\n",
      "25/11/13 16:17:32 INFO TaskSetManager: Finished task 42.0 in stage 38.0 (TID 469) in 287 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (2/50)\n",
      "25/11/13 16:17:32 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:32 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/11/13 16:17:32 INFO MemoryStore: Block rdd_106_1 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:32 INFO BlockManagerInfo: Added rdd_106_1 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:33 INFO MemoryStore: Block rdd_106_0 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:33 INFO BlockManagerInfo: Added rdd_106_0 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:33 INFO Executor: Finished task 1.0 in stage 38.0 (TID 471). 5364 bytes result sent to driver\n",
      "25/11/13 16:17:33 INFO TaskSetManager: Starting task 2.0 in stage 38.0 (TID 472) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 2, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:33 INFO TaskSetManager: Finished task 1.0 in stage 38.0 (TID 471) in 295 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (3/50)\n",
      "25/11/13 16:17:33 INFO Executor: Running task 2.0 in stage 38.0 (TID 472)\n",
      "25/11/13 16:17:33 INFO Executor: Finished task 0.0 in stage 38.0 (TID 470). 5364 bytes result sent to driver\n",
      "25/11/13 16:17:33 INFO TaskSetManager: Starting task 3.0 in stage 38.0 (TID 473) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 3, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:33 INFO Executor: Running task 3.0 in stage 38.0 (TID 473)\n",
      "25/11/13 16:17:33 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 470) in 362 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (4/50)\n",
      "25/11/13 16:17:33 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:33 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/11/13 16:17:33 INFO MemoryStore: Block rdd_106_2 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:33 INFO BlockManagerInfo: Added rdd_106_2 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:33 INFO MemoryStore: Block rdd_106_3 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:33 INFO BlockManagerInfo: Added rdd_106_3 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:33 INFO Executor: Finished task 2.0 in stage 38.0 (TID 472). 5364 bytes result sent to driver\n",
      "25/11/13 16:17:33 INFO TaskSetManager: Starting task 4.0 in stage 38.0 (TID 474) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 4, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:33 INFO Executor: Running task 4.0 in stage 38.0 (TID 474)\n",
      "25/11/13 16:17:33 INFO TaskSetManager: Finished task 2.0 in stage 38.0 (TID 472) in 299 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (5/50)\n",
      "25/11/13 16:17:33 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:33 INFO Executor: Finished task 3.0 in stage 38.0 (TID 473). 5364 bytes result sent to driver\n",
      "25/11/13 16:17:33 INFO TaskSetManager: Starting task 5.0 in stage 38.0 (TID 475) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 5, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:33 INFO Executor: Running task 5.0 in stage 38.0 (TID 475)\n",
      "25/11/13 16:17:33 INFO TaskSetManager: Finished task 3.0 in stage 38.0 (TID 473) in 302 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (6/50)\n",
      "25/11/13 16:17:33 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:33 INFO MemoryStore: Block rdd_106_4 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:33 INFO BlockManagerInfo: Added rdd_106_4 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:33 INFO MemoryStore: Block rdd_106_5 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:33 INFO BlockManagerInfo: Added rdd_106_5 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:33 INFO Executor: Finished task 4.0 in stage 38.0 (TID 474). 5321 bytes result sent to driver\n",
      "25/11/13 16:17:33 INFO TaskSetManager: Starting task 6.0 in stage 38.0 (TID 476) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 6, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:33 INFO TaskSetManager: Finished task 4.0 in stage 38.0 (TID 474) in 289 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (7/50)\n",
      "25/11/13 16:17:33 INFO Executor: Running task 6.0 in stage 38.0 (TID 476)\n",
      "25/11/13 16:17:33 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:33 INFO Executor: Finished task 5.0 in stage 38.0 (TID 475). 5364 bytes result sent to driver\n",
      "25/11/13 16:17:33 INFO TaskSetManager: Starting task 7.0 in stage 38.0 (TID 477) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 7, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:33 INFO Executor: Running task 7.0 in stage 38.0 (TID 477)\n",
      "25/11/13 16:17:33 INFO TaskSetManager: Finished task 5.0 in stage 38.0 (TID 475) in 309 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (8/50)\n",
      "25/11/13 16:17:33 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:33 INFO MemoryStore: Block rdd_106_6 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:33 INFO BlockManagerInfo: Added rdd_106_6 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:33 INFO Executor: Finished task 6.0 in stage 38.0 (TID 476). 5321 bytes result sent to driver\n",
      "25/11/13 16:17:34 INFO TaskSetManager: Starting task 8.0 in stage 38.0 (TID 478) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 8, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:34 INFO Executor: Running task 8.0 in stage 38.0 (TID 478)\n",
      "25/11/13 16:17:34 INFO TaskSetManager: Finished task 6.0 in stage 38.0 (TID 476) in 365 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (9/50)\n",
      "25/11/13 16:17:34 INFO MemoryStore: Block rdd_106_7 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:34 INFO BlockManagerInfo: Added rdd_106_7 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:34 INFO Executor: Finished task 7.0 in stage 38.0 (TID 477). 5364 bytes result sent to driver\n",
      "25/11/13 16:17:34 INFO TaskSetManager: Starting task 9.0 in stage 38.0 (TID 479) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 9, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:34 INFO Executor: Running task 9.0 in stage 38.0 (TID 479)\n",
      "25/11/13 16:17:34 INFO TaskSetManager: Finished task 7.0 in stage 38.0 (TID 477) in 393 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (10/50)\n",
      "25/11/13 16:17:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:34 INFO MemoryStore: Block rdd_106_8 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:34 INFO BlockManagerInfo: Added rdd_106_8 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:34 INFO Executor: Finished task 8.0 in stage 38.0 (TID 478). 5364 bytes result sent to driver\n",
      "25/11/13 16:17:34 INFO TaskSetManager: Starting task 10.0 in stage 38.0 (TID 480) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 10, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:34 INFO Executor: Running task 10.0 in stage 38.0 (TID 480)\n",
      "25/11/13 16:17:34 INFO TaskSetManager: Finished task 8.0 in stage 38.0 (TID 478) in 297 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (11/50)\n",
      "25/11/13 16:17:34 INFO MemoryStore: Block rdd_106_9 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:34 INFO BlockManagerInfo: Added rdd_106_9 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:34 INFO Executor: Finished task 9.0 in stage 38.0 (TID 479). 5364 bytes result sent to driver\n",
      "25/11/13 16:17:34 INFO TaskSetManager: Starting task 11.0 in stage 38.0 (TID 481) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 11, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:34 INFO Executor: Running task 11.0 in stage 38.0 (TID 481)\n",
      "25/11/13 16:17:34 INFO TaskSetManager: Finished task 9.0 in stage 38.0 (TID 479) in 342 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (12/50)\n",
      "25/11/13 16:17:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:34 INFO MemoryStore: Block rdd_106_10 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:34 INFO BlockManagerInfo: Added rdd_106_10 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:34 INFO Executor: Finished task 10.0 in stage 38.0 (TID 480). 5321 bytes result sent to driver\n",
      "25/11/13 16:17:34 INFO TaskSetManager: Starting task 12.0 in stage 38.0 (TID 482) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 12, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:34 INFO TaskSetManager: Finished task 10.0 in stage 38.0 (TID 480) in 299 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (13/50)\n",
      "25/11/13 16:17:34 INFO Executor: Running task 12.0 in stage 38.0 (TID 482)\n",
      "25/11/13 16:17:34 INFO MemoryStore: Block rdd_106_11 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:34 INFO BlockManagerInfo: Added rdd_106_11 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:34 INFO Executor: Finished task 11.0 in stage 38.0 (TID 481). 5321 bytes result sent to driver\n",
      "25/11/13 16:17:34 INFO TaskSetManager: Starting task 13.0 in stage 38.0 (TID 483) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 13, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:34 INFO TaskSetManager: Finished task 11.0 in stage 38.0 (TID 481) in 404 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (14/50)\n",
      "25/11/13 16:17:34 INFO Executor: Running task 13.0 in stage 38.0 (TID 483)\n",
      "25/11/13 16:17:34 INFO MemoryStore: Block rdd_106_12 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:34 INFO BlockManagerInfo: Added rdd_106_12 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:34 INFO Executor: Finished task 12.0 in stage 38.0 (TID 482). 5321 bytes result sent to driver\n",
      "25/11/13 16:17:34 INFO TaskSetManager: Starting task 14.0 in stage 38.0 (TID 484) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 14, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:34 INFO Executor: Running task 14.0 in stage 38.0 (TID 484)\n",
      "25/11/13 16:17:34 INFO TaskSetManager: Finished task 12.0 in stage 38.0 (TID 482) in 379 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (15/50)\n",
      "25/11/13 16:17:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:34 INFO MemoryStore: Block rdd_106_13 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:34 INFO BlockManagerInfo: Added rdd_106_13 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:35 INFO Executor: Finished task 13.0 in stage 38.0 (TID 483). 5321 bytes result sent to driver\n",
      "25/11/13 16:17:35 INFO TaskSetManager: Starting task 15.0 in stage 38.0 (TID 485) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 15, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:35 INFO Executor: Running task 15.0 in stage 38.0 (TID 485)\n",
      "25/11/13 16:17:35 INFO TaskSetManager: Finished task 13.0 in stage 38.0 (TID 483) in 246 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (16/50)\n",
      "25/11/13 16:17:35 INFO MemoryStore: Block rdd_106_14 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:35 INFO BlockManagerInfo: Added rdd_106_14 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:35 INFO Executor: Finished task 14.0 in stage 38.0 (TID 484). 5364 bytes result sent to driver\n",
      "25/11/13 16:17:35 INFO TaskSetManager: Starting task 16.0 in stage 38.0 (TID 486) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 16, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:35 INFO Executor: Running task 16.0 in stage 38.0 (TID 486)\n",
      "25/11/13 16:17:35 INFO TaskSetManager: Finished task 14.0 in stage 38.0 (TID 484) in 210 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (17/50)\n",
      "25/11/13 16:17:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/11/13 16:17:35 INFO MemoryStore: Block rdd_106_15 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:35 INFO BlockManagerInfo: Added rdd_106_15 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:35 INFO MemoryStore: Block rdd_106_16 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:35 INFO BlockManagerInfo: Added rdd_106_16 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:35 INFO Executor: Finished task 15.0 in stage 38.0 (TID 485). 5364 bytes result sent to driver\n",
      "25/11/13 16:17:35 INFO TaskSetManager: Starting task 17.0 in stage 38.0 (TID 487) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 17, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:35 INFO Executor: Running task 17.0 in stage 38.0 (TID 487)\n",
      "25/11/13 16:17:35 INFO TaskSetManager: Finished task 15.0 in stage 38.0 (TID 485) in 246 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (18/50)\n",
      "25/11/13 16:17:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:35 INFO Executor: Finished task 16.0 in stage 38.0 (TID 486). 5364 bytes result sent to driver\n",
      "25/11/13 16:17:35 INFO TaskSetManager: Starting task 18.0 in stage 38.0 (TID 488) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 18, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:35 INFO Executor: Running task 18.0 in stage 38.0 (TID 488)\n",
      "25/11/13 16:17:35 INFO TaskSetManager: Finished task 16.0 in stage 38.0 (TID 486) in 204 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (19/50)\n",
      "25/11/13 16:17:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:35 INFO MemoryStore: Block rdd_106_17 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:35 INFO BlockManagerInfo: Added rdd_106_17 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:35 INFO MemoryStore: Block rdd_106_18 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:35 INFO BlockManagerInfo: Added rdd_106_18 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:35 INFO Executor: Finished task 17.0 in stage 38.0 (TID 487). 5321 bytes result sent to driver\n",
      "25/11/13 16:17:35 INFO TaskSetManager: Starting task 19.0 in stage 38.0 (TID 489) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 19, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:35 INFO Executor: Running task 19.0 in stage 38.0 (TID 489)\n",
      "25/11/13 16:17:35 INFO TaskSetManager: Finished task 17.0 in stage 38.0 (TID 487) in 194 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (20/50)\n",
      "25/11/13 16:17:35 INFO Executor: Finished task 18.0 in stage 38.0 (TID 488). 5321 bytes result sent to driver\n",
      "25/11/13 16:17:35 INFO TaskSetManager: Starting task 21.0 in stage 38.0 (TID 490) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 21, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:35 INFO TaskSetManager: Finished task 18.0 in stage 38.0 (TID 488) in 165 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (21/50)\n",
      "25/11/13 16:17:35 INFO Executor: Running task 21.0 in stage 38.0 (TID 490)\n",
      "25/11/13 16:17:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:35 INFO MemoryStore: Block rdd_106_19 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:35 INFO BlockManagerInfo: Added rdd_106_19 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:35 INFO MemoryStore: Block rdd_106_21 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:35 INFO BlockManagerInfo: Added rdd_106_21 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:35 INFO Executor: Finished task 19.0 in stage 38.0 (TID 489). 5321 bytes result sent to driver\n",
      "25/11/13 16:17:35 INFO TaskSetManager: Starting task 22.0 in stage 38.0 (TID 491) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 22, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:35 INFO Executor: Running task 22.0 in stage 38.0 (TID 491)\n",
      "25/11/13 16:17:35 INFO TaskSetManager: Finished task 19.0 in stage 38.0 (TID 489) in 195 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (22/50)\n",
      "25/11/13 16:17:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:35 INFO Executor: Finished task 21.0 in stage 38.0 (TID 490). 5321 bytes result sent to driver\n",
      "25/11/13 16:17:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 23 ms\n",
      "25/11/13 16:17:35 INFO TaskSetManager: Starting task 23.0 in stage 38.0 (TID 492) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 23, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:35 INFO TaskSetManager: Finished task 21.0 in stage 38.0 (TID 490) in 222 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (23/50)\n",
      "25/11/13 16:17:35 INFO Executor: Running task 23.0 in stage 38.0 (TID 492)\n",
      "25/11/13 16:17:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:35 INFO MemoryStore: Block rdd_106_22 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:35 INFO BlockManagerInfo: Added rdd_106_22 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:35 INFO MemoryStore: Block rdd_106_23 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:35 INFO BlockManagerInfo: Added rdd_106_23 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:35 INFO Executor: Finished task 22.0 in stage 38.0 (TID 491). 5364 bytes result sent to driver\n",
      "25/11/13 16:17:35 INFO TaskSetManager: Starting task 24.0 in stage 38.0 (TID 493) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 24, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:35 INFO Executor: Running task 24.0 in stage 38.0 (TID 493)\n",
      "25/11/13 16:17:35 INFO TaskSetManager: Finished task 22.0 in stage 38.0 (TID 491) in 231 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (24/50)\n",
      "25/11/13 16:17:35 INFO Executor: Finished task 23.0 in stage 38.0 (TID 492). 5364 bytes result sent to driver\n",
      "25/11/13 16:17:35 INFO TaskSetManager: Starting task 25.0 in stage 38.0 (TID 494) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 25, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:35 INFO Executor: Running task 25.0 in stage 38.0 (TID 494)\n",
      "25/11/13 16:17:35 INFO TaskSetManager: Finished task 23.0 in stage 38.0 (TID 492) in 171 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (25/50)\n",
      "25/11/13 16:17:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:35 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:36 INFO MemoryStore: Block rdd_106_24 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:36 INFO BlockManagerInfo: Added rdd_106_24 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:36 INFO MemoryStore: Block rdd_106_25 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:36 INFO BlockManagerInfo: Added rdd_106_25 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:36 INFO Executor: Finished task 25.0 in stage 38.0 (TID 494). 5321 bytes result sent to driver\n",
      "25/11/13 16:17:36 INFO TaskSetManager: Starting task 26.0 in stage 38.0 (TID 495) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 26, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:36 INFO Executor: Running task 26.0 in stage 38.0 (TID 495)\n",
      "25/11/13 16:17:36 INFO TaskSetManager: Finished task 25.0 in stage 38.0 (TID 494) in 138 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (26/50)\n",
      "25/11/13 16:17:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:36 INFO Executor: Finished task 24.0 in stage 38.0 (TID 493). 5321 bytes result sent to driver\n",
      "25/11/13 16:17:36 INFO TaskSetManager: Starting task 27.0 in stage 38.0 (TID 496) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 27, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:36 INFO Executor: Running task 27.0 in stage 38.0 (TID 496)\n",
      "25/11/13 16:17:36 INFO TaskSetManager: Finished task 24.0 in stage 38.0 (TID 493) in 170 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (27/50)\n",
      "25/11/13 16:17:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:36 INFO MemoryStore: Block rdd_106_26 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:36 INFO BlockManagerInfo: Added rdd_106_26 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:36 INFO MemoryStore: Block rdd_106_27 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:36 INFO Executor: Finished task 26.0 in stage 38.0 (TID 495). 5321 bytes result sent to driver\n",
      "25/11/13 16:17:36 INFO BlockManagerInfo: Added rdd_106_27 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:36 INFO TaskSetManager: Starting task 28.0 in stage 38.0 (TID 497) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 28, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:36 INFO TaskSetManager: Finished task 26.0 in stage 38.0 (TID 495) in 207 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (28/50)\n",
      "25/11/13 16:17:36 INFO Executor: Running task 28.0 in stage 38.0 (TID 497)\n",
      "25/11/13 16:17:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:36 INFO Executor: Finished task 27.0 in stage 38.0 (TID 496). 5364 bytes result sent to driver\n",
      "25/11/13 16:17:36 INFO TaskSetManager: Starting task 29.0 in stage 38.0 (TID 498) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 29, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:36 INFO TaskSetManager: Finished task 27.0 in stage 38.0 (TID 496) in 250 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (29/50)\n",
      "25/11/13 16:17:36 INFO Executor: Running task 29.0 in stage 38.0 (TID 498)\n",
      "25/11/13 16:17:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:36 INFO MemoryStore: Block rdd_106_28 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:36 INFO BlockManagerInfo: Added rdd_106_28 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:36 INFO Executor: Finished task 28.0 in stage 38.0 (TID 497). 5321 bytes result sent to driver\n",
      "25/11/13 16:17:36 INFO TaskSetManager: Starting task 30.0 in stage 38.0 (TID 499) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 30, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:36 INFO Executor: Running task 30.0 in stage 38.0 (TID 499)\n",
      "25/11/13 16:17:36 INFO TaskSetManager: Finished task 28.0 in stage 38.0 (TID 497) in 185 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (30/50)\n",
      "25/11/13 16:17:36 INFO MemoryStore: Block rdd_106_29 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:36 INFO BlockManagerInfo: Added rdd_106_29 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:36 INFO Executor: Finished task 29.0 in stage 38.0 (TID 498). 5364 bytes result sent to driver\n",
      "25/11/13 16:17:36 INFO TaskSetManager: Starting task 31.0 in stage 38.0 (TID 500) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 31, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:36 INFO Executor: Running task 31.0 in stage 38.0 (TID 500)\n",
      "25/11/13 16:17:36 INFO TaskSetManager: Finished task 29.0 in stage 38.0 (TID 498) in 196 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (31/50)\n",
      "25/11/13 16:17:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:36 INFO MemoryStore: Block rdd_106_30 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:36 INFO BlockManagerInfo: Added rdd_106_30 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:36 INFO Executor: Finished task 30.0 in stage 38.0 (TID 499). 5364 bytes result sent to driver\n",
      "25/11/13 16:17:36 INFO TaskSetManager: Starting task 32.0 in stage 38.0 (TID 501) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 32, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:36 INFO Executor: Running task 32.0 in stage 38.0 (TID 501)\n",
      "25/11/13 16:17:36 INFO TaskSetManager: Finished task 30.0 in stage 38.0 (TID 499) in 201 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (32/50)\n",
      "25/11/13 16:17:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:36 INFO MemoryStore: Block rdd_106_31 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:36 INFO BlockManagerInfo: Added rdd_106_31 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:36 INFO Executor: Finished task 31.0 in stage 38.0 (TID 500). 5364 bytes result sent to driver\n",
      "25/11/13 16:17:36 INFO TaskSetManager: Starting task 33.0 in stage 38.0 (TID 502) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 33, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:36 INFO Executor: Running task 33.0 in stage 38.0 (TID 502)\n",
      "25/11/13 16:17:36 INFO TaskSetManager: Finished task 31.0 in stage 38.0 (TID 500) in 250 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (33/50)\n",
      "25/11/13 16:17:36 INFO MemoryStore: Block rdd_106_32 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:36 INFO BlockManagerInfo: Added rdd_106_32 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:36 INFO Executor: Finished task 32.0 in stage 38.0 (TID 501). 5364 bytes result sent to driver\n",
      "25/11/13 16:17:36 INFO TaskSetManager: Starting task 34.0 in stage 38.0 (TID 503) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 34, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:36 INFO Executor: Running task 34.0 in stage 38.0 (TID 503)\n",
      "25/11/13 16:17:36 INFO TaskSetManager: Finished task 32.0 in stage 38.0 (TID 501) in 194 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (34/50)\n",
      "25/11/13 16:17:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:36 INFO MemoryStore: Block rdd_106_33 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:36 INFO BlockManagerInfo: Added rdd_106_33 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:36 INFO MemoryStore: Block rdd_106_34 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:36 INFO BlockManagerInfo: Added rdd_106_34 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:36 INFO Executor: Finished task 33.0 in stage 38.0 (TID 502). 5321 bytes result sent to driver\n",
      "25/11/13 16:17:36 INFO TaskSetManager: Starting task 35.0 in stage 38.0 (TID 504) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 35, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:36 INFO TaskSetManager: Finished task 33.0 in stage 38.0 (TID 502) in 198 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (35/50)\n",
      "25/11/13 16:17:36 INFO Executor: Running task 35.0 in stage 38.0 (TID 504)\n",
      "25/11/13 16:17:36 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:36 INFO Executor: Finished task 34.0 in stage 38.0 (TID 503). 5321 bytes result sent to driver\n",
      "25/11/13 16:17:36 INFO TaskSetManager: Starting task 36.0 in stage 38.0 (TID 505) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 36, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:37 INFO Executor: Running task 36.0 in stage 38.0 (TID 505)\n",
      "25/11/13 16:17:37 INFO TaskSetManager: Finished task 34.0 in stage 38.0 (TID 503) in 169 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (36/50)\n",
      "25/11/13 16:17:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:37 INFO MemoryStore: Block rdd_106_35 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:37 INFO BlockManagerInfo: Added rdd_106_35 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:37 INFO MemoryStore: Block rdd_106_36 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:37 INFO BlockManagerInfo: Added rdd_106_36 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:37 INFO Executor: Finished task 35.0 in stage 38.0 (TID 504). 5321 bytes result sent to driver\n",
      "25/11/13 16:17:37 INFO TaskSetManager: Starting task 37.0 in stage 38.0 (TID 506) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 37, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:37 INFO TaskSetManager: Finished task 35.0 in stage 38.0 (TID 504) in 207 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (37/50)\n",
      "25/11/13 16:17:37 INFO Executor: Running task 37.0 in stage 38.0 (TID 506)\n",
      "25/11/13 16:17:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:37 INFO Executor: Finished task 36.0 in stage 38.0 (TID 505). 5321 bytes result sent to driver\n",
      "25/11/13 16:17:37 INFO TaskSetManager: Starting task 38.0 in stage 38.0 (TID 507) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 38, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:37 INFO Executor: Running task 38.0 in stage 38.0 (TID 507)\n",
      "25/11/13 16:17:37 INFO TaskSetManager: Finished task 36.0 in stage 38.0 (TID 505) in 236 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (38/50)\n",
      "25/11/13 16:17:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:37 INFO MemoryStore: Block rdd_106_37 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:37 INFO BlockManagerInfo: Added rdd_106_37 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:37 INFO MemoryStore: Block rdd_106_38 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:37 INFO BlockManagerInfo: Added rdd_106_38 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:37 INFO Executor: Finished task 37.0 in stage 38.0 (TID 506). 5321 bytes result sent to driver\n",
      "25/11/13 16:17:37 INFO TaskSetManager: Starting task 39.0 in stage 38.0 (TID 508) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 39, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:37 INFO Executor: Running task 39.0 in stage 38.0 (TID 508)\n",
      "25/11/13 16:17:37 INFO TaskSetManager: Finished task 37.0 in stage 38.0 (TID 506) in 194 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (39/50)\n",
      "25/11/13 16:17:37 INFO Executor: Finished task 38.0 in stage 38.0 (TID 507). 5321 bytes result sent to driver\n",
      "25/11/13 16:17:37 INFO TaskSetManager: Starting task 40.0 in stage 38.0 (TID 509) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 40, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:37 INFO TaskSetManager: Finished task 38.0 in stage 38.0 (TID 507) in 154 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (40/50)\n",
      "25/11/13 16:17:37 INFO Executor: Running task 40.0 in stage 38.0 (TID 509)\n",
      "25/11/13 16:17:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:37 INFO MemoryStore: Block rdd_106_39 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:37 INFO BlockManagerInfo: Added rdd_106_39 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:37 INFO MemoryStore: Block rdd_106_40 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:37 INFO BlockManagerInfo: Added rdd_106_40 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:37 INFO Executor: Finished task 39.0 in stage 38.0 (TID 508). 5364 bytes result sent to driver\n",
      "25/11/13 16:17:37 INFO TaskSetManager: Starting task 41.0 in stage 38.0 (TID 510) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 41, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:37 INFO Executor: Running task 41.0 in stage 38.0 (TID 510)\n",
      "25/11/13 16:17:37 INFO TaskSetManager: Finished task 39.0 in stage 38.0 (TID 508) in 197 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (41/50)\n",
      "25/11/13 16:17:37 INFO Executor: Finished task 40.0 in stage 38.0 (TID 509). 5364 bytes result sent to driver\n",
      "25/11/13 16:17:37 INFO TaskSetManager: Starting task 43.0 in stage 38.0 (TID 511) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 43, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:37 INFO TaskSetManager: Finished task 40.0 in stage 38.0 (TID 509) in 190 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (42/50)\n",
      "25/11/13 16:17:37 INFO Executor: Running task 43.0 in stage 38.0 (TID 511)\n",
      "25/11/13 16:17:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:37 INFO MemoryStore: Block rdd_106_41 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:37 INFO BlockManagerInfo: Added rdd_106_41 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:37 INFO MemoryStore: Block rdd_106_43 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:37 INFO BlockManagerInfo: Added rdd_106_43 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:37 INFO Executor: Finished task 41.0 in stage 38.0 (TID 510). 5321 bytes result sent to driver\n",
      "25/11/13 16:17:37 INFO TaskSetManager: Starting task 44.0 in stage 38.0 (TID 512) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 44, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:37 INFO Executor: Running task 44.0 in stage 38.0 (TID 512)\n",
      "25/11/13 16:17:37 INFO TaskSetManager: Finished task 41.0 in stage 38.0 (TID 510) in 168 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (43/50)\n",
      "25/11/13 16:17:37 INFO Executor: Finished task 43.0 in stage 38.0 (TID 511). 5321 bytes result sent to driver\n",
      "25/11/13 16:17:37 INFO TaskSetManager: Starting task 45.0 in stage 38.0 (TID 513) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 45, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:37 INFO Executor: Running task 45.0 in stage 38.0 (TID 513)\n",
      "25/11/13 16:17:37 INFO TaskSetManager: Finished task 43.0 in stage 38.0 (TID 511) in 187 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (44/50)\n",
      "25/11/13 16:17:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:37 INFO MemoryStore: Block rdd_106_44 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:37 INFO BlockManagerInfo: Added rdd_106_44 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:37 INFO MemoryStore: Block rdd_106_45 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:37 INFO BlockManagerInfo: Added rdd_106_45 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:37 INFO Executor: Finished task 44.0 in stage 38.0 (TID 512). 5321 bytes result sent to driver\n",
      "25/11/13 16:17:37 INFO TaskSetManager: Starting task 46.0 in stage 38.0 (TID 514) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 46, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:37 INFO Executor: Running task 46.0 in stage 38.0 (TID 514)\n",
      "25/11/13 16:17:37 INFO TaskSetManager: Finished task 44.0 in stage 38.0 (TID 512) in 171 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (45/50)\n",
      "25/11/13 16:17:37 INFO Executor: Finished task 45.0 in stage 38.0 (TID 513). 5321 bytes result sent to driver\n",
      "25/11/13 16:17:37 INFO TaskSetManager: Starting task 47.0 in stage 38.0 (TID 515) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 47, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:37 INFO Executor: Running task 47.0 in stage 38.0 (TID 515)\n",
      "25/11/13 16:17:37 INFO TaskSetManager: Finished task 45.0 in stage 38.0 (TID 513) in 185 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (46/50)\n",
      "25/11/13 16:17:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:38 INFO MemoryStore: Block rdd_106_46 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:38 INFO BlockManagerInfo: Added rdd_106_46 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:38 INFO MemoryStore: Block rdd_106_47 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:38 INFO BlockManagerInfo: Added rdd_106_47 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:38 INFO Executor: Finished task 46.0 in stage 38.0 (TID 514). 5364 bytes result sent to driver\n",
      "25/11/13 16:17:38 INFO TaskSetManager: Starting task 48.0 in stage 38.0 (TID 516) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 48, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:38 INFO Executor: Running task 48.0 in stage 38.0 (TID 516)\n",
      "25/11/13 16:17:38 INFO TaskSetManager: Finished task 46.0 in stage 38.0 (TID 514) in 179 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (47/50)\n",
      "25/11/13 16:17:38 INFO Executor: Finished task 47.0 in stage 38.0 (TID 515). 5321 bytes result sent to driver\n",
      "25/11/13 16:17:38 INFO TaskSetManager: Starting task 49.0 in stage 38.0 (TID 517) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 49, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:38 INFO Executor: Running task 49.0 in stage 38.0 (TID 517)\n",
      "25/11/13 16:17:38 INFO TaskSetManager: Finished task 47.0 in stage 38.0 (TID 515) in 161 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (48/50)\n",
      "25/11/13 16:17:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:38 INFO MemoryStore: Block rdd_106_48 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:38 INFO BlockManagerInfo: Added rdd_106_48 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:38 INFO MemoryStore: Block rdd_106_49 stored as values in memory (estimated size 46.0 B, free 1047.1 MiB)\n",
      "25/11/13 16:17:38 INFO BlockManagerInfo: Added rdd_106_49 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:38 INFO Executor: Finished task 48.0 in stage 38.0 (TID 516). 5364 bytes result sent to driver\n",
      "25/11/13 16:17:38 INFO TaskSetManager: Finished task 48.0 in stage 38.0 (TID 516) in 157 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (49/50)\n",
      "25/11/13 16:17:38 INFO Executor: Finished task 49.0 in stage 38.0 (TID 517). 5364 bytes result sent to driver\n",
      "25/11/13 16:17:38 INFO TaskSetManager: Finished task 49.0 in stage 38.0 (TID 517) in 217 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (50/50)\n",
      "25/11/13 16:17:38 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool \n",
      "25/11/13 16:17:38 INFO DAGScheduler: ShuffleMapStage 38 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 6.029 s\n",
      "25/11/13 16:17:38 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/11/13 16:17:38 INFO DAGScheduler: running: Set()\n",
      "25/11/13 16:17:38 INFO DAGScheduler: waiting: Set()\n",
      "25/11/13 16:17:38 INFO DAGScheduler: failed: Set()\n",
      "25/11/13 16:17:38 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128\n",
      "25/11/13 16:17:38 INFO DAGScheduler: Got job 26 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions\n",
      "25/11/13 16:17:38 INFO DAGScheduler: Final stage: ResultStage 41 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)\n",
      "25/11/13 16:17:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 40)\n",
      "25/11/13 16:17:38 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 16:17:38 INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[112] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents\n",
      "25/11/13 16:17:38 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 534.4 KiB, free 1046.6 MiB)\n",
      "25/11/13 16:17:38 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 124.9 KiB, free 1046.5 MiB)\n",
      "25/11/13 16:17:38 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 124.9 KiB, free: 1048.4 MiB)\n",
      "25/11/13 16:17:38 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 16:17:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[112] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))\n",
      "25/11/13 16:17:38 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks resource profile 0\n",
      "25/11/13 16:17:38 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 518) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, NODE_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:38 INFO Executor: Running task 0.0 in stage 41.0 (TID 518)\n",
      "25/11/13 16:17:38 INFO ShuffleBlockFetcherIterator: Getting 50 (4.9 KiB) non-empty blocks including 50 (4.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/11/13 16:17:38 INFO Executor: Finished task 0.0 in stage 41.0 (TID 518). 7168 bytes result sent to driver\n",
      "25/11/13 16:17:38 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 518) in 73 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/1)\n",
      "25/11/13 16:17:38 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool \n",
      "25/11/13 16:17:38 INFO DAGScheduler: ResultStage 41 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.093 s\n",
      "25/11/13 16:17:38 INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/11/13 16:17:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 41: Stage finished\n",
      "25/11/13 16:17:38 INFO DAGScheduler: Job 26 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.103968 s\n",
      "25/11/13 16:17:38 INFO Snapshot: [tableId=cecff036-318c-4ebc-be9d-1081081bfefa] DELTA: Done\n",
      "25/11/13 16:17:38 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128\n",
      "25/11/13 16:17:38 INFO DAGScheduler: Got job 27 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions\n",
      "25/11/13 16:17:38 INFO DAGScheduler: Final stage: ResultStage 43 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)\n",
      "25/11/13 16:17:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 42)\n",
      "25/11/13 16:17:38 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 16:17:38 INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[114] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents\n",
      "25/11/13 16:17:38 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 684.9 KiB, free 1045.8 MiB)\n",
      "25/11/13 16:17:38 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 154.5 KiB, free 1045.7 MiB)\n",
      "25/11/13 16:17:38 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 154.5 KiB, free: 1048.2 MiB)\n",
      "25/11/13 16:17:38 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 16:17:38 INFO DAGScheduler: Submitting 50 missing tasks from ResultStage 43 (MapPartitionsRDD[114] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n",
      "25/11/13 16:17:38 INFO TaskSchedulerImpl: Adding task set 43.0 with 50 tasks resource profile 0\n",
      "25/11/13 16:17:38 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 519) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:38 INFO TaskSetManager: Starting task 1.0 in stage 43.0 (TID 520) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 1, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:38 INFO Executor: Running task 0.0 in stage 43.0 (TID 519)\n",
      "25/11/13 16:17:38 INFO Executor: Running task 1.0 in stage 43.0 (TID 520)\n",
      "25/11/13 16:17:38 INFO BlockManager: Found block rdd_106_0 locally\n",
      "25/11/13 16:17:38 INFO BlockManager: Found block rdd_106_1 locally\n",
      "25/11/13 16:17:38 INFO Executor: Finished task 0.0 in stage 43.0 (TID 519). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:38 INFO TaskSetManager: Starting task 2.0 in stage 43.0 (TID 521) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 2, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:38 INFO Executor: Finished task 1.0 in stage 43.0 (TID 520). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:38 INFO Executor: Running task 2.0 in stage 43.0 (TID 521)\n",
      "25/11/13 16:17:38 INFO TaskSetManager: Starting task 3.0 in stage 43.0 (TID 522) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 3, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:38 INFO Executor: Running task 3.0 in stage 43.0 (TID 522)\n",
      "25/11/13 16:17:38 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 519) in 43 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/50)\n",
      "25/11/13 16:17:38 INFO TaskSetManager: Finished task 1.0 in stage 43.0 (TID 520) in 44 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (2/50)\n",
      "25/11/13 16:17:38 INFO BlockManager: Found block rdd_106_2 locally\n",
      "25/11/13 16:17:38 INFO BlockManager: Found block rdd_106_3 locally\n",
      "25/11/13 16:17:38 INFO Executor: Finished task 2.0 in stage 43.0 (TID 521). 4224 bytes result sent to driver\n",
      "25/11/13 16:17:38 INFO TaskSetManager: Starting task 4.0 in stage 43.0 (TID 523) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 4, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:38 INFO Executor: Running task 4.0 in stage 43.0 (TID 523)\n",
      "25/11/13 16:17:38 INFO Executor: Finished task 3.0 in stage 43.0 (TID 522). 4224 bytes result sent to driver\n",
      "25/11/13 16:17:38 INFO TaskSetManager: Starting task 5.0 in stage 43.0 (TID 524) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 5, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:38 INFO TaskSetManager: Finished task 3.0 in stage 43.0 (TID 522) in 20 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (3/50)\n",
      "25/11/13 16:17:38 INFO Executor: Running task 5.0 in stage 43.0 (TID 524)\n",
      "25/11/13 16:17:38 INFO TaskSetManager: Finished task 2.0 in stage 43.0 (TID 521) in 23 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (4/50)\n",
      "25/11/13 16:17:38 INFO BlockManager: Found block rdd_106_4 locally\n",
      "25/11/13 16:17:38 INFO Executor: Finished task 4.0 in stage 43.0 (TID 523). 4224 bytes result sent to driver\n",
      "25/11/13 16:17:38 INFO TaskSetManager: Starting task 6.0 in stage 43.0 (TID 525) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 6, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:38 INFO TaskSetManager: Finished task 4.0 in stage 43.0 (TID 523) in 77 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (5/50)\n",
      "25/11/13 16:17:38 INFO Executor: Running task 6.0 in stage 43.0 (TID 525)\n",
      "25/11/13 16:17:38 INFO BlockManager: Found block rdd_106_5 locally\n",
      "25/11/13 16:17:38 INFO BlockManagerInfo: Removed broadcast_41_piece0 on jupyter-spark-758b7c86d8-7j77n:32921 in memory (size: 124.9 KiB, free: 1048.4 MiB)\n",
      "25/11/13 16:17:38 INFO Executor: Finished task 5.0 in stage 43.0 (TID 524). 4224 bytes result sent to driver\n",
      "25/11/13 16:17:38 INFO TaskSetManager: Starting task 7.0 in stage 43.0 (TID 526) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 7, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:38 INFO Executor: Running task 7.0 in stage 43.0 (TID 526)\n",
      "25/11/13 16:17:38 INFO TaskSetManager: Finished task 5.0 in stage 43.0 (TID 524) in 88 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (6/50)\n",
      "25/11/13 16:17:38 INFO BlockManager: Found block rdd_106_6 locally\n",
      "25/11/13 16:17:38 INFO BlockManagerInfo: Removed broadcast_40_piece0 on jupyter-spark-758b7c86d8-7j77n:32921 in memory (size: 138.2 KiB, free: 1048.5 MiB)\n",
      "25/11/13 16:17:38 INFO Executor: Finished task 6.0 in stage 43.0 (TID 525). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:38 INFO TaskSetManager: Starting task 8.0 in stage 43.0 (TID 527) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 8, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:38 INFO Executor: Running task 8.0 in stage 43.0 (TID 527)\n",
      "25/11/13 16:17:38 INFO TaskSetManager: Finished task 6.0 in stage 43.0 (TID 525) in 23 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (7/50)\n",
      "25/11/13 16:17:39 INFO BlockManager: Found block rdd_106_7 locally\n",
      "25/11/13 16:17:39 INFO Executor: Finished task 7.0 in stage 43.0 (TID 526). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Starting task 9.0 in stage 43.0 (TID 528) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 9, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:39 INFO Executor: Running task 9.0 in stage 43.0 (TID 528)\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Finished task 7.0 in stage 43.0 (TID 526) in 92 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (8/50)\n",
      "25/11/13 16:17:39 INFO BlockManager: Found block rdd_106_8 locally\n",
      "25/11/13 16:17:39 INFO Executor: Finished task 8.0 in stage 43.0 (TID 527). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Starting task 10.0 in stage 43.0 (TID 529) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 10, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:39 INFO BlockManager: Found block rdd_106_9 locally\n",
      "25/11/13 16:17:39 INFO Executor: Running task 10.0 in stage 43.0 (TID 529)\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Finished task 8.0 in stage 43.0 (TID 527) in 96 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (9/50)\n",
      "25/11/13 16:17:39 INFO Executor: Finished task 9.0 in stage 43.0 (TID 528). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Starting task 11.0 in stage 43.0 (TID 530) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 11, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:39 INFO Executor: Running task 11.0 in stage 43.0 (TID 530)\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Finished task 9.0 in stage 43.0 (TID 528) in 46 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (10/50)\n",
      "25/11/13 16:17:39 INFO BlockManager: Found block rdd_106_10 locally\n",
      "25/11/13 16:17:39 INFO Executor: Finished task 10.0 in stage 43.0 (TID 529). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Starting task 12.0 in stage 43.0 (TID 531) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 12, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:39 INFO Executor: Running task 12.0 in stage 43.0 (TID 531)\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Finished task 10.0 in stage 43.0 (TID 529) in 58 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (11/50)\n",
      "25/11/13 16:17:39 INFO BlockManager: Found block rdd_106_11 locally\n",
      "25/11/13 16:17:39 INFO Executor: Finished task 11.0 in stage 43.0 (TID 530). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Starting task 13.0 in stage 43.0 (TID 532) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 13, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:39 INFO TaskSetManager: Finished task 11.0 in stage 43.0 (TID 530) in 92 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (12/50)\n",
      "25/11/13 16:17:39 INFO Executor: Running task 13.0 in stage 43.0 (TID 532)\n",
      "25/11/13 16:17:39 INFO BlockManager: Found block rdd_106_12 locally\n",
      "25/11/13 16:17:39 INFO Executor: Finished task 12.0 in stage 43.0 (TID 531). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Starting task 14.0 in stage 43.0 (TID 533) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 14, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:39 INFO Executor: Running task 14.0 in stage 43.0 (TID 533)\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Finished task 12.0 in stage 43.0 (TID 531) in 50 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (13/50)\n",
      "25/11/13 16:17:39 INFO BlockManager: Found block rdd_106_13 locally\n",
      "25/11/13 16:17:39 INFO Executor: Finished task 13.0 in stage 43.0 (TID 532). 4224 bytes result sent to driver\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Starting task 15.0 in stage 43.0 (TID 534) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 15, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:39 INFO TaskSetManager: Finished task 13.0 in stage 43.0 (TID 532) in 55 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (14/50)\n",
      "25/11/13 16:17:39 INFO Executor: Running task 15.0 in stage 43.0 (TID 534)\n",
      "25/11/13 16:17:39 INFO BlockManager: Found block rdd_106_14 locally\n",
      "25/11/13 16:17:39 INFO Executor: Finished task 14.0 in stage 43.0 (TID 533). 4224 bytes result sent to driver\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Starting task 16.0 in stage 43.0 (TID 535) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 16, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:39 INFO Executor: Running task 16.0 in stage 43.0 (TID 535)\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Finished task 14.0 in stage 43.0 (TID 533) in 82 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (15/50)\n",
      "25/11/13 16:17:39 INFO BlockManager: Found block rdd_106_15 locally\n",
      "25/11/13 16:17:39 INFO Executor: Finished task 15.0 in stage 43.0 (TID 534). 4224 bytes result sent to driver\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Starting task 17.0 in stage 43.0 (TID 536) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 17, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:39 INFO TaskSetManager: Finished task 15.0 in stage 43.0 (TID 534) in 50 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (16/50)\n",
      "25/11/13 16:17:39 INFO BlockManager: Found block rdd_106_16 locally\n",
      "25/11/13 16:17:39 INFO Executor: Running task 17.0 in stage 43.0 (TID 536)\n",
      "25/11/13 16:17:39 INFO Executor: Finished task 16.0 in stage 43.0 (TID 535). 4224 bytes result sent to driver\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Starting task 18.0 in stage 43.0 (TID 537) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 18, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:39 INFO Executor: Running task 18.0 in stage 43.0 (TID 537)\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Finished task 16.0 in stage 43.0 (TID 535) in 22 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (17/50)\n",
      "25/11/13 16:17:39 INFO BlockManager: Found block rdd_106_17 locally\n",
      "25/11/13 16:17:39 INFO BlockManager: Found block rdd_106_18 locally\n",
      "25/11/13 16:17:39 INFO Executor: Finished task 17.0 in stage 43.0 (TID 536). 4224 bytes result sent to driver\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Starting task 19.0 in stage 43.0 (TID 538) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 19, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:39 INFO TaskSetManager: Finished task 17.0 in stage 43.0 (TID 536) in 60 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (18/50)\n",
      "25/11/13 16:17:39 INFO Executor: Running task 19.0 in stage 43.0 (TID 538)\n",
      "25/11/13 16:17:39 INFO Executor: Finished task 18.0 in stage 43.0 (TID 537). 4224 bytes result sent to driver\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Starting task 20.0 in stage 43.0 (TID 539) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 20, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:39 INFO TaskSetManager: Finished task 18.0 in stage 43.0 (TID 537) in 55 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (19/50)\n",
      "25/11/13 16:17:39 INFO Executor: Running task 20.0 in stage 43.0 (TID 539)\n",
      "25/11/13 16:17:39 INFO BlockManager: Found block rdd_106_19 locally18 + 3) / 50]\n",
      "25/11/13 16:17:39 INFO Executor: Finished task 19.0 in stage 43.0 (TID 538). 4224 bytes result sent to driver\n",
      "25/11/13 16:17:39 INFO BlockManager: Found block rdd_106_20 locally\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Starting task 21.0 in stage 43.0 (TID 540) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 21, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:39 INFO TaskSetManager: Finished task 19.0 in stage 43.0 (TID 538) in 45 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (20/50)\n",
      "25/11/13 16:17:39 INFO Executor: Running task 21.0 in stage 43.0 (TID 540)\n",
      "25/11/13 16:17:39 INFO Executor: Finished task 20.0 in stage 43.0 (TID 539). 4389 bytes result sent to driver\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Starting task 22.0 in stage 43.0 (TID 541) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 22, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:39 INFO TaskSetManager: Finished task 20.0 in stage 43.0 (TID 539) in 46 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (21/50)\n",
      "25/11/13 16:17:39 INFO Executor: Running task 22.0 in stage 43.0 (TID 541)\n",
      "25/11/13 16:17:39 INFO BlockManager: Found block rdd_106_21 locally\n",
      "25/11/13 16:17:39 INFO Executor: Finished task 21.0 in stage 43.0 (TID 540). 4224 bytes result sent to driver\n",
      "25/11/13 16:17:39 INFO BlockManager: Found block rdd_106_22 locally\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Starting task 23.0 in stage 43.0 (TID 542) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 23, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:39 INFO Executor: Running task 23.0 in stage 43.0 (TID 542)\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Finished task 21.0 in stage 43.0 (TID 540) in 54 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (22/50)\n",
      "25/11/13 16:17:39 INFO Executor: Finished task 22.0 in stage 43.0 (TID 541). 4224 bytes result sent to driver\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Starting task 24.0 in stage 43.0 (TID 543) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 24, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:39 INFO Executor: Running task 24.0 in stage 43.0 (TID 543)\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Finished task 22.0 in stage 43.0 (TID 541) in 54 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (23/50)\n",
      "25/11/13 16:17:39 INFO BlockManager: Found block rdd_106_23 locally\n",
      "25/11/13 16:17:39 INFO Executor: Finished task 23.0 in stage 43.0 (TID 542). 4224 bytes result sent to driver\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Starting task 25.0 in stage 43.0 (TID 544) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 25, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:39 INFO Executor: Running task 25.0 in stage 43.0 (TID 544)\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Finished task 23.0 in stage 43.0 (TID 542) in 44 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (24/50)\n",
      "25/11/13 16:17:39 INFO BlockManager: Found block rdd_106_24 locally\n",
      "25/11/13 16:17:39 INFO Executor: Finished task 24.0 in stage 43.0 (TID 543). 4224 bytes result sent to driver\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Starting task 26.0 in stage 43.0 (TID 545) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 26, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:39 INFO TaskSetManager: Finished task 24.0 in stage 43.0 (TID 543) in 46 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (25/50)\n",
      "25/11/13 16:17:39 INFO Executor: Running task 26.0 in stage 43.0 (TID 545)\n",
      "25/11/13 16:17:39 INFO BlockManager: Found block rdd_106_25 locally\n",
      "25/11/13 16:17:39 INFO Executor: Finished task 25.0 in stage 43.0 (TID 544). 4224 bytes result sent to driver\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Starting task 27.0 in stage 43.0 (TID 546) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 27, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:39 INFO Executor: Running task 27.0 in stage 43.0 (TID 546)\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Finished task 25.0 in stage 43.0 (TID 544) in 60 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (26/50)\n",
      "25/11/13 16:17:39 INFO BlockManager: Found block rdd_106_26 locally\n",
      "25/11/13 16:17:39 INFO Executor: Finished task 26.0 in stage 43.0 (TID 545). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Starting task 28.0 in stage 43.0 (TID 547) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 28, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:39 INFO TaskSetManager: Finished task 26.0 in stage 43.0 (TID 545) in 58 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (27/50)\n",
      "25/11/13 16:17:39 INFO Executor: Running task 28.0 in stage 43.0 (TID 547)\n",
      "25/11/13 16:17:39 INFO BlockManager: Found block rdd_106_28 locally26 + 2) / 50]\n",
      "25/11/13 16:17:39 INFO BlockManager: Found block rdd_106_27 locally\n",
      "25/11/13 16:17:39 INFO Executor: Finished task 28.0 in stage 43.0 (TID 547). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Starting task 29.0 in stage 43.0 (TID 548) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 29, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:39 INFO Executor: Finished task 27.0 in stage 43.0 (TID 546). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:39 INFO Executor: Running task 29.0 in stage 43.0 (TID 548)\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Starting task 30.0 in stage 43.0 (TID 549) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 30, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:39 INFO TaskSetManager: Finished task 28.0 in stage 43.0 (TID 547) in 147 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (28/50)\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Finished task 27.0 in stage 43.0 (TID 546) in 155 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (29/50)\n",
      "25/11/13 16:17:39 INFO Executor: Running task 30.0 in stage 43.0 (TID 549)\n",
      "25/11/13 16:17:39 INFO BlockManager: Found block rdd_106_30 locally\n",
      "25/11/13 16:17:39 INFO Executor: Finished task 30.0 in stage 43.0 (TID 549). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Starting task 31.0 in stage 43.0 (TID 550) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 31, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:39 INFO TaskSetManager: Finished task 30.0 in stage 43.0 (TID 549) in 20 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (30/50)\n",
      "25/11/13 16:17:39 INFO Executor: Running task 31.0 in stage 43.0 (TID 550)\n",
      "25/11/13 16:17:39 INFO BlockManager: Found block rdd_106_29 locally\n",
      "25/11/13 16:17:39 INFO Executor: Finished task 29.0 in stage 43.0 (TID 548). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Starting task 32.0 in stage 43.0 (TID 551) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 32, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:39 INFO Executor: Running task 32.0 in stage 43.0 (TID 551)\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Finished task 29.0 in stage 43.0 (TID 548) in 51 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (31/50)\n",
      "25/11/13 16:17:39 INFO BlockManager: Found block rdd_106_31 locally\n",
      "25/11/13 16:17:39 INFO Executor: Finished task 31.0 in stage 43.0 (TID 550). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Starting task 33.0 in stage 43.0 (TID 552) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 33, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:39 INFO Executor: Running task 33.0 in stage 43.0 (TID 552)\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Finished task 31.0 in stage 43.0 (TID 550) in 62 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (32/50)\n",
      "25/11/13 16:17:39 INFO BlockManager: Found block rdd_106_32 locally31 + 3) / 50]\n",
      "25/11/13 16:17:39 INFO Executor: Finished task 32.0 in stage 43.0 (TID 551). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Starting task 34.0 in stage 43.0 (TID 553) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 34, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:39 INFO Executor: Running task 34.0 in stage 43.0 (TID 553)\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Finished task 32.0 in stage 43.0 (TID 551) in 44 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (33/50)\n",
      "25/11/13 16:17:39 INFO BlockManager: Found block rdd_106_33 locally\n",
      "25/11/13 16:17:39 INFO Executor: Finished task 33.0 in stage 43.0 (TID 552). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Starting task 35.0 in stage 43.0 (TID 554) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 35, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:39 INFO Executor: Running task 35.0 in stage 43.0 (TID 554)\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Finished task 33.0 in stage 43.0 (TID 552) in 20 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (34/50)\n",
      "25/11/13 16:17:39 INFO BlockManager: Found block rdd_106_34 locally\n",
      "25/11/13 16:17:39 INFO Executor: Finished task 34.0 in stage 43.0 (TID 553). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Starting task 36.0 in stage 43.0 (TID 555) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 36, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:39 INFO Executor: Running task 36.0 in stage 43.0 (TID 555)\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Finished task 34.0 in stage 43.0 (TID 553) in 60 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (35/50)\n",
      "25/11/13 16:17:39 INFO BlockManager: Found block rdd_106_35 locally\n",
      "25/11/13 16:17:39 INFO Executor: Finished task 35.0 in stage 43.0 (TID 554). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Starting task 37.0 in stage 43.0 (TID 556) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 37, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:39 INFO Executor: Running task 37.0 in stage 43.0 (TID 556)\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Finished task 35.0 in stage 43.0 (TID 554) in 82 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (36/50)\n",
      "25/11/13 16:17:39 INFO BlockManager: Found block rdd_106_36 locally\n",
      "25/11/13 16:17:39 INFO Executor: Finished task 36.0 in stage 43.0 (TID 555). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:39 INFO BlockManager: Found block rdd_106_37 locally\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Starting task 38.0 in stage 43.0 (TID 557) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 38, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:39 INFO Executor: Running task 38.0 in stage 43.0 (TID 557)\n",
      "25/11/13 16:17:39 INFO Executor: Finished task 37.0 in stage 43.0 (TID 556). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Starting task 39.0 in stage 43.0 (TID 558) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 39, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:39 INFO Executor: Running task 39.0 in stage 43.0 (TID 558)\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Finished task 36.0 in stage 43.0 (TID 555) in 54 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (37/50)\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Finished task 37.0 in stage 43.0 (TID 556) in 62 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (38/50)\n",
      "25/11/13 16:17:39 INFO BlockManager: Found block rdd_106_39 locally\n",
      "25/11/13 16:17:39 INFO Executor: Finished task 39.0 in stage 43.0 (TID 558). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Starting task 40.0 in stage 43.0 (TID 559) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 40, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:39 INFO Executor: Running task 40.0 in stage 43.0 (TID 559)\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Finished task 39.0 in stage 43.0 (TID 558) in 77 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (39/50)\n",
      "25/11/13 16:17:39 INFO BlockManager: Found block rdd_106_38 locally39 + 2) / 50]\n",
      "25/11/13 16:17:39 INFO Executor: Finished task 38.0 in stage 43.0 (TID 557). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Starting task 41.0 in stage 43.0 (TID 560) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 41, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:39 INFO Executor: Running task 41.0 in stage 43.0 (TID 560)\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Finished task 38.0 in stage 43.0 (TID 557) in 86 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (40/50)\n",
      "25/11/13 16:17:39 INFO BlockManager: Found block rdd_106_41 locally\n",
      "25/11/13 16:17:39 INFO BlockManager: Found block rdd_106_40 locally\n",
      "25/11/13 16:17:39 INFO Executor: Finished task 41.0 in stage 43.0 (TID 560). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Starting task 42.0 in stage 43.0 (TID 561) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 42, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:39 INFO Executor: Running task 42.0 in stage 43.0 (TID 561)\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Finished task 41.0 in stage 43.0 (TID 560) in 17 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (41/50)\n",
      "25/11/13 16:17:39 INFO Executor: Finished task 40.0 in stage 43.0 (TID 559). 4224 bytes result sent to driver\n",
      "25/11/13 16:17:39 INFO TaskSetManager: Starting task 43.0 in stage 43.0 (TID 562) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 43, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:39 INFO Executor: Running task 43.0 in stage 43.0 (TID 562)\n",
      "25/11/13 16:17:40 INFO TaskSetManager: Finished task 40.0 in stage 43.0 (TID 559) in 111 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (42/50)\n",
      "25/11/13 16:17:40 INFO BlockManager: Found block rdd_106_43 locally\n",
      "25/11/13 16:17:40 INFO BlockManager: Found block rdd_106_42 locally\n",
      "25/11/13 16:17:40 INFO Executor: Finished task 43.0 in stage 43.0 (TID 562). 4224 bytes result sent to driver\n",
      "25/11/13 16:17:40 INFO Executor: Finished task 42.0 in stage 43.0 (TID 561). 4267 bytes result sent to driver\n",
      "25/11/13 16:17:40 INFO TaskSetManager: Starting task 44.0 in stage 43.0 (TID 563) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 44, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:40 INFO TaskSetManager: Starting task 45.0 in stage 43.0 (TID 564) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 45, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:40 INFO TaskSetManager: Finished task 43.0 in stage 43.0 (TID 562) in 92 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (43/50)\n",
      "25/11/13 16:17:40 INFO TaskSetManager: Finished task 42.0 in stage 43.0 (TID 561) in 94 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (44/50)\n",
      "25/11/13 16:17:40 INFO Executor: Running task 44.0 in stage 43.0 (TID 563)\n",
      "25/11/13 16:17:40 INFO Executor: Running task 45.0 in stage 43.0 (TID 564)\n",
      "25/11/13 16:17:40 INFO BlockManager: Found block rdd_106_44 locally\n",
      "25/11/13 16:17:40 INFO BlockManager: Found block rdd_106_45 locally\n",
      "25/11/13 16:17:40 INFO Executor: Finished task 45.0 in stage 43.0 (TID 564). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:40 INFO Executor: Finished task 44.0 in stage 43.0 (TID 563). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:40 INFO TaskSetManager: Starting task 46.0 in stage 43.0 (TID 565) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 46, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:40 INFO TaskSetManager: Starting task 47.0 in stage 43.0 (TID 566) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 47, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:40 INFO Executor: Running task 46.0 in stage 43.0 (TID 565)\n",
      "25/11/13 16:17:40 INFO TaskSetManager: Finished task 45.0 in stage 43.0 (TID 564) in 21 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (45/50)\n",
      "25/11/13 16:17:40 INFO Executor: Running task 47.0 in stage 43.0 (TID 566)\n",
      "25/11/13 16:17:40 INFO TaskSetManager: Finished task 44.0 in stage 43.0 (TID 563) in 24 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (46/50)\n",
      "25/11/13 16:17:40 INFO BlockManager: Found block rdd_106_46 locally\n",
      "25/11/13 16:17:40 INFO Executor: Finished task 46.0 in stage 43.0 (TID 565). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:40 INFO BlockManager: Found block rdd_106_47 locally\n",
      "25/11/13 16:17:40 INFO TaskSetManager: Starting task 48.0 in stage 43.0 (TID 567) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 48, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:40 INFO TaskSetManager: Finished task 46.0 in stage 43.0 (TID 565) in 43 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (47/50)\n",
      "25/11/13 16:17:40 INFO Executor: Running task 48.0 in stage 43.0 (TID 567)\n",
      "25/11/13 16:17:40 INFO Executor: Finished task 47.0 in stage 43.0 (TID 566). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:40 INFO TaskSetManager: Starting task 49.0 in stage 43.0 (TID 568) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 49, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:40 INFO Executor: Running task 49.0 in stage 43.0 (TID 568)\n",
      "25/11/13 16:17:40 INFO TaskSetManager: Finished task 47.0 in stage 43.0 (TID 566) in 63 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (48/50)\n",
      "25/11/13 16:17:40 INFO BlockManager: Found block rdd_106_49 locally48 + 2) / 50]\n",
      "25/11/13 16:17:40 INFO Executor: Finished task 49.0 in stage 43.0 (TID 568). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:40 INFO TaskSetManager: Finished task 49.0 in stage 43.0 (TID 568) in 16 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (49/50)\n",
      "25/11/13 16:17:40 INFO BlockManager: Found block rdd_106_48 locally\n",
      "25/11/13 16:17:40 INFO Executor: Finished task 48.0 in stage 43.0 (TID 567). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:40 INFO TaskSetManager: Finished task 48.0 in stage 43.0 (TID 567) in 42 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (50/50)\n",
      "25/11/13 16:17:40 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool \n",
      "25/11/13 16:17:40 INFO DAGScheduler: ResultStage 43 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 1.382 s\n",
      "25/11/13 16:17:40 INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/11/13 16:17:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 43: Stage finished\n",
      "25/11/13 16:17:40 INFO DAGScheduler: Job 27 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 1.388890 s\n",
      "25/11/13 16:17:40 INFO PrepareDeltaScan: DELTA: Done                            \n",
      "25/11/13 16:17:40 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/11/13 16:17:40 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/11/13 16:17:40 INFO CodeGenerator: Code generated in 33.546106 ms\n",
      "25/11/13 16:17:40 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 207.5 KiB, free 1046.8 MiB)\n",
      "25/11/13 16:17:40 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 36.9 KiB, free 1046.8 MiB)\n",
      "25/11/13 16:17:40 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 36.9 KiB, free: 1048.5 MiB)\n",
      "25/11/13 16:17:40 INFO SparkContext: Created broadcast 43 from showString at NativeMethodAccessorImpl.java:0\n",
      "25/11/13 16:17:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 5904079 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/11/13 16:17:40 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "25/11/13 16:17:40 INFO DAGScheduler: Got job 28 (showString at NativeMethodAccessorImpl.java:0) with 2 output partitions\n",
      "25/11/13 16:17:40 INFO DAGScheduler: Final stage: ResultStage 44 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/11/13 16:17:40 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/11/13 16:17:40 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 16:17:40 INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[119] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/11/13 16:17:40 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 30.9 KiB, free 1046.8 MiB)\n",
      "25/11/13 16:17:40 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 10.4 KiB, free 1046.8 MiB)\n",
      "25/11/13 16:17:40 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 10.4 KiB, free: 1048.5 MiB)\n",
      "25/11/13 16:17:40 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 16:17:40 INFO BlockManagerInfo: Removed broadcast_42_piece0 on jupyter-spark-758b7c86d8-7j77n:32921 in memory (size: 154.5 KiB, free: 1048.6 MiB)\n",
      "25/11/13 16:17:40 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 44 (MapPartitionsRDD[119] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))\n",
      "25/11/13 16:17:40 INFO TaskSchedulerImpl: Adding task set 44.0 with 2 tasks resource profile 0\n",
      "25/11/13 16:17:40 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 569) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 9679 bytes) \n",
      "25/11/13 16:17:40 INFO TaskSetManager: Starting task 1.0 in stage 44.0 (TID 570) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 1, PROCESS_LOCAL, 9679 bytes) \n",
      "25/11/13 16:17:40 INFO Executor: Running task 1.0 in stage 44.0 (TID 570)\n",
      "25/11/13 16:17:40 INFO Executor: Running task 0.0 in stage 44.0 (TID 569)\n",
      "25/11/13 16:17:40 INFO CodeGenerator: Code generated in 15.819492 ms\n",
      "25/11/13 16:17:40 INFO FileScanRDD: Reading File path: s3a://nau-local-analytics-silver/dim_user_profile/part-00000-26092a00-ec88-42f6-860b-8e610b908cb4-c000.snappy.parquet, range: 5904079-7613854, partition values: [empty row]\n",
      "25/11/13 16:17:40 INFO FileScanRDD: Reading File path: s3a://nau-local-analytics-silver/dim_user_profile/part-00000-26092a00-ec88-42f6-860b-8e610b908cb4-c000.snappy.parquet, range: 0-5904079, partition values: [empty row]\n",
      "25/11/13 16:17:40 INFO S3AInputStream: Switching to Random IO seek policy\n",
      "25/11/13 16:17:40 INFO S3AInputStream: Switching to Random IO seek policy\n",
      "25/11/13 16:17:40 INFO Executor: Finished task 1.0 in stage 44.0 (TID 570). 1453 bytes result sent to driver\n",
      "25/11/13 16:17:40 INFO TaskSetManager: Finished task 1.0 in stage 44.0 (TID 570) in 286 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/2)\n",
      "25/11/13 16:17:42 INFO Executor: Finished task 0.0 in stage 44.0 (TID 569). 3878 bytes result sent to driver\n",
      "25/11/13 16:17:42 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 569) in 1748 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (2/2)\n",
      "25/11/13 16:17:42 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool \n",
      "25/11/13 16:17:42 INFO DAGScheduler: ResultStage 44 (showString at NativeMethodAccessorImpl.java:0) finished in 1.783 s\n",
      "25/11/13 16:17:42 INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/11/13 16:17:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 44: Stage finished\n",
      "25/11/13 16:17:42 INFO DAGScheduler: Job 28 finished: showString at NativeMethodAccessorImpl.java:0, took 1.786498 s\n",
      "25/11/13 16:17:42 INFO CodeGenerator: Code generated in 16.448186 ms            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-------+-------------+--------+------+-------+----+--------+------------------+--------+----------+------------+-----+--------------------------+----------------+\n",
      "|profile_sk|profile_id|user_id|year_of_birth|age_band|gender|country|city|location|level_of_education|language|courseware|phone_number|state|ingestion_date            |source_name     |\n",
      "+----------+----------+-------+-------------+--------+------+-------+----+--------+------------------+--------+----------+------------+-----+--------------------------+----------------+\n",
      "|1         |1         |1      |NULL         |NULL    |NULL  |NULL   |NULL|        |NULL              |        |course.xml|NULL        |NULL |2025-11-04 18:27:24.809743|auth_userprofile|\n",
      "|2         |2         |2      |NULL         |NULL    |NULL  |NULL   |NULL|        |NULL              |        |course.xml|NULL        |NULL |2025-11-04 18:27:24.809743|auth_userprofile|\n",
      "|3         |3         |3      |NULL         |NULL    |NULL  |NULL   |NULL|        |NULL              |        |course.xml|NULL        |NULL |2025-11-04 18:27:24.809743|auth_userprofile|\n",
      "|4         |4         |4      |NULL         |NULL    |NULL  |NULL   |NULL|        |NULL              |        |course.xml|NULL        |NULL |2025-11-04 18:27:24.809743|auth_userprofile|\n",
      "|5         |5         |6      |NULL         |NULL    |NULL  |NULL   |NULL|        |NULL              |        |course.xml|NULL        |NULL |2025-11-04 18:27:24.809743|auth_userprofile|\n",
      "|6         |6         |7      |1976         |30_54   |m     |NULL   |NULL|        |NULL              |        |course.xml|NULL        |NULL |2025-11-04 18:27:24.809743|auth_userprofile|\n",
      "|7         |7         |8      |2017         |UNDER_18|o     |PT     |    |        |other             |        |course.xml|NULL        |NULL |2025-11-04 18:27:24.809743|auth_userprofile|\n",
      "|8         |8         |10     |NULL         |NULL    |NULL  |PT     |    |        |NULL              |        |course.xml|NULL        |NULL |2025-11-04 18:27:24.809743|auth_userprofile|\n",
      "|9         |9         |11     |NULL         |NULL    |NULL  |PT     |    |        |NULL              |        |course.xml|NULL        |NULL |2025-11-04 18:27:24.809743|auth_userprofile|\n",
      "|10        |10        |12     |NULL         |NULL    |NULL  |PT     |    |        |NULL              |        |course.xml|NULL        |NULL |2025-11-04 18:27:24.809743|auth_userprofile|\n",
      "+----------+----------+-------+-------------+--------+------+-------+----+--------+------------------+--------+----------+------------+-----+--------------------------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/13 16:17:42 INFO BlockManagerInfo: Removed broadcast_43_piece0 on jupyter-spark-758b7c86d8-7j77n:32921 in memory (size: 36.9 KiB, free: 1048.6 MiB)\n",
      "25/11/13 16:17:42 INFO BlockManagerInfo: Removed broadcast_44_piece0 on jupyter-spark-758b7c86d8-7j77n:32921 in memory (size: 10.4 KiB, free: 1048.7 MiB)\n",
      "25/11/13 16:17:42 INFO CodeGenerator: Code generated in 37.337245 ms\n",
      "25/11/13 16:17:42 INFO DAGScheduler: Registering RDD 125 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 6\n",
      "25/11/13 16:17:42 INFO DAGScheduler: Got map stage job 29 (count at NativeMethodAccessorImpl.java:0) with 50 output partitions\n",
      "25/11/13 16:17:42 INFO DAGScheduler: Final stage: ShuffleMapStage 46 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/11/13 16:17:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 45)\n",
      "25/11/13 16:17:42 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 16:17:42 INFO DAGScheduler: Submitting ShuffleMapStage 46 (MapPartitionsRDD[125] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/11/13 16:17:42 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 712.4 KiB, free 1047.2 MiB)\n",
      "25/11/13 16:17:42 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 162.8 KiB, free 1047.0 MiB)\n",
      "25/11/13 16:17:42 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 162.8 KiB, free: 1048.5 MiB)\n",
      "25/11/13 16:17:42 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 16:17:42 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 46 (MapPartitionsRDD[125] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n",
      "25/11/13 16:17:42 INFO TaskSchedulerImpl: Adding task set 46.0 with 50 tasks resource profile 0\n",
      "25/11/13 16:17:42 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 571) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:42 INFO TaskSetManager: Starting task 1.0 in stage 46.0 (TID 572) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 1, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:42 INFO Executor: Running task 0.0 in stage 46.0 (TID 571)\n",
      "25/11/13 16:17:42 INFO Executor: Running task 1.0 in stage 46.0 (TID 572)\n",
      "25/11/13 16:17:42 INFO BlockManager: Found block rdd_106_1 locally\n",
      "25/11/13 16:17:42 INFO BlockManager: Found block rdd_106_0 locally\n",
      "25/11/13 16:17:42 INFO CodeGenerator: Code generated in 28.769574 ms\n",
      "25/11/13 16:17:42 INFO MemoryStore: Block rdd_123_1 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:42 INFO MemoryStore: Block rdd_123_0 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:42 INFO BlockManagerInfo: Added rdd_123_0 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:42 INFO BlockManagerInfo: Added rdd_123_1 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:42 INFO CodeGenerator: Code generated in 32.648662 ms\n",
      "25/11/13 16:17:42 INFO Executor: Finished task 0.0 in stage 46.0 (TID 571). 4613 bytes result sent to driver\n",
      "25/11/13 16:17:42 INFO TaskSetManager: Starting task 2.0 in stage 46.0 (TID 573) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 2, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:42 INFO Executor: Running task 2.0 in stage 46.0 (TID 573)\n",
      "25/11/13 16:17:42 INFO Executor: Finished task 1.0 in stage 46.0 (TID 572). 4613 bytes result sent to driver\n",
      "25/11/13 16:17:42 INFO TaskSetManager: Starting task 3.0 in stage 46.0 (TID 574) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 3, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:42 INFO Executor: Running task 3.0 in stage 46.0 (TID 574)\n",
      "25/11/13 16:17:42 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 571) in 116 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/50)\n",
      "25/11/13 16:17:42 INFO TaskSetManager: Finished task 1.0 in stage 46.0 (TID 572) in 131 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (2/50)\n",
      "25/11/13 16:17:42 INFO BlockManager: Found block rdd_106_2 locally\n",
      "25/11/13 16:17:42 INFO MemoryStore: Block rdd_123_2 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:42 INFO BlockManagerInfo: Added rdd_123_2 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:42 INFO BlockManager: Found block rdd_106_3 locally\n",
      "25/11/13 16:17:42 INFO Executor: Finished task 2.0 in stage 46.0 (TID 573). 4613 bytes result sent to driver\n",
      "25/11/13 16:17:42 INFO TaskSetManager: Starting task 4.0 in stage 46.0 (TID 575) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 4, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:42 INFO TaskSetManager: Finished task 2.0 in stage 46.0 (TID 573) in 43 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (3/50)\n",
      "25/11/13 16:17:42 INFO Executor: Running task 4.0 in stage 46.0 (TID 575)\n",
      "25/11/13 16:17:42 INFO MemoryStore: Block rdd_123_3 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:42 INFO BlockManagerInfo: Added rdd_123_3 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:42 INFO Executor: Finished task 3.0 in stage 46.0 (TID 574). 4613 bytes result sent to driver\n",
      "25/11/13 16:17:42 INFO TaskSetManager: Starting task 5.0 in stage 46.0 (TID 576) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 5, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:42 INFO TaskSetManager: Finished task 3.0 in stage 46.0 (TID 574) in 50 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (4/50)\n",
      "25/11/13 16:17:42 INFO Executor: Running task 5.0 in stage 46.0 (TID 576)\n",
      "25/11/13 16:17:42 INFO BlockManager: Found block rdd_106_4 locally\n",
      "25/11/13 16:17:42 INFO BlockManager: Found block rdd_106_5 locally\n",
      "25/11/13 16:17:42 INFO MemoryStore: Block rdd_123_5 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:42 INFO BlockManagerInfo: Added rdd_123_5 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:42 INFO MemoryStore: Block rdd_123_4 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:42 INFO BlockManagerInfo: Added rdd_123_4 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:42 INFO Executor: Finished task 5.0 in stage 46.0 (TID 576). 4613 bytes result sent to driver\n",
      "25/11/13 16:17:42 INFO TaskSetManager: Starting task 6.0 in stage 46.0 (TID 577) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 6, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:42 INFO Executor: Running task 6.0 in stage 46.0 (TID 577)\n",
      "25/11/13 16:17:42 INFO TaskSetManager: Finished task 5.0 in stage 46.0 (TID 576) in 66 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (5/50)\n",
      "25/11/13 16:17:42 INFO Executor: Finished task 4.0 in stage 46.0 (TID 575). 4613 bytes result sent to driver\n",
      "25/11/13 16:17:42 INFO TaskSetManager: Starting task 7.0 in stage 46.0 (TID 578) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 7, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:42 INFO Executor: Running task 7.0 in stage 46.0 (TID 578)\n",
      "25/11/13 16:17:42 INFO TaskSetManager: Finished task 4.0 in stage 46.0 (TID 575) in 80 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (6/50)\n",
      "25/11/13 16:17:42 INFO BlockManager: Found block rdd_106_6 locally\n",
      "25/11/13 16:17:42 INFO BlockManager: Found block rdd_106_7 locally\n",
      "25/11/13 16:17:42 INFO MemoryStore: Block rdd_123_6 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:42 INFO BlockManagerInfo: Added rdd_123_6 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:42 INFO Executor: Finished task 6.0 in stage 46.0 (TID 577). 4613 bytes result sent to driver\n",
      "25/11/13 16:17:42 INFO MemoryStore: Block rdd_123_7 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:42 INFO BlockManagerInfo: Added rdd_123_7 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:42 INFO TaskSetManager: Starting task 8.0 in stage 46.0 (TID 579) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 8, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:42 INFO Executor: Running task 8.0 in stage 46.0 (TID 579)\n",
      "25/11/13 16:17:42 INFO TaskSetManager: Finished task 6.0 in stage 46.0 (TID 577) in 53 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (7/50)\n",
      "25/11/13 16:17:43 INFO Executor: Finished task 7.0 in stage 46.0 (TID 578). 4699 bytes result sent to driver\n",
      "25/11/13 16:17:43 INFO TaskSetManager: Starting task 9.0 in stage 46.0 (TID 580) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 9, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:43 INFO TaskSetManager: Finished task 7.0 in stage 46.0 (TID 578) in 82 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (8/50)\n",
      "25/11/13 16:17:43 INFO Executor: Running task 9.0 in stage 46.0 (TID 580)\n",
      "25/11/13 16:17:43 INFO BlockManager: Found block rdd_106_8 locally\n",
      "25/11/13 16:17:43 INFO BlockManager: Found block rdd_106_9 locally\n",
      "25/11/13 16:17:43 INFO MemoryStore: Block rdd_123_8 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:43 INFO BlockManagerInfo: Added rdd_123_8 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:43 INFO Executor: Finished task 8.0 in stage 46.0 (TID 579). 4656 bytes result sent to driver\n",
      "25/11/13 16:17:43 INFO MemoryStore: Block rdd_123_9 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:43 INFO TaskSetManager: Starting task 10.0 in stage 46.0 (TID 581) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 10, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:43 INFO TaskSetManager: Finished task 8.0 in stage 46.0 (TID 579) in 96 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (9/50)\n",
      "25/11/13 16:17:43 INFO Executor: Running task 10.0 in stage 46.0 (TID 581)\n",
      "25/11/13 16:17:43 INFO BlockManagerInfo: Added rdd_123_9 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:43 INFO Executor: Finished task 9.0 in stage 46.0 (TID 580). 4613 bytes result sent to driver\n",
      "25/11/13 16:17:43 INFO TaskSetManager: Starting task 11.0 in stage 46.0 (TID 582) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 11, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:43 INFO Executor: Running task 11.0 in stage 46.0 (TID 582)\n",
      "25/11/13 16:17:43 INFO TaskSetManager: Finished task 9.0 in stage 46.0 (TID 580) in 88 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (10/50)\n",
      "25/11/13 16:17:43 INFO BlockManager: Found block rdd_106_10 locally\n",
      "25/11/13 16:17:43 INFO MemoryStore: Block rdd_123_10 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:43 INFO BlockManagerInfo: Added rdd_123_10 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:43 INFO BlockManager: Found block rdd_106_11 locally\n",
      "25/11/13 16:17:43 INFO Executor: Finished task 10.0 in stage 46.0 (TID 581). 4613 bytes result sent to driver\n",
      "25/11/13 16:17:43 INFO TaskSetManager: Starting task 12.0 in stage 46.0 (TID 583) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 12, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:43 INFO TaskSetManager: Finished task 10.0 in stage 46.0 (TID 581) in 96 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (11/50)\n",
      "25/11/13 16:17:43 INFO Executor: Running task 12.0 in stage 46.0 (TID 583)\n",
      "25/11/13 16:17:43 INFO MemoryStore: Block rdd_123_11 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:43 INFO BlockManagerInfo: Added rdd_123_11 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:43 INFO Executor: Finished task 11.0 in stage 46.0 (TID 582). 4613 bytes result sent to driver\n",
      "25/11/13 16:17:43 INFO TaskSetManager: Starting task 13.0 in stage 46.0 (TID 584) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 13, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:43 INFO TaskSetManager: Finished task 11.0 in stage 46.0 (TID 582) in 63 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (12/50)\n",
      "25/11/13 16:17:43 INFO Executor: Running task 13.0 in stage 46.0 (TID 584)\n",
      "25/11/13 16:17:43 INFO BlockManager: Found block rdd_106_13 locally\n",
      "25/11/13 16:17:43 INFO BlockManager: Found block rdd_106_12 locally\n",
      "25/11/13 16:17:43 INFO MemoryStore: Block rdd_123_12 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:43 INFO BlockManagerInfo: Added rdd_123_12 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:43 INFO MemoryStore: Block rdd_123_13 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:43 INFO BlockManagerInfo: Added rdd_123_13 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:43 INFO Executor: Finished task 12.0 in stage 46.0 (TID 583). 4613 bytes result sent to driver\n",
      "25/11/13 16:17:43 INFO TaskSetManager: Starting task 14.0 in stage 46.0 (TID 585) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 14, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:43 INFO Executor: Running task 14.0 in stage 46.0 (TID 585)\n",
      "25/11/13 16:17:43 INFO Executor: Finished task 13.0 in stage 46.0 (TID 584). 4613 bytes result sent to driver\n",
      "25/11/13 16:17:43 INFO TaskSetManager: Finished task 12.0 in stage 46.0 (TID 583) in 94 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (13/50)\n",
      "25/11/13 16:17:43 INFO TaskSetManager: Starting task 15.0 in stage 46.0 (TID 586) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 15, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:43 INFO Executor: Running task 15.0 in stage 46.0 (TID 586)\n",
      "25/11/13 16:17:43 INFO TaskSetManager: Finished task 13.0 in stage 46.0 (TID 584) in 87 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (14/50)\n",
      "25/11/13 16:17:43 INFO BlockManager: Found block rdd_106_15 locally\n",
      "25/11/13 16:17:43 INFO BlockManager: Found block rdd_106_14 locally\n",
      "25/11/13 16:17:43 INFO MemoryStore: Block rdd_123_15 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:43 INFO BlockManagerInfo: Added rdd_123_15 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:43 INFO Executor: Finished task 15.0 in stage 46.0 (TID 586). 4613 bytes result sent to driver\n",
      "25/11/13 16:17:43 INFO TaskSetManager: Starting task 16.0 in stage 46.0 (TID 587) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 16, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:43 INFO TaskSetManager: Finished task 15.0 in stage 46.0 (TID 586) in 94 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (15/50)\n",
      "25/11/13 16:17:43 INFO Executor: Running task 16.0 in stage 46.0 (TID 587)\n",
      "25/11/13 16:17:43 INFO MemoryStore: Block rdd_123_14 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:43 INFO BlockManagerInfo: Added rdd_123_14 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:43 INFO Executor: Finished task 14.0 in stage 46.0 (TID 585). 4613 bytes result sent to driver\n",
      "25/11/13 16:17:43 INFO TaskSetManager: Starting task 17.0 in stage 46.0 (TID 588) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 17, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:43 INFO TaskSetManager: Finished task 14.0 in stage 46.0 (TID 585) in 104 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (16/50)\n",
      "25/11/13 16:17:43 INFO Executor: Running task 17.0 in stage 46.0 (TID 588)\n",
      "25/11/13 16:17:43 INFO BlockManager: Found block rdd_106_16 locally\n",
      "25/11/13 16:17:43 INFO BlockManager: Found block rdd_106_17 locally\n",
      "25/11/13 16:17:43 INFO MemoryStore: Block rdd_123_16 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:43 INFO BlockManagerInfo: Added rdd_123_16 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:43 INFO Executor: Finished task 16.0 in stage 46.0 (TID 587). 4656 bytes result sent to driver\n",
      "25/11/13 16:17:43 INFO TaskSetManager: Starting task 18.0 in stage 46.0 (TID 589) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 18, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:43 INFO Executor: Running task 18.0 in stage 46.0 (TID 589)\n",
      "25/11/13 16:17:43 INFO TaskSetManager: Finished task 16.0 in stage 46.0 (TID 587) in 72 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (17/50)\n",
      "25/11/13 16:17:43 INFO MemoryStore: Block rdd_123_17 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:43 INFO BlockManagerInfo: Added rdd_123_17 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:43 INFO Executor: Finished task 17.0 in stage 46.0 (TID 588). 4656 bytes result sent to driver\n",
      "25/11/13 16:17:43 INFO TaskSetManager: Starting task 19.0 in stage 46.0 (TID 590) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 19, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:43 INFO Executor: Running task 19.0 in stage 46.0 (TID 590)\n",
      "25/11/13 16:17:43 INFO TaskSetManager: Finished task 17.0 in stage 46.0 (TID 588) in 89 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (18/50)\n",
      "25/11/13 16:17:43 INFO BlockManager: Found block rdd_106_18 locally\n",
      "25/11/13 16:17:43 INFO BlockManager: Found block rdd_106_19 locally\n",
      "25/11/13 16:17:43 INFO MemoryStore: Block rdd_123_18 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:43 INFO BlockManagerInfo: Added rdd_123_18 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:43 INFO Executor: Finished task 18.0 in stage 46.0 (TID 589). 4656 bytes result sent to driver\n",
      "25/11/13 16:17:43 INFO TaskSetManager: Starting task 20.0 in stage 46.0 (TID 591) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 20, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:43 INFO TaskSetManager: Finished task 18.0 in stage 46.0 (TID 589) in 88 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (19/50)\n",
      "25/11/13 16:17:43 INFO Executor: Running task 20.0 in stage 46.0 (TID 591)\n",
      "25/11/13 16:17:43 INFO MemoryStore: Block rdd_123_19 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:43 INFO BlockManagerInfo: Added rdd_123_19 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:43 INFO Executor: Finished task 19.0 in stage 46.0 (TID 590). 4656 bytes result sent to driver\n",
      "25/11/13 16:17:43 INFO TaskSetManager: Starting task 21.0 in stage 46.0 (TID 592) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 21, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:43 INFO Executor: Running task 21.0 in stage 46.0 (TID 592)\n",
      "25/11/13 16:17:43 INFO TaskSetManager: Finished task 19.0 in stage 46.0 (TID 590) in 176 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (20/50)\n",
      "25/11/13 16:17:43 INFO BlockManager: Found block rdd_106_20 locally\n",
      "25/11/13 16:17:43 INFO BlockManager: Found block rdd_106_21 locally\n",
      "25/11/13 16:17:43 INFO MemoryStore: Block rdd_123_20 stored as values in memory (estimated size 593.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:43 INFO BlockManagerInfo: Added rdd_123_20 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 593.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:43 INFO Executor: Finished task 20.0 in stage 46.0 (TID 591). 4699 bytes result sent to driver\n",
      "25/11/13 16:17:43 INFO MemoryStore: Block rdd_123_21 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:43 INFO BlockManagerInfo: Added rdd_123_21 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:43 INFO TaskSetManager: Starting task 22.0 in stage 46.0 (TID 593) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 22, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:43 INFO TaskSetManager: Finished task 20.0 in stage 46.0 (TID 591) in 196 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (21/50)\n",
      "25/11/13 16:17:43 INFO Executor: Running task 22.0 in stage 46.0 (TID 593)\n",
      "25/11/13 16:17:43 INFO Executor: Finished task 21.0 in stage 46.0 (TID 592). 4656 bytes result sent to driver\n",
      "25/11/13 16:17:43 INFO TaskSetManager: Starting task 23.0 in stage 46.0 (TID 594) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 23, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:43 INFO Executor: Running task 23.0 in stage 46.0 (TID 594)\n",
      "25/11/13 16:17:43 INFO TaskSetManager: Finished task 21.0 in stage 46.0 (TID 592) in 88 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (22/50)\n",
      "25/11/13 16:17:43 INFO BlockManager: Found block rdd_106_22 locally\n",
      "25/11/13 16:17:43 INFO BlockManager: Found block rdd_106_23 locally\n",
      "25/11/13 16:17:43 INFO MemoryStore: Block rdd_123_23 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:43 INFO BlockManagerInfo: Added rdd_123_23 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:43 INFO MemoryStore: Block rdd_123_22 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:43 INFO BlockManagerInfo: Added rdd_123_22 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:43 INFO Executor: Finished task 23.0 in stage 46.0 (TID 594). 4656 bytes result sent to driver\n",
      "25/11/13 16:17:43 INFO TaskSetManager: Starting task 24.0 in stage 46.0 (TID 595) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 24, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:43 INFO Executor: Running task 24.0 in stage 46.0 (TID 595)\n",
      "25/11/13 16:17:43 INFO TaskSetManager: Finished task 23.0 in stage 46.0 (TID 594) in 94 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (23/50)\n",
      "25/11/13 16:17:43 INFO Executor: Finished task 22.0 in stage 46.0 (TID 593). 4656 bytes result sent to driver\n",
      "25/11/13 16:17:43 INFO TaskSetManager: Starting task 25.0 in stage 46.0 (TID 596) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 25, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:43 INFO TaskSetManager: Finished task 22.0 in stage 46.0 (TID 593) in 138 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (24/50)\n",
      "25/11/13 16:17:43 INFO Executor: Running task 25.0 in stage 46.0 (TID 596)\n",
      "25/11/13 16:17:43 INFO BlockManager: Found block rdd_106_24 locally24 + 2) / 50]\n",
      "25/11/13 16:17:43 INFO BlockManager: Found block rdd_106_25 locally\n",
      "25/11/13 16:17:43 INFO MemoryStore: Block rdd_123_24 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:43 INFO BlockManagerInfo: Added rdd_123_24 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:43 INFO Executor: Finished task 24.0 in stage 46.0 (TID 595). 4656 bytes result sent to driver\n",
      "25/11/13 16:17:43 INFO TaskSetManager: Starting task 26.0 in stage 46.0 (TID 597) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 26, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:43 INFO MemoryStore: Block rdd_123_25 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:43 INFO BlockManagerInfo: Added rdd_123_25 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:43 INFO Executor: Running task 26.0 in stage 46.0 (TID 597)\n",
      "25/11/13 16:17:43 INFO TaskSetManager: Finished task 24.0 in stage 46.0 (TID 595) in 129 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (25/50)\n",
      "25/11/13 16:17:43 INFO Executor: Finished task 25.0 in stage 46.0 (TID 596). 4656 bytes result sent to driver\n",
      "25/11/13 16:17:43 INFO TaskSetManager: Starting task 27.0 in stage 46.0 (TID 598) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 27, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:43 INFO Executor: Running task 27.0 in stage 46.0 (TID 598)\n",
      "25/11/13 16:17:43 INFO TaskSetManager: Finished task 25.0 in stage 46.0 (TID 596) in 103 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (26/50)\n",
      "25/11/13 16:17:43 INFO BlockManager: Found block rdd_106_26 locally\n",
      "25/11/13 16:17:43 INFO BlockManager: Found block rdd_106_27 locally\n",
      "25/11/13 16:17:43 INFO MemoryStore: Block rdd_123_26 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:43 INFO BlockManagerInfo: Added rdd_123_26 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:43 INFO Executor: Finished task 26.0 in stage 46.0 (TID 597). 4613 bytes result sent to driver\n",
      "25/11/13 16:17:43 INFO TaskSetManager: Starting task 28.0 in stage 46.0 (TID 599) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 28, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:43 INFO Executor: Running task 28.0 in stage 46.0 (TID 599)\n",
      "25/11/13 16:17:43 INFO TaskSetManager: Finished task 26.0 in stage 46.0 (TID 597) in 100 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (27/50)\n",
      "25/11/13 16:17:44 INFO MemoryStore: Block rdd_123_27 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:44 INFO BlockManagerInfo: Added rdd_123_27 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:44 INFO Executor: Finished task 27.0 in stage 46.0 (TID 598). 4656 bytes result sent to driver\n",
      "25/11/13 16:17:44 INFO TaskSetManager: Starting task 29.0 in stage 46.0 (TID 600) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 29, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:44 INFO TaskSetManager: Finished task 27.0 in stage 46.0 (TID 598) in 108 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (28/50)\n",
      "25/11/13 16:17:44 INFO Executor: Running task 29.0 in stage 46.0 (TID 600)\n",
      "25/11/13 16:17:44 INFO BlockManager: Found block rdd_106_28 locally\n",
      "25/11/13 16:17:44 INFO MemoryStore: Block rdd_123_28 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:44 INFO BlockManagerInfo: Added rdd_123_28 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:44 INFO Executor: Finished task 28.0 in stage 46.0 (TID 599). 4656 bytes result sent to driver\n",
      "25/11/13 16:17:44 INFO TaskSetManager: Starting task 30.0 in stage 46.0 (TID 601) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 30, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:44 INFO BlockManager: Found block rdd_106_29 locally\n",
      "25/11/13 16:17:44 INFO Executor: Running task 30.0 in stage 46.0 (TID 601)\n",
      "25/11/13 16:17:44 INFO TaskSetManager: Finished task 28.0 in stage 46.0 (TID 599) in 119 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (29/50)\n",
      "25/11/13 16:17:44 INFO MemoryStore: Block rdd_123_29 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:44 INFO BlockManagerInfo: Added rdd_123_29 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:44 INFO Executor: Finished task 29.0 in stage 46.0 (TID 600). 4656 bytes result sent to driver\n",
      "25/11/13 16:17:44 INFO TaskSetManager: Starting task 31.0 in stage 46.0 (TID 602) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 31, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:44 INFO Executor: Running task 31.0 in stage 46.0 (TID 602)\n",
      "25/11/13 16:17:44 INFO TaskSetManager: Finished task 29.0 in stage 46.0 (TID 600) in 101 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (30/50)\n",
      "25/11/13 16:17:44 INFO BlockManager: Found block rdd_106_30 locally\n",
      "25/11/13 16:17:44 INFO BlockManager: Found block rdd_106_31 locally\n",
      "25/11/13 16:17:44 INFO MemoryStore: Block rdd_123_30 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:44 INFO BlockManagerInfo: Added rdd_123_30 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:44 INFO Executor: Finished task 30.0 in stage 46.0 (TID 601). 4613 bytes result sent to driver\n",
      "25/11/13 16:17:44 INFO TaskSetManager: Starting task 32.0 in stage 46.0 (TID 603) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 32, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:44 INFO Executor: Running task 32.0 in stage 46.0 (TID 603)\n",
      "25/11/13 16:17:44 INFO TaskSetManager: Finished task 30.0 in stage 46.0 (TID 601) in 80 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (31/50)\n",
      "25/11/13 16:17:44 INFO MemoryStore: Block rdd_123_31 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:44 INFO BlockManagerInfo: Added rdd_123_31 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:44 INFO Executor: Finished task 31.0 in stage 46.0 (TID 602). 4613 bytes result sent to driver\n",
      "25/11/13 16:17:44 INFO TaskSetManager: Starting task 33.0 in stage 46.0 (TID 604) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 33, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:44 INFO TaskSetManager: Finished task 31.0 in stage 46.0 (TID 602) in 97 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (32/50)\n",
      "25/11/13 16:17:44 INFO Executor: Running task 33.0 in stage 46.0 (TID 604)\n",
      "25/11/13 16:17:44 INFO BlockManager: Found block rdd_106_32 locally32 + 2) / 50]\n",
      "25/11/13 16:17:44 INFO BlockManager: Found block rdd_106_33 locally\n",
      "25/11/13 16:17:44 INFO MemoryStore: Block rdd_123_32 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:44 INFO BlockManagerInfo: Added rdd_123_32 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:44 INFO MemoryStore: Block rdd_123_33 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:44 INFO BlockManagerInfo: Added rdd_123_33 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:44 INFO Executor: Finished task 32.0 in stage 46.0 (TID 603). 4613 bytes result sent to driver\n",
      "25/11/13 16:17:44 INFO TaskSetManager: Starting task 34.0 in stage 46.0 (TID 605) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 34, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:44 INFO Executor: Running task 34.0 in stage 46.0 (TID 605)\n",
      "25/11/13 16:17:44 INFO TaskSetManager: Finished task 32.0 in stage 46.0 (TID 603) in 102 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (33/50)\n",
      "25/11/13 16:17:44 INFO Executor: Finished task 33.0 in stage 46.0 (TID 604). 4613 bytes result sent to driver\n",
      "25/11/13 16:17:44 INFO TaskSetManager: Starting task 35.0 in stage 46.0 (TID 606) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 35, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:44 INFO Executor: Running task 35.0 in stage 46.0 (TID 606)\n",
      "25/11/13 16:17:44 INFO TaskSetManager: Finished task 33.0 in stage 46.0 (TID 604) in 94 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (34/50)\n",
      "25/11/13 16:17:44 INFO BlockManager: Found block rdd_106_35 locally\n",
      "25/11/13 16:17:44 INFO BlockManager: Found block rdd_106_34 locally\n",
      "25/11/13 16:17:44 INFO MemoryStore: Block rdd_123_35 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:44 INFO BlockManagerInfo: Added rdd_123_35 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:44 INFO MemoryStore: Block rdd_123_34 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:44 INFO BlockManagerInfo: Added rdd_123_34 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:44 INFO Executor: Finished task 35.0 in stage 46.0 (TID 606). 4613 bytes result sent to driver\n",
      "25/11/13 16:17:44 INFO TaskSetManager: Starting task 36.0 in stage 46.0 (TID 607) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 36, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:44 INFO Executor: Running task 36.0 in stage 46.0 (TID 607)\n",
      "25/11/13 16:17:44 INFO TaskSetManager: Finished task 35.0 in stage 46.0 (TID 606) in 92 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (35/50)\n",
      "25/11/13 16:17:44 INFO Executor: Finished task 34.0 in stage 46.0 (TID 605). 4613 bytes result sent to driver\n",
      "25/11/13 16:17:44 INFO TaskSetManager: Starting task 37.0 in stage 46.0 (TID 608) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 37, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:44 INFO Executor: Running task 37.0 in stage 46.0 (TID 608)\n",
      "25/11/13 16:17:44 INFO TaskSetManager: Finished task 34.0 in stage 46.0 (TID 605) in 97 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (36/50)\n",
      "25/11/13 16:17:44 INFO BlockManager: Found block rdd_106_37 locally\n",
      "25/11/13 16:17:44 INFO BlockManager: Found block rdd_106_36 locally\n",
      "25/11/13 16:17:44 INFO MemoryStore: Block rdd_123_37 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:44 INFO BlockManagerInfo: Added rdd_123_37 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:44 INFO Executor: Finished task 37.0 in stage 46.0 (TID 608). 4613 bytes result sent to driver\n",
      "25/11/13 16:17:44 INFO TaskSetManager: Starting task 38.0 in stage 46.0 (TID 609) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 38, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:44 INFO Executor: Running task 38.0 in stage 46.0 (TID 609)\n",
      "25/11/13 16:17:44 INFO MemoryStore: Block rdd_123_36 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:44 INFO TaskSetManager: Finished task 37.0 in stage 46.0 (TID 608) in 89 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (37/50)\n",
      "25/11/13 16:17:44 INFO BlockManagerInfo: Added rdd_123_36 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:44 INFO Executor: Finished task 36.0 in stage 46.0 (TID 607). 4613 bytes result sent to driver\n",
      "25/11/13 16:17:44 INFO TaskSetManager: Starting task 39.0 in stage 46.0 (TID 610) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 39, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:44 INFO Executor: Running task 39.0 in stage 46.0 (TID 610)\n",
      "25/11/13 16:17:44 INFO TaskSetManager: Finished task 36.0 in stage 46.0 (TID 607) in 98 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (38/50)\n",
      "25/11/13 16:17:44 INFO BlockManager: Found block rdd_106_38 locally\n",
      "25/11/13 16:17:44 INFO BlockManager: Found block rdd_106_39 locally\n",
      "25/11/13 16:17:44 INFO MemoryStore: Block rdd_123_38 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:44 INFO BlockManagerInfo: Added rdd_123_38 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:44 INFO Executor: Finished task 38.0 in stage 46.0 (TID 609). 4613 bytes result sent to driver\n",
      "25/11/13 16:17:44 INFO TaskSetManager: Starting task 40.0 in stage 46.0 (TID 611) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 40, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:44 INFO TaskSetManager: Finished task 38.0 in stage 46.0 (TID 609) in 73 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (39/50)\n",
      "25/11/13 16:17:44 INFO Executor: Running task 40.0 in stage 46.0 (TID 611)\n",
      "25/11/13 16:17:44 INFO MemoryStore: Block rdd_123_39 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:44 INFO BlockManagerInfo: Added rdd_123_39 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:44 INFO Executor: Finished task 39.0 in stage 46.0 (TID 610). 4613 bytes result sent to driver\n",
      "25/11/13 16:17:44 INFO TaskSetManager: Starting task 41.0 in stage 46.0 (TID 612) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 41, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:44 INFO TaskSetManager: Finished task 39.0 in stage 46.0 (TID 610) in 98 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (40/50)\n",
      "25/11/13 16:17:44 INFO Executor: Running task 41.0 in stage 46.0 (TID 612)\n",
      "25/11/13 16:17:44 INFO BlockManager: Found block rdd_106_40 locally\n",
      "25/11/13 16:17:44 INFO MemoryStore: Block rdd_123_40 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:44 INFO BlockManagerInfo: Added rdd_123_40 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:44 INFO BlockManager: Found block rdd_106_41 locally\n",
      "25/11/13 16:17:44 INFO Executor: Finished task 40.0 in stage 46.0 (TID 611). 4613 bytes result sent to driver\n",
      "25/11/13 16:17:44 INFO TaskSetManager: Starting task 42.0 in stage 46.0 (TID 613) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 42, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:44 INFO Executor: Running task 42.0 in stage 46.0 (TID 613)\n",
      "25/11/13 16:17:44 INFO TaskSetManager: Finished task 40.0 in stage 46.0 (TID 611) in 91 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (41/50)\n",
      "25/11/13 16:17:44 INFO MemoryStore: Block rdd_123_41 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:44 INFO BlockManagerInfo: Added rdd_123_41 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:44 INFO Executor: Finished task 41.0 in stage 46.0 (TID 612). 4613 bytes result sent to driver\n",
      "25/11/13 16:17:44 INFO TaskSetManager: Starting task 43.0 in stage 46.0 (TID 614) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 43, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:44 INFO Executor: Running task 43.0 in stage 46.0 (TID 614)\n",
      "25/11/13 16:17:44 INFO TaskSetManager: Finished task 41.0 in stage 46.0 (TID 612) in 157 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (42/50)\n",
      "25/11/13 16:17:44 INFO BlockManager: Found block rdd_106_42 locally\n",
      "25/11/13 16:17:44 INFO BlockManager: Found block rdd_106_43 locally\n",
      "25/11/13 16:17:44 INFO MemoryStore: Block rdd_123_42 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:44 INFO BlockManagerInfo: Added rdd_123_42 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:44 INFO Executor: Finished task 42.0 in stage 46.0 (TID 613). 4699 bytes result sent to driver\n",
      "25/11/13 16:17:44 INFO TaskSetManager: Starting task 44.0 in stage 46.0 (TID 615) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 44, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:44 INFO MemoryStore: Block rdd_123_43 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:44 INFO TaskSetManager: Finished task 42.0 in stage 46.0 (TID 613) in 150 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (43/50)\n",
      "25/11/13 16:17:44 INFO Executor: Running task 44.0 in stage 46.0 (TID 615)\n",
      "25/11/13 16:17:44 INFO BlockManagerInfo: Added rdd_123_43 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:44 INFO Executor: Finished task 43.0 in stage 46.0 (TID 614). 4613 bytes result sent to driver\n",
      "25/11/13 16:17:44 INFO TaskSetManager: Starting task 45.0 in stage 46.0 (TID 616) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 45, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:44 INFO TaskSetManager: Finished task 43.0 in stage 46.0 (TID 614) in 57 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (44/50)\n",
      "25/11/13 16:17:44 INFO Executor: Running task 45.0 in stage 46.0 (TID 616)\n",
      "25/11/13 16:17:44 INFO BlockManager: Found block rdd_106_44 locally\n",
      "25/11/13 16:17:44 INFO BlockManager: Found block rdd_106_45 locally\n",
      "25/11/13 16:17:44 INFO MemoryStore: Block rdd_123_44 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:44 INFO BlockManagerInfo: Added rdd_123_44 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:44 INFO Executor: Finished task 44.0 in stage 46.0 (TID 615). 4613 bytes result sent to driver\n",
      "25/11/13 16:17:44 INFO TaskSetManager: Starting task 46.0 in stage 46.0 (TID 617) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 46, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:44 INFO Executor: Running task 46.0 in stage 46.0 (TID 617)\n",
      "25/11/13 16:17:44 INFO TaskSetManager: Finished task 44.0 in stage 46.0 (TID 615) in 90 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (45/50)\n",
      "25/11/13 16:17:44 INFO MemoryStore: Block rdd_123_45 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:44 INFO BlockManagerInfo: Added rdd_123_45 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:44 INFO Executor: Finished task 45.0 in stage 46.0 (TID 616). 4613 bytes result sent to driver\n",
      "25/11/13 16:17:44 INFO TaskSetManager: Starting task 47.0 in stage 46.0 (TID 618) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 47, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:44 INFO TaskSetManager: Finished task 45.0 in stage 46.0 (TID 616) in 90 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (46/50)\n",
      "25/11/13 16:17:44 INFO Executor: Running task 47.0 in stage 46.0 (TID 618)\n",
      "25/11/13 16:17:44 INFO BlockManager: Found block rdd_106_46 locally\n",
      "25/11/13 16:17:44 INFO BlockManager: Found block rdd_106_47 locally\n",
      "25/11/13 16:17:44 INFO MemoryStore: Block rdd_123_46 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:44 INFO BlockManagerInfo: Added rdd_123_46 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:44 INFO MemoryStore: Block rdd_123_47 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:44 INFO BlockManagerInfo: Added rdd_123_47 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:44 INFO Executor: Finished task 46.0 in stage 46.0 (TID 617). 4656 bytes result sent to driver\n",
      "25/11/13 16:17:44 INFO TaskSetManager: Starting task 48.0 in stage 46.0 (TID 619) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 48, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:44 INFO Executor: Running task 48.0 in stage 46.0 (TID 619)\n",
      "25/11/13 16:17:44 INFO TaskSetManager: Finished task 46.0 in stage 46.0 (TID 617) in 97 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (47/50)\n",
      "25/11/13 16:17:44 INFO Executor: Finished task 47.0 in stage 46.0 (TID 618). 4613 bytes result sent to driver\n",
      "25/11/13 16:17:44 INFO TaskSetManager: Starting task 49.0 in stage 46.0 (TID 620) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 49, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:44 INFO TaskSetManager: Finished task 47.0 in stage 46.0 (TID 618) in 91 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (48/50)\n",
      "25/11/13 16:17:44 INFO Executor: Running task 49.0 in stage 46.0 (TID 620)\n",
      "25/11/13 16:17:44 INFO BlockManager: Found block rdd_106_48 locally\n",
      "25/11/13 16:17:44 INFO BlockManager: Found block rdd_106_49 locally\n",
      "25/11/13 16:17:44 INFO MemoryStore: Block rdd_123_48 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:44 INFO MemoryStore: Block rdd_123_49 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 16:17:44 INFO BlockManagerInfo: Added rdd_123_48 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:44 INFO BlockManagerInfo: Added rdd_123_49 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 16:17:45 INFO Executor: Finished task 49.0 in stage 46.0 (TID 620). 4613 bytes result sent to driver\n",
      "25/11/13 16:17:45 INFO Executor: Finished task 48.0 in stage 46.0 (TID 619). 4699 bytes result sent to driver\n",
      "25/11/13 16:17:45 INFO TaskSetManager: Finished task 48.0 in stage 46.0 (TID 619) in 88 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (49/50)\n",
      "25/11/13 16:17:45 INFO TaskSetManager: Finished task 49.0 in stage 46.0 (TID 620) in 93 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (50/50)\n",
      "25/11/13 16:17:45 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool \n",
      "25/11/13 16:17:45 INFO DAGScheduler: ShuffleMapStage 46 (count at NativeMethodAccessorImpl.java:0) finished in 2.363 s\n",
      "25/11/13 16:17:45 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/11/13 16:17:45 INFO DAGScheduler: running: Set()\n",
      "25/11/13 16:17:45 INFO DAGScheduler: waiting: Set()\n",
      "25/11/13 16:17:45 INFO DAGScheduler: failed: Set()\n",
      "25/11/13 16:17:45 INFO CodeGenerator: Code generated in 11.024448 ms\n",
      "25/11/13 16:17:45 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0\n",
      "25/11/13 16:17:45 INFO DAGScheduler: Got job 30 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/11/13 16:17:45 INFO DAGScheduler: Final stage: ResultStage 49 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/11/13 16:17:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 48)\n",
      "25/11/13 16:17:45 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 16:17:45 INFO DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[128] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/11/13 16:17:45 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 14.9 KiB, free 1047.0 MiB)\n",
      "25/11/13 16:17:45 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 1047.0 MiB)\n",
      "25/11/13 16:17:45 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 6.6 KiB, free: 1048.5 MiB)\n",
      "25/11/13 16:17:45 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 16:17:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[128] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/11/13 16:17:45 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks resource profile 0\n",
      "25/11/13 16:17:45 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 621) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, NODE_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:45 INFO Executor: Running task 0.0 in stage 49.0 (TID 621)\n",
      "25/11/13 16:17:45 INFO ShuffleBlockFetcherIterator: Getting 50 (2.9 KiB) non-empty blocks including 50 (2.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/11/13 16:17:45 INFO CodeGenerator: Code generated in 9.727404 ms\n",
      "25/11/13 16:17:45 INFO Executor: Finished task 0.0 in stage 49.0 (TID 621). 4004 bytes result sent to driver\n",
      "25/11/13 16:17:45 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 621) in 59 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/1)\n",
      "25/11/13 16:17:45 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool \n",
      "25/11/13 16:17:45 INFO DAGScheduler: ResultStage 49 (count at NativeMethodAccessorImpl.java:0) finished in 0.077 s\n",
      "25/11/13 16:17:45 INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/11/13 16:17:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 49: Stage finished\n",
      "25/11/13 16:17:45 INFO DAGScheduler: Job 30 finished: count at NativeMethodAccessorImpl.java:0, took 0.101390 s\n",
      "25/11/13 16:17:45 INFO CodeGenerator: Code generated in 10.998358 ms            \n",
      "25/11/13 16:17:45 INFO CodeGenerator: Code generated in 6.739949 ms\n",
      "25/11/13 16:17:45 INFO PrepareDeltaScan: DELTA: Filtering files for query\n",
      "25/11/13 16:17:45 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128\n",
      "25/11/13 16:17:45 INFO DAGScheduler: Got job 31 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions\n",
      "25/11/13 16:17:45 INFO DAGScheduler: Final stage: ResultStage 51 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)\n",
      "25/11/13 16:17:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 50)\n",
      "25/11/13 16:17:45 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 16:17:45 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[130] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents\n",
      "25/11/13 16:17:45 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 684.9 KiB, free 1046.3 MiB)\n",
      "25/11/13 16:17:45 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 154.5 KiB, free 1046.2 MiB)\n",
      "25/11/13 16:17:45 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 154.5 KiB, free: 1048.3 MiB)\n",
      "25/11/13 16:17:45 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 16:17:45 INFO DAGScheduler: Submitting 50 missing tasks from ResultStage 51 (MapPartitionsRDD[130] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n",
      "25/11/13 16:17:45 INFO TaskSchedulerImpl: Adding task set 51.0 with 50 tasks resource profile 0\n",
      "25/11/13 16:17:45 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 622) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:45 INFO TaskSetManager: Starting task 1.0 in stage 51.0 (TID 623) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 1, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:45 INFO Executor: Running task 1.0 in stage 51.0 (TID 623)\n",
      "25/11/13 16:17:45 INFO Executor: Running task 0.0 in stage 51.0 (TID 622)\n",
      "25/11/13 16:17:45 INFO BlockManager: Found block rdd_106_1 locally\n",
      "25/11/13 16:17:45 INFO Executor: Finished task 1.0 in stage 51.0 (TID 623). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:45 INFO TaskSetManager: Starting task 2.0 in stage 51.0 (TID 624) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 2, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:45 INFO TaskSetManager: Finished task 1.0 in stage 51.0 (TID 623) in 31 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/50)\n",
      "25/11/13 16:17:45 INFO Executor: Running task 2.0 in stage 51.0 (TID 624)\n",
      "25/11/13 16:17:45 INFO BlockManager: Found block rdd_106_0 locally\n",
      "25/11/13 16:17:45 INFO Executor: Finished task 0.0 in stage 51.0 (TID 622). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:45 INFO TaskSetManager: Starting task 3.0 in stage 51.0 (TID 625) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 3, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:45 INFO Executor: Running task 3.0 in stage 51.0 (TID 625)\n",
      "25/11/13 16:17:45 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 622) in 35 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (2/50)\n",
      "25/11/13 16:17:45 INFO BlockManager: Found block rdd_106_2 locally\n",
      "25/11/13 16:17:45 INFO Executor: Finished task 2.0 in stage 51.0 (TID 624). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:45 INFO BlockManager: Found block rdd_106_3 locally\n",
      "25/11/13 16:17:45 INFO TaskSetManager: Starting task 4.0 in stage 51.0 (TID 626) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 4, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:45 INFO Executor: Running task 4.0 in stage 51.0 (TID 626)\n",
      "25/11/13 16:17:45 INFO TaskSetManager: Finished task 2.0 in stage 51.0 (TID 624) in 22 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (3/50)\n",
      "25/11/13 16:17:45 INFO Executor: Finished task 3.0 in stage 51.0 (TID 625). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:45 INFO TaskSetManager: Starting task 5.0 in stage 51.0 (TID 627) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 5, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:45 INFO TaskSetManager: Finished task 3.0 in stage 51.0 (TID 625) in 20 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (4/50)\n",
      "25/11/13 16:17:45 INFO Executor: Running task 5.0 in stage 51.0 (TID 627)\n",
      "25/11/13 16:17:46 INFO BlockManager: Found block rdd_106_4 locally\n",
      "25/11/13 16:17:46 INFO Executor: Finished task 4.0 in stage 51.0 (TID 626). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Starting task 6.0 in stage 51.0 (TID 628) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 6, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:46 INFO TaskSetManager: Finished task 4.0 in stage 51.0 (TID 626) in 39 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (5/50)\n",
      "25/11/13 16:17:46 INFO Executor: Running task 6.0 in stage 51.0 (TID 628)\n",
      "25/11/13 16:17:46 INFO BlockManager: Found block rdd_106_5 locally\n",
      "25/11/13 16:17:46 INFO Executor: Finished task 5.0 in stage 51.0 (TID 627). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Starting task 7.0 in stage 51.0 (TID 629) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 7, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:46 INFO Executor: Running task 7.0 in stage 51.0 (TID 629)\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Finished task 5.0 in stage 51.0 (TID 627) in 43 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (6/50)\n",
      "25/11/13 16:17:46 INFO BlockManager: Found block rdd_106_6 locally\n",
      "25/11/13 16:17:46 INFO Executor: Finished task 6.0 in stage 51.0 (TID 628). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Starting task 8.0 in stage 51.0 (TID 630) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 8, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:46 INFO TaskSetManager: Finished task 6.0 in stage 51.0 (TID 628) in 45 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (7/50)\n",
      "25/11/13 16:17:46 INFO Executor: Running task 8.0 in stage 51.0 (TID 630)\n",
      "25/11/13 16:17:46 INFO BlockManager: Found block rdd_106_7 locally\n",
      "25/11/13 16:17:46 INFO Executor: Finished task 7.0 in stage 51.0 (TID 629). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Starting task 9.0 in stage 51.0 (TID 631) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 9, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:46 INFO Executor: Running task 9.0 in stage 51.0 (TID 631)\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Finished task 7.0 in stage 51.0 (TID 629) in 41 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (8/50)\n",
      "25/11/13 16:17:46 INFO BlockManager: Found block rdd_106_8 locally\n",
      "25/11/13 16:17:46 INFO Executor: Finished task 8.0 in stage 51.0 (TID 630). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Starting task 10.0 in stage 51.0 (TID 632) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 10, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:46 INFO TaskSetManager: Finished task 8.0 in stage 51.0 (TID 630) in 18 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (9/50)\n",
      "25/11/13 16:17:46 INFO Executor: Running task 10.0 in stage 51.0 (TID 632)\n",
      "25/11/13 16:17:46 INFO BlockManager: Found block rdd_106_9 locally\n",
      "25/11/13 16:17:46 INFO Executor: Finished task 9.0 in stage 51.0 (TID 631). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Starting task 11.0 in stage 51.0 (TID 633) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 11, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:46 INFO TaskSetManager: Finished task 9.0 in stage 51.0 (TID 631) in 18 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (10/50)\n",
      "25/11/13 16:17:46 INFO Executor: Running task 11.0 in stage 51.0 (TID 633)\n",
      "25/11/13 16:17:46 INFO BlockManager: Found block rdd_106_10 locally\n",
      "25/11/13 16:17:46 INFO Executor: Finished task 10.0 in stage 51.0 (TID 632). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Starting task 12.0 in stage 51.0 (TID 634) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 12, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:46 INFO Executor: Running task 12.0 in stage 51.0 (TID 634)\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Finished task 10.0 in stage 51.0 (TID 632) in 39 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (11/50)\n",
      "25/11/13 16:17:46 INFO BlockManager: Found block rdd_106_11 locally\n",
      "25/11/13 16:17:46 INFO Executor: Finished task 11.0 in stage 51.0 (TID 633). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Starting task 13.0 in stage 51.0 (TID 635) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 13, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:46 INFO Executor: Running task 13.0 in stage 51.0 (TID 635)\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Finished task 11.0 in stage 51.0 (TID 633) in 41 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (12/50)\n",
      "25/11/13 16:17:46 INFO BlockManager: Found block rdd_106_12 locally\n",
      "25/11/13 16:17:46 INFO BlockManager: Found block rdd_106_13 locally\n",
      "25/11/13 16:17:46 INFO Executor: Finished task 12.0 in stage 51.0 (TID 634). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Starting task 14.0 in stage 51.0 (TID 636) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 14, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:46 INFO Executor: Finished task 13.0 in stage 51.0 (TID 635). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:46 INFO Executor: Running task 14.0 in stage 51.0 (TID 636)\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Starting task 15.0 in stage 51.0 (TID 637) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 15, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:46 INFO Executor: Running task 15.0 in stage 51.0 (TID 637)\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Finished task 12.0 in stage 51.0 (TID 634) in 65 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (13/50)\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Finished task 13.0 in stage 51.0 (TID 635) in 36 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (14/50)\n",
      "25/11/13 16:17:46 INFO BlockManager: Found block rdd_106_15 locally\n",
      "25/11/13 16:17:46 INFO BlockManager: Found block rdd_106_14 locally\n",
      "25/11/13 16:17:46 INFO Executor: Finished task 14.0 in stage 51.0 (TID 636). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:46 INFO Executor: Finished task 15.0 in stage 51.0 (TID 637). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Starting task 16.0 in stage 51.0 (TID 638) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 16, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:46 INFO Executor: Running task 16.0 in stage 51.0 (TID 638)\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Starting task 17.0 in stage 51.0 (TID 639) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 17, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:46 INFO Executor: Running task 17.0 in stage 51.0 (TID 639)\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Finished task 14.0 in stage 51.0 (TID 636) in 21 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (15/50)\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Finished task 15.0 in stage 51.0 (TID 637) in 20 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (16/50)\n",
      "25/11/13 16:17:46 INFO BlockManager: Found block rdd_106_16 locally\n",
      "25/11/13 16:17:46 INFO BlockManager: Found block rdd_106_17 locally\n",
      "25/11/13 16:17:46 INFO Executor: Finished task 16.0 in stage 51.0 (TID 638). 4267 bytes result sent to driver\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Starting task 18.0 in stage 51.0 (TID 640) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 18, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:46 INFO Executor: Running task 18.0 in stage 51.0 (TID 640)\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Finished task 16.0 in stage 51.0 (TID 638) in 87 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (17/50)\n",
      "25/11/13 16:17:46 INFO Executor: Finished task 17.0 in stage 51.0 (TID 639). 4224 bytes result sent to driver\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Starting task 19.0 in stage 51.0 (TID 641) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 19, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:46 INFO Executor: Running task 19.0 in stage 51.0 (TID 641)\n",
      "25/11/13 16:17:46 INFO BlockManagerInfo: Removed broadcast_45_piece0 on jupyter-spark-758b7c86d8-7j77n:32921 in memory (size: 162.8 KiB, free: 1048.5 MiB)\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Finished task 17.0 in stage 51.0 (TID 639) in 92 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (18/50)\n",
      "25/11/13 16:17:46 INFO BlockManagerInfo: Removed broadcast_46_piece0 on jupyter-spark-758b7c86d8-7j77n:32921 in memory (size: 6.6 KiB, free: 1048.5 MiB)\n",
      "25/11/13 16:17:46 INFO BlockManager: Found block rdd_106_18 locally\n",
      "25/11/13 16:17:46 INFO Executor: Finished task 18.0 in stage 51.0 (TID 640). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Starting task 20.0 in stage 51.0 (TID 642) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 20, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:46 INFO Executor: Running task 20.0 in stage 51.0 (TID 642)\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Finished task 18.0 in stage 51.0 (TID 640) in 59 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (19/50)\n",
      "25/11/13 16:17:46 INFO BlockManager: Found block rdd_106_19 locally\n",
      "25/11/13 16:17:46 INFO Executor: Finished task 19.0 in stage 51.0 (TID 641). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Starting task 21.0 in stage 51.0 (TID 643) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 21, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:46 INFO Executor: Running task 21.0 in stage 51.0 (TID 643)\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Finished task 19.0 in stage 51.0 (TID 641) in 87 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (20/50)\n",
      "25/11/13 16:17:46 INFO BlockManager: Found block rdd_106_20 locally\n",
      "25/11/13 16:17:46 INFO Executor: Finished task 20.0 in stage 51.0 (TID 642). 4346 bytes result sent to driver\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Starting task 22.0 in stage 51.0 (TID 644) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 22, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:46 INFO Executor: Running task 22.0 in stage 51.0 (TID 644)\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Finished task 20.0 in stage 51.0 (TID 642) in 48 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (21/50)\n",
      "25/11/13 16:17:46 INFO BlockManager: Found block rdd_106_21 locally\n",
      "25/11/13 16:17:46 INFO Executor: Finished task 21.0 in stage 51.0 (TID 643). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Starting task 23.0 in stage 51.0 (TID 645) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 23, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:46 INFO Executor: Running task 23.0 in stage 51.0 (TID 645)\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Finished task 21.0 in stage 51.0 (TID 643) in 52 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (22/50)\n",
      "25/11/13 16:17:46 INFO BlockManager: Found block rdd_106_22 locally\n",
      "25/11/13 16:17:46 INFO Executor: Finished task 22.0 in stage 51.0 (TID 644). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Starting task 24.0 in stage 51.0 (TID 646) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 24, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:46 INFO TaskSetManager: Finished task 22.0 in stage 51.0 (TID 644) in 61 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (23/50)\n",
      "25/11/13 16:17:46 INFO BlockManager: Found block rdd_106_23 locally\n",
      "25/11/13 16:17:46 INFO Executor: Running task 24.0 in stage 51.0 (TID 646)\n",
      "25/11/13 16:17:46 INFO Executor: Finished task 23.0 in stage 51.0 (TID 645). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Starting task 25.0 in stage 51.0 (TID 647) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 25, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:46 INFO Executor: Running task 25.0 in stage 51.0 (TID 647)\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Finished task 23.0 in stage 51.0 (TID 645) in 81 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (24/50)\n",
      "25/11/13 16:17:46 INFO BlockManager: Found block rdd_106_24 locally\n",
      "25/11/13 16:17:46 INFO BlockManager: Found block rdd_106_25 locally\n",
      "25/11/13 16:17:46 INFO Executor: Finished task 25.0 in stage 51.0 (TID 647). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:46 INFO Executor: Finished task 24.0 in stage 51.0 (TID 646). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Starting task 26.0 in stage 51.0 (TID 648) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 26, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:46 INFO Executor: Running task 26.0 in stage 51.0 (TID 648)\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Starting task 27.0 in stage 51.0 (TID 649) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 27, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:46 INFO Executor: Running task 27.0 in stage 51.0 (TID 649)\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Finished task 24.0 in stage 51.0 (TID 646) in 51 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (25/50)\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Finished task 25.0 in stage 51.0 (TID 647) in 23 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (26/50)\n",
      "25/11/13 16:17:46 INFO BlockManager: Found block rdd_106_27 locally26 + 2) / 50]\n",
      "25/11/13 16:17:46 INFO Executor: Finished task 27.0 in stage 51.0 (TID 649). 4224 bytes result sent to driver\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Starting task 28.0 in stage 51.0 (TID 650) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 28, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:46 INFO Executor: Running task 28.0 in stage 51.0 (TID 650)\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Finished task 27.0 in stage 51.0 (TID 649) in 81 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (27/50)\n",
      "25/11/13 16:17:46 INFO BlockManager: Found block rdd_106_26 locally\n",
      "25/11/13 16:17:46 INFO Executor: Finished task 26.0 in stage 51.0 (TID 648). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Starting task 29.0 in stage 51.0 (TID 651) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 29, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:46 INFO Executor: Running task 29.0 in stage 51.0 (TID 651)\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Finished task 26.0 in stage 51.0 (TID 648) in 90 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (28/50)\n",
      "25/11/13 16:17:46 INFO BlockManager: Found block rdd_106_28 locally\n",
      "25/11/13 16:17:46 INFO Executor: Finished task 28.0 in stage 51.0 (TID 650). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Starting task 30.0 in stage 51.0 (TID 652) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 30, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:46 INFO Executor: Running task 30.0 in stage 51.0 (TID 652)\n",
      "25/11/13 16:17:46 INFO BlockManager: Found block rdd_106_29 locally\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Finished task 28.0 in stage 51.0 (TID 650) in 24 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (29/50)\n",
      "25/11/13 16:17:46 INFO Executor: Finished task 29.0 in stage 51.0 (TID 651). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Starting task 31.0 in stage 51.0 (TID 653) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 31, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:46 INFO Executor: Running task 31.0 in stage 51.0 (TID 653)\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Finished task 29.0 in stage 51.0 (TID 651) in 19 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (30/50)\n",
      "25/11/13 16:17:46 INFO BlockManager: Found block rdd_106_30 locally\n",
      "25/11/13 16:17:46 INFO Executor: Finished task 30.0 in stage 51.0 (TID 652). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Starting task 32.0 in stage 51.0 (TID 654) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 32, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:46 INFO Executor: Running task 32.0 in stage 51.0 (TID 654)\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Finished task 30.0 in stage 51.0 (TID 652) in 80 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (31/50)\n",
      "25/11/13 16:17:46 INFO BlockManager: Found block rdd_106_31 locally\n",
      "25/11/13 16:17:46 INFO Executor: Finished task 31.0 in stage 51.0 (TID 653). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Starting task 33.0 in stage 51.0 (TID 655) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 33, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:46 INFO Executor: Running task 33.0 in stage 51.0 (TID 655)\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Finished task 31.0 in stage 51.0 (TID 653) in 81 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (32/50)\n",
      "25/11/13 16:17:46 INFO BlockManager: Found block rdd_106_32 locally\n",
      "25/11/13 16:17:46 INFO Executor: Finished task 32.0 in stage 51.0 (TID 654). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Starting task 34.0 in stage 51.0 (TID 656) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 34, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:46 INFO BlockManager: Found block rdd_106_33 locally\n",
      "25/11/13 16:17:46 INFO Executor: Running task 34.0 in stage 51.0 (TID 656)\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Finished task 32.0 in stage 51.0 (TID 654) in 22 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (33/50)\n",
      "25/11/13 16:17:46 INFO Executor: Finished task 33.0 in stage 51.0 (TID 655). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Starting task 35.0 in stage 51.0 (TID 657) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 35, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:46 INFO TaskSetManager: Finished task 33.0 in stage 51.0 (TID 655) in 19 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (34/50)\n",
      "25/11/13 16:17:46 INFO Executor: Running task 35.0 in stage 51.0 (TID 657)\n",
      "25/11/13 16:17:46 INFO BlockManager: Found block rdd_106_34 locally34 + 2) / 50]\n",
      "25/11/13 16:17:46 INFO BlockManager: Found block rdd_106_35 locally\n",
      "25/11/13 16:17:46 INFO Executor: Finished task 34.0 in stage 51.0 (TID 656). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Starting task 36.0 in stage 51.0 (TID 658) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 36, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:46 INFO Executor: Finished task 35.0 in stage 51.0 (TID 657). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:46 INFO Executor: Running task 36.0 in stage 51.0 (TID 658)\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Starting task 37.0 in stage 51.0 (TID 659) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 37, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:46 INFO TaskSetManager: Finished task 34.0 in stage 51.0 (TID 656) in 53 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (35/50)\n",
      "25/11/13 16:17:46 INFO Executor: Running task 37.0 in stage 51.0 (TID 659)\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Finished task 35.0 in stage 51.0 (TID 657) in 72 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (36/50)\n",
      "25/11/13 16:17:46 INFO BlockManager: Found block rdd_106_36 locally\n",
      "25/11/13 16:17:46 INFO BlockManager: Found block rdd_106_37 locally\n",
      "25/11/13 16:17:46 INFO Executor: Finished task 36.0 in stage 51.0 (TID 658). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:46 INFO Executor: Finished task 37.0 in stage 51.0 (TID 659). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Starting task 38.0 in stage 51.0 (TID 660) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 38, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:46 INFO Executor: Running task 38.0 in stage 51.0 (TID 660)\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Starting task 39.0 in stage 51.0 (TID 661) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 39, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:46 INFO Executor: Running task 39.0 in stage 51.0 (TID 661)\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Finished task 36.0 in stage 51.0 (TID 658) in 41 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (37/50)\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Finished task 37.0 in stage 51.0 (TID 659) in 41 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (38/50)\n",
      "25/11/13 16:17:46 INFO BlockManager: Found block rdd_106_38 locally\n",
      "25/11/13 16:17:46 INFO Executor: Finished task 38.0 in stage 51.0 (TID 660). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Starting task 40.0 in stage 51.0 (TID 662) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 40, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:46 INFO Executor: Running task 40.0 in stage 51.0 (TID 662)\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Finished task 38.0 in stage 51.0 (TID 660) in 50 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (39/50)\n",
      "25/11/13 16:17:46 INFO BlockManager: Found block rdd_106_39 locally\n",
      "25/11/13 16:17:46 INFO Executor: Finished task 39.0 in stage 51.0 (TID 661). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Starting task 41.0 in stage 51.0 (TID 663) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 41, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:46 INFO Executor: Running task 41.0 in stage 51.0 (TID 663)\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Finished task 39.0 in stage 51.0 (TID 661) in 56 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (40/50)\n",
      "25/11/13 16:17:46 INFO BlockManager: Found block rdd_106_40 locally\n",
      "25/11/13 16:17:46 INFO Executor: Finished task 40.0 in stage 51.0 (TID 662). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Starting task 42.0 in stage 51.0 (TID 664) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 42, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:46 INFO Executor: Running task 42.0 in stage 51.0 (TID 664)\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Finished task 40.0 in stage 51.0 (TID 662) in 77 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (41/50)\n",
      "25/11/13 16:17:46 INFO BlockManager: Found block rdd_106_41 locally\n",
      "25/11/13 16:17:46 INFO Executor: Finished task 41.0 in stage 51.0 (TID 663). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Starting task 43.0 in stage 51.0 (TID 665) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 43, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:46 INFO Executor: Running task 43.0 in stage 51.0 (TID 665)\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Finished task 41.0 in stage 51.0 (TID 663) in 45 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (42/50)\n",
      "25/11/13 16:17:46 INFO BlockManager: Found block rdd_106_42 locally\n",
      "25/11/13 16:17:46 INFO Executor: Finished task 42.0 in stage 51.0 (TID 664). 4224 bytes result sent to driver\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Starting task 44.0 in stage 51.0 (TID 666) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 44, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:46 INFO Executor: Running task 44.0 in stage 51.0 (TID 666)\n",
      "25/11/13 16:17:46 INFO TaskSetManager: Finished task 42.0 in stage 51.0 (TID 664) in 17 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (43/50)\n",
      "25/11/13 16:17:47 INFO BlockManager: Found block rdd_106_43 locally43 + 2) / 50]\n",
      "25/11/13 16:17:47 INFO Executor: Finished task 43.0 in stage 51.0 (TID 665). 4224 bytes result sent to driver\n",
      "25/11/13 16:17:47 INFO TaskSetManager: Starting task 45.0 in stage 51.0 (TID 667) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 45, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:47 INFO Executor: Running task 45.0 in stage 51.0 (TID 667)\n",
      "25/11/13 16:17:47 INFO TaskSetManager: Finished task 43.0 in stage 51.0 (TID 665) in 152 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (44/50)\n",
      "25/11/13 16:17:47 INFO BlockManager: Found block rdd_106_44 locally\n",
      "25/11/13 16:17:47 INFO Executor: Finished task 44.0 in stage 51.0 (TID 666). 4224 bytes result sent to driver\n",
      "25/11/13 16:17:47 INFO BlockManager: Found block rdd_106_45 locally\n",
      "25/11/13 16:17:47 INFO TaskSetManager: Starting task 46.0 in stage 51.0 (TID 668) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 46, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:47 INFO Executor: Running task 46.0 in stage 51.0 (TID 668)\n",
      "25/11/13 16:17:47 INFO TaskSetManager: Finished task 44.0 in stage 51.0 (TID 666) in 184 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (45/50)\n",
      "25/11/13 16:17:47 INFO Executor: Finished task 45.0 in stage 51.0 (TID 667). 4224 bytes result sent to driver\n",
      "25/11/13 16:17:47 INFO TaskSetManager: Starting task 47.0 in stage 51.0 (TID 669) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 47, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:47 INFO Executor: Running task 47.0 in stage 51.0 (TID 669)\n",
      "25/11/13 16:17:47 INFO TaskSetManager: Finished task 45.0 in stage 51.0 (TID 667) in 45 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (46/50)\n",
      "25/11/13 16:17:47 INFO BlockManager: Found block rdd_106_46 locally\n",
      "25/11/13 16:17:47 INFO BlockManager: Found block rdd_106_47 locally\n",
      "25/11/13 16:17:47 INFO Executor: Finished task 46.0 in stage 51.0 (TID 668). 4224 bytes result sent to driver\n",
      "25/11/13 16:17:47 INFO TaskSetManager: Starting task 48.0 in stage 51.0 (TID 670) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 48, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:47 INFO Executor: Running task 48.0 in stage 51.0 (TID 670)\n",
      "25/11/13 16:17:47 INFO TaskSetManager: Finished task 46.0 in stage 51.0 (TID 668) in 27 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (47/50)\n",
      "25/11/13 16:17:47 INFO Executor: Finished task 47.0 in stage 51.0 (TID 669). 4224 bytes result sent to driver\n",
      "25/11/13 16:17:47 INFO TaskSetManager: Starting task 49.0 in stage 51.0 (TID 671) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 49, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:47 INFO Executor: Running task 49.0 in stage 51.0 (TID 671)\n",
      "25/11/13 16:17:47 INFO TaskSetManager: Finished task 47.0 in stage 51.0 (TID 669) in 25 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (48/50)\n",
      "25/11/13 16:17:47 INFO BlockManager: Found block rdd_106_48 locally\n",
      "25/11/13 16:17:47 INFO BlockManager: Found block rdd_106_49 locally\n",
      "25/11/13 16:17:47 INFO Executor: Finished task 48.0 in stage 51.0 (TID 670). 4224 bytes result sent to driver\n",
      "25/11/13 16:17:47 INFO Executor: Finished task 49.0 in stage 51.0 (TID 671). 4224 bytes result sent to driver\n",
      "25/11/13 16:17:47 INFO TaskSetManager: Finished task 48.0 in stage 51.0 (TID 670) in 50 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (49/50)\n",
      "25/11/13 16:17:47 INFO TaskSetManager: Finished task 49.0 in stage 51.0 (TID 671) in 66 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (50/50)\n",
      "25/11/13 16:17:47 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool \n",
      "25/11/13 16:17:47 INFO DAGScheduler: ResultStage 51 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 1.243 s\n",
      "25/11/13 16:17:47 INFO DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/11/13 16:17:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 51: Stage finished\n",
      "25/11/13 16:17:47 INFO DAGScheduler: Job 31 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 1.252757 s\n",
      "25/11/13 16:17:47 INFO PrepareDeltaScan: DELTA: Done                            \n",
      "25/11/13 16:17:47 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/11/13 16:17:47 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/11/13 16:17:47 INFO CodeGenerator: Code generated in 65.143579 ms\n",
      "25/11/13 16:17:47 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 204.3 KiB, free 1046.8 MiB)\n",
      "25/11/13 16:17:47 INFO BlockManagerInfo: Removed broadcast_47_piece0 on jupyter-spark-758b7c86d8-7j77n:32921 in memory (size: 154.5 KiB, free: 1048.6 MiB)\n",
      "25/11/13 16:17:47 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 36.0 KiB, free 1047.6 MiB)\n",
      "25/11/13 16:17:47 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 36.0 KiB, free: 1048.6 MiB)\n",
      "25/11/13 16:17:47 INFO SparkContext: Created broadcast 48 from count at NativeMethodAccessorImpl.java:0\n",
      "25/11/13 16:17:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 5904079 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/11/13 16:17:47 INFO DAGScheduler: Registering RDD 134 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 7\n",
      "25/11/13 16:17:47 INFO DAGScheduler: Got map stage job 32 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions\n",
      "25/11/13 16:17:47 INFO DAGScheduler: Final stage: ShuffleMapStage 52 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/11/13 16:17:47 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/11/13 16:17:47 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 16:17:47 INFO DAGScheduler: Submitting ShuffleMapStage 52 (MapPartitionsRDD[134] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/11/13 16:17:47 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 34.3 KiB, free 1047.6 MiB)\n",
      "25/11/13 16:17:47 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1047.6 MiB)\n",
      "25/11/13 16:17:47 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 14.8 KiB, free: 1048.6 MiB)\n",
      "25/11/13 16:17:47 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 16:17:47 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 52 (MapPartitionsRDD[134] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))\n",
      "25/11/13 16:17:47 INFO TaskSchedulerImpl: Adding task set 52.0 with 2 tasks resource profile 0\n",
      "25/11/13 16:17:47 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 672) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 9668 bytes) \n",
      "25/11/13 16:17:47 INFO TaskSetManager: Starting task 1.0 in stage 52.0 (TID 673) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 1, PROCESS_LOCAL, 9668 bytes) \n",
      "25/11/13 16:17:47 INFO Executor: Running task 1.0 in stage 52.0 (TID 673)\n",
      "25/11/13 16:17:47 INFO Executor: Running task 0.0 in stage 52.0 (TID 672)\n",
      "25/11/13 16:17:47 INFO CodeGenerator: Code generated in 92.563221 ms\n",
      "25/11/13 16:17:47 INFO CodeGenerator: Code generated in 16.530038 ms\n",
      "25/11/13 16:17:47 INFO CodeGenerator: Code generated in 9.972199 ms\n",
      "25/11/13 16:17:47 INFO FileScanRDD: Reading File path: s3a://nau-local-analytics-silver/dim_user_profile/part-00000-26092a00-ec88-42f6-860b-8e610b908cb4-c000.snappy.parquet, range: 5904079-7613854, partition values: [empty row]\n",
      "25/11/13 16:17:47 INFO FileScanRDD: Reading File path: s3a://nau-local-analytics-silver/dim_user_profile/part-00000-26092a00-ec88-42f6-860b-8e610b908cb4-c000.snappy.parquet, range: 0-5904079, partition values: [empty row]\n",
      "25/11/13 16:17:47 INFO S3AInputStream: Switching to Random IO seek policy\n",
      "25/11/13 16:17:47 INFO S3AInputStream: Switching to Random IO seek policy\n",
      "25/11/13 16:17:47 INFO Executor: Finished task 1.0 in stage 52.0 (TID 673). 2779 bytes result sent to driver\n",
      "25/11/13 16:17:47 INFO TaskSetManager: Finished task 1.0 in stage 52.0 (TID 673) in 410 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/2)\n",
      "25/11/13 16:17:49 INFO Executor: Finished task 0.0 in stage 52.0 (TID 672). 2951 bytes result sent to driver\n",
      "25/11/13 16:17:49 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 672) in 1595 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (2/2)\n",
      "25/11/13 16:17:49 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool \n",
      "25/11/13 16:17:49 INFO DAGScheduler: ShuffleMapStage 52 (count at NativeMethodAccessorImpl.java:0) finished in 1.626 s\n",
      "25/11/13 16:17:49 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/11/13 16:17:49 INFO DAGScheduler: running: Set()\n",
      "25/11/13 16:17:49 INFO DAGScheduler: waiting: Set()\n",
      "25/11/13 16:17:49 INFO DAGScheduler: failed: Set()\n",
      "25/11/13 16:17:49 INFO ShufflePartitionsUtil: For shuffle(7), advisory target size: 67108864, actual target size 1407690, minimum partition size: 1048576\n",
      "25/11/13 16:17:49 INFO CodeGenerator: Code generated in 45.06008 ms\n",
      "25/11/13 16:17:49 INFO DAGScheduler: Registering RDD 137 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 8\n",
      "25/11/13 16:17:49 INFO DAGScheduler: Got map stage job 33 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions\n",
      "25/11/13 16:17:49 INFO DAGScheduler: Final stage: ShuffleMapStage 54 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/11/13 16:17:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 53)\n",
      "25/11/13 16:17:49 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 16:17:49 INFO DAGScheduler: Submitting ShuffleMapStage 54 (MapPartitionsRDD[137] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/11/13 16:17:49 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 49.3 KiB, free 1047.5 MiB)\n",
      "25/11/13 16:17:49 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 21.8 KiB, free 1047.5 MiB)\n",
      "25/11/13 16:17:49 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 21.8 KiB, free: 1048.6 MiB)\n",
      "25/11/13 16:17:49 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 16:17:49 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 54 (MapPartitionsRDD[137] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))\n",
      "25/11/13 16:17:49 INFO TaskSchedulerImpl: Adding task set 54.0 with 2 tasks resource profile 0\n",
      "25/11/13 16:17:49 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 674) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, NODE_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:49 INFO TaskSetManager: Starting task 1.0 in stage 54.0 (TID 675) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 1, NODE_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:49 INFO Executor: Running task 0.0 in stage 54.0 (TID 674)\n",
      "25/11/13 16:17:49 INFO Executor: Running task 1.0 in stage 54.0 (TID 675)\n",
      "25/11/13 16:17:49 INFO ShuffleBlockFetcherIterator: Getting 1 (1370.0 KiB) non-empty blocks including 1 (1370.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:49 INFO ShuffleBlockFetcherIterator: Getting 1 (1379.3 KiB) non-empty blocks including 1 (1379.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "25/11/13 16:17:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/11/13 16:17:49 INFO CodeGenerator: Code generated in 60.184313 ms\n",
      "25/11/13 16:17:49 INFO BlockManagerInfo: Removed broadcast_49_piece0 on jupyter-spark-758b7c86d8-7j77n:32921 in memory (size: 14.8 KiB, free: 1048.6 MiB)\n",
      "25/11/13 16:17:51 INFO Executor: Finished task 1.0 in stage 54.0 (TID 675). 5864 bytes result sent to driver\n",
      "25/11/13 16:17:51 INFO TaskSetManager: Finished task 1.0 in stage 54.0 (TID 675) in 1871 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/2)\n",
      "25/11/13 16:17:51 INFO Executor: Finished task 0.0 in stage 54.0 (TID 674). 5864 bytes result sent to driver\n",
      "25/11/13 16:17:51 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 674) in 1906 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (2/2)\n",
      "25/11/13 16:17:51 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool \n",
      "25/11/13 16:17:51 INFO DAGScheduler: ShuffleMapStage 54 (count at NativeMethodAccessorImpl.java:0) finished in 1.931 s\n",
      "25/11/13 16:17:51 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/11/13 16:17:51 INFO DAGScheduler: running: Set()\n",
      "25/11/13 16:17:51 INFO DAGScheduler: waiting: Set()\n",
      "25/11/13 16:17:51 INFO DAGScheduler: failed: Set()\n",
      "25/11/13 16:17:51 INFO CodeGenerator: Code generated in 12.193569 ms\n",
      "25/11/13 16:17:51 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0\n",
      "25/11/13 16:17:51 INFO DAGScheduler: Got job 34 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/11/13 16:17:51 INFO DAGScheduler: Final stage: ResultStage 57 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/11/13 16:17:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 56)\n",
      "25/11/13 16:17:51 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 16:17:51 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[140] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/11/13 16:17:51 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 12.5 KiB, free 1047.5 MiB)\n",
      "25/11/13 16:17:51 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 1047.5 MiB)\n",
      "25/11/13 16:17:51 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 5.9 KiB, free: 1048.6 MiB)\n",
      "25/11/13 16:17:51 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 16:17:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[140] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/11/13 16:17:51 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks resource profile 0\n",
      "25/11/13 16:17:51 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 676) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, NODE_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:51 INFO Executor: Running task 0.0 in stage 57.0 (TID 676)\n",
      "25/11/13 16:17:51 INFO ShuffleBlockFetcherIterator: Getting 2 (120.0 B) non-empty blocks including 2 (120.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:51 INFO CodeGenerator: Code generated in 7.594972 ms\n",
      "25/11/13 16:17:51 INFO Executor: Finished task 0.0 in stage 57.0 (TID 676). 3995 bytes result sent to driver\n",
      "25/11/13 16:17:51 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 676) in 19 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/1)\n",
      "25/11/13 16:17:51 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool \n",
      "25/11/13 16:17:51 INFO DAGScheduler: ResultStage 57 (count at NativeMethodAccessorImpl.java:0) finished in 0.034 s\n",
      "25/11/13 16:17:51 INFO DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/11/13 16:17:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 57: Stage finished\n",
      "25/11/13 16:17:51 INFO DAGScheduler: Job 34 finished: count at NativeMethodAccessorImpl.java:0, took 0.058041 s\n",
      "25/11/13 16:17:51 INFO PrepareDeltaScan: DELTA: Filtering files for query       \n",
      "25/11/13 16:17:51 INFO BlockManagerInfo: Removed broadcast_48_piece0 on jupyter-spark-758b7c86d8-7j77n:32921 in memory (size: 36.0 KiB, free: 1048.6 MiB)\n",
      "25/11/13 16:17:51 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128\n",
      "25/11/13 16:17:51 INFO DAGScheduler: Got job 35 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions\n",
      "25/11/13 16:17:51 INFO DAGScheduler: Final stage: ResultStage 59 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)\n",
      "25/11/13 16:17:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 58)\n",
      "25/11/13 16:17:51 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 16:17:51 INFO DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[142] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents\n",
      "25/11/13 16:17:51 INFO BlockManagerInfo: Removed broadcast_51_piece0 on jupyter-spark-758b7c86d8-7j77n:32921 in memory (size: 5.9 KiB, free: 1048.6 MiB)\n",
      "25/11/13 16:17:51 INFO BlockManagerInfo: Removed broadcast_50_piece0 on jupyter-spark-758b7c86d8-7j77n:32921 in memory (size: 21.8 KiB, free: 1048.6 MiB)\n",
      "25/11/13 16:17:51 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 684.9 KiB, free 1047.2 MiB)\n",
      "25/11/13 16:17:51 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 154.5 KiB, free 1047.0 MiB)\n",
      "25/11/13 16:17:51 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 154.5 KiB, free: 1048.5 MiB)\n",
      "25/11/13 16:17:51 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 16:17:51 INFO DAGScheduler: Submitting 50 missing tasks from ResultStage 59 (MapPartitionsRDD[142] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n",
      "25/11/13 16:17:51 INFO TaskSchedulerImpl: Adding task set 59.0 with 50 tasks resource profile 0\n",
      "25/11/13 16:17:51 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 677) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:51 INFO TaskSetManager: Starting task 1.0 in stage 59.0 (TID 678) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 1, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:51 INFO Executor: Running task 1.0 in stage 59.0 (TID 678)\n",
      "25/11/13 16:17:51 INFO Executor: Running task 0.0 in stage 59.0 (TID 677)\n",
      "25/11/13 16:17:51 INFO BlockManager: Found block rdd_106_1 locally\n",
      "25/11/13 16:17:51 INFO Executor: Finished task 1.0 in stage 59.0 (TID 678). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:51 INFO BlockManager: Found block rdd_106_0 locally\n",
      "25/11/13 16:17:51 INFO TaskSetManager: Starting task 2.0 in stage 59.0 (TID 679) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 2, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:51 INFO Executor: Running task 2.0 in stage 59.0 (TID 679)\n",
      "25/11/13 16:17:51 INFO TaskSetManager: Finished task 1.0 in stage 59.0 (TID 678) in 34 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/50)\n",
      "25/11/13 16:17:51 INFO Executor: Finished task 0.0 in stage 59.0 (TID 677). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:51 INFO TaskSetManager: Starting task 3.0 in stage 59.0 (TID 680) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 3, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:51 INFO Executor: Running task 3.0 in stage 59.0 (TID 680)\n",
      "25/11/13 16:17:51 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 677) in 43 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (2/50)\n",
      "25/11/13 16:17:51 INFO BlockManager: Found block rdd_106_2 locally\n",
      "25/11/13 16:17:51 INFO Executor: Finished task 2.0 in stage 59.0 (TID 679). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:51 INFO TaskSetManager: Starting task 4.0 in stage 59.0 (TID 681) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 4, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:51 INFO Executor: Running task 4.0 in stage 59.0 (TID 681)\n",
      "25/11/13 16:17:51 INFO BlockManager: Found block rdd_106_3 locally\n",
      "25/11/13 16:17:51 INFO Executor: Finished task 3.0 in stage 59.0 (TID 680). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:51 INFO TaskSetManager: Finished task 2.0 in stage 59.0 (TID 679) in 24 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (3/50)\n",
      "25/11/13 16:17:51 INFO TaskSetManager: Starting task 5.0 in stage 59.0 (TID 682) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 5, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:51 INFO Executor: Running task 5.0 in stage 59.0 (TID 682)\n",
      "25/11/13 16:17:51 INFO TaskSetManager: Finished task 3.0 in stage 59.0 (TID 680) in 61 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (4/50)\n",
      "25/11/13 16:17:51 INFO BlockManager: Found block rdd_106_4 locally\n",
      "25/11/13 16:17:51 INFO Executor: Finished task 4.0 in stage 59.0 (TID 681). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:51 INFO TaskSetManager: Starting task 6.0 in stage 59.0 (TID 683) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 6, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:51 INFO Executor: Running task 6.0 in stage 59.0 (TID 683)\n",
      "25/11/13 16:17:51 INFO TaskSetManager: Finished task 4.0 in stage 59.0 (TID 681) in 56 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (5/50)\n",
      "25/11/13 16:17:51 INFO BlockManager: Found block rdd_106_5 locally\n",
      "25/11/13 16:17:51 INFO Executor: Finished task 5.0 in stage 59.0 (TID 682). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:51 INFO TaskSetManager: Finished task 5.0 in stage 59.0 (TID 682) in 75 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (6/50)\n",
      "25/11/13 16:17:51 INFO TaskSetManager: Starting task 7.0 in stage 59.0 (TID 684) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 7, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:51 INFO Executor: Running task 7.0 in stage 59.0 (TID 684)\n",
      "25/11/13 16:17:51 INFO BlockManager: Found block rdd_106_6 locally\n",
      "25/11/13 16:17:51 INFO Executor: Finished task 6.0 in stage 59.0 (TID 683). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:51 INFO TaskSetManager: Starting task 8.0 in stage 59.0 (TID 685) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 8, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:51 INFO Executor: Running task 8.0 in stage 59.0 (TID 685)\n",
      "25/11/13 16:17:51 INFO TaskSetManager: Finished task 6.0 in stage 59.0 (TID 683) in 46 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (7/50)\n",
      "25/11/13 16:17:51 INFO BlockManager: Found block rdd_106_7 locally\n",
      "25/11/13 16:17:51 INFO Executor: Finished task 7.0 in stage 59.0 (TID 684). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:51 INFO TaskSetManager: Starting task 9.0 in stage 59.0 (TID 686) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 9, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:51 INFO Executor: Running task 9.0 in stage 59.0 (TID 686)\n",
      "25/11/13 16:17:51 INFO TaskSetManager: Finished task 7.0 in stage 59.0 (TID 684) in 28 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (8/50)\n",
      "25/11/13 16:17:52 INFO BlockManager: Found block rdd_106_8 locally\n",
      "25/11/13 16:17:52 INFO Executor: Finished task 8.0 in stage 59.0 (TID 685). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Starting task 10.0 in stage 59.0 (TID 687) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 10, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:52 INFO Executor: Running task 10.0 in stage 59.0 (TID 687)\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Finished task 8.0 in stage 59.0 (TID 685) in 85 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (9/50)\n",
      "25/11/13 16:17:52 INFO BlockManager: Found block rdd_106_9 locally\n",
      "25/11/13 16:17:52 INFO Executor: Finished task 9.0 in stage 59.0 (TID 686). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:52 INFO BlockManager: Found block rdd_106_10 locally\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Starting task 11.0 in stage 59.0 (TID 688) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 11, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:52 INFO Executor: Running task 11.0 in stage 59.0 (TID 688)\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Finished task 9.0 in stage 59.0 (TID 686) in 93 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (10/50)\n",
      "25/11/13 16:17:52 INFO Executor: Finished task 10.0 in stage 59.0 (TID 687). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Starting task 12.0 in stage 59.0 (TID 689) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 12, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:52 INFO Executor: Running task 12.0 in stage 59.0 (TID 689)\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Finished task 10.0 in stage 59.0 (TID 687) in 23 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (11/50)\n",
      "25/11/13 16:17:52 INFO BlockManager: Found block rdd_106_11 locally\n",
      "25/11/13 16:17:52 INFO Executor: Finished task 11.0 in stage 59.0 (TID 688). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Starting task 13.0 in stage 59.0 (TID 690) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 13, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:52 INFO TaskSetManager: Finished task 11.0 in stage 59.0 (TID 688) in 58 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (12/50)\n",
      "25/11/13 16:17:52 INFO Executor: Running task 13.0 in stage 59.0 (TID 690)\n",
      "25/11/13 16:17:52 INFO BlockManager: Found block rdd_106_12 locally\n",
      "25/11/13 16:17:52 INFO Executor: Finished task 12.0 in stage 59.0 (TID 689). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Starting task 14.0 in stage 59.0 (TID 691) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 14, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:52 INFO Executor: Running task 14.0 in stage 59.0 (TID 691)\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Finished task 12.0 in stage 59.0 (TID 689) in 60 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (13/50)\n",
      "25/11/13 16:17:52 INFO BlockManager: Found block rdd_106_13 locally\n",
      "25/11/13 16:17:52 INFO Executor: Finished task 13.0 in stage 59.0 (TID 690). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Starting task 15.0 in stage 59.0 (TID 692) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 15, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:52 INFO BlockManager: Found block rdd_106_14 locally\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Finished task 13.0 in stage 59.0 (TID 690) in 41 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (14/50)\n",
      "25/11/13 16:17:52 INFO Executor: Running task 15.0 in stage 59.0 (TID 692)\n",
      "25/11/13 16:17:52 INFO Executor: Finished task 14.0 in stage 59.0 (TID 691). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Starting task 16.0 in stage 59.0 (TID 693) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 16, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:52 INFO Executor: Running task 16.0 in stage 59.0 (TID 693)\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Finished task 14.0 in stage 59.0 (TID 691) in 38 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (15/50)\n",
      "25/11/13 16:17:52 INFO BlockManager: Found block rdd_106_15 locally\n",
      "25/11/13 16:17:52 INFO BlockManager: Found block rdd_106_16 locally\n",
      "25/11/13 16:17:52 INFO Executor: Finished task 15.0 in stage 59.0 (TID 692). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:52 INFO Executor: Finished task 16.0 in stage 59.0 (TID 693). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Starting task 17.0 in stage 59.0 (TID 694) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 17, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:52 INFO Executor: Running task 17.0 in stage 59.0 (TID 694)\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Starting task 18.0 in stage 59.0 (TID 695) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 18, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:52 INFO TaskSetManager: Finished task 16.0 in stage 59.0 (TID 693) in 59 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (16/50)\n",
      "25/11/13 16:17:52 INFO Executor: Running task 18.0 in stage 59.0 (TID 695)\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Finished task 15.0 in stage 59.0 (TID 692) in 62 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (17/50)\n",
      "25/11/13 16:17:52 INFO BlockManager: Found block rdd_106_17 locally\n",
      "25/11/13 16:17:52 INFO BlockManager: Found block rdd_106_18 locally\n",
      "25/11/13 16:17:52 INFO Executor: Finished task 17.0 in stage 59.0 (TID 694). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:52 INFO Executor: Finished task 18.0 in stage 59.0 (TID 695). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Starting task 19.0 in stage 59.0 (TID 696) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 19, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:52 INFO TaskSetManager: Starting task 20.0 in stage 59.0 (TID 697) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 20, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:52 INFO Executor: Running task 19.0 in stage 59.0 (TID 696)\n",
      "25/11/13 16:17:52 INFO Executor: Running task 20.0 in stage 59.0 (TID 697)\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Finished task 17.0 in stage 59.0 (TID 694) in 37 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (18/50)\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Finished task 18.0 in stage 59.0 (TID 695) in 37 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (19/50)\n",
      "25/11/13 16:17:52 INFO BlockManager: Found block rdd_106_19 locally19 + 2) / 50]\n",
      "25/11/13 16:17:52 INFO Executor: Finished task 19.0 in stage 59.0 (TID 696). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Starting task 21.0 in stage 59.0 (TID 698) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 21, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:52 INFO BlockManager: Found block rdd_106_20 locally\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Finished task 19.0 in stage 59.0 (TID 696) in 55 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (20/50)\n",
      "25/11/13 16:17:52 INFO Executor: Running task 21.0 in stage 59.0 (TID 698)\n",
      "25/11/13 16:17:52 INFO Executor: Finished task 20.0 in stage 59.0 (TID 697). 4346 bytes result sent to driver\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Starting task 22.0 in stage 59.0 (TID 699) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 22, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:52 INFO TaskSetManager: Finished task 20.0 in stage 59.0 (TID 697) in 58 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (21/50)\n",
      "25/11/13 16:17:52 INFO Executor: Running task 22.0 in stage 59.0 (TID 699)\n",
      "25/11/13 16:17:52 INFO BlockManager: Found block rdd_106_22 locally\n",
      "25/11/13 16:17:52 INFO BlockManager: Found block rdd_106_21 locally\n",
      "25/11/13 16:17:52 INFO Executor: Finished task 22.0 in stage 59.0 (TID 699). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Starting task 23.0 in stage 59.0 (TID 700) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 23, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:52 INFO Executor: Finished task 21.0 in stage 59.0 (TID 698). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:52 INFO Executor: Running task 23.0 in stage 59.0 (TID 700)\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Starting task 24.0 in stage 59.0 (TID 701) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 24, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:52 INFO Executor: Running task 24.0 in stage 59.0 (TID 701)\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Finished task 21.0 in stage 59.0 (TID 698) in 139 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (22/50)\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Finished task 22.0 in stage 59.0 (TID 699) in 136 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (23/50)\n",
      "25/11/13 16:17:52 INFO BlockManager: Found block rdd_106_23 locally\n",
      "25/11/13 16:17:52 INFO BlockManager: Found block rdd_106_24 locally\n",
      "25/11/13 16:17:52 INFO Executor: Finished task 23.0 in stage 59.0 (TID 700). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:52 INFO Executor: Finished task 24.0 in stage 59.0 (TID 701). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Starting task 25.0 in stage 59.0 (TID 702) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 25, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:52 INFO TaskSetManager: Finished task 23.0 in stage 59.0 (TID 700) in 18 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (24/50)\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Finished task 24.0 in stage 59.0 (TID 701) in 18 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (25/50)\n",
      "25/11/13 16:17:52 INFO Executor: Running task 25.0 in stage 59.0 (TID 702)\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Starting task 26.0 in stage 59.0 (TID 703) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 26, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:52 INFO Executor: Running task 26.0 in stage 59.0 (TID 703)\n",
      "25/11/13 16:17:52 INFO BlockManager: Found block rdd_106_26 locally25 + 2) / 50]\n",
      "25/11/13 16:17:52 INFO BlockManager: Found block rdd_106_25 locally\n",
      "25/11/13 16:17:52 INFO Executor: Finished task 26.0 in stage 59.0 (TID 703). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Starting task 27.0 in stage 59.0 (TID 704) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 27, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:52 INFO Executor: Finished task 25.0 in stage 59.0 (TID 702). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:52 INFO Executor: Running task 27.0 in stage 59.0 (TID 704)\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Starting task 28.0 in stage 59.0 (TID 705) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 28, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:52 INFO Executor: Running task 28.0 in stage 59.0 (TID 705)\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Finished task 26.0 in stage 59.0 (TID 703) in 79 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (26/50)\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Finished task 25.0 in stage 59.0 (TID 702) in 82 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (27/50)\n",
      "25/11/13 16:17:52 INFO BlockManager: Found block rdd_106_28 locally\n",
      "25/11/13 16:17:52 INFO BlockManager: Found block rdd_106_27 locally\n",
      "25/11/13 16:17:52 INFO Executor: Finished task 28.0 in stage 59.0 (TID 705). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:52 INFO Executor: Finished task 27.0 in stage 59.0 (TID 704). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Starting task 29.0 in stage 59.0 (TID 706) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 29, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:52 INFO Executor: Running task 29.0 in stage 59.0 (TID 706)\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Starting task 30.0 in stage 59.0 (TID 707) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 30, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:52 INFO Executor: Running task 30.0 in stage 59.0 (TID 707)\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Finished task 28.0 in stage 59.0 (TID 705) in 34 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (28/50)\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Finished task 27.0 in stage 59.0 (TID 704) in 35 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (29/50)\n",
      "25/11/13 16:17:52 INFO BlockManager: Found block rdd_106_29 locally\n",
      "25/11/13 16:17:52 INFO Executor: Finished task 29.0 in stage 59.0 (TID 706). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Starting task 31.0 in stage 59.0 (TID 708) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 31, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:52 INFO TaskSetManager: Finished task 29.0 in stage 59.0 (TID 706) in 59 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (30/50)\n",
      "25/11/13 16:17:52 INFO Executor: Running task 31.0 in stage 59.0 (TID 708)\n",
      "25/11/13 16:17:52 INFO BlockManager: Found block rdd_106_30 locally\n",
      "25/11/13 16:17:52 INFO Executor: Finished task 30.0 in stage 59.0 (TID 707). 4224 bytes result sent to driver\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Starting task 32.0 in stage 59.0 (TID 709) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 32, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:52 INFO Executor: Running task 32.0 in stage 59.0 (TID 709)\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Finished task 30.0 in stage 59.0 (TID 707) in 114 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (31/50)\n",
      "25/11/13 16:17:52 INFO BlockManager: Found block rdd_106_32 locally\n",
      "25/11/13 16:17:52 INFO Executor: Finished task 32.0 in stage 59.0 (TID 709). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Starting task 33.0 in stage 59.0 (TID 710) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 33, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:52 INFO Executor: Running task 33.0 in stage 59.0 (TID 710)\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Finished task 32.0 in stage 59.0 (TID 709) in 17 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (32/50)\n",
      "25/11/13 16:17:52 INFO BlockManager: Found block rdd_106_31 locally\n",
      "25/11/13 16:17:52 INFO Executor: Finished task 31.0 in stage 59.0 (TID 708). 4224 bytes result sent to driver\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Starting task 34.0 in stage 59.0 (TID 711) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 34, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:52 INFO TaskSetManager: Finished task 31.0 in stage 59.0 (TID 708) in 104 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (33/50)\n",
      "25/11/13 16:17:52 INFO Executor: Running task 34.0 in stage 59.0 (TID 711)\n",
      "25/11/13 16:17:52 INFO BlockManager: Found block rdd_106_33 locally\n",
      "25/11/13 16:17:52 INFO Executor: Finished task 33.0 in stage 59.0 (TID 710). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Starting task 35.0 in stage 59.0 (TID 712) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 35, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:52 INFO Executor: Running task 35.0 in stage 59.0 (TID 712)\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Finished task 33.0 in stage 59.0 (TID 710) in 59 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (34/50)\n",
      "25/11/13 16:17:52 INFO BlockManager: Found block rdd_106_35 locally\n",
      "25/11/13 16:17:52 INFO BlockManager: Found block rdd_106_34 locally\n",
      "25/11/13 16:17:52 INFO Executor: Finished task 35.0 in stage 59.0 (TID 712). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Starting task 36.0 in stage 59.0 (TID 713) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 36, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:52 INFO Executor: Running task 36.0 in stage 59.0 (TID 713)\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Finished task 35.0 in stage 59.0 (TID 712) in 19 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (35/50)\n",
      "25/11/13 16:17:52 INFO Executor: Finished task 34.0 in stage 59.0 (TID 711). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Starting task 37.0 in stage 59.0 (TID 714) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 37, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:52 INFO Executor: Running task 37.0 in stage 59.0 (TID 714)\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Finished task 34.0 in stage 59.0 (TID 711) in 46 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (36/50)\n",
      "25/11/13 16:17:52 INFO BlockManager: Found block rdd_106_36 locally\n",
      "25/11/13 16:17:52 INFO Executor: Finished task 36.0 in stage 59.0 (TID 713). 4267 bytes result sent to driver\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Starting task 38.0 in stage 59.0 (TID 715) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 38, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:52 INFO Executor: Running task 38.0 in stage 59.0 (TID 715)\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Finished task 36.0 in stage 59.0 (TID 713) in 89 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (37/50)\n",
      "25/11/13 16:17:52 INFO BlockManager: Found block rdd_106_37 locally\n",
      "25/11/13 16:17:52 INFO Executor: Finished task 37.0 in stage 59.0 (TID 714). 4224 bytes result sent to driver\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Starting task 39.0 in stage 59.0 (TID 716) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 39, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:52 INFO Executor: Running task 39.0 in stage 59.0 (TID 716)\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Finished task 37.0 in stage 59.0 (TID 714) in 99 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (38/50)\n",
      "25/11/13 16:17:52 INFO BlockManager: Found block rdd_106_38 locally\n",
      "25/11/13 16:17:52 INFO Executor: Finished task 38.0 in stage 59.0 (TID 715). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Starting task 40.0 in stage 59.0 (TID 717) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 40, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:52 INFO Executor: Running task 40.0 in stage 59.0 (TID 717)\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Finished task 38.0 in stage 59.0 (TID 715) in 19 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (39/50)\n",
      "25/11/13 16:17:52 INFO BlockManager: Found block rdd_106_40 locally39 + 2) / 50]\n",
      "25/11/13 16:17:52 INFO Executor: Finished task 40.0 in stage 59.0 (TID 717). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Starting task 41.0 in stage 59.0 (TID 718) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 41, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:52 INFO BlockManager: Found block rdd_106_39 locally\n",
      "25/11/13 16:17:52 INFO Executor: Running task 41.0 in stage 59.0 (TID 718)\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Finished task 40.0 in stage 59.0 (TID 717) in 77 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (40/50)\n",
      "25/11/13 16:17:52 INFO Executor: Finished task 39.0 in stage 59.0 (TID 716). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Starting task 42.0 in stage 59.0 (TID 719) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 42, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:52 INFO Executor: Running task 42.0 in stage 59.0 (TID 719)\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Finished task 39.0 in stage 59.0 (TID 716) in 85 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (41/50)\n",
      "25/11/13 16:17:52 INFO BlockManager: Found block rdd_106_41 locally\n",
      "25/11/13 16:17:52 INFO BlockManager: Found block rdd_106_42 locally\n",
      "25/11/13 16:17:52 INFO Executor: Finished task 41.0 in stage 59.0 (TID 718). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Starting task 43.0 in stage 59.0 (TID 720) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 43, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:52 INFO Executor: Finished task 42.0 in stage 59.0 (TID 719). 4224 bytes result sent to driver\n",
      "25/11/13 16:17:52 INFO Executor: Running task 43.0 in stage 59.0 (TID 720)\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Finished task 41.0 in stage 59.0 (TID 718) in 41 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (42/50)\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Starting task 44.0 in stage 59.0 (TID 721) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 44, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:52 INFO Executor: Running task 44.0 in stage 59.0 (TID 721)\n",
      "25/11/13 16:17:52 INFO TaskSetManager: Finished task 42.0 in stage 59.0 (TID 719) in 21 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (43/50)\n",
      "25/11/13 16:17:53 INFO BlockManager: Found block rdd_106_44 locally\n",
      "25/11/13 16:17:53 INFO Executor: Finished task 44.0 in stage 59.0 (TID 721). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:53 INFO TaskSetManager: Starting task 45.0 in stage 59.0 (TID 722) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 45, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:53 INFO Executor: Running task 45.0 in stage 59.0 (TID 722)\n",
      "25/11/13 16:17:53 INFO TaskSetManager: Finished task 44.0 in stage 59.0 (TID 721) in 56 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (44/50)\n",
      "25/11/13 16:17:53 INFO BlockManager: Found block rdd_106_43 locally\n",
      "25/11/13 16:17:53 INFO Executor: Finished task 43.0 in stage 59.0 (TID 720). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:53 INFO TaskSetManager: Starting task 46.0 in stage 59.0 (TID 723) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 46, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:53 INFO Executor: Running task 46.0 in stage 59.0 (TID 723)\n",
      "25/11/13 16:17:53 INFO TaskSetManager: Finished task 43.0 in stage 59.0 (TID 720) in 79 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (45/50)\n",
      "25/11/13 16:17:53 INFO BlockManager: Found block rdd_106_45 locally\n",
      "25/11/13 16:17:53 INFO Executor: Finished task 45.0 in stage 59.0 (TID 722). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:53 INFO BlockManager: Found block rdd_106_46 locally\n",
      "25/11/13 16:17:53 INFO TaskSetManager: Starting task 47.0 in stage 59.0 (TID 724) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 47, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:53 INFO Executor: Finished task 46.0 in stage 59.0 (TID 723). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:53 INFO Executor: Running task 47.0 in stage 59.0 (TID 724)\n",
      "25/11/13 16:17:53 INFO TaskSetManager: Starting task 48.0 in stage 59.0 (TID 725) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 48, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:53 INFO Executor: Running task 48.0 in stage 59.0 (TID 725)\n",
      "25/11/13 16:17:53 INFO TaskSetManager: Finished task 45.0 in stage 59.0 (TID 722) in 39 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (46/50)\n",
      "25/11/13 16:17:53 INFO TaskSetManager: Finished task 46.0 in stage 59.0 (TID 723) in 36 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (47/50)\n",
      "25/11/13 16:17:53 INFO BlockManager: Found block rdd_106_48 locally47 + 2) / 50]\n",
      "25/11/13 16:17:53 INFO BlockManager: Found block rdd_106_47 locally\n",
      "25/11/13 16:17:53 INFO Executor: Finished task 48.0 in stage 59.0 (TID 725). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:53 INFO Executor: Finished task 47.0 in stage 59.0 (TID 724). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:53 INFO TaskSetManager: Starting task 49.0 in stage 59.0 (TID 726) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 49, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:53 INFO Executor: Running task 49.0 in stage 59.0 (TID 726)\n",
      "25/11/13 16:17:53 INFO TaskSetManager: Finished task 47.0 in stage 59.0 (TID 724) in 57 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (48/50)\n",
      "25/11/13 16:17:53 INFO TaskSetManager: Finished task 48.0 in stage 59.0 (TID 725) in 57 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (49/50)\n",
      "25/11/13 16:17:53 INFO BlockManager: Found block rdd_106_49 locally\n",
      "25/11/13 16:17:53 INFO Executor: Finished task 49.0 in stage 59.0 (TID 726). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:53 INFO TaskSetManager: Finished task 49.0 in stage 59.0 (TID 726) in 19 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (50/50)\n",
      "25/11/13 16:17:53 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool \n",
      "25/11/13 16:17:53 INFO DAGScheduler: ResultStage 59 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 1.389 s\n",
      "25/11/13 16:17:53 INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/11/13 16:17:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 59: Stage finished\n",
      "25/11/13 16:17:53 INFO DAGScheduler: Job 35 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 1.402325 s\n",
      "25/11/13 16:17:53 INFO PrepareDeltaScan: DELTA: Done                            \n",
      "25/11/13 16:17:53 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/11/13 16:17:53 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/11/13 16:17:53 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 204.3 KiB, free 1046.8 MiB)\n",
      "25/11/13 16:17:53 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 36.1 KiB, free 1046.8 MiB)\n",
      "25/11/13 16:17:53 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 36.1 KiB, free: 1048.5 MiB)\n",
      "25/11/13 16:17:53 INFO SparkContext: Created broadcast 53 from count at NativeMethodAccessorImpl.java:0\n",
      "25/11/13 16:17:53 INFO FileSourceScanExec: Planning scan with bin packing, max size: 5904079 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/11/13 16:17:53 INFO DAGScheduler: Registering RDD 146 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 9\n",
      "25/11/13 16:17:53 INFO DAGScheduler: Got map stage job 36 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions\n",
      "25/11/13 16:17:53 INFO DAGScheduler: Final stage: ShuffleMapStage 60 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/11/13 16:17:53 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/11/13 16:17:53 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 16:17:53 INFO DAGScheduler: Submitting ShuffleMapStage 60 (MapPartitionsRDD[146] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/11/13 16:17:53 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 34.3 KiB, free 1046.8 MiB)\n",
      "25/11/13 16:17:53 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1046.8 MiB)\n",
      "25/11/13 16:17:53 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 14.8 KiB, free: 1048.4 MiB)\n",
      "25/11/13 16:17:53 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 16:17:53 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 60 (MapPartitionsRDD[146] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))\n",
      "25/11/13 16:17:53 INFO TaskSchedulerImpl: Adding task set 60.0 with 2 tasks resource profile 0\n",
      "25/11/13 16:17:53 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 727) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 9668 bytes) \n",
      "25/11/13 16:17:53 INFO TaskSetManager: Starting task 1.0 in stage 60.0 (TID 728) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 1, PROCESS_LOCAL, 9668 bytes) \n",
      "25/11/13 16:17:53 INFO Executor: Running task 0.0 in stage 60.0 (TID 727)\n",
      "25/11/13 16:17:53 INFO Executor: Running task 1.0 in stage 60.0 (TID 728)\n",
      "25/11/13 16:17:53 INFO FileScanRDD: Reading File path: s3a://nau-local-analytics-silver/dim_user_profile/part-00000-26092a00-ec88-42f6-860b-8e610b908cb4-c000.snappy.parquet, range: 0-5904079, partition values: [empty row]\n",
      "25/11/13 16:17:53 INFO FileScanRDD: Reading File path: s3a://nau-local-analytics-silver/dim_user_profile/part-00000-26092a00-ec88-42f6-860b-8e610b908cb4-c000.snappy.parquet, range: 5904079-7613854, partition values: [empty row]\n",
      "25/11/13 16:17:53 INFO S3AInputStream: Switching to Random IO seek policy\n",
      "25/11/13 16:17:53 INFO S3AInputStream: Switching to Random IO seek policy\n",
      "25/11/13 16:17:53 INFO Executor: Finished task 1.0 in stage 60.0 (TID 728). 2779 bytes result sent to driver\n",
      "25/11/13 16:17:53 INFO TaskSetManager: Finished task 1.0 in stage 60.0 (TID 728) in 173 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/2)\n",
      "25/11/13 16:17:53 INFO BlockManagerInfo: Removed broadcast_52_piece0 on jupyter-spark-758b7c86d8-7j77n:32921 in memory (size: 154.5 KiB, free: 1048.6 MiB)\n",
      "25/11/13 16:17:54 INFO Executor: Finished task 0.0 in stage 60.0 (TID 727). 3037 bytes result sent to driver\n",
      "25/11/13 16:17:54 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 727) in 1238 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (2/2)\n",
      "25/11/13 16:17:54 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool \n",
      "25/11/13 16:17:54 INFO DAGScheduler: ShuffleMapStage 60 (count at NativeMethodAccessorImpl.java:0) finished in 1.250 s\n",
      "25/11/13 16:17:54 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/11/13 16:17:54 INFO DAGScheduler: running: Set()\n",
      "25/11/13 16:17:54 INFO DAGScheduler: waiting: Set()\n",
      "25/11/13 16:17:54 INFO DAGScheduler: failed: Set()\n",
      "25/11/13 16:17:54 INFO ShufflePartitionsUtil: For shuffle(9), advisory target size: 67108864, actual target size 1408441, minimum partition size: 1048576\n",
      "25/11/13 16:17:54 INFO DAGScheduler: Registering RDD 149 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 10\n",
      "25/11/13 16:17:54 INFO DAGScheduler: Got map stage job 37 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions\n",
      "25/11/13 16:17:54 INFO DAGScheduler: Final stage: ShuffleMapStage 62 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/11/13 16:17:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 61)\n",
      "25/11/13 16:17:54 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 16:17:54 INFO DAGScheduler: Submitting ShuffleMapStage 62 (MapPartitionsRDD[149] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/11/13 16:17:54 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 49.3 KiB, free 1047.5 MiB)\n",
      "25/11/13 16:17:54 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 21.9 KiB, free 1047.5 MiB)\n",
      "25/11/13 16:17:54 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 21.9 KiB, free: 1048.6 MiB)\n",
      "25/11/13 16:17:54 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 16:17:54 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 62 (MapPartitionsRDD[149] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))\n",
      "25/11/13 16:17:54 INFO TaskSchedulerImpl: Adding task set 62.0 with 2 tasks resource profile 0\n",
      "25/11/13 16:17:54 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 729) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, NODE_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:54 INFO TaskSetManager: Starting task 1.0 in stage 62.0 (TID 730) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 1, NODE_LOCAL, 8988 bytes) \n",
      "25/11/13 16:17:54 INFO Executor: Running task 1.0 in stage 62.0 (TID 730)\n",
      "25/11/13 16:17:54 INFO Executor: Running task 0.0 in stage 62.0 (TID 729)\n",
      "25/11/13 16:17:54 INFO ShuffleBlockFetcherIterator: Getting 1 (1379.5 KiB) non-empty blocks including 1 (1379.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/11/13 16:17:54 INFO ShuffleBlockFetcherIterator: Getting 1 (1371.4 KiB) non-empty blocks including 1 (1371.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/11/13 16:17:55 INFO Executor: Finished task 0.0 in stage 62.0 (TID 729). 5907 bytes result sent to driver\n",
      "25/11/13 16:17:55 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 729) in 1124 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/2)\n",
      "25/11/13 16:17:55 INFO BlockManagerInfo: Removed broadcast_54_piece0 on jupyter-spark-758b7c86d8-7j77n:32921 in memory (size: 14.8 KiB, free: 1048.6 MiB)\n",
      "25/11/13 16:17:55 INFO Executor: Finished task 1.0 in stage 62.0 (TID 730). 5864 bytes result sent to driver\n",
      "25/11/13 16:17:55 INFO TaskSetManager: Finished task 1.0 in stage 62.0 (TID 730) in 1160 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (2/2)\n",
      "25/11/13 16:17:55 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool \n",
      "25/11/13 16:17:55 INFO DAGScheduler: ShuffleMapStage 62 (count at NativeMethodAccessorImpl.java:0) finished in 1.170 s\n",
      "25/11/13 16:17:55 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/11/13 16:17:55 INFO DAGScheduler: running: Set()\n",
      "25/11/13 16:17:55 INFO DAGScheduler: waiting: Set()\n",
      "25/11/13 16:17:55 INFO DAGScheduler: failed: Set()\n",
      "25/11/13 16:17:55 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0\n",
      "25/11/13 16:17:55 INFO DAGScheduler: Got job 38 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/11/13 16:17:55 INFO DAGScheduler: Final stage: ResultStage 65 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/11/13 16:17:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 64)\n",
      "25/11/13 16:17:55 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 16:17:55 INFO DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[152] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/11/13 16:17:55 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 12.5 KiB, free 1047.5 MiB)\n",
      "25/11/13 16:17:55 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 1047.5 MiB)\n",
      "25/11/13 16:17:55 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 5.9 KiB, free: 1048.6 MiB)\n",
      "25/11/13 16:17:55 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 16:17:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[152] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/11/13 16:17:55 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks resource profile 0\n",
      "25/11/13 16:17:55 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 731) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, NODE_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:55 INFO Executor: Running task 0.0 in stage 65.0 (TID 731)\n",
      "25/11/13 16:17:55 INFO ShuffleBlockFetcherIterator: Getting 2 (120.0 B) non-empty blocks including 2 (120.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 16:17:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 16:17:55 INFO Executor: Finished task 0.0 in stage 65.0 (TID 731). 3995 bytes result sent to driver\n",
      "25/11/13 16:17:55 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 731) in 39 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/1)\n",
      "25/11/13 16:17:55 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool \n",
      "25/11/13 16:17:55 INFO DAGScheduler: ResultStage 65 (count at NativeMethodAccessorImpl.java:0) finished in 0.045 s\n",
      "25/11/13 16:17:55 INFO DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/11/13 16:17:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 65: Stage finished\n",
      "25/11/13 16:17:55 INFO DAGScheduler: Job 38 finished: count at NativeMethodAccessorImpl.java:0, took 0.050388 s\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> [dim_user_profile] Total rows in Silver: 494033\n",
      ">> [dim_user_profile] Distinct profile_id in Silver: 494033\n",
      ">> [dim_user_profile] Distinct user_id in Silver: 494033\n",
      "\n",
      ">> [dim_user_profile] Checking if table is available in the catalog (if created):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/13 16:17:56 INFO CodeGenerator: Code generated in 39.117776 ms\n",
      "25/11/13 16:17:56 INFO CodeGenerator: Code generated in 8.684317 ms\n",
      "25/11/13 16:17:56 INFO CodeGenerator: Code generated in 8.88097 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+-----------+\n",
      "|namespace|tableName       |isTemporary|\n",
      "+---------+----------------+-----------+\n",
      "|default  |dim_user_profile|false      |\n",
      "+---------+----------------+-----------+\n",
      "\n",
      "\n",
      ">> [dim_user_profile] Preview via SQL (if table is registered):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/13 16:17:56 INFO PrepareDeltaScan: DELTA: Filtering files for query\n",
      "25/11/13 16:17:56 INFO BlockManagerInfo: Removed broadcast_55_piece0 on jupyter-spark-758b7c86d8-7j77n:32921 in memory (size: 21.9 KiB, free: 1048.6 MiB)\n",
      "25/11/13 16:17:56 INFO BlockManagerInfo: Removed broadcast_53_piece0 on jupyter-spark-758b7c86d8-7j77n:32921 in memory (size: 36.1 KiB, free: 1048.6 MiB)\n",
      "25/11/13 16:17:56 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128\n",
      "25/11/13 16:17:56 INFO DAGScheduler: Got job 39 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions\n",
      "25/11/13 16:17:56 INFO DAGScheduler: Final stage: ResultStage 67 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)\n",
      "25/11/13 16:17:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 66)\n",
      "25/11/13 16:17:56 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 16:17:56 INFO DAGScheduler: Submitting ResultStage 67 (MapPartitionsRDD[154] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents\n",
      "25/11/13 16:17:56 INFO BlockManagerInfo: Removed broadcast_56_piece0 on jupyter-spark-758b7c86d8-7j77n:32921 in memory (size: 5.9 KiB, free: 1048.6 MiB)\n",
      "25/11/13 16:17:56 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 684.9 KiB, free 1047.2 MiB)\n",
      "25/11/13 16:17:56 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 154.5 KiB, free 1047.0 MiB)\n",
      "25/11/13 16:17:56 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 154.5 KiB, free: 1048.5 MiB)\n",
      "25/11/13 16:17:56 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 16:17:56 INFO DAGScheduler: Submitting 50 missing tasks from ResultStage 67 (MapPartitionsRDD[154] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n",
      "25/11/13 16:17:56 INFO TaskSchedulerImpl: Adding task set 67.0 with 50 tasks resource profile 0\n",
      "25/11/13 16:17:56 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 732) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:56 INFO TaskSetManager: Starting task 1.0 in stage 67.0 (TID 733) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 1, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:56 INFO Executor: Running task 0.0 in stage 67.0 (TID 732)\n",
      "25/11/13 16:17:56 INFO Executor: Running task 1.0 in stage 67.0 (TID 733)\n",
      "25/11/13 16:17:56 INFO BlockManager: Found block rdd_106_1 locally\n",
      "25/11/13 16:17:56 INFO BlockManager: Found block rdd_106_0 locally\n",
      "25/11/13 16:17:56 INFO Executor: Finished task 1.0 in stage 67.0 (TID 733). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:56 INFO Executor: Finished task 0.0 in stage 67.0 (TID 732). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:56 INFO TaskSetManager: Starting task 2.0 in stage 67.0 (TID 734) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 2, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:56 INFO Executor: Running task 2.0 in stage 67.0 (TID 734)\n",
      "25/11/13 16:17:56 INFO TaskSetManager: Starting task 3.0 in stage 67.0 (TID 735) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 3, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:56 INFO Executor: Running task 3.0 in stage 67.0 (TID 735)\n",
      "25/11/13 16:17:56 INFO TaskSetManager: Finished task 1.0 in stage 67.0 (TID 733) in 38 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/50)\n",
      "25/11/13 16:17:56 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 732) in 39 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (2/50)\n",
      "25/11/13 16:17:56 INFO BlockManager: Found block rdd_106_2 locally\n",
      "25/11/13 16:17:57 INFO BlockManager: Found block rdd_106_3 locally\n",
      "25/11/13 16:17:57 INFO Executor: Finished task 3.0 in stage 67.0 (TID 735). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Starting task 4.0 in stage 67.0 (TID 736) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 4, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:57 INFO Executor: Finished task 2.0 in stage 67.0 (TID 734). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:57 INFO Executor: Running task 4.0 in stage 67.0 (TID 736)\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Finished task 3.0 in stage 67.0 (TID 735) in 51 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (3/50)\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Starting task 5.0 in stage 67.0 (TID 737) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 5, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:57 INFO Executor: Running task 5.0 in stage 67.0 (TID 737)\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Finished task 2.0 in stage 67.0 (TID 734) in 81 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (4/50)\n",
      "25/11/13 16:17:57 INFO BlockManager: Found block rdd_106_4 locally\n",
      "25/11/13 16:17:57 INFO Executor: Finished task 4.0 in stage 67.0 (TID 736). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Starting task 6.0 in stage 67.0 (TID 738) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 6, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:57 INFO Executor: Running task 6.0 in stage 67.0 (TID 738)\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Finished task 4.0 in stage 67.0 (TID 736) in 42 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (5/50)\n",
      "25/11/13 16:17:57 INFO BlockManager: Found block rdd_106_5 locally\n",
      "25/11/13 16:17:57 INFO Executor: Finished task 5.0 in stage 67.0 (TID 737). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Starting task 7.0 in stage 67.0 (TID 739) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 7, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:57 INFO Executor: Running task 7.0 in stage 67.0 (TID 739)\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Finished task 5.0 in stage 67.0 (TID 737) in 44 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (6/50)\n",
      "25/11/13 16:17:57 INFO BlockManager: Found block rdd_106_6 locally\n",
      "25/11/13 16:17:57 INFO Executor: Finished task 6.0 in stage 67.0 (TID 738). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Starting task 8.0 in stage 67.0 (TID 740) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 8, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:57 INFO Executor: Running task 8.0 in stage 67.0 (TID 740)\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Finished task 6.0 in stage 67.0 (TID 738) in 57 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (7/50)\n",
      "25/11/13 16:17:57 INFO BlockManager: Found block rdd_106_7 locally\n",
      "25/11/13 16:17:57 INFO Executor: Finished task 7.0 in stage 67.0 (TID 739). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Starting task 9.0 in stage 67.0 (TID 741) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 9, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:57 INFO TaskSetManager: Finished task 7.0 in stage 67.0 (TID 739) in 54 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (8/50)\n",
      "25/11/13 16:17:57 INFO Executor: Running task 9.0 in stage 67.0 (TID 741)\n",
      "25/11/13 16:17:57 INFO BlockManager: Found block rdd_106_8 locally\n",
      "25/11/13 16:17:57 INFO BlockManager: Found block rdd_106_9 locally\n",
      "25/11/13 16:17:57 INFO Executor: Finished task 9.0 in stage 67.0 (TID 741). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Starting task 10.0 in stage 67.0 (TID 742) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 10, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:57 INFO Executor: Running task 10.0 in stage 67.0 (TID 742)\n",
      "25/11/13 16:17:57 INFO Executor: Finished task 8.0 in stage 67.0 (TID 740). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Starting task 11.0 in stage 67.0 (TID 743) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 11, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:57 INFO Executor: Running task 11.0 in stage 67.0 (TID 743)\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Finished task 8.0 in stage 67.0 (TID 740) in 56 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (9/50)\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Finished task 9.0 in stage 67.0 (TID 741) in 51 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (10/50)\n",
      "25/11/13 16:17:57 INFO BlockManager: Found block rdd_106_10 locally\n",
      "25/11/13 16:17:57 INFO Executor: Finished task 10.0 in stage 67.0 (TID 742). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Starting task 12.0 in stage 67.0 (TID 744) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 12, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:57 INFO TaskSetManager: Finished task 10.0 in stage 67.0 (TID 742) in 59 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (11/50)\n",
      "25/11/13 16:17:57 INFO BlockManager: Found block rdd_106_11 locally\n",
      "25/11/13 16:17:57 INFO Executor: Running task 12.0 in stage 67.0 (TID 744)\n",
      "25/11/13 16:17:57 INFO Executor: Finished task 11.0 in stage 67.0 (TID 743). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Starting task 13.0 in stage 67.0 (TID 745) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 13, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:57 INFO Executor: Running task 13.0 in stage 67.0 (TID 745)\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Finished task 11.0 in stage 67.0 (TID 743) in 81 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (12/50)\n",
      "25/11/13 16:17:57 INFO BlockManager: Found block rdd_106_13 locally\n",
      "25/11/13 16:17:57 INFO BlockManager: Found block rdd_106_12 locally\n",
      "25/11/13 16:17:57 INFO Executor: Finished task 13.0 in stage 67.0 (TID 745). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Starting task 14.0 in stage 67.0 (TID 746) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 14, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:57 INFO Executor: Running task 14.0 in stage 67.0 (TID 746)\n",
      "25/11/13 16:17:57 INFO Executor: Finished task 12.0 in stage 67.0 (TID 744). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Finished task 13.0 in stage 67.0 (TID 745) in 17 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (13/50)\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Starting task 15.0 in stage 67.0 (TID 747) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 15, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:57 INFO TaskSetManager: Finished task 12.0 in stage 67.0 (TID 744) in 44 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (14/50)\n",
      "25/11/13 16:17:57 INFO Executor: Running task 15.0 in stage 67.0 (TID 747)\n",
      "25/11/13 16:17:57 INFO BlockManager: Found block rdd_106_14 locally\n",
      "25/11/13 16:17:57 INFO Executor: Finished task 14.0 in stage 67.0 (TID 746). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:57 INFO BlockManager: Found block rdd_106_15 locally\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Starting task 16.0 in stage 67.0 (TID 748) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 16, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:57 INFO Executor: Running task 16.0 in stage 67.0 (TID 748)\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Finished task 14.0 in stage 67.0 (TID 746) in 52 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (15/50)\n",
      "25/11/13 16:17:57 INFO Executor: Finished task 15.0 in stage 67.0 (TID 747). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Starting task 17.0 in stage 67.0 (TID 749) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 17, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:57 INFO Executor: Running task 17.0 in stage 67.0 (TID 749)\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Finished task 15.0 in stage 67.0 (TID 747) in 55 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (16/50)\n",
      "25/11/13 16:17:57 INFO BlockManager: Found block rdd_106_17 locally\n",
      "25/11/13 16:17:57 INFO Executor: Finished task 17.0 in stage 67.0 (TID 749). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:57 INFO BlockManager: Found block rdd_106_16 locally\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Starting task 18.0 in stage 67.0 (TID 750) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 18, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:57 INFO Executor: Finished task 16.0 in stage 67.0 (TID 748). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:57 INFO Executor: Running task 18.0 in stage 67.0 (TID 750)\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Starting task 19.0 in stage 67.0 (TID 751) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 19, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:57 INFO Executor: Running task 19.0 in stage 67.0 (TID 751)\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Finished task 17.0 in stage 67.0 (TID 749) in 40 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (17/50)\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Finished task 16.0 in stage 67.0 (TID 748) in 45 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (18/50)\n",
      "25/11/13 16:17:57 INFO BlockManager: Found block rdd_106_19 locally\n",
      "25/11/13 16:17:57 INFO Executor: Finished task 19.0 in stage 67.0 (TID 751). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Starting task 20.0 in stage 67.0 (TID 752) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 20, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:57 INFO Executor: Running task 20.0 in stage 67.0 (TID 752)\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Finished task 19.0 in stage 67.0 (TID 751) in 14 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (19/50)\n",
      "25/11/13 16:17:57 INFO BlockManager: Found block rdd_106_18 locally\n",
      "25/11/13 16:17:57 INFO Executor: Finished task 18.0 in stage 67.0 (TID 750). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Starting task 21.0 in stage 67.0 (TID 753) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 21, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:57 INFO TaskSetManager: Finished task 18.0 in stage 67.0 (TID 750) in 20 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (20/50)\n",
      "25/11/13 16:17:57 INFO Executor: Running task 21.0 in stage 67.0 (TID 753)\n",
      "25/11/13 16:17:57 INFO BlockManager: Found block rdd_106_20 locally\n",
      "25/11/13 16:17:57 INFO Executor: Finished task 20.0 in stage 67.0 (TID 752). 4346 bytes result sent to driver\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Starting task 22.0 in stage 67.0 (TID 754) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 22, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:57 INFO Executor: Running task 22.0 in stage 67.0 (TID 754)\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Finished task 20.0 in stage 67.0 (TID 752) in 178 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (21/50)\n",
      "25/11/13 16:17:57 INFO BlockManager: Found block rdd_106_21 locally\n",
      "25/11/13 16:17:57 INFO Executor: Finished task 21.0 in stage 67.0 (TID 753). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Starting task 23.0 in stage 67.0 (TID 755) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 23, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:57 INFO TaskSetManager: Finished task 21.0 in stage 67.0 (TID 753) in 181 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (22/50)\n",
      "25/11/13 16:17:57 INFO Executor: Running task 23.0 in stage 67.0 (TID 755)\n",
      "25/11/13 16:17:57 INFO BlockManager: Found block rdd_106_22 locally\n",
      "25/11/13 16:17:57 INFO Executor: Finished task 22.0 in stage 67.0 (TID 754). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Starting task 24.0 in stage 67.0 (TID 756) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 24, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:57 INFO TaskSetManager: Finished task 22.0 in stage 67.0 (TID 754) in 17 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (23/50)\n",
      "25/11/13 16:17:57 INFO Executor: Running task 24.0 in stage 67.0 (TID 756)\n",
      "25/11/13 16:17:57 INFO BlockManager: Found block rdd_106_23 locally\n",
      "25/11/13 16:17:57 INFO Executor: Finished task 23.0 in stage 67.0 (TID 755). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Starting task 25.0 in stage 67.0 (TID 757) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 25, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:57 INFO Executor: Running task 25.0 in stage 67.0 (TID 757)\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Finished task 23.0 in stage 67.0 (TID 755) in 53 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (24/50)\n",
      "25/11/13 16:17:57 INFO BlockManager: Found block rdd_106_24 locally\n",
      "25/11/13 16:17:57 INFO BlockManager: Found block rdd_106_25 locally\n",
      "25/11/13 16:17:57 INFO Executor: Finished task 24.0 in stage 67.0 (TID 756). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Starting task 26.0 in stage 67.0 (TID 758) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 26, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:57 INFO Executor: Running task 26.0 in stage 67.0 (TID 758)\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Finished task 24.0 in stage 67.0 (TID 756) in 78 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (25/50)\n",
      "25/11/13 16:17:57 INFO Executor: Finished task 25.0 in stage 67.0 (TID 757). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Starting task 27.0 in stage 67.0 (TID 759) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 27, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:57 INFO Executor: Running task 27.0 in stage 67.0 (TID 759)\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Finished task 25.0 in stage 67.0 (TID 757) in 73 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (26/50)\n",
      "25/11/13 16:17:57 INFO BlockManager: Found block rdd_106_26 locally\n",
      "25/11/13 16:17:57 INFO Executor: Finished task 26.0 in stage 67.0 (TID 758). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Starting task 28.0 in stage 67.0 (TID 760) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 28, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:57 INFO Executor: Running task 28.0 in stage 67.0 (TID 760)\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Finished task 26.0 in stage 67.0 (TID 758) in 37 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (27/50)\n",
      "25/11/13 16:17:57 INFO BlockManager: Found block rdd_106_27 locally\n",
      "25/11/13 16:17:57 INFO Executor: Finished task 27.0 in stage 67.0 (TID 759). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Starting task 29.0 in stage 67.0 (TID 761) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 29, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:57 INFO Executor: Running task 29.0 in stage 67.0 (TID 761)\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Finished task 27.0 in stage 67.0 (TID 759) in 70 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (28/50)\n",
      "25/11/13 16:17:57 INFO BlockManager: Found block rdd_106_28 locally\n",
      "25/11/13 16:17:57 INFO Executor: Finished task 28.0 in stage 67.0 (TID 760). 4224 bytes result sent to driver\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Starting task 30.0 in stage 67.0 (TID 762) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 30, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:57 INFO Executor: Running task 30.0 in stage 67.0 (TID 762)\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Finished task 28.0 in stage 67.0 (TID 760) in 70 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (29/50)\n",
      "25/11/13 16:17:57 INFO BlockManager: Found block rdd_106_29 locally\n",
      "25/11/13 16:17:57 INFO Executor: Finished task 29.0 in stage 67.0 (TID 761). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Starting task 31.0 in stage 67.0 (TID 763) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 31, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:57 INFO Executor: Running task 31.0 in stage 67.0 (TID 763)\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Finished task 29.0 in stage 67.0 (TID 761) in 30 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (30/50)\n",
      "25/11/13 16:17:57 INFO BlockManager: Found block rdd_106_30 locally30 + 2) / 50]\n",
      "25/11/13 16:17:57 INFO Executor: Finished task 30.0 in stage 67.0 (TID 762). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Starting task 32.0 in stage 67.0 (TID 764) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 32, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:57 INFO TaskSetManager: Finished task 30.0 in stage 67.0 (TID 762) in 29 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (31/50)\n",
      "25/11/13 16:17:57 INFO Executor: Running task 32.0 in stage 67.0 (TID 764)\n",
      "25/11/13 16:17:57 INFO BlockManager: Found block rdd_106_31 locally\n",
      "25/11/13 16:17:57 INFO Executor: Finished task 31.0 in stage 67.0 (TID 763). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Starting task 33.0 in stage 67.0 (TID 765) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 33, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:57 INFO Executor: Running task 33.0 in stage 67.0 (TID 765)\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Finished task 31.0 in stage 67.0 (TID 763) in 33 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (32/50)\n",
      "25/11/13 16:17:57 INFO BlockManager: Found block rdd_106_32 locally\n",
      "25/11/13 16:17:57 INFO Executor: Finished task 32.0 in stage 67.0 (TID 764). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Starting task 34.0 in stage 67.0 (TID 766) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 34, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:57 INFO TaskSetManager: Finished task 32.0 in stage 67.0 (TID 764) in 18 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (33/50)\n",
      "25/11/13 16:17:57 INFO BlockManager: Found block rdd_106_33 locally\n",
      "25/11/13 16:17:57 INFO Executor: Running task 34.0 in stage 67.0 (TID 766)\n",
      "25/11/13 16:17:57 INFO Executor: Finished task 33.0 in stage 67.0 (TID 765). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Starting task 35.0 in stage 67.0 (TID 767) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 35, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:57 INFO Executor: Running task 35.0 in stage 67.0 (TID 767)\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Finished task 33.0 in stage 67.0 (TID 765) in 50 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (34/50)\n",
      "25/11/13 16:17:57 INFO BlockManager: Found block rdd_106_35 locally\n",
      "25/11/13 16:17:57 INFO Executor: Finished task 35.0 in stage 67.0 (TID 767). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Starting task 36.0 in stage 67.0 (TID 768) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 36, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:57 INFO Executor: Running task 36.0 in stage 67.0 (TID 768)\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Finished task 35.0 in stage 67.0 (TID 767) in 42 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (35/50)\n",
      "25/11/13 16:17:57 INFO BlockManager: Found block rdd_106_34 locally\n",
      "25/11/13 16:17:57 INFO Executor: Finished task 34.0 in stage 67.0 (TID 766). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Starting task 37.0 in stage 67.0 (TID 769) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 37, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:57 INFO Executor: Running task 37.0 in stage 67.0 (TID 769)\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Finished task 34.0 in stage 67.0 (TID 766) in 89 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (36/50)\n",
      "25/11/13 16:17:57 INFO BlockManager: Found block rdd_106_36 locally\n",
      "25/11/13 16:17:57 INFO Executor: Finished task 36.0 in stage 67.0 (TID 768). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Starting task 38.0 in stage 67.0 (TID 770) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 38, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:57 INFO Executor: Running task 38.0 in stage 67.0 (TID 770)\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Finished task 36.0 in stage 67.0 (TID 768) in 63 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (37/50)\n",
      "25/11/13 16:17:57 INFO BlockManager: Found block rdd_106_37 locally\n",
      "25/11/13 16:17:57 INFO Executor: Finished task 37.0 in stage 67.0 (TID 769). 4267 bytes result sent to driver\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Starting task 39.0 in stage 67.0 (TID 771) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 39, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:57 INFO Executor: Running task 39.0 in stage 67.0 (TID 771)\n",
      "25/11/13 16:17:57 INFO TaskSetManager: Finished task 37.0 in stage 67.0 (TID 769) in 106 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (38/50)\n",
      "25/11/13 16:17:57 INFO BlockManager: Found block rdd_106_38 locally\n",
      "25/11/13 16:17:57 INFO BlockManager: Found block rdd_106_39 locally\n",
      "25/11/13 16:17:57 INFO Executor: Finished task 38.0 in stage 67.0 (TID 770). 4224 bytes result sent to driver\n",
      "25/11/13 16:17:58 INFO TaskSetManager: Starting task 40.0 in stage 67.0 (TID 772) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 40, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:58 INFO Executor: Finished task 39.0 in stage 67.0 (TID 771). 4224 bytes result sent to driver\n",
      "25/11/13 16:17:58 INFO TaskSetManager: Finished task 38.0 in stage 67.0 (TID 770) in 100 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (39/50)\n",
      "25/11/13 16:17:58 INFO Executor: Running task 40.0 in stage 67.0 (TID 772)\n",
      "25/11/13 16:17:58 INFO TaskSetManager: Starting task 41.0 in stage 67.0 (TID 773) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 41, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:58 INFO Executor: Running task 41.0 in stage 67.0 (TID 773)\n",
      "25/11/13 16:17:58 INFO TaskSetManager: Finished task 39.0 in stage 67.0 (TID 771) in 45 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (40/50)\n",
      "25/11/13 16:17:58 INFO BlockManager: Found block rdd_106_41 locally\n",
      "25/11/13 16:17:58 INFO Executor: Finished task 41.0 in stage 67.0 (TID 773). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:58 INFO TaskSetManager: Starting task 42.0 in stage 67.0 (TID 774) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 42, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:58 INFO TaskSetManager: Finished task 41.0 in stage 67.0 (TID 773) in 16 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (41/50)\n",
      "25/11/13 16:17:58 INFO Executor: Running task 42.0 in stage 67.0 (TID 774)\n",
      "25/11/13 16:17:58 INFO BlockManager: Found block rdd_106_40 locally\n",
      "25/11/13 16:17:58 INFO Executor: Finished task 40.0 in stage 67.0 (TID 772). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:58 INFO TaskSetManager: Starting task 43.0 in stage 67.0 (TID 775) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 43, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:58 INFO Executor: Running task 43.0 in stage 67.0 (TID 775)\n",
      "25/11/13 16:17:58 INFO TaskSetManager: Finished task 40.0 in stage 67.0 (TID 772) in 64 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (42/50)\n",
      "25/11/13 16:17:58 INFO BlockManager: Found block rdd_106_42 locally\n",
      "25/11/13 16:17:58 INFO Executor: Finished task 42.0 in stage 67.0 (TID 774). 4224 bytes result sent to driver\n",
      "25/11/13 16:17:58 INFO BlockManager: Found block rdd_106_43 locally\n",
      "25/11/13 16:17:58 INFO TaskSetManager: Starting task 44.0 in stage 67.0 (TID 776) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 44, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:58 INFO TaskSetManager: Finished task 42.0 in stage 67.0 (TID 774) in 38 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (43/50)\n",
      "25/11/13 16:17:58 INFO Executor: Finished task 43.0 in stage 67.0 (TID 775). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:58 INFO Executor: Running task 44.0 in stage 67.0 (TID 776)\n",
      "25/11/13 16:17:58 INFO TaskSetManager: Starting task 45.0 in stage 67.0 (TID 777) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 45, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:58 INFO Executor: Running task 45.0 in stage 67.0 (TID 777)\n",
      "25/11/13 16:17:58 INFO TaskSetManager: Finished task 43.0 in stage 67.0 (TID 775) in 19 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (44/50)\n",
      "25/11/13 16:17:58 INFO BlockManager: Found block rdd_106_44 locally\n",
      "25/11/13 16:17:58 INFO Executor: Finished task 44.0 in stage 67.0 (TID 776). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:58 INFO TaskSetManager: Starting task 46.0 in stage 67.0 (TID 778) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 46, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:58 INFO TaskSetManager: Finished task 44.0 in stage 67.0 (TID 776) in 51 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (45/50)\n",
      "25/11/13 16:17:58 INFO Executor: Running task 46.0 in stage 67.0 (TID 778)\n",
      "25/11/13 16:17:58 INFO BlockManager: Found block rdd_106_45 locally\n",
      "25/11/13 16:17:58 INFO Executor: Finished task 45.0 in stage 67.0 (TID 777). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:58 INFO TaskSetManager: Starting task 47.0 in stage 67.0 (TID 779) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 47, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:58 INFO Executor: Running task 47.0 in stage 67.0 (TID 779)\n",
      "25/11/13 16:17:58 INFO TaskSetManager: Finished task 45.0 in stage 67.0 (TID 777) in 56 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (46/50)\n",
      "25/11/13 16:17:58 INFO BlockManager: Found block rdd_106_46 locally\n",
      "25/11/13 16:17:58 INFO Executor: Finished task 46.0 in stage 67.0 (TID 778). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:58 INFO TaskSetManager: Starting task 48.0 in stage 67.0 (TID 780) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 48, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:58 INFO Executor: Running task 48.0 in stage 67.0 (TID 780)\n",
      "25/11/13 16:17:58 INFO TaskSetManager: Finished task 46.0 in stage 67.0 (TID 778) in 39 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (47/50)\n",
      "25/11/13 16:17:58 INFO BlockManager: Found block rdd_106_47 locally\n",
      "25/11/13 16:17:58 INFO Executor: Finished task 47.0 in stage 67.0 (TID 779). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:58 INFO TaskSetManager: Starting task 49.0 in stage 67.0 (TID 781) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 49, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 16:17:58 INFO Executor: Running task 49.0 in stage 67.0 (TID 781) / 50]\n",
      "25/11/13 16:17:58 INFO TaskSetManager: Finished task 47.0 in stage 67.0 (TID 779) in 43 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (48/50)\n",
      "25/11/13 16:17:58 INFO BlockManager: Found block rdd_106_48 locally\n",
      "25/11/13 16:17:58 INFO Executor: Finished task 48.0 in stage 67.0 (TID 780). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:58 INFO TaskSetManager: Finished task 48.0 in stage 67.0 (TID 780) in 17 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (49/50)\n",
      "25/11/13 16:17:58 INFO BlockManager: Found block rdd_106_49 locally\n",
      "25/11/13 16:17:58 INFO Executor: Finished task 49.0 in stage 67.0 (TID 781). 4181 bytes result sent to driver\n",
      "25/11/13 16:17:58 INFO TaskSetManager: Finished task 49.0 in stage 67.0 (TID 781) in 59 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (50/50)\n",
      "25/11/13 16:17:58 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool \n",
      "25/11/13 16:17:58 INFO DAGScheduler: ResultStage 67 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 1.314 s\n",
      "25/11/13 16:17:58 INFO DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/11/13 16:17:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 67: Stage finished\n",
      "25/11/13 16:17:58 INFO DAGScheduler: Job 39 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 1.345342 s\n",
      "25/11/13 16:17:58 INFO PrepareDeltaScan: DELTA: Done                            \n",
      "25/11/13 16:17:58 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/11/13 16:17:58 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/11/13 16:17:58 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 207.5 KiB, free 1046.8 MiB)\n",
      "25/11/13 16:17:58 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 36.9 KiB, free 1046.8 MiB)\n",
      "25/11/13 16:17:58 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 36.9 KiB, free: 1048.5 MiB)\n",
      "25/11/13 16:17:58 INFO SparkContext: Created broadcast 58 from showString at NativeMethodAccessorImpl.java:0\n",
      "25/11/13 16:17:58 INFO FileSourceScanExec: Planning scan with bin packing, max size: 5904079 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/11/13 16:17:58 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "25/11/13 16:17:58 INFO DAGScheduler: Got job 40 (showString at NativeMethodAccessorImpl.java:0) with 2 output partitions\n",
      "25/11/13 16:17:58 INFO DAGScheduler: Final stage: ResultStage 68 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/11/13 16:17:58 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/11/13 16:17:58 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 16:17:58 INFO DAGScheduler: Submitting ResultStage 68 (MapPartitionsRDD[159] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/11/13 16:17:58 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 31.0 KiB, free 1046.8 MiB)\n",
      "25/11/13 16:17:58 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 10.5 KiB, free 1046.8 MiB)\n",
      "25/11/13 16:17:58 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:32921 (size: 10.5 KiB, free: 1048.5 MiB)\n",
      "25/11/13 16:17:58 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 16:17:58 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 68 (MapPartitionsRDD[159] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))\n",
      "25/11/13 16:17:58 INFO TaskSchedulerImpl: Adding task set 68.0 with 2 tasks resource profile 0\n",
      "25/11/13 16:17:58 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 782) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 9679 bytes) \n",
      "25/11/13 16:17:58 INFO TaskSetManager: Starting task 1.0 in stage 68.0 (TID 783) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 1, PROCESS_LOCAL, 9679 bytes) \n",
      "25/11/13 16:17:58 INFO Executor: Running task 0.0 in stage 68.0 (TID 782)\n",
      "25/11/13 16:17:58 INFO Executor: Running task 1.0 in stage 68.0 (TID 783)\n",
      "25/11/13 16:17:58 INFO FileScanRDD: Reading File path: s3a://nau-local-analytics-silver/dim_user_profile/part-00000-26092a00-ec88-42f6-860b-8e610b908cb4-c000.snappy.parquet, range: 0-5904079, partition values: [empty row]\n",
      "25/11/13 16:17:58 INFO FileScanRDD: Reading File path: s3a://nau-local-analytics-silver/dim_user_profile/part-00000-26092a00-ec88-42f6-860b-8e610b908cb4-c000.snappy.parquet, range: 5904079-7613854, partition values: [empty row]\n",
      "25/11/13 16:17:58 INFO S3AInputStream: Switching to Random IO seek policy\n",
      "25/11/13 16:17:58 INFO S3AInputStream: Switching to Random IO seek policy\n",
      "25/11/13 16:17:58 INFO Executor: Finished task 1.0 in stage 68.0 (TID 783). 1453 bytes result sent to driver\n",
      "25/11/13 16:17:58 INFO TaskSetManager: Finished task 1.0 in stage 68.0 (TID 783) in 222 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/2)\n",
      "25/11/13 16:17:59 INFO BlockManagerInfo: Removed broadcast_57_piece0 on jupyter-spark-758b7c86d8-7j77n:32921 in memory (size: 154.5 KiB, free: 1048.6 MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-------+-------------+--------+------+-------+----+--------+------------------+--------+----------+------------+-----+--------------------------+----------------+\n",
      "|profile_sk|profile_id|user_id|year_of_birth|age_band|gender|country|city|location|level_of_education|language|courseware|phone_number|state|ingestion_date            |source_name     |\n",
      "+----------+----------+-------+-------------+--------+------+-------+----+--------+------------------+--------+----------+------------+-----+--------------------------+----------------+\n",
      "|1         |1         |1      |NULL         |NULL    |NULL  |NULL   |NULL|        |NULL              |        |course.xml|NULL        |NULL |2025-11-04 18:27:24.809743|auth_userprofile|\n",
      "|2         |2         |2      |NULL         |NULL    |NULL  |NULL   |NULL|        |NULL              |        |course.xml|NULL        |NULL |2025-11-04 18:27:24.809743|auth_userprofile|\n",
      "|3         |3         |3      |NULL         |NULL    |NULL  |NULL   |NULL|        |NULL              |        |course.xml|NULL        |NULL |2025-11-04 18:27:24.809743|auth_userprofile|\n",
      "|4         |4         |4      |NULL         |NULL    |NULL  |NULL   |NULL|        |NULL              |        |course.xml|NULL        |NULL |2025-11-04 18:27:24.809743|auth_userprofile|\n",
      "|5         |5         |6      |NULL         |NULL    |NULL  |NULL   |NULL|        |NULL              |        |course.xml|NULL        |NULL |2025-11-04 18:27:24.809743|auth_userprofile|\n",
      "|6         |6         |7      |1976         |30_54   |m     |NULL   |NULL|        |NULL              |        |course.xml|NULL        |NULL |2025-11-04 18:27:24.809743|auth_userprofile|\n",
      "|7         |7         |8      |2017         |UNDER_18|o     |PT     |    |        |other             |        |course.xml|NULL        |NULL |2025-11-04 18:27:24.809743|auth_userprofile|\n",
      "|8         |8         |10     |NULL         |NULL    |NULL  |PT     |    |        |NULL              |        |course.xml|NULL        |NULL |2025-11-04 18:27:24.809743|auth_userprofile|\n",
      "|9         |9         |11     |NULL         |NULL    |NULL  |PT     |    |        |NULL              |        |course.xml|NULL        |NULL |2025-11-04 18:27:24.809743|auth_userprofile|\n",
      "|10        |10        |12     |NULL         |NULL    |NULL  |PT     |    |        |NULL              |        |course.xml|NULL        |NULL |2025-11-04 18:27:24.809743|auth_userprofile|\n",
      "+----------+----------+-------+-------------+--------+------+-------+----+--------+------------------+--------+----------+------------+-----+--------------------------+----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/13 16:17:59 INFO Executor: Finished task 0.0 in stage 68.0 (TID 782). 3682 bytes result sent to driver\n",
      "25/11/13 16:17:59 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 782) in 1562 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (2/2)\n",
      "25/11/13 16:17:59 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool \n",
      "25/11/13 16:18:00 INFO DAGScheduler: ResultStage 68 (showString at NativeMethodAccessorImpl.java:0) finished in 1.608 s\n",
      "25/11/13 16:18:00 INFO DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/11/13 16:18:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 68: Stage finished\n",
      "25/11/13 16:18:00 INFO DAGScheduler: Job 40 finished: showString at NativeMethodAccessorImpl.java:0, took 1.614643 s\n",
      "25/11/13 16:32:44 INFO BlockManagerInfo: Removed broadcast_58_piece0 on jupyter-spark-758b7c86d8-7j77n:32921 in memory (size: 36.9 KiB, free: 1048.6 MiB)\n",
      "25/11/13 16:32:44 INFO BlockManagerInfo: Removed broadcast_59_piece0 on jupyter-spark-758b7c86d8-7j77n:32921 in memory (size: 10.5 KiB, free: 1048.6 MiB)\n"
     ]
    }
   ],
   "source": [
    "silver_profile_path = \"s3a://nau-local-analytics-silver/dim_user_profile\"\n",
    "dim_profile_table_name = \"dim_user_profile\"\n",
    "\n",
    "print(\">> [dim_user_profile] Reading Silver Delta table from path:\")\n",
    "print(f\"   {silver_profile_path}\\n\")\n",
    "\n",
    "df_dim_user_profile = (\n",
    "    spark.read\n",
    "         .format(\"delta\")\n",
    "         .load(silver_profile_path)\n",
    ")\n",
    "\n",
    "print(\">> [dim_user_profile] Schema:\")\n",
    "df_dim_user_profile.printSchema()\n",
    "\n",
    "print(\">> [dim_user_profile] Sample rows:\")\n",
    "df_dim_user_profile.orderBy(\"profile_sk\").show(10, truncate=False)\n",
    "\n",
    "total_rows = df_dim_user_profile.count()\n",
    "distinct_profiles = df_dim_user_profile.select(\"profile_id\").distinct().count()\n",
    "distinct_users = df_dim_user_profile.select(\"user_id\").distinct().count()\n",
    "\n",
    "print(f\">> [dim_user_profile] Total rows in Silver: {total_rows}\")\n",
    "print(f\">> [dim_user_profile] Distinct profile_id in Silver: {distinct_profiles}\")\n",
    "print(f\">> [dim_user_profile] Distinct user_id in Silver: {distinct_users}\")\n",
    "\n",
    "print(\"\\n>> [dim_user_profile] Checking if table is available in the catalog (if created):\")\n",
    "spark.sql(f\"SHOW TABLES LIKE '{dim_profile_table_name}'\").show(truncate=False)\n",
    "\n",
    "print(\"\\n>> [dim_user_profile] Preview via SQL (if table is registered):\")\n",
    "spark.sql(f\"SELECT * FROM {dim_profile_table_name} ORDER BY profile_sk LIMIT 10\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a039e422-f392-4b1b-ac7c-b48096369d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
