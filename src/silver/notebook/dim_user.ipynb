{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a366484b-571c-4a82-a973-0cac26498317",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/13 14:32:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/11/13 14:32:35 WARN DependencyUtils: Local jar /opt/jars/hadoop-aws-3.3.1.jar does not exist, skipping.\n",
      "25/11/13 14:32:35 WARN DependencyUtils: Local jar /opt/jars/aws-java-sdk-bundle-1.12.375.jar does not exist, skipping.\n",
      "25/11/13 14:32:35 WARN DependencyUtils: Local jar /opt/jars/delta-spark_2.12-3.2.1.jar does not exist, skipping.\n",
      "25/11/13 14:32:35 WARN DependencyUtils: Local jar /opt/jars/delta-storage-3.2.1.jar does not exist, skipping.\n",
      "25/11/13 14:32:35 WARN DependencyUtils: Local jar /opt/jars/delta-kernel-api-3.2.1.jar does not exist, skipping.\n",
      "25/11/13 14:32:35 WARN DependencyUtils: Local jar /opt/jars/mysql-connector-j-8.3.0.jar does not exist, skipping.\n",
      "25/11/13 14:32:35 INFO SparkContext: Running Spark version 3.5.6\n",
      "25/11/13 14:32:35 INFO SparkContext: OS info Linux, 6.8.0-87-generic, amd64\n",
      "25/11/13 14:32:35 INFO SparkContext: Java version 11.0.28\n",
      "25/11/13 14:32:36 INFO ResourceUtils: ==============================================================\n",
      "25/11/13 14:32:36 INFO ResourceUtils: No custom resources configured for spark.driver.\n",
      "25/11/13 14:32:36 INFO ResourceUtils: ==============================================================\n",
      "25/11/13 14:32:36 INFO SparkContext: Submitted application: MyApp\n",
      "25/11/13 14:32:36 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n",
      "25/11/13 14:32:36 INFO ResourceProfile: Limiting resource is cpu\n",
      "25/11/13 14:32:36 INFO ResourceProfileManager: Added ResourceProfile id: 0\n",
      "25/11/13 14:32:36 INFO SecurityManager: Changing view acls to: spark\n",
      "25/11/13 14:32:36 INFO SecurityManager: Changing modify acls to: spark\n",
      "25/11/13 14:32:36 INFO SecurityManager: Changing view acls groups to: \n",
      "25/11/13 14:32:36 INFO SecurityManager: Changing modify acls groups to: \n",
      "25/11/13 14:32:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY\n",
      "25/11/13 14:32:36 INFO Utils: Successfully started service 'sparkDriver' on port 37533.\n",
      "25/11/13 14:32:37 INFO SparkEnv: Registering MapOutputTracker\n",
      "25/11/13 14:32:37 INFO SparkEnv: Registering BlockManagerMaster\n",
      "25/11/13 14:32:37 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "25/11/13 14:32:37 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "25/11/13 14:32:37 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "25/11/13 14:32:37 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-13725e4e-547c-4415-b4cc-519e926b1b74\n",
      "25/11/13 14:32:37 INFO MemoryStore: MemoryStore started with capacity 1048.8 MiB\n",
      "25/11/13 14:32:37 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "25/11/13 14:32:37 INFO JettyUtils: Start Jetty 10.244.0.6:4040 for SparkUI\n",
      "25/11/13 14:32:37 INFO Utils: Successfully started service 'SparkUI' on port 4040.\n",
      "25/11/13 14:32:37 ERROR SparkContext: Failed to add /opt/jars/hadoop-aws-3.3.1.jar to Spark environment\n",
      "java.io.FileNotFoundException: Jar /opt/jars/hadoop-aws-3.3.1.jar not found\n",
      "\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2095)\n",
      "\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2151)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:521)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:521)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:521)\n",
      "\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:238)\n",
      "\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n",
      "\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "25/11/13 14:32:37 ERROR SparkContext: Failed to add /opt/jars/aws-java-sdk-bundle-1.12.375.jar to Spark environment\n",
      "java.io.FileNotFoundException: Jar /opt/jars/aws-java-sdk-bundle-1.12.375.jar not found\n",
      "\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2095)\n",
      "\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2151)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:521)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:521)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:521)\n",
      "\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:238)\n",
      "\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n",
      "\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "25/11/13 14:32:37 ERROR SparkContext: Failed to add /opt/jars/delta-spark_2.12-3.2.1.jar to Spark environment\n",
      "java.io.FileNotFoundException: Jar /opt/jars/delta-spark_2.12-3.2.1.jar not found\n",
      "\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2095)\n",
      "\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2151)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:521)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:521)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:521)\n",
      "\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:238)\n",
      "\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n",
      "\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "25/11/13 14:32:37 ERROR SparkContext: Failed to add /opt/jars/delta-storage-3.2.1.jar to Spark environment\n",
      "java.io.FileNotFoundException: Jar /opt/jars/delta-storage-3.2.1.jar not found\n",
      "\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2095)\n",
      "\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2151)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:521)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:521)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:521)\n",
      "\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:238)\n",
      "\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n",
      "\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "25/11/13 14:32:37 ERROR SparkContext: Failed to add /opt/jars/delta-kernel-api-3.2.1.jar to Spark environment\n",
      "java.io.FileNotFoundException: Jar /opt/jars/delta-kernel-api-3.2.1.jar not found\n",
      "\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2095)\n",
      "\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2151)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:521)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:521)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:521)\n",
      "\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:238)\n",
      "\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n",
      "\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "25/11/13 14:32:37 ERROR SparkContext: Failed to add /opt/jars/mysql-connector-j-8.3.0.jar to Spark environment\n",
      "java.io.FileNotFoundException: Jar /opt/jars/mysql-connector-j-8.3.0.jar not found\n",
      "\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2095)\n",
      "\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2151)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:521)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:521)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:521)\n",
      "\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:238)\n",
      "\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n",
      "\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "25/11/13 14:32:38 INFO Executor: Starting executor ID driver on host jupyter-spark-758b7c86d8-7j77n\n",
      "25/11/13 14:32:38 INFO Executor: OS info Linux, 6.8.0-87-generic, amd64\n",
      "25/11/13 14:32:38 INFO Executor: Java version 11.0.28\n",
      "25/11/13 14:32:38 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''\n",
      "25/11/13 14:32:38 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@5bb97169 for default.\n",
      "25/11/13 14:32:38 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43517.\n",
      "25/11/13 14:32:38 INFO NettyBlockTransferService: Server created on jupyter-spark-758b7c86d8-7j77n:43517\n",
      "25/11/13 14:32:38 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "25/11/13 14:32:38 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, jupyter-spark-758b7c86d8-7j77n, 43517, None)\n",
      "25/11/13 14:32:38 INFO BlockManagerMasterEndpoint: Registering block manager jupyter-spark-758b7c86d8-7j77n:43517 with 1048.8 MiB RAM, BlockManagerId(driver, jupyter-spark-758b7c86d8-7j77n, 43517, None)\n",
      "25/11/13 14:32:38 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, jupyter-spark-758b7c86d8-7j77n, 43517, None)\n",
      "25/11/13 14:32:38 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, jupyter-spark-758b7c86d8-7j77n, 43517, None)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "        .appName(\"MyApp\") \\\n",
    "        .config(\"spark.jars\", \"/opt/jars/hadoop-aws-3.3.1.jar,/opt/jars/aws-java-sdk-bundle-1.12.375.jar,/opt/jars/delta-spark_2.12-3.2.1.jar,/opt/jars/delta-storage-3.2.1.jar,/opt/jars/delta-kernel-api-3.2.1.jar,/opt/jars/mysql-connector-j-8.3.0.jar\") \\\n",
    "        .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\\\n",
    "        .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\\\n",
    "        .config(\"spark.hadoop.fs.s3a.access.key\", \"NJ3L4SVUPNXQG3Q8G467\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.secret.key\", \"xJwXJYnzpsIDlDpFGOPspi8ryChaBJJ94XMFICwj\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.endpoint\", \"https://rgw.nau.fccn.pt\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd6a0f22-1327-4cfc-bb70-52cec59bc05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/13 14:32:39 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.\n",
      "25/11/13 14:32:39 INFO SharedState: Warehouse path is 'file:/opt/spark/work-dir/notebooks/spark-warehouse'.\n",
      "25/11/13 14:32:42 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "25/11/13 14:32:42 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
      "25/11/13 14:32:42 INFO MetricsSystemImpl: s3a-file-system metrics system started\n",
      "25/11/13 14:32:45 INFO DelegatingLogStore: LogStore `LogStoreAdapter(io.delta.storage.S3SingleDriverLogStore)` is used for scheme `s3a`\n",
      "25/11/13 14:32:45 INFO DeltaLog: Loading version 0.\n",
      "25/11/13 14:32:50 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(JSON, numFilesInSegment: 1, totalFileSize: 3137)\n",
      "25/11/13 14:32:52 INFO DataSourceStrategy: Pruning directories with: \n",
      "25/11/13 14:32:52 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/11/13 14:32:52 INFO FileSourceStrategy: Post-Scan Filters: ((isnotnull(protocol#11.minReaderVersion) OR isnotnull(metaData#10.id)) OR (isnotnull(commitInfo#12.inCommitTimestamp) AND (version#13L = 0)))\n",
      "25/11/13 14:32:54 INFO CodeGenerator: Code generated in 931.282233 ms\n",
      "25/11/13 14:32:54 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 202.7 KiB, free 1048.6 MiB)\n",
      "25/11/13 14:32:54 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 1048.6 MiB)\n",
      "25/11/13 14:32:54 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 35.4 KiB, free: 1048.8 MiB)\n",
      "25/11/13 14:32:54 INFO SparkContext: Created broadcast 0 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128\n",
      "25/11/13 14:32:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/11/13 14:32:55 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128\n",
      "25/11/13 14:32:55 INFO DAGScheduler: Got job 0 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions\n",
      "25/11/13 14:32:55 INFO DAGScheduler: Final stage: ResultStage 0 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)\n",
      "25/11/13 14:32:55 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/11/13 14:32:55 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 14:32:55 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents\n",
      "25/11/13 14:32:55 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 55.2 KiB, free 1048.5 MiB)\n",
      "25/11/13 14:32:55 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1048.5 MiB)\n",
      "25/11/13 14:32:55 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 17.1 KiB, free: 1048.7 MiB)\n",
      "25/11/13 14:32:55 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 14:32:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))\n",
      "25/11/13 14:32:55 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0\n",
      "25/11/13 14:32:55 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 9692 bytes) \n",
      "25/11/13 14:32:55 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)\n",
      "25/11/13 14:32:56 INFO CodeGenerator: Code generated in 201.874072 ms0 + 1) / 1]\n",
      "25/11/13 14:32:56 INFO FileScanRDD: Reading File path: s3a://nau-local-analytics-bronze/auth_user/_delta_log/00000000000000000000.json, range: 0-3137, partition values: [0]\n",
      "25/11/13 14:32:56 INFO CodeGenerator: Code generated in 121.027004 ms\n",
      "25/11/13 14:32:56 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2176 bytes result sent to driver\n",
      "25/11/13 14:32:56 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1219 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/1)\n",
      "25/11/13 14:32:56 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
      "25/11/13 14:32:56 INFO DAGScheduler: ResultStage 0 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 1.419 s\n",
      "25/11/13 14:32:56 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/11/13 14:32:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished\n",
      "25/11/13 14:32:56 INFO DAGScheduler: Job 0 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 1.573571 s\n",
      "25/11/13 14:32:56 INFO CodeGenerator: Code generated in 106.562842 ms           \n",
      "25/11/13 14:32:57 INFO Snapshot: [tableId=2fa3c141-de45-4b15-8b05-8d925c9a09f1] Created snapshot Snapshot(path=s3a://nau-local-analytics-bronze/auth_user/_delta_log, version=0, metadata=Metadata(38adf0a9-1004-4125-bd0a-04861e01e169,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{\"isSigned\":true,\"scale\":0}},{\"name\":\"last_login\",\"type\":\"timestamp\",\"nullable\":true,\"metadata\":{\"isSigned\":false,\"scale\":0}},{\"name\":\"is_superuser\",\"type\":\"boolean\",\"nullable\":true,\"metadata\":{\"isSigned\":false,\"scale\":0}},{\"name\":\"username\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(150)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"first_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(150)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"last_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(150)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"email\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(254)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"is_staff\",\"type\":\"boolean\",\"nullable\":true,\"metadata\":{\"isSigned\":false,\"scale\":0}},{\"name\":\"is_active\",\"type\":\"boolean\",\"nullable\":true,\"metadata\":{\"isSigned\":false,\"scale\":0}},{\"name\":\"date_joined\",\"type\":\"timestamp\",\"nullable\":true,\"metadata\":{\"isSigned\":false,\"scale\":0}},{\"name\":\"ingestion_date\",\"type\":\"timestamp\",\"nullable\":true,\"metadata\":{}},{\"name\":\"source_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1762280814998)), logSegment=LogSegment(s3a://nau-local-analytics-bronze/auth_user/_delta_log,0,WrappedArray(S3AFileStatus{path=s3a://nau-local-analytics-bronze/auth_user/_delta_log/00000000000000000000.json; isDirectory=false; length=3137; replication=1; blocksize=33554432; modification_time=1762280838754; access_time=0; owner=spark; group=spark; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=5351a42e21ad769c64184d4514f27587 versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@65a2ce0d,1762280838754), checksumOpt=None)\n",
      "25/11/13 14:32:57 INFO DeltaLog: Updated snapshot to Snapshot(path=s3a://nau-local-analytics-bronze/auth_user/_delta_log, version=0, metadata=Metadata(38adf0a9-1004-4125-bd0a-04861e01e169,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{\"isSigned\":true,\"scale\":0}},{\"name\":\"last_login\",\"type\":\"timestamp\",\"nullable\":true,\"metadata\":{\"isSigned\":false,\"scale\":0}},{\"name\":\"is_superuser\",\"type\":\"boolean\",\"nullable\":true,\"metadata\":{\"isSigned\":false,\"scale\":0}},{\"name\":\"username\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(150)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"first_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(150)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"last_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(150)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"email\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(254)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"is_staff\",\"type\":\"boolean\",\"nullable\":true,\"metadata\":{\"isSigned\":false,\"scale\":0}},{\"name\":\"is_active\",\"type\":\"boolean\",\"nullable\":true,\"metadata\":{\"isSigned\":false,\"scale\":0}},{\"name\":\"date_joined\",\"type\":\"timestamp\",\"nullable\":true,\"metadata\":{\"isSigned\":false,\"scale\":0}},{\"name\":\"ingestion_date\",\"type\":\"timestamp\",\"nullable\":true,\"metadata\":{}},{\"name\":\"source_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1762280814998)), logSegment=LogSegment(s3a://nau-local-analytics-bronze/auth_user/_delta_log,0,WrappedArray(S3AFileStatus{path=s3a://nau-local-analytics-bronze/auth_user/_delta_log/00000000000000000000.json; isDirectory=false; length=3137; replication=1; blocksize=33554432; modification_time=1762280838754; access_time=0; owner=spark; group=spark; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=5351a42e21ad769c64184d4514f27587 versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@65a2ce0d,1762280838754), checksumOpt=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- last_login: timestamp (nullable = true)\n",
      " |-- is_superuser: boolean (nullable = true)\n",
      " |-- username: string (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- is_staff: boolean (nullable = true)\n",
      " |-- is_active: boolean (nullable = true)\n",
      " |-- date_joined: timestamp (nullable = true)\n",
      " |-- ingestion_date: timestamp (nullable = true)\n",
      " |-- source_name: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/13 14:32:57 INFO PrepareDeltaScan: DELTA: Filtering files for query\n",
      "25/11/13 14:32:57 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 202.4 KiB, free 1048.3 MiB)\n",
      "25/11/13 14:32:57 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 1048.3 MiB)\n",
      "25/11/13 14:32:57 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 35.4 KiB, free: 1048.7 MiB)\n",
      "25/11/13 14:32:57 INFO SparkContext: Created broadcast 2 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128\n",
      "25/11/13 14:32:59 INFO BlockManagerInfo: Removed broadcast_1_piece0 on jupyter-spark-758b7c86d8-7j77n:43517 in memory (size: 17.1 KiB, free: 1048.7 MiB)\n",
      "25/11/13 14:32:59 INFO BlockManagerInfo: Removed broadcast_0_piece0 on jupyter-spark-758b7c86d8-7j77n:43517 in memory (size: 35.4 KiB, free: 1048.8 MiB)\n",
      "25/11/13 14:32:59 INFO DataSourceStrategy: Pruning directories with: \n",
      "25/11/13 14:32:59 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/11/13 14:32:59 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/11/13 14:32:59 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "25/11/13 14:33:00 INFO CodeGenerator: Code generated in 227.260947 ms\n",
      "25/11/13 14:33:00 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 202.7 KiB, free 1048.4 MiB)\n",
      "25/11/13 14:33:00 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 1048.3 MiB)\n",
      "25/11/13 14:33:00 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 35.4 KiB, free: 1048.7 MiB)\n",
      "25/11/13 14:33:00 INFO SparkContext: Created broadcast 3 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128\n",
      "25/11/13 14:33:00 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/11/13 14:33:00 INFO DAGScheduler: Registering RDD 7 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 0\n",
      "25/11/13 14:33:00 INFO DAGScheduler: Got map stage job 1 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions\n",
      "25/11/13 14:33:00 INFO DAGScheduler: Final stage: ShuffleMapStage 1 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)\n",
      "25/11/13 14:33:00 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/11/13 14:33:00 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 14:33:00 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents\n",
      "25/11/13 14:33:00 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 105.9 KiB, free 1048.2 MiB)\n",
      "25/11/13 14:33:00 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 32.7 KiB, free 1048.2 MiB)\n",
      "25/11/13 14:33:00 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 32.7 KiB, free: 1048.7 MiB)\n",
      "25/11/13 14:33:00 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 14:33:00 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))\n",
      "25/11/13 14:33:00 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0\n",
      "25/11/13 14:33:00 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 9681 bytes) \n",
      "25/11/13 14:33:00 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)\n",
      "25/11/13 14:33:01 INFO CodeGenerator: Code generated in 132.603381 ms\n",
      "25/11/13 14:33:01 INFO CodeGenerator: Code generated in 18.308446 ms\n",
      "25/11/13 14:33:01 INFO FileScanRDD: Reading File path: s3a://nau-local-analytics-bronze/auth_user/_delta_log/00000000000000000000.json, range: 0-3137, partition values: [0]\n",
      "25/11/13 14:33:01 INFO CodeGenerator: Code generated in 105.078998 ms0 + 1) / 1]\n",
      "25/11/13 14:33:01 INFO CodeGenerator: Code generated in 19.547398 ms\n",
      "25/11/13 14:33:01 INFO CodeGenerator: Code generated in 18.229222 ms\n",
      "25/11/13 14:33:01 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1897 bytes result sent to driver\n",
      "25/11/13 14:33:01 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 792 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/1)\n",
      "25/11/13 14:33:01 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool \n",
      "25/11/13 14:33:01 INFO DAGScheduler: ShuffleMapStage 1 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.874 s\n",
      "25/11/13 14:33:01 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/11/13 14:33:01 INFO DAGScheduler: running: Set()\n",
      "25/11/13 14:33:01 INFO DAGScheduler: waiting: Set()\n",
      "25/11/13 14:33:01 INFO DAGScheduler: failed: Set()\n",
      "25/11/13 14:33:01 INFO BlockManagerInfo: Removed broadcast_4_piece0 on jupyter-spark-758b7c86d8-7j77n:43517 in memory (size: 32.7 KiB, free: 1048.7 MiB)\n",
      "25/11/13 14:33:02 INFO CodeGenerator: Generated method too long to be JIT compiled: org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.serializefromobject_doConsume_0$ is 25072 bytes\n",
      "25/11/13 14:33:02 INFO CodeGenerator: Code generated in 598.087905 ms\n",
      "25/11/13 14:33:03 INFO CodeGenerator: Code generated in 114.233325 ms\n",
      "25/11/13 14:33:04 INFO CodeGenerator: Code generated in 265.136862 ms\n",
      "25/11/13 14:33:04 INFO CodeGenerator: Code generated in 43.140432 ms\n",
      "25/11/13 14:33:04 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128\n",
      "25/11/13 14:33:04 INFO DAGScheduler: Got job 2 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions\n",
      "25/11/13 14:33:04 INFO DAGScheduler: Final stage: ResultStage 3 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)\n",
      "25/11/13 14:33:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)\n",
      "25/11/13 14:33:04 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 14:33:04 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents\n",
      "25/11/13 14:33:05 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 715.2 KiB, free 1047.6 MiB)\n",
      "25/11/13 14:33:05 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 163.1 KiB, free 1047.5 MiB)\n",
      "25/11/13 14:33:05 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 163.1 KiB, free: 1048.6 MiB)\n",
      "25/11/13 14:33:05 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 14:33:05 INFO DAGScheduler: Submitting 50 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n",
      "25/11/13 14:33:05 INFO TaskSchedulerImpl: Adding task set 3.0 with 50 tasks resource profile 0\n",
      "25/11/13 14:33:05 INFO TaskSetManager: Starting task 7.0 in stage 3.0 (TID 2) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 7, NODE_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:05 INFO TaskSetManager: Starting task 42.0 in stage 3.0 (TID 3) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 42, NODE_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:05 INFO Executor: Running task 7.0 in stage 3.0 (TID 2)\n",
      "25/11/13 14:33:05 INFO Executor: Running task 42.0 in stage 3.0 (TID 3)\n",
      "25/11/13 14:33:05 INFO ShuffleBlockFetcherIterator: Getting 1 (1051.0 B) non-empty blocks including 1 (1051.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:05 INFO ShuffleBlockFetcherIterator: Getting 1 (652.0 B) non-empty blocks including 1 (652.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 20 ms\n",
      "25/11/13 14:33:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 20 ms\n",
      "25/11/13 14:33:05 INFO CodeGenerator: Code generated in 132.723137 ms + 2) / 50]\n",
      "25/11/13 14:33:05 INFO CodeGenerator: Code generated in 22.88489 ms\n",
      "25/11/13 14:33:05 INFO CodeGenerator: Code generated in 9.023365 ms\n",
      "25/11/13 14:33:06 INFO CodeGenerator: Code generated in 204.481053 ms\n",
      "25/11/13 14:33:07 INFO CodeGenerator: Generated method too long to be JIT compiled: org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.serializefromobject_doConsume_0$ is 25072 bytes\n",
      "25/11/13 14:33:07 INFO CodeGenerator: Code generated in 774.094499 ms\n",
      "25/11/13 14:33:07 INFO MemoryStore: Block rdd_14_42 stored as values in memory (estimated size 731.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:07 INFO MemoryStore: Block rdd_14_7 stored as values in memory (estimated size 765.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:07 INFO BlockManagerInfo: Added rdd_14_42 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 731.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:07 INFO BlockManagerInfo: Added rdd_14_7 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 765.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:07 INFO CodeGenerator: Code generated in 194.10753 ms\n",
      "25/11/13 14:33:07 INFO CodeGenerator: Code generated in 38.269912 ms\n",
      "25/11/13 14:33:07 INFO MemoryStore: Block rdd_18_42 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:07 INFO BlockManagerInfo: Added rdd_18_42 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:07 INFO CodeGenerator: Code generated in 48.809213 ms\n",
      "25/11/13 14:33:07 INFO Executor: Finished task 42.0 in stage 3.0 (TID 3). 5067 bytes result sent to driver\n",
      "25/11/13 14:33:07 INFO MemoryStore: Block rdd_18_7 stored as values in memory (estimated size 543.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:07 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 4) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:07 INFO BlockManagerInfo: Added rdd_18_7 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 543.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:07 INFO TaskSetManager: Finished task 42.0 in stage 3.0 (TID 3) in 2359 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/50)\n",
      "25/11/13 14:33:07 INFO Executor: Running task 0.0 in stage 3.0 (TID 4)\n",
      "25/11/13 14:33:07 INFO Executor: Finished task 7.0 in stage 3.0 (TID 2). 5218 bytes result sent to driver\n",
      "25/11/13 14:33:07 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 5) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 1, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:07 INFO Executor: Running task 1.0 in stage 3.0 (TID 5)\n",
      "25/11/13 14:33:07 INFO TaskSetManager: Finished task 7.0 in stage 3.0 (TID 2) in 2392 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (2/50)\n",
      "25/11/13 14:33:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "25/11/13 14:33:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/11/13 14:33:07 INFO MemoryStore: Block rdd_14_1 stored as values in memory (estimated size 46.0 B, free 1047.4 MiB)\n",
      "25/11/13 14:33:07 INFO BlockManagerInfo: Added rdd_14_1 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:07 INFO MemoryStore: Block rdd_14_0 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:07 INFO BlockManagerInfo: Added rdd_14_0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:07 INFO MemoryStore: Block rdd_18_0 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:07 INFO MemoryStore: Block rdd_18_1 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:07 INFO BlockManagerInfo: Added rdd_18_0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:07 INFO BlockManagerInfo: Added rdd_18_1 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:07 INFO Executor: Finished task 0.0 in stage 3.0 (TID 4). 5067 bytes result sent to driver\n",
      "25/11/13 14:33:07 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 6) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 2, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:07 INFO Executor: Finished task 1.0 in stage 3.0 (TID 5). 5067 bytes result sent to driver\n",
      "25/11/13 14:33:07 INFO Executor: Running task 2.0 in stage 3.0 (TID 6)\n",
      "25/11/13 14:33:07 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 7) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 3, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:07 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 4) in 449 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (3/50)\n",
      "25/11/13 14:33:07 INFO Executor: Running task 3.0 in stage 3.0 (TID 7)\n",
      "25/11/13 14:33:07 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 5) in 437 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (4/50)\n",
      "25/11/13 14:33:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/11/13 14:33:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/11/13 14:33:08 INFO MemoryStore: Block rdd_14_3 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:08 INFO BlockManagerInfo: Added rdd_14_3 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:08 INFO MemoryStore: Block rdd_14_2 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:08 INFO BlockManagerInfo: Added rdd_14_2 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:08 INFO MemoryStore: Block rdd_18_3 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:08 INFO MemoryStore: Block rdd_18_2 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:08 INFO BlockManagerInfo: Added rdd_18_3 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:08 INFO BlockManagerInfo: Added rdd_18_2 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:08 INFO Executor: Finished task 2.0 in stage 3.0 (TID 6). 5067 bytes result sent to driver\n",
      "25/11/13 14:33:08 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 8) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 4, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:08 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 6) in 563 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (5/50)\n",
      "25/11/13 14:33:08 INFO Executor: Finished task 3.0 in stage 3.0 (TID 7). 5110 bytes result sent to driver\n",
      "25/11/13 14:33:08 INFO Executor: Running task 4.0 in stage 3.0 (TID 8)\n",
      "25/11/13 14:33:08 INFO TaskSetManager: Starting task 5.0 in stage 3.0 (TID 9) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 5, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:08 INFO Executor: Running task 5.0 in stage 3.0 (TID 9)\n",
      "25/11/13 14:33:08 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 7) in 586 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (6/50)\n",
      "25/11/13 14:33:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/11/13 14:33:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "25/11/13 14:33:08 INFO MemoryStore: Block rdd_14_5 stored as values in memory (estimated size 46.0 B, free 1047.4 MiB)\n",
      "25/11/13 14:33:08 INFO BlockManagerInfo: Added rdd_14_5 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:08 INFO MemoryStore: Block rdd_14_4 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:08 INFO BlockManagerInfo: Added rdd_14_4 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:08 INFO MemoryStore: Block rdd_18_5 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:08 INFO BlockManagerInfo: Added rdd_18_5 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:08 INFO Executor: Finished task 5.0 in stage 3.0 (TID 9). 5067 bytes result sent to driver\n",
      "25/11/13 14:33:08 INFO TaskSetManager: Starting task 6.0 in stage 3.0 (TID 10) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 6, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:08 INFO Executor: Running task 6.0 in stage 3.0 (TID 10)\n",
      "25/11/13 14:33:08 INFO TaskSetManager: Finished task 5.0 in stage 3.0 (TID 9) in 414 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (7/50)\n",
      "25/11/13 14:33:08 INFO MemoryStore: Block rdd_18_4 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:08 INFO BlockManagerInfo: Added rdd_18_4 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:08 INFO Executor: Finished task 4.0 in stage 3.0 (TID 8). 5067 bytes result sent to driver\n",
      "25/11/13 14:33:08 INFO TaskSetManager: Starting task 8.0 in stage 3.0 (TID 11) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 8, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:08 INFO Executor: Running task 8.0 in stage 3.0 (TID 11)\n",
      "25/11/13 14:33:08 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 8) in 495 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (8/50)\n",
      "25/11/13 14:33:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/11/13 14:33:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/11/13 14:33:09 INFO MemoryStore: Block rdd_14_6 stored as values in memory (estimated size 46.0 B, free 1047.4 MiB)\n",
      "25/11/13 14:33:09 INFO BlockManagerInfo: Added rdd_14_6 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:09 INFO MemoryStore: Block rdd_18_6 stored as values in memory (estimated size 46.0 B, free 1047.4 MiB)\n",
      "25/11/13 14:33:09 INFO BlockManagerInfo: Added rdd_18_6 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:09 INFO Executor: Finished task 6.0 in stage 3.0 (TID 10). 5024 bytes result sent to driver\n",
      "25/11/13 14:33:09 INFO TaskSetManager: Starting task 9.0 in stage 3.0 (TID 12) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 9, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:09 INFO Executor: Running task 9.0 in stage 3.0 (TID 12)\n",
      "25/11/13 14:33:09 INFO TaskSetManager: Finished task 6.0 in stage 3.0 (TID 10) in 476 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (9/50)\n",
      "25/11/13 14:33:09 INFO MemoryStore: Block rdd_14_8 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:09 INFO BlockManagerInfo: Added rdd_14_8 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:09 INFO MemoryStore: Block rdd_18_8 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:09 INFO BlockManagerInfo: Added rdd_18_8 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/11/13 14:33:09 INFO Executor: Finished task 8.0 in stage 3.0 (TID 11). 5067 bytes result sent to driver\n",
      "25/11/13 14:33:09 INFO TaskSetManager: Starting task 10.0 in stage 3.0 (TID 13) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 10, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:09 INFO Executor: Running task 10.0 in stage 3.0 (TID 13)\n",
      "25/11/13 14:33:09 INFO TaskSetManager: Finished task 8.0 in stage 3.0 (TID 11) in 537 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (10/50)\n",
      "25/11/13 14:33:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "25/11/13 14:33:09 INFO MemoryStore: Block rdd_14_9 stored as values in memory (estimated size 46.0 B, free 1047.4 MiB)\n",
      "25/11/13 14:33:09 INFO BlockManagerInfo: Added rdd_14_9 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:09 INFO MemoryStore: Block rdd_18_9 stored as values in memory (estimated size 46.0 B, free 1047.4 MiB)\n",
      "25/11/13 14:33:09 INFO BlockManagerInfo: Added rdd_18_9 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:09 INFO Executor: Finished task 9.0 in stage 3.0 (TID 12). 5024 bytes result sent to driver\n",
      "25/11/13 14:33:09 INFO TaskSetManager: Starting task 11.0 in stage 3.0 (TID 14) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 11, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:09 INFO Executor: Running task 11.0 in stage 3.0 (TID 14)\n",
      "25/11/13 14:33:09 INFO TaskSetManager: Finished task 9.0 in stage 3.0 (TID 12) in 385 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (11/50)\n",
      "25/11/13 14:33:09 INFO MemoryStore: Block rdd_14_10 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:09 INFO BlockManagerInfo: Added rdd_14_10 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:09 INFO MemoryStore: Block rdd_18_10 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:09 INFO BlockManagerInfo: Added rdd_18_10 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/11/13 14:33:09 INFO Executor: Finished task 10.0 in stage 3.0 (TID 13). 5067 bytes result sent to driver\n",
      "25/11/13 14:33:09 INFO TaskSetManager: Starting task 12.0 in stage 3.0 (TID 15) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 12, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:09 INFO Executor: Running task 12.0 in stage 3.0 (TID 15)\n",
      "25/11/13 14:33:09 INFO TaskSetManager: Finished task 10.0 in stage 3.0 (TID 13) in 335 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (12/50)\n",
      "25/11/13 14:33:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/11/13 14:33:09 INFO MemoryStore: Block rdd_14_11 stored as values in memory (estimated size 46.0 B, free 1047.4 MiB)\n",
      "25/11/13 14:33:09 INFO BlockManagerInfo: Added rdd_14_11 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:09 INFO MemoryStore: Block rdd_18_11 stored as values in memory (estimated size 46.0 B, free 1047.4 MiB)\n",
      "25/11/13 14:33:09 INFO BlockManagerInfo: Added rdd_18_11 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:10 INFO Executor: Finished task 11.0 in stage 3.0 (TID 14). 5067 bytes result sent to driver\n",
      "25/11/13 14:33:10 INFO TaskSetManager: Starting task 13.0 in stage 3.0 (TID 16) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 13, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:10 INFO Executor: Running task 13.0 in stage 3.0 (TID 16)\n",
      "25/11/13 14:33:10 INFO TaskSetManager: Finished task 11.0 in stage 3.0 (TID 14) in 302 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (13/50)\n",
      "25/11/13 14:33:10 INFO MemoryStore: Block rdd_14_12 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:10 INFO BlockManagerInfo: Added rdd_14_12 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:10 INFO MemoryStore: Block rdd_18_12 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:10 INFO BlockManagerInfo: Added rdd_18_12 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:10 INFO Executor: Finished task 12.0 in stage 3.0 (TID 15). 5067 bytes result sent to driver\n",
      "25/11/13 14:33:10 INFO TaskSetManager: Starting task 14.0 in stage 3.0 (TID 17) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 14, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:10 INFO Executor: Running task 14.0 in stage 3.0 (TID 17)\n",
      "25/11/13 14:33:10 INFO TaskSetManager: Finished task 12.0 in stage 3.0 (TID 15) in 296 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (14/50)\n",
      "25/11/13 14:33:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/11/13 14:33:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/11/13 14:33:10 INFO MemoryStore: Block rdd_14_13 stored as values in memory (estimated size 46.0 B, free 1047.4 MiB)\n",
      "25/11/13 14:33:10 INFO BlockManagerInfo: Added rdd_14_13 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:10 INFO MemoryStore: Block rdd_18_13 stored as values in memory (estimated size 46.0 B, free 1047.4 MiB)\n",
      "25/11/13 14:33:10 INFO BlockManagerInfo: Added rdd_18_13 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:10 INFO Executor: Finished task 13.0 in stage 3.0 (TID 16). 5067 bytes result sent to driver\n",
      "25/11/13 14:33:10 INFO TaskSetManager: Starting task 15.0 in stage 3.0 (TID 18) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 15, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:10 INFO Executor: Running task 15.0 in stage 3.0 (TID 18)\n",
      "25/11/13 14:33:10 INFO MemoryStore: Block rdd_14_14 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:10 INFO BlockManagerInfo: Added rdd_14_14 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:10 INFO TaskSetManager: Finished task 13.0 in stage 3.0 (TID 16) in 330 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (15/50)\n",
      "25/11/13 14:33:10 INFO MemoryStore: Block rdd_18_14 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:10 INFO BlockManagerInfo: Added rdd_18_14 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:10 INFO Executor: Finished task 14.0 in stage 3.0 (TID 17). 5067 bytes result sent to driver\n",
      "25/11/13 14:33:10 INFO TaskSetManager: Starting task 16.0 in stage 3.0 (TID 19) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 16, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:10 INFO Executor: Running task 16.0 in stage 3.0 (TID 19)\n",
      "25/11/13 14:33:10 INFO TaskSetManager: Finished task 14.0 in stage 3.0 (TID 17) in 345 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (16/50)\n",
      "25/11/13 14:33:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/11/13 14:33:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/11/13 14:33:10 INFO MemoryStore: Block rdd_14_15 stored as values in memory (estimated size 46.0 B, free 1047.4 MiB)\n",
      "25/11/13 14:33:10 INFO BlockManagerInfo: Added rdd_14_15 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:10 INFO MemoryStore: Block rdd_14_16 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:10 INFO BlockManagerInfo: Added rdd_14_16 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:10 INFO MemoryStore: Block rdd_18_15 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:10 INFO BlockManagerInfo: Added rdd_18_15 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:10 INFO Executor: Finished task 15.0 in stage 3.0 (TID 18). 5067 bytes result sent to driver\n",
      "25/11/13 14:33:10 INFO TaskSetManager: Starting task 17.0 in stage 3.0 (TID 20) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 17, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:10 INFO Executor: Running task 17.0 in stage 3.0 (TID 20)\n",
      "25/11/13 14:33:10 INFO TaskSetManager: Finished task 15.0 in stage 3.0 (TID 18) in 392 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (17/50)\n",
      "25/11/13 14:33:10 INFO MemoryStore: Block rdd_18_16 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:10 INFO BlockManagerInfo: Added rdd_18_16 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:10 INFO Executor: Finished task 16.0 in stage 3.0 (TID 19). 5067 bytes result sent to driver\n",
      "25/11/13 14:33:10 INFO TaskSetManager: Starting task 18.0 in stage 3.0 (TID 21) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 18, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:10 INFO TaskSetManager: Finished task 16.0 in stage 3.0 (TID 19) in 334 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (18/50)\n",
      "25/11/13 14:33:10 INFO Executor: Running task 18.0 in stage 3.0 (TID 21)\n",
      "25/11/13 14:33:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "25/11/13 14:33:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 14:33:10 INFO MemoryStore: Block rdd_14_18 stored as values in memory (estimated size 46.0 B, free 1047.4 MiB)\n",
      "25/11/13 14:33:10 INFO BlockManagerInfo: Added rdd_14_18 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:10 INFO MemoryStore: Block rdd_14_17 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:10 INFO BlockManagerInfo: Added rdd_14_17 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:11 INFO MemoryStore: Block rdd_18_18 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:11 INFO BlockManagerInfo: Added rdd_18_18 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:11 INFO Executor: Finished task 18.0 in stage 3.0 (TID 21). 5067 bytes result sent to driver\n",
      "25/11/13 14:33:11 INFO TaskSetManager: Starting task 19.0 in stage 3.0 (TID 22) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 19, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:11 INFO Executor: Running task 19.0 in stage 3.0 (TID 22)\n",
      "25/11/13 14:33:11 INFO TaskSetManager: Finished task 18.0 in stage 3.0 (TID 21) in 274 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (19/50)\n",
      "25/11/13 14:33:11 INFO MemoryStore: Block rdd_18_17 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:11 INFO BlockManagerInfo: Added rdd_18_17 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:11 INFO Executor: Finished task 17.0 in stage 3.0 (TID 20). 5110 bytes result sent to driver\n",
      "25/11/13 14:33:11 INFO TaskSetManager: Starting task 20.0 in stage 3.0 (TID 23) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 20, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:11 INFO Executor: Running task 20.0 in stage 3.0 (TID 23)\n",
      "25/11/13 14:33:11 INFO TaskSetManager: Finished task 17.0 in stage 3.0 (TID 20) in 341 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (20/50)\n",
      "25/11/13 14:33:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/11/13 14:33:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/11/13 14:33:11 INFO MemoryStore: Block rdd_14_19 stored as values in memory (estimated size 46.0 B, free 1047.4 MiB)\n",
      "25/11/13 14:33:11 INFO BlockManagerInfo: Added rdd_14_19 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:11 INFO MemoryStore: Block rdd_14_20 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:11 INFO BlockManagerInfo: Added rdd_14_20 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:11 INFO MemoryStore: Block rdd_18_19 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:11 INFO BlockManagerInfo: Added rdd_18_19 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:11 INFO Executor: Finished task 19.0 in stage 3.0 (TID 22). 5067 bytes result sent to driver\n",
      "25/11/13 14:33:11 INFO MemoryStore: Block rdd_18_20 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:11 INFO TaskSetManager: Starting task 21.0 in stage 3.0 (TID 24) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 21, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:11 INFO BlockManagerInfo: Added rdd_18_20 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:11 INFO Executor: Running task 21.0 in stage 3.0 (TID 24)\n",
      "25/11/13 14:33:11 INFO TaskSetManager: Finished task 19.0 in stage 3.0 (TID 22) in 257 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (21/50)\n",
      "25/11/13 14:33:11 INFO Executor: Finished task 20.0 in stage 3.0 (TID 23). 5067 bytes result sent to driver\n",
      "25/11/13 14:33:11 INFO TaskSetManager: Starting task 22.0 in stage 3.0 (TID 25) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 22, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:11 INFO Executor: Running task 22.0 in stage 3.0 (TID 25)\n",
      "25/11/13 14:33:11 INFO TaskSetManager: Finished task 20.0 in stage 3.0 (TID 23) in 267 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (22/50)\n",
      "25/11/13 14:33:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 14:33:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/11/13 14:33:11 INFO MemoryStore: Block rdd_14_21 stored as values in memory (estimated size 46.0 B, free 1047.4 MiB)\n",
      "25/11/13 14:33:11 INFO BlockManagerInfo: Added rdd_14_21 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:11 INFO MemoryStore: Block rdd_14_22 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:11 INFO BlockManagerInfo: Added rdd_14_22 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:11 INFO MemoryStore: Block rdd_18_21 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:11 INFO BlockManagerInfo: Added rdd_18_21 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:11 INFO Executor: Finished task 21.0 in stage 3.0 (TID 24). 5067 bytes result sent to driver\n",
      "25/11/13 14:33:11 INFO TaskSetManager: Starting task 23.0 in stage 3.0 (TID 26) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 23, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:11 INFO Executor: Running task 23.0 in stage 3.0 (TID 26)\n",
      "25/11/13 14:33:11 INFO TaskSetManager: Finished task 21.0 in stage 3.0 (TID 24) in 379 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (23/50)\n",
      "25/11/13 14:33:11 INFO MemoryStore: Block rdd_18_22 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:11 INFO BlockManagerInfo: Added rdd_18_22 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:11 INFO Executor: Finished task 22.0 in stage 3.0 (TID 25). 5067 bytes result sent to driver\n",
      "25/11/13 14:33:11 INFO TaskSetManager: Starting task 24.0 in stage 3.0 (TID 27) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 24, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:11 INFO Executor: Running task 24.0 in stage 3.0 (TID 27)\n",
      "25/11/13 14:33:11 INFO TaskSetManager: Finished task 22.0 in stage 3.0 (TID 25) in 355 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (24/50)\n",
      "25/11/13 14:33:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/11/13 14:33:11 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 14:33:11 INFO MemoryStore: Block rdd_14_23 stored as values in memory (estimated size 46.0 B, free 1047.4 MiB)\n",
      "25/11/13 14:33:11 INFO BlockManagerInfo: Added rdd_14_23 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:11 INFO MemoryStore: Block rdd_14_24 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:11 INFO BlockManagerInfo: Added rdd_14_24 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:11 INFO MemoryStore: Block rdd_18_23 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:11 INFO BlockManagerInfo: Added rdd_18_23 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:11 INFO Executor: Finished task 23.0 in stage 3.0 (TID 26). 5067 bytes result sent to driver\n",
      "25/11/13 14:33:11 INFO TaskSetManager: Starting task 25.0 in stage 3.0 (TID 28) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 25, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:11 INFO Executor: Running task 25.0 in stage 3.0 (TID 28)\n",
      "25/11/13 14:33:11 INFO TaskSetManager: Finished task 23.0 in stage 3.0 (TID 26) in 272 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (25/50)\n",
      "25/11/13 14:33:11 INFO MemoryStore: Block rdd_18_24 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:11 INFO BlockManagerInfo: Added rdd_18_24 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:11 INFO Executor: Finished task 24.0 in stage 3.0 (TID 27). 5067 bytes result sent to driver\n",
      "25/11/13 14:33:11 INFO TaskSetManager: Starting task 26.0 in stage 3.0 (TID 29) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 26, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:11 INFO Executor: Running task 26.0 in stage 3.0 (TID 29)\n",
      "25/11/13 14:33:11 INFO TaskSetManager: Finished task 24.0 in stage 3.0 (TID 27) in 287 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (26/50)\n",
      "25/11/13 14:33:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/11/13 14:33:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 14:33:12 INFO MemoryStore: Block rdd_14_26 stored as values in memory (estimated size 46.0 B, free 1047.4 MiB)\n",
      "25/11/13 14:33:12 INFO BlockManagerInfo: Added rdd_14_26 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:12 INFO MemoryStore: Block rdd_14_25 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:12 INFO BlockManagerInfo: Added rdd_14_25 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:12 INFO MemoryStore: Block rdd_18_26 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:12 INFO BlockManagerInfo: Added rdd_18_26 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:12 INFO MemoryStore: Block rdd_18_25 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:12 INFO BlockManagerInfo: Added rdd_18_25 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:12 INFO Executor: Finished task 26.0 in stage 3.0 (TID 29). 5067 bytes result sent to driver\n",
      "25/11/13 14:33:12 INFO TaskSetManager: Starting task 27.0 in stage 3.0 (TID 30) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 27, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:12 INFO Executor: Running task 27.0 in stage 3.0 (TID 30)\n",
      "25/11/13 14:33:12 INFO TaskSetManager: Finished task 26.0 in stage 3.0 (TID 29) in 272 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (27/50)\n",
      "25/11/13 14:33:12 INFO Executor: Finished task 25.0 in stage 3.0 (TID 28). 5067 bytes result sent to driver\n",
      "25/11/13 14:33:12 INFO TaskSetManager: Starting task 28.0 in stage 3.0 (TID 31) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 28, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:12 INFO Executor: Running task 28.0 in stage 3.0 (TID 31)\n",
      "25/11/13 14:33:12 INFO TaskSetManager: Finished task 25.0 in stage 3.0 (TID 28) in 325 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (28/50)\n",
      "25/11/13 14:33:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 14:33:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 14:33:12 INFO MemoryStore: Block rdd_14_28 stored as values in memory (estimated size 46.0 B, free 1047.4 MiB)\n",
      "25/11/13 14:33:12 INFO BlockManagerInfo: Added rdd_14_28 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:12 INFO MemoryStore: Block rdd_14_27 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:12 INFO BlockManagerInfo: Added rdd_14_27 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:12 INFO MemoryStore: Block rdd_18_28 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:12 INFO BlockManagerInfo: Added rdd_18_28 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:12 INFO MemoryStore: Block rdd_18_27 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:12 INFO BlockManagerInfo: Added rdd_18_27 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:12 INFO Executor: Finished task 28.0 in stage 3.0 (TID 31). 5067 bytes result sent to driver\n",
      "25/11/13 14:33:12 INFO Executor: Finished task 27.0 in stage 3.0 (TID 30). 5067 bytes result sent to driver\n",
      "25/11/13 14:33:12 INFO TaskSetManager: Starting task 29.0 in stage 3.0 (TID 32) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 29, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:12 INFO Executor: Running task 29.0 in stage 3.0 (TID 32)\n",
      "25/11/13 14:33:12 INFO TaskSetManager: Starting task 30.0 in stage 3.0 (TID 33) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 30, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:12 INFO Executor: Running task 30.0 in stage 3.0 (TID 33)\n",
      "25/11/13 14:33:12 INFO TaskSetManager: Finished task 27.0 in stage 3.0 (TID 30) in 252 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (29/50)\n",
      "25/11/13 14:33:12 INFO TaskSetManager: Finished task 28.0 in stage 3.0 (TID 31) in 247 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (30/50)\n",
      "25/11/13 14:33:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 14:33:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/11/13 14:33:12 INFO MemoryStore: Block rdd_14_29 stored as values in memory (estimated size 46.0 B, free 1047.4 MiB)\n",
      "25/11/13 14:33:12 INFO BlockManagerInfo: Added rdd_14_29 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:12 INFO MemoryStore: Block rdd_14_30 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:12 INFO BlockManagerInfo: Added rdd_14_30 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:12 INFO MemoryStore: Block rdd_18_29 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:12 INFO BlockManagerInfo: Added rdd_18_29 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:12 INFO MemoryStore: Block rdd_18_30 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:12 INFO BlockManagerInfo: Added rdd_18_30 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:12 INFO Executor: Finished task 29.0 in stage 3.0 (TID 32). 5067 bytes result sent to driver\n",
      "25/11/13 14:33:12 INFO TaskSetManager: Starting task 31.0 in stage 3.0 (TID 34) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 31, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:12 INFO Executor: Finished task 30.0 in stage 3.0 (TID 33). 5067 bytes result sent to driver\n",
      "25/11/13 14:33:12 INFO Executor: Running task 31.0 in stage 3.0 (TID 34)\n",
      "25/11/13 14:33:12 INFO TaskSetManager: Starting task 32.0 in stage 3.0 (TID 35) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 32, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:12 INFO Executor: Running task 32.0 in stage 3.0 (TID 35)\n",
      "25/11/13 14:33:12 INFO TaskSetManager: Finished task 30.0 in stage 3.0 (TID 33) in 276 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (31/50)\n",
      "25/11/13 14:33:12 INFO TaskSetManager: Finished task 29.0 in stage 3.0 (TID 32) in 278 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (32/50)\n",
      "25/11/13 14:33:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 14:33:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 14:33:12 INFO MemoryStore: Block rdd_14_31 stored as values in memory (estimated size 46.0 B, free 1047.4 MiB)\n",
      "25/11/13 14:33:12 INFO BlockManagerInfo: Added rdd_14_31 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:12 INFO MemoryStore: Block rdd_18_31 stored as values in memory (estimated size 46.0 B, free 1047.4 MiB)\n",
      "25/11/13 14:33:12 INFO BlockManagerInfo: Added rdd_18_31 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:12 INFO MemoryStore: Block rdd_14_32 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:12 INFO Executor: Finished task 31.0 in stage 3.0 (TID 34). 5067 bytes result sent to driver\n",
      "25/11/13 14:33:12 INFO BlockManagerInfo: Added rdd_14_32 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:12 INFO TaskSetManager: Starting task 33.0 in stage 3.0 (TID 36) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 33, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:12 INFO TaskSetManager: Finished task 31.0 in stage 3.0 (TID 34) in 200 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (33/50)\n",
      "25/11/13 14:33:12 INFO Executor: Running task 33.0 in stage 3.0 (TID 36)\n",
      "25/11/13 14:33:12 INFO MemoryStore: Block rdd_18_32 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:12 INFO BlockManagerInfo: Added rdd_18_32 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:12 INFO Executor: Finished task 32.0 in stage 3.0 (TID 35). 5067 bytes result sent to driver\n",
      "25/11/13 14:33:12 INFO TaskSetManager: Starting task 34.0 in stage 3.0 (TID 37) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 34, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:12 INFO Executor: Running task 34.0 in stage 3.0 (TID 37)\n",
      "25/11/13 14:33:12 INFO TaskSetManager: Finished task 32.0 in stage 3.0 (TID 35) in 244 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (34/50)\n",
      "25/11/13 14:33:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 14:33:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 14:33:13 INFO MemoryStore: Block rdd_14_34 stored as values in memory (estimated size 46.0 B, free 1047.4 MiB)\n",
      "25/11/13 14:33:13 INFO BlockManagerInfo: Added rdd_14_34 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:13 INFO MemoryStore: Block rdd_14_33 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:13 INFO BlockManagerInfo: Added rdd_14_33 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:13 INFO MemoryStore: Block rdd_18_34 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:13 INFO BlockManagerInfo: Added rdd_18_34 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:13 INFO Executor: Finished task 34.0 in stage 3.0 (TID 37). 5024 bytes result sent to driver\n",
      "25/11/13 14:33:13 INFO TaskSetManager: Starting task 35.0 in stage 3.0 (TID 38) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 35, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:13 INFO Executor: Running task 35.0 in stage 3.0 (TID 38)\n",
      "25/11/13 14:33:13 INFO TaskSetManager: Finished task 34.0 in stage 3.0 (TID 37) in 192 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (35/50)\n",
      "25/11/13 14:33:13 INFO MemoryStore: Block rdd_18_33 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:13 INFO BlockManagerInfo: Added rdd_18_33 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:13 INFO Executor: Finished task 33.0 in stage 3.0 (TID 36). 5067 bytes result sent to driver\n",
      "25/11/13 14:33:13 INFO TaskSetManager: Starting task 36.0 in stage 3.0 (TID 39) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 36, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:13 INFO TaskSetManager: Finished task 33.0 in stage 3.0 (TID 36) in 248 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (36/50)\n",
      "25/11/13 14:33:13 INFO Executor: Running task 36.0 in stage 3.0 (TID 39)\n",
      "25/11/13 14:33:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 14:33:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 19 ms\n",
      "25/11/13 14:33:13 INFO MemoryStore: Block rdd_14_35 stored as values in memory (estimated size 46.0 B, free 1047.4 MiB)\n",
      "25/11/13 14:33:13 INFO BlockManagerInfo: Added rdd_14_35 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:13 INFO MemoryStore: Block rdd_18_35 stored as values in memory (estimated size 46.0 B, free 1047.4 MiB)\n",
      "25/11/13 14:33:13 INFO BlockManagerInfo: Added rdd_18_35 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:13 INFO Executor: Finished task 35.0 in stage 3.0 (TID 38). 5067 bytes result sent to driver\n",
      "25/11/13 14:33:13 INFO TaskSetManager: Starting task 37.0 in stage 3.0 (TID 40) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 37, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:13 INFO Executor: Running task 37.0 in stage 3.0 (TID 40)\n",
      "25/11/13 14:33:13 INFO TaskSetManager: Finished task 35.0 in stage 3.0 (TID 38) in 215 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (37/50)\n",
      "25/11/13 14:33:13 INFO MemoryStore: Block rdd_14_36 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:13 INFO BlockManagerInfo: Added rdd_14_36 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 14:33:13 INFO MemoryStore: Block rdd_18_36 stored as values in memory (estimated size 46.0 B, free 1047.4 MiB)\n",
      "25/11/13 14:33:13 INFO BlockManagerInfo: Added rdd_18_36 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:13 INFO Executor: Finished task 36.0 in stage 3.0 (TID 39). 5067 bytes result sent to driver\n",
      "25/11/13 14:33:13 INFO TaskSetManager: Starting task 38.0 in stage 3.0 (TID 41) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 38, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:13 INFO Executor: Running task 38.0 in stage 3.0 (TID 41)\n",
      "25/11/13 14:33:13 INFO TaskSetManager: Finished task 36.0 in stage 3.0 (TID 39) in 291 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (38/50)\n",
      "25/11/13 14:33:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 14:33:13 INFO MemoryStore: Block rdd_14_37 stored as values in memory (estimated size 46.0 B, free 1047.4 MiB)\n",
      "25/11/13 14:33:13 INFO BlockManagerInfo: Added rdd_14_37 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:13 INFO MemoryStore: Block rdd_18_37 stored as values in memory (estimated size 46.0 B, free 1047.4 MiB)\n",
      "25/11/13 14:33:13 INFO BlockManagerInfo: Added rdd_18_37 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:13 INFO Executor: Finished task 37.0 in stage 3.0 (TID 40). 5024 bytes result sent to driver\n",
      "25/11/13 14:33:13 INFO TaskSetManager: Starting task 39.0 in stage 3.0 (TID 42) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 39, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:13 INFO TaskSetManager: Finished task 37.0 in stage 3.0 (TID 40) in 202 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (39/50)\n",
      "25/11/13 14:33:13 INFO Executor: Running task 39.0 in stage 3.0 (TID 42)\n",
      "25/11/13 14:33:13 INFO MemoryStore: Block rdd_14_38 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 14:33:13 INFO BlockManagerInfo: Added rdd_14_38 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:13 INFO MemoryStore: Block rdd_18_38 stored as values in memory (estimated size 46.0 B, free 1047.4 MiB)\n",
      "25/11/13 14:33:13 INFO BlockManagerInfo: Added rdd_18_38 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:13 INFO Executor: Finished task 38.0 in stage 3.0 (TID 41). 5024 bytes result sent to driver\n",
      "25/11/13 14:33:13 INFO TaskSetManager: Starting task 40.0 in stage 3.0 (TID 43) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 40, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:13 INFO Executor: Running task 40.0 in stage 3.0 (TID 43)\n",
      "25/11/13 14:33:13 INFO TaskSetManager: Finished task 38.0 in stage 3.0 (TID 41) in 255 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (40/50)\n",
      "25/11/13 14:33:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 14:33:13 INFO MemoryStore: Block rdd_14_39 stored as values in memory (estimated size 46.0 B, free 1047.4 MiB)\n",
      "25/11/13 14:33:13 INFO BlockManagerInfo: Added rdd_14_39 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:13 INFO MemoryStore: Block rdd_18_39 stored as values in memory (estimated size 46.0 B, free 1047.4 MiB)\n",
      "25/11/13 14:33:13 INFO BlockManagerInfo: Added rdd_18_39 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:13 INFO Executor: Finished task 39.0 in stage 3.0 (TID 42). 5067 bytes result sent to driver\n",
      "25/11/13 14:33:13 INFO TaskSetManager: Starting task 41.0 in stage 3.0 (TID 44) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 41, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:13 INFO Executor: Running task 41.0 in stage 3.0 (TID 44)\n",
      "25/11/13 14:33:13 INFO TaskSetManager: Finished task 39.0 in stage 3.0 (TID 42) in 283 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (41/50)\n",
      "25/11/13 14:33:13 INFO MemoryStore: Block rdd_14_40 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:13 INFO BlockManagerInfo: Added rdd_14_40 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 14:33:13 INFO MemoryStore: Block rdd_18_40 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:13 INFO BlockManagerInfo: Added rdd_18_40 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:13 INFO Executor: Finished task 40.0 in stage 3.0 (TID 43). 5024 bytes result sent to driver\n",
      "25/11/13 14:33:13 INFO TaskSetManager: Starting task 43.0 in stage 3.0 (TID 45) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 43, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:13 INFO Executor: Running task 43.0 in stage 3.0 (TID 45)\n",
      "25/11/13 14:33:13 INFO TaskSetManager: Finished task 40.0 in stage 3.0 (TID 43) in 245 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (42/50)\n",
      "25/11/13 14:33:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 14:33:14 INFO MemoryStore: Block rdd_14_41 stored as values in memory (estimated size 46.0 B, free 1047.4 MiB)\n",
      "25/11/13 14:33:14 INFO BlockManagerInfo: Added rdd_14_41 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:14 INFO MemoryStore: Block rdd_18_41 stored as values in memory (estimated size 46.0 B, free 1047.4 MiB)\n",
      "25/11/13 14:33:14 INFO BlockManagerInfo: Added rdd_18_41 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:14 INFO Executor: Finished task 41.0 in stage 3.0 (TID 44). 5024 bytes result sent to driver\n",
      "25/11/13 14:33:14 INFO TaskSetManager: Starting task 44.0 in stage 3.0 (TID 46) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 44, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:14 INFO Executor: Running task 44.0 in stage 3.0 (TID 46)\n",
      "25/11/13 14:33:14 INFO TaskSetManager: Finished task 41.0 in stage 3.0 (TID 44) in 207 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (43/50)\n",
      "25/11/13 14:33:14 INFO MemoryStore: Block rdd_14_43 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:14 INFO BlockManagerInfo: Added rdd_14_43 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:14 INFO MemoryStore: Block rdd_18_43 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:14 INFO BlockManagerInfo: Added rdd_18_43 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms\n",
      "25/11/13 14:33:14 INFO Executor: Finished task 43.0 in stage 3.0 (TID 45). 5067 bytes result sent to driver\n",
      "25/11/13 14:33:14 INFO TaskSetManager: Starting task 45.0 in stage 3.0 (TID 47) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 45, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:14 INFO TaskSetManager: Finished task 43.0 in stage 3.0 (TID 45) in 240 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (44/50)\n",
      "25/11/13 14:33:14 INFO Executor: Running task 45.0 in stage 3.0 (TID 47)\n",
      "25/11/13 14:33:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 14:33:14 INFO MemoryStore: Block rdd_14_44 stored as values in memory (estimated size 46.0 B, free 1047.4 MiB)\n",
      "25/11/13 14:33:14 INFO BlockManagerInfo: Added rdd_14_44 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:14 INFO MemoryStore: Block rdd_18_44 stored as values in memory (estimated size 46.0 B, free 1047.4 MiB)\n",
      "25/11/13 14:33:14 INFO BlockManagerInfo: Added rdd_18_44 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:14 INFO Executor: Finished task 44.0 in stage 3.0 (TID 46). 5067 bytes result sent to driver\n",
      "25/11/13 14:33:14 INFO TaskSetManager: Starting task 46.0 in stage 3.0 (TID 48) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 46, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:14 INFO Executor: Running task 46.0 in stage 3.0 (TID 48)\n",
      "25/11/13 14:33:14 INFO TaskSetManager: Finished task 44.0 in stage 3.0 (TID 46) in 228 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (45/50)\n",
      "25/11/13 14:33:14 INFO MemoryStore: Block rdd_14_45 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:14 INFO BlockManagerInfo: Added rdd_14_45 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:14 INFO MemoryStore: Block rdd_18_45 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:14 INFO BlockManagerInfo: Added rdd_18_45 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 14:33:14 INFO Executor: Finished task 45.0 in stage 3.0 (TID 47). 5024 bytes result sent to driver\n",
      "25/11/13 14:33:14 INFO TaskSetManager: Starting task 47.0 in stage 3.0 (TID 49) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 47, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:14 INFO Executor: Running task 47.0 in stage 3.0 (TID 49)\n",
      "25/11/13 14:33:14 INFO TaskSetManager: Finished task 45.0 in stage 3.0 (TID 47) in 203 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (46/50)\n",
      "25/11/13 14:33:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 14:33:14 INFO MemoryStore: Block rdd_14_46 stored as values in memory (estimated size 46.0 B, free 1047.4 MiB)\n",
      "25/11/13 14:33:14 INFO BlockManagerInfo: Added rdd_14_46 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:14 INFO MemoryStore: Block rdd_18_46 stored as values in memory (estimated size 46.0 B, free 1047.4 MiB)\n",
      "25/11/13 14:33:14 INFO BlockManagerInfo: Added rdd_18_46 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:14 INFO Executor: Finished task 46.0 in stage 3.0 (TID 48). 5024 bytes result sent to driver\n",
      "25/11/13 14:33:14 INFO MemoryStore: Block rdd_14_47 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:14 INFO TaskSetManager: Starting task 48.0 in stage 3.0 (TID 50) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 48, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:14 INFO Executor: Running task 48.0 in stage 3.0 (TID 50)\n",
      "25/11/13 14:33:14 INFO BlockManagerInfo: Added rdd_14_47 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:14 INFO TaskSetManager: Finished task 46.0 in stage 3.0 (TID 48) in 232 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (47/50)\n",
      "25/11/13 14:33:14 INFO MemoryStore: Block rdd_18_47 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:14 INFO BlockManagerInfo: Added rdd_18_47 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:14 INFO Executor: Finished task 47.0 in stage 3.0 (TID 49). 5024 bytes result sent to driver\n",
      "25/11/13 14:33:14 INFO TaskSetManager: Starting task 49.0 in stage 3.0 (TID 51) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 49, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 14:33:14 INFO Executor: Running task 49.0 in stage 3.0 (TID 51)\n",
      "25/11/13 14:33:14 INFO TaskSetManager: Finished task 47.0 in stage 3.0 (TID 49) in 227 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (48/50)\n",
      "25/11/13 14:33:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 14:33:14 INFO MemoryStore: Block rdd_14_48 stored as values in memory (estimated size 46.0 B, free 1047.4 MiB)\n",
      "25/11/13 14:33:14 INFO BlockManagerInfo: Added rdd_14_48 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:14 INFO MemoryStore: Block rdd_18_48 stored as values in memory (estimated size 46.0 B, free 1047.4 MiB)\n",
      "25/11/13 14:33:14 INFO BlockManagerInfo: Added rdd_18_48 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:14 INFO Executor: Finished task 48.0 in stage 3.0 (TID 50). 5067 bytes result sent to driver\n",
      "25/11/13 14:33:14 INFO TaskSetManager: Finished task 48.0 in stage 3.0 (TID 50) in 264 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (49/50)\n",
      "25/11/13 14:33:14 INFO MemoryStore: Block rdd_14_49 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:14 INFO BlockManagerInfo: Added rdd_14_49 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:14 INFO MemoryStore: Block rdd_18_49 stored as values in memory (estimated size 46.0 B, free 1047.5 MiB)\n",
      "25/11/13 14:33:14 INFO BlockManagerInfo: Added rdd_18_49 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.6 MiB)\n",
      "25/11/13 14:33:14 INFO Executor: Finished task 49.0 in stage 3.0 (TID 51). 5024 bytes result sent to driver\n",
      "25/11/13 14:33:14 INFO TaskSetManager: Finished task 49.0 in stage 3.0 (TID 51) in 205 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (50/50)\n",
      "25/11/13 14:33:14 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool \n",
      "25/11/13 14:33:14 INFO DAGScheduler: ResultStage 3 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 9.792 s\n",
      "25/11/13 14:33:14 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/11/13 14:33:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished\n",
      "25/11/13 14:33:14 INFO DAGScheduler: Job 2 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 9.832962 s\n",
      "25/11/13 14:33:14 INFO CodeGenerator: Code generated in 30.762347 ms            \n",
      "25/11/13 14:33:14 INFO Snapshot: [tableId=38adf0a9-1004-4125-bd0a-04861e01e169] DELTA: Compute snapshot for version: 0\n",
      "25/11/13 14:33:15 INFO CodeGenerator: Code generated in 118.676361 ms\n",
      "25/11/13 14:33:15 INFO DAGScheduler: Registering RDD 23 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 1\n",
      "25/11/13 14:33:15 INFO DAGScheduler: Got map stage job 3 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions\n",
      "25/11/13 14:33:15 INFO DAGScheduler: Final stage: ShuffleMapStage 5 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)\n",
      "25/11/13 14:33:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)\n",
      "25/11/13 14:33:15 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 14:33:15 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[23] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents\n",
      "25/11/13 14:33:15 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 603.2 KiB, free 1046.9 MiB)\n",
      "25/11/13 14:33:15 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 138.2 KiB, free 1046.7 MiB)\n",
      "25/11/13 14:33:15 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 138.2 KiB, free: 1048.4 MiB)\n",
      "25/11/13 14:33:15 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 14:33:15 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[23] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n",
      "25/11/13 14:33:15 INFO TaskSchedulerImpl: Adding task set 5.0 with 50 tasks resource profile 0\n",
      "25/11/13 14:33:15 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 52) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:15 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 53) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 1, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:15 INFO Executor: Running task 1.0 in stage 5.0 (TID 53)\n",
      "25/11/13 14:33:15 INFO Executor: Running task 0.0 in stage 5.0 (TID 52)\n",
      "25/11/13 14:33:15 INFO BlockManager: Found block rdd_14_1 locally\n",
      "25/11/13 14:33:15 INFO BlockManager: Found block rdd_14_0 locally\n",
      "25/11/13 14:33:15 INFO CodeGenerator: Code generated in 82.535021 ms\n",
      "25/11/13 14:33:15 INFO CodeGenerator: Code generated in 8.104498 ms\n",
      "25/11/13 14:33:15 INFO CodeGenerator: Code generated in 15.108267 ms\n",
      "25/11/13 14:33:15 INFO CodeGenerator: Code generated in 6.372052 ms\n",
      "25/11/13 14:33:15 INFO CodeGenerator: Code generated in 32.261813 ms\n",
      "25/11/13 14:33:15 INFO CodeGenerator: Code generated in 12.675662 ms\n",
      "25/11/13 14:33:16 INFO CodeGenerator: Code generated in 9.76604 ms (0 + 2) / 50]\n",
      "25/11/13 14:33:16 INFO CodeGenerator: Code generated in 9.097481 ms\n",
      "25/11/13 14:33:16 INFO Executor: Finished task 0.0 in stage 5.0 (TID 52). 4590 bytes result sent to driver\n",
      "25/11/13 14:33:16 INFO Executor: Finished task 1.0 in stage 5.0 (TID 53). 4590 bytes result sent to driver\n",
      "25/11/13 14:33:16 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 54) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 2, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:16 INFO Executor: Running task 2.0 in stage 5.0 (TID 54)\n",
      "25/11/13 14:33:16 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 55) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 3, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:16 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 53) in 472 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/50)\n",
      "25/11/13 14:33:16 INFO Executor: Running task 3.0 in stage 5.0 (TID 55)\n",
      "25/11/13 14:33:16 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 52) in 473 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (2/50)\n",
      "25/11/13 14:33:16 INFO BlockManager: Found block rdd_14_2 locally\n",
      "25/11/13 14:33:16 INFO BlockManager: Found block rdd_14_3 locally\n",
      "25/11/13 14:33:16 INFO Executor: Finished task 2.0 in stage 5.0 (TID 54). 4590 bytes result sent to driver\n",
      "25/11/13 14:33:16 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 56) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 4, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:16 INFO Executor: Finished task 3.0 in stage 5.0 (TID 55). 4590 bytes result sent to driver\n",
      "25/11/13 14:33:16 INFO Executor: Running task 4.0 in stage 5.0 (TID 56)\n",
      "25/11/13 14:33:16 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 54) in 127 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (3/50)\n",
      "25/11/13 14:33:16 INFO TaskSetManager: Starting task 5.0 in stage 5.0 (TID 57) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 5, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:16 INFO Executor: Running task 5.0 in stage 5.0 (TID 57)\n",
      "25/11/13 14:33:16 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 55) in 157 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (4/50)\n",
      "25/11/13 14:33:16 INFO BlockManager: Found block rdd_14_5 locally  (4 + 2) / 50]\n",
      "25/11/13 14:33:16 INFO BlockManager: Found block rdd_14_4 locally\n",
      "25/11/13 14:33:16 INFO Executor: Finished task 5.0 in stage 5.0 (TID 57). 4590 bytes result sent to driver\n",
      "25/11/13 14:33:16 INFO TaskSetManager: Starting task 6.0 in stage 5.0 (TID 58) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 6, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:16 INFO TaskSetManager: Finished task 5.0 in stage 5.0 (TID 57) in 175 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (5/50)\n",
      "25/11/13 14:33:16 INFO Executor: Running task 6.0 in stage 5.0 (TID 58)\n",
      "25/11/13 14:33:16 INFO Executor: Finished task 4.0 in stage 5.0 (TID 56). 4590 bytes result sent to driver\n",
      "25/11/13 14:33:16 INFO TaskSetManager: Starting task 7.0 in stage 5.0 (TID 59) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 7, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:16 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 56) in 182 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (6/50)\n",
      "25/11/13 14:33:16 INFO Executor: Running task 7.0 in stage 5.0 (TID 59)\n",
      "25/11/13 14:33:16 INFO BlockManager: Found block rdd_14_6 locally\n",
      "25/11/13 14:33:16 INFO BlockManager: Found block rdd_14_7 locally\n",
      "25/11/13 14:33:16 INFO Executor: Finished task 6.0 in stage 5.0 (TID 58). 4590 bytes result sent to driver\n",
      "25/11/13 14:33:16 INFO TaskSetManager: Starting task 8.0 in stage 5.0 (TID 60) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 8, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:16 INFO Executor: Running task 8.0 in stage 5.0 (TID 60)\n",
      "25/11/13 14:33:16 INFO TaskSetManager: Finished task 6.0 in stage 5.0 (TID 58) in 164 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (7/50)\n",
      "25/11/13 14:33:16 INFO Executor: Finished task 7.0 in stage 5.0 (TID 59). 4633 bytes result sent to driver\n",
      "25/11/13 14:33:16 INFO TaskSetManager: Starting task 9.0 in stage 5.0 (TID 61) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 9, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:16 INFO Executor: Running task 9.0 in stage 5.0 (TID 61)\n",
      "25/11/13 14:33:16 INFO TaskSetManager: Finished task 7.0 in stage 5.0 (TID 59) in 187 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (8/50)\n",
      "25/11/13 14:33:16 INFO BlockManager: Found block rdd_14_8 locally\n",
      "25/11/13 14:33:16 INFO BlockManager: Found block rdd_14_9 locally  (8 + 2) / 50]\n",
      "25/11/13 14:33:16 INFO Executor: Finished task 8.0 in stage 5.0 (TID 60). 4633 bytes result sent to driver\n",
      "25/11/13 14:33:16 INFO Executor: Finished task 9.0 in stage 5.0 (TID 61). 4633 bytes result sent to driver\n",
      "25/11/13 14:33:16 INFO TaskSetManager: Starting task 10.0 in stage 5.0 (TID 62) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 10, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:16 INFO TaskSetManager: Finished task 8.0 in stage 5.0 (TID 60) in 243 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (9/50)\n",
      "25/11/13 14:33:16 INFO Executor: Running task 10.0 in stage 5.0 (TID 62)\n",
      "25/11/13 14:33:16 INFO TaskSetManager: Starting task 11.0 in stage 5.0 (TID 63) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 11, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:16 INFO Executor: Running task 11.0 in stage 5.0 (TID 63)\n",
      "25/11/13 14:33:16 INFO TaskSetManager: Finished task 9.0 in stage 5.0 (TID 61) in 221 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (10/50)\n",
      "25/11/13 14:33:16 INFO BlockManager: Found block rdd_14_10 locally(10 + 2) / 50]\n",
      "25/11/13 14:33:16 INFO BlockManager: Found block rdd_14_11 locally\n",
      "25/11/13 14:33:16 INFO Executor: Finished task 11.0 in stage 5.0 (TID 63). 4590 bytes result sent to driver\n",
      "25/11/13 14:33:16 INFO TaskSetManager: Starting task 12.0 in stage 5.0 (TID 64) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 12, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:16 INFO TaskSetManager: Finished task 11.0 in stage 5.0 (TID 63) in 201 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (11/50)\n",
      "25/11/13 14:33:16 INFO Executor: Running task 12.0 in stage 5.0 (TID 64)\n",
      "25/11/13 14:33:16 INFO Executor: Finished task 10.0 in stage 5.0 (TID 62). 4590 bytes result sent to driver\n",
      "25/11/13 14:33:16 INFO TaskSetManager: Starting task 13.0 in stage 5.0 (TID 65) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 13, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:16 INFO TaskSetManager: Finished task 10.0 in stage 5.0 (TID 62) in 210 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (12/50)\n",
      "25/11/13 14:33:16 INFO Executor: Running task 13.0 in stage 5.0 (TID 65)\n",
      "25/11/13 14:33:17 INFO BlockManager: Found block rdd_14_12 locally(12 + 2) / 50]\n",
      "25/11/13 14:33:17 INFO BlockManager: Found block rdd_14_13 locally\n",
      "25/11/13 14:33:17 INFO Executor: Finished task 13.0 in stage 5.0 (TID 65). 4590 bytes result sent to driver\n",
      "25/11/13 14:33:17 INFO TaskSetManager: Starting task 14.0 in stage 5.0 (TID 66) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 14, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:17 INFO Executor: Running task 14.0 in stage 5.0 (TID 66)\n",
      "25/11/13 14:33:17 INFO TaskSetManager: Finished task 13.0 in stage 5.0 (TID 65) in 195 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (13/50)\n",
      "25/11/13 14:33:17 INFO Executor: Finished task 12.0 in stage 5.0 (TID 64). 4590 bytes result sent to driver\n",
      "25/11/13 14:33:17 INFO TaskSetManager: Starting task 15.0 in stage 5.0 (TID 67) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 15, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:17 INFO Executor: Running task 15.0 in stage 5.0 (TID 67)\n",
      "25/11/13 14:33:17 INFO TaskSetManager: Finished task 12.0 in stage 5.0 (TID 64) in 204 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (14/50)\n",
      "25/11/13 14:33:17 INFO BlockManager: Found block rdd_14_14 locally\n",
      "25/11/13 14:33:17 INFO BlockManager: Found block rdd_14_15 locally(14 + 2) / 50]\n",
      "25/11/13 14:33:17 INFO Executor: Finished task 14.0 in stage 5.0 (TID 66). 4590 bytes result sent to driver\n",
      "25/11/13 14:33:17 INFO TaskSetManager: Starting task 16.0 in stage 5.0 (TID 68) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 16, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:17 INFO Executor: Running task 16.0 in stage 5.0 (TID 68)\n",
      "25/11/13 14:33:17 INFO TaskSetManager: Finished task 14.0 in stage 5.0 (TID 66) in 152 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (15/50)\n",
      "25/11/13 14:33:17 INFO Executor: Finished task 15.0 in stage 5.0 (TID 67). 4590 bytes result sent to driver\n",
      "25/11/13 14:33:17 INFO BlockManager: Found block rdd_14_16 locally\n",
      "25/11/13 14:33:17 INFO TaskSetManager: Starting task 17.0 in stage 5.0 (TID 69) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 17, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:17 INFO Executor: Running task 17.0 in stage 5.0 (TID 69)\n",
      "25/11/13 14:33:17 INFO TaskSetManager: Finished task 15.0 in stage 5.0 (TID 67) in 182 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (16/50)\n",
      "25/11/13 14:33:17 INFO BlockManager: Found block rdd_14_17 locally\n",
      "25/11/13 14:33:17 INFO Executor: Finished task 16.0 in stage 5.0 (TID 68). 4590 bytes result sent to driver\n",
      "25/11/13 14:33:17 INFO TaskSetManager: Starting task 18.0 in stage 5.0 (TID 70) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 18, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:17 INFO TaskSetManager: Finished task 16.0 in stage 5.0 (TID 68) in 144 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (17/50)\n",
      "25/11/13 14:33:17 INFO Executor: Running task 18.0 in stage 5.0 (TID 70)\n",
      "25/11/13 14:33:17 INFO BlockManager: Found block rdd_14_18 locally(16 + 3) / 50]\n",
      "25/11/13 14:33:17 INFO Executor: Finished task 17.0 in stage 5.0 (TID 69). 4590 bytes result sent to driver\n",
      "25/11/13 14:33:17 INFO TaskSetManager: Starting task 19.0 in stage 5.0 (TID 71) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 19, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:17 INFO Executor: Running task 19.0 in stage 5.0 (TID 71)\n",
      "25/11/13 14:33:17 INFO TaskSetManager: Finished task 17.0 in stage 5.0 (TID 69) in 140 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (18/50)\n",
      "25/11/13 14:33:17 INFO BlockManager: Found block rdd_14_19 locally\n",
      "25/11/13 14:33:17 INFO Executor: Finished task 18.0 in stage 5.0 (TID 70). 4590 bytes result sent to driver\n",
      "25/11/13 14:33:17 INFO TaskSetManager: Starting task 20.0 in stage 5.0 (TID 72) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 20, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:17 INFO TaskSetManager: Finished task 18.0 in stage 5.0 (TID 70) in 127 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (19/50)\n",
      "25/11/13 14:33:17 INFO Executor: Running task 20.0 in stage 5.0 (TID 72)\n",
      "25/11/13 14:33:17 INFO BlockManager: Found block rdd_14_20 locally\n",
      "25/11/13 14:33:17 INFO Executor: Finished task 19.0 in stage 5.0 (TID 71). 4676 bytes result sent to driver\n",
      "25/11/13 14:33:17 INFO TaskSetManager: Starting task 21.0 in stage 5.0 (TID 73) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 21, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:17 INFO TaskSetManager: Finished task 19.0 in stage 5.0 (TID 71) in 161 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (20/50)\n",
      "25/11/13 14:33:17 INFO Executor: Running task 21.0 in stage 5.0 (TID 73)\n",
      "25/11/13 14:33:17 INFO BlockManager: Found block rdd_14_21 locally\n",
      "25/11/13 14:33:17 INFO Executor: Finished task 20.0 in stage 5.0 (TID 72). 4633 bytes result sent to driver\n",
      "25/11/13 14:33:17 INFO TaskSetManager: Starting task 22.0 in stage 5.0 (TID 74) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 22, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:17 INFO Executor: Running task 22.0 in stage 5.0 (TID 74)\n",
      "25/11/13 14:33:17 INFO TaskSetManager: Finished task 20.0 in stage 5.0 (TID 72) in 127 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (21/50)\n",
      "25/11/13 14:33:17 INFO Executor: Finished task 21.0 in stage 5.0 (TID 73). 4590 bytes result sent to driver\n",
      "25/11/13 14:33:17 INFO TaskSetManager: Starting task 23.0 in stage 5.0 (TID 75) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 23, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:17 INFO BlockManager: Found block rdd_14_22 locally\n",
      "25/11/13 14:33:17 INFO Executor: Running task 23.0 in stage 5.0 (TID 75)\n",
      "25/11/13 14:33:17 INFO TaskSetManager: Finished task 21.0 in stage 5.0 (TID 73) in 123 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (22/50)\n",
      "25/11/13 14:33:17 INFO BlockManager: Found block rdd_14_23 locally\n",
      "25/11/13 14:33:17 INFO Executor: Finished task 22.0 in stage 5.0 (TID 74). 4590 bytes result sent to driver\n",
      "25/11/13 14:33:17 INFO TaskSetManager: Starting task 24.0 in stage 5.0 (TID 76) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 24, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:17 INFO TaskSetManager: Finished task 22.0 in stage 5.0 (TID 74) in 147 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (23/50)\n",
      "25/11/13 14:33:17 INFO Executor: Running task 24.0 in stage 5.0 (TID 76)\n",
      "25/11/13 14:33:17 INFO Executor: Finished task 23.0 in stage 5.0 (TID 75). 4590 bytes result sent to driver\n",
      "25/11/13 14:33:17 INFO TaskSetManager: Starting task 25.0 in stage 5.0 (TID 77) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 25, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:17 INFO Executor: Running task 25.0 in stage 5.0 (TID 77)\n",
      "25/11/13 14:33:17 INFO TaskSetManager: Finished task 23.0 in stage 5.0 (TID 75) in 110 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (24/50)\n",
      "25/11/13 14:33:17 INFO BlockManager: Found block rdd_14_24 locally\n",
      "25/11/13 14:33:17 INFO BlockManager: Found block rdd_14_25 locally\n",
      "25/11/13 14:33:17 INFO Executor: Finished task 24.0 in stage 5.0 (TID 76). 4590 bytes result sent to driver\n",
      "25/11/13 14:33:17 INFO TaskSetManager: Starting task 26.0 in stage 5.0 (TID 78) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 26, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:17 INFO Executor: Running task 26.0 in stage 5.0 (TID 78)\n",
      "25/11/13 14:33:17 INFO Executor: Finished task 25.0 in stage 5.0 (TID 77). 4590 bytes result sent to driver\n",
      "25/11/13 14:33:17 INFO TaskSetManager: Starting task 27.0 in stage 5.0 (TID 79) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 27, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:17 INFO TaskSetManager: Finished task 24.0 in stage 5.0 (TID 76) in 142 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (25/50)\n",
      "25/11/13 14:33:17 INFO Executor: Running task 27.0 in stage 5.0 (TID 79)\n",
      "25/11/13 14:33:17 INFO TaskSetManager: Finished task 25.0 in stage 5.0 (TID 77) in 109 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (26/50)\n",
      "25/11/13 14:33:18 INFO BlockManager: Found block rdd_14_26 locally\n",
      "25/11/13 14:33:18 INFO BlockManager: Found block rdd_14_27 locally\n",
      "25/11/13 14:33:18 INFO Executor: Finished task 26.0 in stage 5.0 (TID 78). 4590 bytes result sent to driver\n",
      "25/11/13 14:33:18 INFO TaskSetManager: Starting task 28.0 in stage 5.0 (TID 80) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 28, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:18 INFO TaskSetManager: Finished task 26.0 in stage 5.0 (TID 78) in 110 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (27/50)\n",
      "25/11/13 14:33:18 INFO Executor: Running task 28.0 in stage 5.0 (TID 80)\n",
      "25/11/13 14:33:18 INFO Executor: Finished task 27.0 in stage 5.0 (TID 79). 4590 bytes result sent to driver\n",
      "25/11/13 14:33:18 INFO TaskSetManager: Starting task 29.0 in stage 5.0 (TID 81) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 29, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:18 INFO Executor: Running task 29.0 in stage 5.0 (TID 81)\n",
      "25/11/13 14:33:18 INFO TaskSetManager: Finished task 27.0 in stage 5.0 (TID 79) in 117 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (28/50)\n",
      "25/11/13 14:33:18 INFO BlockManager: Found block rdd_14_28 locally\n",
      "25/11/13 14:33:18 INFO BlockManager: Found block rdd_14_29 locally\n",
      "25/11/13 14:33:18 INFO Executor: Finished task 29.0 in stage 5.0 (TID 81). 4590 bytes result sent to driver\n",
      "25/11/13 14:33:18 INFO TaskSetManager: Starting task 30.0 in stage 5.0 (TID 82) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 30, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:18 INFO Executor: Finished task 28.0 in stage 5.0 (TID 80). 4590 bytes result sent to driver\n",
      "25/11/13 14:33:18 INFO TaskSetManager: Finished task 29.0 in stage 5.0 (TID 81) in 134 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (29/50)\n",
      "25/11/13 14:33:18 INFO Executor: Running task 30.0 in stage 5.0 (TID 82)\n",
      "25/11/13 14:33:18 INFO TaskSetManager: Starting task 31.0 in stage 5.0 (TID 83) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 31, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:18 INFO Executor: Running task 31.0 in stage 5.0 (TID 83)\n",
      "25/11/13 14:33:18 INFO TaskSetManager: Finished task 28.0 in stage 5.0 (TID 80) in 147 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (30/50)\n",
      "25/11/13 14:33:18 INFO BlockManager: Found block rdd_14_30 locally(30 + 2) / 50]\n",
      "25/11/13 14:33:18 INFO BlockManager: Found block rdd_14_31 locally\n",
      "25/11/13 14:33:18 INFO Executor: Finished task 30.0 in stage 5.0 (TID 82). 4590 bytes result sent to driver\n",
      "25/11/13 14:33:18 INFO TaskSetManager: Starting task 32.0 in stage 5.0 (TID 84) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 32, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:18 INFO TaskSetManager: Finished task 30.0 in stage 5.0 (TID 82) in 101 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (31/50)\n",
      "25/11/13 14:33:18 INFO Executor: Running task 32.0 in stage 5.0 (TID 84)\n",
      "25/11/13 14:33:18 INFO Executor: Finished task 31.0 in stage 5.0 (TID 83). 4590 bytes result sent to driver\n",
      "25/11/13 14:33:18 INFO BlockManager: Found block rdd_14_32 locally\n",
      "25/11/13 14:33:18 INFO TaskSetManager: Starting task 33.0 in stage 5.0 (TID 85) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 33, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:18 INFO Executor: Running task 33.0 in stage 5.0 (TID 85)\n",
      "25/11/13 14:33:18 INFO TaskSetManager: Finished task 31.0 in stage 5.0 (TID 83) in 136 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (32/50)\n",
      "25/11/13 14:33:18 INFO BlockManager: Found block rdd_14_33 locally\n",
      "25/11/13 14:33:18 INFO Executor: Finished task 32.0 in stage 5.0 (TID 84). 4633 bytes result sent to driver\n",
      "25/11/13 14:33:18 INFO TaskSetManager: Starting task 34.0 in stage 5.0 (TID 86) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 34, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:18 INFO Executor: Running task 34.0 in stage 5.0 (TID 86)\n",
      "25/11/13 14:33:18 INFO TaskSetManager: Finished task 32.0 in stage 5.0 (TID 84) in 166 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (33/50)\n",
      "25/11/13 14:33:18 INFO Executor: Finished task 33.0 in stage 5.0 (TID 85). 4633 bytes result sent to driver\n",
      "25/11/13 14:33:18 INFO BlockManager: Found block rdd_14_34 locally\n",
      "25/11/13 14:33:18 INFO TaskSetManager: Starting task 35.0 in stage 5.0 (TID 87) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 35, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:18 INFO Executor: Running task 35.0 in stage 5.0 (TID 87)\n",
      "25/11/13 14:33:18 INFO TaskSetManager: Finished task 33.0 in stage 5.0 (TID 85) in 124 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (34/50)\n",
      "25/11/13 14:33:18 INFO BlockManager: Found block rdd_14_35 locally\n",
      "25/11/13 14:33:18 INFO Executor: Finished task 34.0 in stage 5.0 (TID 86). 4590 bytes result sent to driver\n",
      "25/11/13 14:33:18 INFO TaskSetManager: Starting task 36.0 in stage 5.0 (TID 88) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 36, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:18 INFO Executor: Running task 36.0 in stage 5.0 (TID 88)\n",
      "25/11/13 14:33:18 INFO TaskSetManager: Finished task 34.0 in stage 5.0 (TID 86) in 117 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (35/50)\n",
      "25/11/13 14:33:18 INFO Executor: Finished task 35.0 in stage 5.0 (TID 87). 4590 bytes result sent to driver\n",
      "25/11/13 14:33:18 INFO TaskSetManager: Starting task 37.0 in stage 5.0 (TID 89) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 37, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:18 INFO Executor: Running task 37.0 in stage 5.0 (TID 89)\n",
      "25/11/13 14:33:18 INFO TaskSetManager: Finished task 35.0 in stage 5.0 (TID 87) in 103 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (36/50)\n",
      "25/11/13 14:33:18 INFO BlockManager: Found block rdd_14_36 locally\n",
      "25/11/13 14:33:18 INFO BlockManager: Found block rdd_14_37 locally\n",
      "25/11/13 14:33:18 INFO Executor: Finished task 37.0 in stage 5.0 (TID 89). 4590 bytes result sent to driver\n",
      "25/11/13 14:33:18 INFO TaskSetManager: Starting task 38.0 in stage 5.0 (TID 90) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 38, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:18 INFO Executor: Running task 38.0 in stage 5.0 (TID 90)\n",
      "25/11/13 14:33:18 INFO TaskSetManager: Finished task 37.0 in stage 5.0 (TID 89) in 102 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (37/50)\n",
      "25/11/13 14:33:18 INFO Executor: Finished task 36.0 in stage 5.0 (TID 88). 4590 bytes result sent to driver\n",
      "25/11/13 14:33:18 INFO TaskSetManager: Starting task 39.0 in stage 5.0 (TID 91) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 39, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:18 INFO TaskSetManager: Finished task 36.0 in stage 5.0 (TID 88) in 113 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (38/50)\n",
      "25/11/13 14:33:18 INFO Executor: Running task 39.0 in stage 5.0 (TID 91)\n",
      "25/11/13 14:33:18 INFO BlockManager: Found block rdd_14_38 locally\n",
      "25/11/13 14:33:18 INFO BlockManager: Found block rdd_14_39 locally\n",
      "25/11/13 14:33:18 INFO Executor: Finished task 38.0 in stage 5.0 (TID 90). 4590 bytes result sent to driver\n",
      "25/11/13 14:33:18 INFO TaskSetManager: Starting task 40.0 in stage 5.0 (TID 92) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 40, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:18 INFO Executor: Finished task 39.0 in stage 5.0 (TID 91). 4590 bytes result sent to driver\n",
      "25/11/13 14:33:18 INFO TaskSetManager: Finished task 38.0 in stage 5.0 (TID 90) in 111 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (39/50)\n",
      "25/11/13 14:33:18 INFO Executor: Running task 40.0 in stage 5.0 (TID 92)\n",
      "25/11/13 14:33:18 INFO TaskSetManager: Starting task 41.0 in stage 5.0 (TID 93) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 41, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:18 INFO Executor: Running task 41.0 in stage 5.0 (TID 93)\n",
      "25/11/13 14:33:18 INFO TaskSetManager: Finished task 39.0 in stage 5.0 (TID 91) in 138 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (40/50)\n",
      "25/11/13 14:33:18 INFO BlockManager: Found block rdd_14_40 locally(40 + 2) / 50]\n",
      "25/11/13 14:33:18 INFO BlockManager: Found block rdd_14_41 locally\n",
      "25/11/13 14:33:18 INFO Executor: Finished task 40.0 in stage 5.0 (TID 92). 4590 bytes result sent to driver\n",
      "25/11/13 14:33:18 INFO TaskSetManager: Starting task 42.0 in stage 5.0 (TID 94) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 42, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:18 INFO Executor: Running task 42.0 in stage 5.0 (TID 94)\n",
      "25/11/13 14:33:18 INFO Executor: Finished task 41.0 in stage 5.0 (TID 93). 4590 bytes result sent to driver\n",
      "25/11/13 14:33:18 INFO TaskSetManager: Finished task 40.0 in stage 5.0 (TID 92) in 140 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (41/50)\n",
      "25/11/13 14:33:18 INFO TaskSetManager: Starting task 43.0 in stage 5.0 (TID 95) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 43, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:18 INFO Executor: Running task 43.0 in stage 5.0 (TID 95)\n",
      "25/11/13 14:33:18 INFO TaskSetManager: Finished task 41.0 in stage 5.0 (TID 93) in 143 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (42/50)\n",
      "25/11/13 14:33:18 INFO BlockManager: Found block rdd_14_42 locally\n",
      "25/11/13 14:33:18 INFO BlockManager: Found block rdd_14_43 locally\n",
      "25/11/13 14:33:19 INFO Executor: Finished task 42.0 in stage 5.0 (TID 94). 4633 bytes result sent to driver\n",
      "25/11/13 14:33:19 INFO TaskSetManager: Starting task 44.0 in stage 5.0 (TID 96) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 44, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:19 INFO TaskSetManager: Finished task 42.0 in stage 5.0 (TID 94) in 107 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (43/50)\n",
      "25/11/13 14:33:19 INFO Executor: Running task 44.0 in stage 5.0 (TID 96)\n",
      "25/11/13 14:33:19 INFO Executor: Finished task 43.0 in stage 5.0 (TID 95). 4590 bytes result sent to driver\n",
      "25/11/13 14:33:19 INFO TaskSetManager: Starting task 45.0 in stage 5.0 (TID 97) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 45, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:19 INFO Executor: Running task 45.0 in stage 5.0 (TID 97)3) / 50]\n",
      "25/11/13 14:33:19 INFO TaskSetManager: Finished task 43.0 in stage 5.0 (TID 95) in 131 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (44/50)\n",
      "25/11/13 14:33:19 INFO BlockManager: Found block rdd_14_44 locally\n",
      "25/11/13 14:33:19 INFO BlockManager: Found block rdd_14_45 locally\n",
      "25/11/13 14:33:19 INFO Executor: Finished task 45.0 in stage 5.0 (TID 97). 4633 bytes result sent to driver\n",
      "25/11/13 14:33:19 INFO TaskSetManager: Starting task 46.0 in stage 5.0 (TID 98) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 46, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:19 INFO Executor: Running task 46.0 in stage 5.0 (TID 98)\n",
      "25/11/13 14:33:19 INFO TaskSetManager: Finished task 45.0 in stage 5.0 (TID 97) in 115 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (45/50)\n",
      "25/11/13 14:33:19 INFO Executor: Finished task 44.0 in stage 5.0 (TID 96). 4633 bytes result sent to driver\n",
      "25/11/13 14:33:19 INFO TaskSetManager: Starting task 47.0 in stage 5.0 (TID 99) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 47, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:19 INFO Executor: Running task 47.0 in stage 5.0 (TID 99)\n",
      "25/11/13 14:33:19 INFO TaskSetManager: Finished task 44.0 in stage 5.0 (TID 96) in 150 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (46/50)\n",
      "25/11/13 14:33:19 INFO BlockManager: Found block rdd_14_46 locally\n",
      "25/11/13 14:33:19 INFO BlockManager: Found block rdd_14_47 locally\n",
      "25/11/13 14:33:19 INFO Executor: Finished task 46.0 in stage 5.0 (TID 98). 4590 bytes result sent to driver\n",
      "25/11/13 14:33:19 INFO TaskSetManager: Starting task 48.0 in stage 5.0 (TID 100) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 48, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:19 INFO TaskSetManager: Finished task 46.0 in stage 5.0 (TID 98) in 109 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (47/50)\n",
      "25/11/13 14:33:19 INFO Executor: Running task 48.0 in stage 5.0 (TID 100)\n",
      "25/11/13 14:33:19 INFO Executor: Finished task 47.0 in stage 5.0 (TID 99). 4590 bytes result sent to driver\n",
      "25/11/13 14:33:19 INFO TaskSetManager: Starting task 49.0 in stage 5.0 (TID 101) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 49, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 14:33:19 INFO Executor: Running task 49.0 in stage 5.0 (TID 101)\n",
      "25/11/13 14:33:19 INFO TaskSetManager: Finished task 47.0 in stage 5.0 (TID 99) in 147 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (48/50)\n",
      "25/11/13 14:33:19 INFO BlockManager: Found block rdd_14_48 locally\n",
      "25/11/13 14:33:19 INFO BlockManager: Found block rdd_14_49 locally\n",
      "25/11/13 14:33:19 INFO Executor: Finished task 48.0 in stage 5.0 (TID 100). 4590 bytes result sent to driver\n",
      "25/11/13 14:33:19 INFO TaskSetManager: Finished task 48.0 in stage 5.0 (TID 100) in 106 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (49/50)\n",
      "25/11/13 14:33:19 INFO Executor: Finished task 49.0 in stage 5.0 (TID 101). 4590 bytes result sent to driver\n",
      "25/11/13 14:33:19 INFO TaskSetManager: Finished task 49.0 in stage 5.0 (TID 101) in 150 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (50/50)\n",
      "25/11/13 14:33:19 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool \n",
      "25/11/13 14:33:19 INFO DAGScheduler: ShuffleMapStage 5 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 3.966 s\n",
      "25/11/13 14:33:19 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/11/13 14:33:19 INFO DAGScheduler: running: Set()\n",
      "25/11/13 14:33:19 INFO DAGScheduler: waiting: Set()\n",
      "25/11/13 14:33:19 INFO DAGScheduler: failed: Set()\n",
      "25/11/13 14:33:19 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128\n",
      "25/11/13 14:33:19 INFO DAGScheduler: Got job 4 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions\n",
      "25/11/13 14:33:19 INFO DAGScheduler: Final stage: ResultStage 8 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)\n",
      "25/11/13 14:33:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)\n",
      "25/11/13 14:33:19 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 14:33:19 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[26] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents\n",
      "25/11/13 14:33:19 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 534.3 KiB, free 1046.2 MiB)\n",
      "25/11/13 14:33:19 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 124.8 KiB, free 1046.1 MiB)\n",
      "25/11/13 14:33:19 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 124.8 KiB, free: 1048.3 MiB)\n",
      "25/11/13 14:33:19 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 14:33:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[26] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))\n",
      "25/11/13 14:33:19 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0\n",
      "25/11/13 14:33:19 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 102) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, NODE_LOCAL, 8999 bytes) \n",
      "25/11/13 14:33:19 INFO Executor: Running task 0.0 in stage 8.0 (TID 102)\n",
      "25/11/13 14:33:19 INFO ShuffleBlockFetcherIterator: Getting 50 (4.9 KiB) non-empty blocks including 50 (4.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 14:33:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/11/13 14:33:19 INFO CodeGenerator: Code generated in 14.128562 ms\n",
      "25/11/13 14:33:19 INFO CodeGenerator: Code generated in 34.22058 ms\n",
      "25/11/13 14:33:19 INFO Executor: Finished task 0.0 in stage 8.0 (TID 102). 7115 bytes result sent to driver\n",
      "25/11/13 14:33:19 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 102) in 136 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/1)\n",
      "25/11/13 14:33:19 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool \n",
      "25/11/13 14:33:19 INFO DAGScheduler: ResultStage 8 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.164 s\n",
      "25/11/13 14:33:19 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/11/13 14:33:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished\n",
      "25/11/13 14:33:19 INFO DAGScheduler: Job 4 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.173644 s\n",
      "25/11/13 14:33:19 INFO CodeGenerator: Code generated in 48.552572 ms            \n",
      "25/11/13 14:33:19 INFO Snapshot: [tableId=38adf0a9-1004-4125-bd0a-04861e01e169] DELTA: Done\n",
      "25/11/13 14:33:19 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/11/13 14:33:19 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/11/13 14:33:19 INFO CodeGenerator: Code generated in 26.625161 ms\n",
      "25/11/13 14:33:19 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 206.2 KiB, free 1045.9 MiB)\n",
      "25/11/13 14:33:19 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 36.6 KiB, free 1045.9 MiB)\n",
      "25/11/13 14:33:19 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 36.6 KiB, free: 1048.3 MiB)\n",
      "25/11/13 14:33:19 INFO SparkContext: Created broadcast 8 from showString at NativeMethodAccessorImpl.java:0\n",
      "25/11/13 14:33:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 15790468 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/11/13 14:33:20 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "25/11/13 14:33:20 INFO DAGScheduler: Got job 5 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/11/13 14:33:20 INFO DAGScheduler: Final stage: ResultStage 9 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/11/13 14:33:20 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/11/13 14:33:20 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 14:33:20 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[30] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/11/13 14:33:20 INFO BlockManagerInfo: Removed broadcast_7_piece0 on jupyter-spark-758b7c86d8-7j77n:43517 in memory (size: 124.8 KiB, free: 1048.4 MiB)\n",
      "25/11/13 14:33:20 INFO BlockManagerInfo: Removed broadcast_6_piece0 on jupyter-spark-758b7c86d8-7j77n:43517 in memory (size: 138.2 KiB, free: 1048.5 MiB)\n",
      "25/11/13 14:33:20 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 27.4 KiB, free 1047.2 MiB)\n",
      "25/11/13 14:33:20 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 9.8 KiB, free 1047.2 MiB)\n",
      "25/11/13 14:33:20 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 9.8 KiB, free: 1048.5 MiB)\n",
      "25/11/13 14:33:20 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 14:33:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[30] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/11/13 14:33:20 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0\n",
      "25/11/13 14:33:20 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 103) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 9672 bytes) \n",
      "25/11/13 14:33:20 INFO Executor: Running task 0.0 in stage 9.0 (TID 103)\n",
      "25/11/13 14:33:20 INFO CodeGenerator: Code generated in 12.083525 ms\n",
      "25/11/13 14:33:20 INFO FileScanRDD: Reading File path: s3a://nau-local-analytics-bronze/auth_user/part-00000-328279f1-d4eb-469c-bf96-b8fd585b9f62-c000.snappy.parquet, range: 0-15790468, partition values: [empty row]\n",
      "25/11/13 14:33:20 INFO S3AInputStream: Switching to Random IO seek policy\n",
      "25/11/13 14:33:22 INFO CodecPool: Got brand-new decompressor [.snappy] + 1) / 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------+-----------------+----------+---------+-----------------------------+--------+---------+--------------------------+--------------------------+-----------+\n",
      "|id |last_login|is_superuser|username         |first_name|last_name|email                        |is_staff|is_active|date_joined               |ingestion_date            |source_name|\n",
      "+---+----------+------------+-----------------+----------+---------+-----------------------------+--------+---------+--------------------------+--------------------------+-----------+\n",
      "|1  |NULL      |false       |enterprise_worker|          |         |enterprise_worker@example.com|true    |true     |2018-08-29 18:34:26.488188|2025-11-04 18:26:56.116039|auth_user  |\n",
      "|2  |NULL      |false       |veda_service_user|          |         |veda_service_user@example.com|true    |true     |2018-08-29 18:34:34.18119 |2025-11-04 18:26:56.116039|auth_user  |\n",
      "|3  |NULL      |true        |ecommerce_worker |          |         |ecommerce_worker@example.com |true    |true     |2018-08-29 18:34:42       |2025-11-04 18:26:56.116039|auth_user  |\n",
      "|4  |NULL      |false       |discovery_worker |          |         |discovery_worker@example.com |true    |true     |2018-08-29 18:34:50.609274|2025-11-04 18:26:56.116039|auth_user  |\n",
      "|6  |NULL      |false       |insights_worker  |          |         |insights_worker@example.com  |true    |true     |2018-08-29 18:34:58.792988|2025-11-04 18:26:56.116039|auth_user  |\n",
      "+---+----------+------------+-----------------+----------+---------+-----------------------------+--------+---------+--------------------------+--------------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/13 14:33:22 INFO Executor: Finished task 0.0 in stage 9.0 (TID 103). 2406 bytes result sent to driver\n",
      "25/11/13 14:33:22 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 103) in 2552 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/1)\n",
      "25/11/13 14:33:22 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool \n",
      "25/11/13 14:33:22 INFO DAGScheduler: ResultStage 9 (showString at NativeMethodAccessorImpl.java:0) finished in 2.622 s\n",
      "25/11/13 14:33:22 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/11/13 14:33:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished\n",
      "25/11/13 14:33:22 INFO DAGScheduler: Job 5 finished: showString at NativeMethodAccessorImpl.java:0, took 2.642456 s\n",
      "25/11/13 14:33:22 INFO CodeGenerator: Code generated in 9.135833 ms             \n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "bronze_path = \"s3a://nau-local-analytics-bronze/auth_user\"\n",
    "\n",
    "df_auth_user_bronze = (\n",
    "    spark.read\n",
    "    .format(\"delta\")\n",
    "    .load(bronze_path)\n",
    ")\n",
    "\n",
    "df_auth_user_bronze.printSchema()\n",
    "df_auth_user_bronze.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aafbbcb3-b18a-42bd-bba5-80c6f57df264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Transformar -> df_users_source (para dim_user)\n",
    "# ============================================\n",
    "df_users_source = (\n",
    "    df_auth_user_bronze\n",
    "    .select(\n",
    "        F.col(\"id\").cast(\"int\").alias(\"user_id\"),\n",
    "        F.col(\"username\"),\n",
    "        F.col(\"email\"),\n",
    "        F.col(\"first_name\"),\n",
    "        F.col(\"last_name\"),\n",
    "        F.concat_ws(\" \", F.trim(\"first_name\"), F.trim(\"last_name\")).alias(\"full_name\"),\n",
    "        F.col(\"is_staff\"),\n",
    "        F.col(\"is_superuser\"),\n",
    "        F.col(\"is_active\"),\n",
    "        F.col(\"date_joined\"),\n",
    "        F.col(\"last_login\"),\n",
    "        F.col(\"ingestion_date\"),\n",
    "        F.col(\"source_name\")\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"user_hash\",\n",
    "        F.sha2(\n",
    "            F.concat_ws(\n",
    "                \"||\",\n",
    "                F.col(\"user_id\").cast(\"string\"),\n",
    "                F.lower(F.col(\"username\")),\n",
    "                F.lower(F.col(\"email\"))\n",
    "            ),\n",
    "            256\n",
    "        )\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04105b8a-b9aa-4998-b84b-263576e3a47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- username: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- full_name: string (nullable = false)\n",
      " |-- is_staff: boolean (nullable = true)\n",
      " |-- is_superuser: boolean (nullable = true)\n",
      " |-- is_active: boolean (nullable = true)\n",
      " |-- date_joined: timestamp (nullable = true)\n",
      " |-- last_login: timestamp (nullable = true)\n",
      " |-- ingestion_date: timestamp (nullable = true)\n",
      " |-- source_name: string (nullable = true)\n",
      " |-- user_hash: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/13 14:59:49 INFO PrepareDeltaScan: DELTA: Filtering files for query\n",
      "25/11/13 14:59:49 INFO BlockManagerInfo: Removed broadcast_12_piece0 on jupyter-spark-758b7c86d8-7j77n:43517 in memory (size: 10.8 KiB, free: 1048.5 MiB)\n",
      "25/11/13 14:59:49 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128\n",
      "25/11/13 14:59:49 INFO DAGScheduler: Got job 8 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions\n",
      "25/11/13 14:59:49 INFO DAGScheduler: Final stage: ResultStage 14 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)\n",
      "25/11/13 14:59:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)\n",
      "25/11/13 14:59:49 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 14:59:49 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[38] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents\n",
      "25/11/13 14:59:49 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 715.2 KiB, free 1046.3 MiB)\n",
      "25/11/13 14:59:49 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 163.1 KiB, free 1046.1 MiB)\n",
      "25/11/13 14:59:49 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 163.1 KiB, free: 1048.3 MiB)\n",
      "25/11/13 14:59:49 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 14:59:49 INFO DAGScheduler: Submitting 50 missing tasks from ResultStage 14 (MapPartitionsRDD[38] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n",
      "25/11/13 14:59:49 INFO TaskSchedulerImpl: Adding task set 14.0 with 50 tasks resource profile 0\n",
      "25/11/13 14:59:49 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 155) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:49 INFO TaskSetManager: Starting task 1.0 in stage 14.0 (TID 156) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 1, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:49 INFO Executor: Running task 1.0 in stage 14.0 (TID 156)\n",
      "25/11/13 14:59:49 INFO Executor: Running task 0.0 in stage 14.0 (TID 155)\n",
      "25/11/13 14:59:49 INFO BlockManager: Found block rdd_18_1 locally\n",
      "25/11/13 14:59:49 INFO BlockManager: Found block rdd_18_0 locally\n",
      "25/11/13 14:59:49 INFO Executor: Finished task 1.0 in stage 14.0 (TID 156). 4336 bytes result sent to driver\n",
      "25/11/13 14:59:49 INFO TaskSetManager: Starting task 2.0 in stage 14.0 (TID 157) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 2, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:49 INFO Executor: Running task 2.0 in stage 14.0 (TID 157)\n",
      "25/11/13 14:59:49 INFO TaskSetManager: Finished task 1.0 in stage 14.0 (TID 156) in 75 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/50)\n",
      "25/11/13 14:59:49 INFO Executor: Finished task 0.0 in stage 14.0 (TID 155). 4336 bytes result sent to driver\n",
      "25/11/13 14:59:49 INFO TaskSetManager: Starting task 3.0 in stage 14.0 (TID 158) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 3, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:49 INFO Executor: Running task 3.0 in stage 14.0 (TID 158)\n",
      "25/11/13 14:59:49 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 155) in 82 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (2/50)\n",
      "25/11/13 14:59:49 INFO BlockManager: Found block rdd_18_2 locally\n",
      "25/11/13 14:59:49 INFO BlockManager: Found block rdd_18_3 locally\n",
      "25/11/13 14:59:49 INFO Executor: Finished task 2.0 in stage 14.0 (TID 157). 4336 bytes result sent to driver\n",
      "25/11/13 14:59:49 INFO TaskSetManager: Starting task 4.0 in stage 14.0 (TID 159) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 4, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:49 INFO Executor: Running task 4.0 in stage 14.0 (TID 159)\n",
      "25/11/13 14:59:49 INFO TaskSetManager: Finished task 2.0 in stage 14.0 (TID 157) in 34 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (3/50)\n",
      "25/11/13 14:59:49 INFO Executor: Finished task 3.0 in stage 14.0 (TID 158). 4336 bytes result sent to driver\n",
      "25/11/13 14:59:49 INFO TaskSetManager: Starting task 5.0 in stage 14.0 (TID 160) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 5, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:49 INFO TaskSetManager: Finished task 3.0 in stage 14.0 (TID 158) in 61 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (4/50)\n",
      "25/11/13 14:59:49 INFO Executor: Running task 5.0 in stage 14.0 (TID 160)\n",
      "25/11/13 14:59:49 INFO BlockManager: Found block rdd_18_5 locally\n",
      "25/11/13 14:59:49 INFO BlockManager: Found block rdd_18_4 locally\n",
      "25/11/13 14:59:49 INFO Executor: Finished task 5.0 in stage 14.0 (TID 160). 4336 bytes result sent to driver\n",
      "25/11/13 14:59:49 INFO Executor: Finished task 4.0 in stage 14.0 (TID 159). 4336 bytes result sent to driver\n",
      "25/11/13 14:59:49 INFO TaskSetManager: Starting task 6.0 in stage 14.0 (TID 161) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 6, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:49 INFO Executor: Running task 6.0 in stage 14.0 (TID 161)\n",
      "25/11/13 14:59:49 INFO TaskSetManager: Starting task 7.0 in stage 14.0 (TID 162) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 7, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:49 INFO TaskSetManager: Finished task 5.0 in stage 14.0 (TID 160) in 51 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (5/50)\n",
      "25/11/13 14:59:49 INFO Executor: Running task 7.0 in stage 14.0 (TID 162)\n",
      "25/11/13 14:59:49 INFO TaskSetManager: Finished task 4.0 in stage 14.0 (TID 159) in 90 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (6/50)\n",
      "25/11/13 14:59:50 INFO BlockManager: Found block rdd_18_6 locally\n",
      "25/11/13 14:59:50 INFO Executor: Finished task 6.0 in stage 14.0 (TID 161). 4336 bytes result sent to driver\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Starting task 8.0 in stage 14.0 (TID 163) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 8, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:50 INFO BlockManager: Found block rdd_18_7 locally\n",
      "25/11/13 14:59:50 INFO Executor: Running task 8.0 in stage 14.0 (TID 163)\n",
      "25/11/13 14:59:50 INFO Executor: Finished task 7.0 in stage 14.0 (TID 162). 4530 bytes result sent to driver\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Starting task 9.0 in stage 14.0 (TID 164) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 9, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:50 INFO TaskSetManager: Finished task 6.0 in stage 14.0 (TID 161) in 86 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (7/50)\n",
      "25/11/13 14:59:50 INFO Executor: Running task 9.0 in stage 14.0 (TID 164)\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Finished task 7.0 in stage 14.0 (TID 162) in 85 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (8/50)\n",
      "25/11/13 14:59:50 INFO BlockManager: Found block rdd_18_9 locally\n",
      "25/11/13 14:59:50 INFO BlockManager: Found block rdd_18_8 locally\n",
      "25/11/13 14:59:50 INFO Executor: Finished task 9.0 in stage 14.0 (TID 164). 4293 bytes result sent to driver\n",
      "25/11/13 14:59:50 INFO Executor: Finished task 8.0 in stage 14.0 (TID 163). 4293 bytes result sent to driver\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Starting task 10.0 in stage 14.0 (TID 165) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 10, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:50 INFO Executor: Running task 10.0 in stage 14.0 (TID 165)\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Starting task 11.0 in stage 14.0 (TID 166) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 11, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:50 INFO Executor: Running task 11.0 in stage 14.0 (TID 166)\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Finished task 9.0 in stage 14.0 (TID 164) in 28 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (9/50)\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Finished task 8.0 in stage 14.0 (TID 163) in 34 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (10/50)\n",
      "25/11/13 14:59:50 INFO BlockManager: Found block rdd_18_11 locally\n",
      "25/11/13 14:59:50 INFO Executor: Finished task 11.0 in stage 14.0 (TID 166). 4336 bytes result sent to driver\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Starting task 12.0 in stage 14.0 (TID 167) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 12, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:50 INFO Executor: Running task 12.0 in stage 14.0 (TID 167)\n",
      "25/11/13 14:59:50 INFO BlockManager: Found block rdd_18_10 locally\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Finished task 11.0 in stage 14.0 (TID 166) in 74 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (11/50)\n",
      "25/11/13 14:59:50 INFO Executor: Finished task 10.0 in stage 14.0 (TID 165). 4336 bytes result sent to driver\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Starting task 13.0 in stage 14.0 (TID 168) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 13, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:50 INFO Executor: Running task 13.0 in stage 14.0 (TID 168)\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Finished task 10.0 in stage 14.0 (TID 165) in 77 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (12/50)\n",
      "25/11/13 14:59:50 INFO BlockManager: Found block rdd_18_12 locally\n",
      "25/11/13 14:59:50 INFO BlockManager: Found block rdd_18_13 locally\n",
      "25/11/13 14:59:50 INFO Executor: Finished task 13.0 in stage 14.0 (TID 168). 4293 bytes result sent to driver\n",
      "25/11/13 14:59:50 INFO Executor: Finished task 12.0 in stage 14.0 (TID 167). 4293 bytes result sent to driver\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Starting task 14.0 in stage 14.0 (TID 169) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 14, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:50 INFO Executor: Running task 14.0 in stage 14.0 (TID 169)\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Starting task 15.0 in stage 14.0 (TID 170) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 15, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:50 INFO TaskSetManager: Finished task 13.0 in stage 14.0 (TID 168) in 24 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (13/50)\n",
      "25/11/13 14:59:50 INFO Executor: Running task 15.0 in stage 14.0 (TID 170)\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Finished task 12.0 in stage 14.0 (TID 167) in 36 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (14/50)\n",
      "25/11/13 14:59:50 INFO BlockManager: Found block rdd_18_14 locally\n",
      "25/11/13 14:59:50 INFO BlockManager: Found block rdd_18_15 locally\n",
      "25/11/13 14:59:50 INFO Executor: Finished task 14.0 in stage 14.0 (TID 169). 4336 bytes result sent to driver\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Starting task 16.0 in stage 14.0 (TID 171) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 16, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:50 INFO Executor: Running task 16.0 in stage 14.0 (TID 171)\n",
      "25/11/13 14:59:50 INFO Executor: Finished task 15.0 in stage 14.0 (TID 170). 4336 bytes result sent to driver\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Finished task 14.0 in stage 14.0 (TID 169) in 54 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (15/50)\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Starting task 17.0 in stage 14.0 (TID 172) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 17, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:50 INFO TaskSetManager: Finished task 15.0 in stage 14.0 (TID 170) in 54 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (16/50)\n",
      "25/11/13 14:59:50 INFO Executor: Running task 17.0 in stage 14.0 (TID 172)\n",
      "25/11/13 14:59:50 INFO BlockManager: Found block rdd_18_16 locally\n",
      "25/11/13 14:59:50 INFO BlockManager: Found block rdd_18_17 locally\n",
      "25/11/13 14:59:50 INFO Executor: Finished task 16.0 in stage 14.0 (TID 171). 4336 bytes result sent to driver\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Starting task 18.0 in stage 14.0 (TID 173) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 18, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:50 INFO Executor: Running task 18.0 in stage 14.0 (TID 173)\n",
      "25/11/13 14:59:50 INFO Executor: Finished task 17.0 in stage 14.0 (TID 172). 4336 bytes result sent to driver\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Finished task 16.0 in stage 14.0 (TID 171) in 38 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (17/50)\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Starting task 19.0 in stage 14.0 (TID 174) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 19, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:50 INFO Executor: Running task 19.0 in stage 14.0 (TID 174)\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Finished task 17.0 in stage 14.0 (TID 172) in 58 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (18/50)\n",
      "25/11/13 14:59:50 INFO BlockManager: Found block rdd_18_18 locally\n",
      "25/11/13 14:59:50 INFO BlockManager: Found block rdd_18_19 locally\n",
      "25/11/13 14:59:50 INFO Executor: Finished task 19.0 in stage 14.0 (TID 174). 4293 bytes result sent to driver\n",
      "25/11/13 14:59:50 INFO Executor: Finished task 18.0 in stage 14.0 (TID 173). 4336 bytes result sent to driver\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Starting task 20.0 in stage 14.0 (TID 175) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 20, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:50 INFO Executor: Running task 20.0 in stage 14.0 (TID 175)\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Starting task 21.0 in stage 14.0 (TID 176) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 21, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:50 INFO Executor: Running task 21.0 in stage 14.0 (TID 176)\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Finished task 19.0 in stage 14.0 (TID 174) in 51 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (19/50)\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Finished task 18.0 in stage 14.0 (TID 173) in 76 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (20/50)\n",
      "25/11/13 14:59:50 INFO BlockManager: Found block rdd_18_20 locally\n",
      "25/11/13 14:59:50 INFO Executor: Finished task 20.0 in stage 14.0 (TID 175). 4293 bytes result sent to driver\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Starting task 22.0 in stage 14.0 (TID 177) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 22, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:50 INFO BlockManager: Found block rdd_18_21 locally\n",
      "25/11/13 14:59:50 INFO Executor: Running task 22.0 in stage 14.0 (TID 177)\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Finished task 20.0 in stage 14.0 (TID 175) in 36 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (21/50)\n",
      "25/11/13 14:59:50 INFO Executor: Finished task 21.0 in stage 14.0 (TID 176). 4293 bytes result sent to driver\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Starting task 23.0 in stage 14.0 (TID 178) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 23, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:50 INFO Executor: Running task 23.0 in stage 14.0 (TID 178)\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Finished task 21.0 in stage 14.0 (TID 176) in 38 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (22/50)\n",
      "25/11/13 14:59:50 INFO BlockManager: Found block rdd_18_22 locally\n",
      "25/11/13 14:59:50 INFO Executor: Finished task 22.0 in stage 14.0 (TID 177). 4336 bytes result sent to driver\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Starting task 24.0 in stage 14.0 (TID 179) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 24, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:50 INFO TaskSetManager: Finished task 22.0 in stage 14.0 (TID 177) in 54 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (23/50)\n",
      "25/11/13 14:59:50 INFO Executor: Running task 24.0 in stage 14.0 (TID 179)\n",
      "25/11/13 14:59:50 INFO BlockManager: Found block rdd_18_23 locally\n",
      "25/11/13 14:59:50 INFO Executor: Finished task 23.0 in stage 14.0 (TID 178). 4293 bytes result sent to driver\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Starting task 25.0 in stage 14.0 (TID 180) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 25, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:50 INFO Executor: Running task 25.0 in stage 14.0 (TID 180)\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Finished task 23.0 in stage 14.0 (TID 178) in 57 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (24/50)\n",
      "25/11/13 14:59:50 INFO BlockManager: Found block rdd_18_25 locally\n",
      "25/11/13 14:59:50 INFO Executor: Finished task 25.0 in stage 14.0 (TID 180). 4293 bytes result sent to driver\n",
      "25/11/13 14:59:50 INFO BlockManager: Found block rdd_18_24 locally\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Starting task 26.0 in stage 14.0 (TID 181) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 26, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:50 INFO TaskSetManager: Finished task 25.0 in stage 14.0 (TID 180) in 32 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (25/50)\n",
      "25/11/13 14:59:50 INFO Executor: Running task 26.0 in stage 14.0 (TID 181)\n",
      "25/11/13 14:59:50 INFO Executor: Finished task 24.0 in stage 14.0 (TID 179). 4293 bytes result sent to driver\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Starting task 27.0 in stage 14.0 (TID 182) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 27, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:50 INFO Executor: Running task 27.0 in stage 14.0 (TID 182)\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Finished task 24.0 in stage 14.0 (TID 179) in 39 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (26/50)\n",
      "25/11/13 14:59:50 INFO BlockManager: Found block rdd_18_26 locally\n",
      "25/11/13 14:59:50 INFO Executor: Finished task 26.0 in stage 14.0 (TID 181). 4336 bytes result sent to driver\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Starting task 28.0 in stage 14.0 (TID 183) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 28, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:50 INFO Executor: Running task 28.0 in stage 14.0 (TID 183)\n",
      "25/11/13 14:59:50 INFO BlockManager: Found block rdd_18_27 locally\n",
      "25/11/13 14:59:50 INFO Executor: Finished task 27.0 in stage 14.0 (TID 182). 4293 bytes result sent to driver\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Starting task 29.0 in stage 14.0 (TID 184) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 29, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:50 INFO Executor: Running task 29.0 in stage 14.0 (TID 184)\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Finished task 27.0 in stage 14.0 (TID 182) in 59 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (27/50)\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Finished task 26.0 in stage 14.0 (TID 181) in 62 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (28/50)\n",
      "25/11/13 14:59:50 INFO BlockManager: Found block rdd_18_28 locally(28 + 2) / 50]\n",
      "25/11/13 14:59:50 INFO BlockManager: Found block rdd_18_29 locally\n",
      "25/11/13 14:59:50 INFO Executor: Finished task 28.0 in stage 14.0 (TID 183). 4336 bytes result sent to driver\n",
      "25/11/13 14:59:50 INFO Executor: Finished task 29.0 in stage 14.0 (TID 184). 4336 bytes result sent to driver\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Starting task 30.0 in stage 14.0 (TID 185) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 30, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:50 INFO Executor: Running task 30.0 in stage 14.0 (TID 185)\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Starting task 31.0 in stage 14.0 (TID 186) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 31, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:50 INFO Executor: Running task 31.0 in stage 14.0 (TID 186)\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Finished task 28.0 in stage 14.0 (TID 183) in 98 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (29/50)\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Finished task 29.0 in stage 14.0 (TID 184) in 96 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (30/50)\n",
      "25/11/13 14:59:50 INFO BlockManager: Found block rdd_18_30 locally\n",
      "25/11/13 14:59:50 INFO Executor: Finished task 30.0 in stage 14.0 (TID 185). 4293 bytes result sent to driver\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Starting task 32.0 in stage 14.0 (TID 187) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 32, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:50 INFO Executor: Running task 32.0 in stage 14.0 (TID 187)\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Finished task 30.0 in stage 14.0 (TID 185) in 49 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (31/50)\n",
      "25/11/13 14:59:50 INFO BlockManager: Found block rdd_18_31 locally\n",
      "25/11/13 14:59:50 INFO Executor: Finished task 31.0 in stage 14.0 (TID 186). 4293 bytes result sent to driver\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Starting task 33.0 in stage 14.0 (TID 188) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 33, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:50 INFO Executor: Running task 33.0 in stage 14.0 (TID 188)\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Finished task 31.0 in stage 14.0 (TID 186) in 56 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (32/50)\n",
      "25/11/13 14:59:50 INFO BlockManager: Found block rdd_18_32 locally\n",
      "25/11/13 14:59:50 INFO Executor: Finished task 32.0 in stage 14.0 (TID 187). 4293 bytes result sent to driver\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Starting task 34.0 in stage 14.0 (TID 189) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 34, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:50 INFO TaskSetManager: Finished task 32.0 in stage 14.0 (TID 187) in 36 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (33/50)\n",
      "25/11/13 14:59:50 INFO Executor: Running task 34.0 in stage 14.0 (TID 189)\n",
      "25/11/13 14:59:50 INFO BlockManager: Found block rdd_18_33 locally\n",
      "25/11/13 14:59:50 INFO Executor: Finished task 33.0 in stage 14.0 (TID 188). 4293 bytes result sent to driver\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Starting task 35.0 in stage 14.0 (TID 190) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 35, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:50 INFO Executor: Running task 35.0 in stage 14.0 (TID 190)\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Finished task 33.0 in stage 14.0 (TID 188) in 36 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (34/50)\n",
      "25/11/13 14:59:50 INFO BlockManager: Found block rdd_18_34 locally\n",
      "25/11/13 14:59:50 INFO Executor: Finished task 34.0 in stage 14.0 (TID 189). 4293 bytes result sent to driver\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Starting task 36.0 in stage 14.0 (TID 191) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 36, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:50 INFO TaskSetManager: Finished task 34.0 in stage 14.0 (TID 189) in 64 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (35/50)\n",
      "25/11/13 14:59:50 INFO Executor: Running task 36.0 in stage 14.0 (TID 191)\n",
      "25/11/13 14:59:50 INFO BlockManager: Found block rdd_18_35 locally\n",
      "25/11/13 14:59:50 INFO Executor: Finished task 35.0 in stage 14.0 (TID 190). 4293 bytes result sent to driver\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Starting task 37.0 in stage 14.0 (TID 192) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 37, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:50 INFO Executor: Running task 37.0 in stage 14.0 (TID 192)\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Finished task 35.0 in stage 14.0 (TID 190) in 69 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (36/50)\n",
      "25/11/13 14:59:50 INFO BlockManager: Found block rdd_18_36 locally\n",
      "25/11/13 14:59:50 INFO BlockManager: Found block rdd_18_37 locally(36 + 2) / 50]\n",
      "25/11/13 14:59:50 INFO Executor: Finished task 36.0 in stage 14.0 (TID 191). 4293 bytes result sent to driver\n",
      "25/11/13 14:59:50 INFO Executor: Finished task 37.0 in stage 14.0 (TID 192). 4293 bytes result sent to driver\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Starting task 38.0 in stage 14.0 (TID 193) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 38, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:50 INFO Executor: Running task 38.0 in stage 14.0 (TID 193)\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Starting task 39.0 in stage 14.0 (TID 194) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 39, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:50 INFO Executor: Running task 39.0 in stage 14.0 (TID 194)\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Finished task 36.0 in stage 14.0 (TID 191) in 51 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (37/50)\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Finished task 37.0 in stage 14.0 (TID 192) in 39 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (38/50)\n",
      "25/11/13 14:59:50 INFO BlockManager: Found block rdd_18_39 locally\n",
      "25/11/13 14:59:50 INFO Executor: Finished task 39.0 in stage 14.0 (TID 194). 4293 bytes result sent to driver\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Starting task 40.0 in stage 14.0 (TID 195) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 40, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:50 INFO Executor: Running task 40.0 in stage 14.0 (TID 195)\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Finished task 39.0 in stage 14.0 (TID 194) in 60 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (39/50)\n",
      "25/11/13 14:59:50 INFO BlockManager: Found block rdd_18_38 locally\n",
      "25/11/13 14:59:50 INFO Executor: Finished task 38.0 in stage 14.0 (TID 193). 4293 bytes result sent to driver\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Starting task 41.0 in stage 14.0 (TID 196) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 41, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:50 INFO Executor: Running task 41.0 in stage 14.0 (TID 196)\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Finished task 38.0 in stage 14.0 (TID 193) in 67 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (40/50)\n",
      "25/11/13 14:59:50 INFO BlockManager: Found block rdd_18_40 locally\n",
      "25/11/13 14:59:50 INFO Executor: Finished task 40.0 in stage 14.0 (TID 195). 4336 bytes result sent to driver\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Starting task 42.0 in stage 14.0 (TID 197) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 42, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:50 INFO Executor: Running task 42.0 in stage 14.0 (TID 197)\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Finished task 40.0 in stage 14.0 (TID 195) in 57 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (41/50)\n",
      "25/11/13 14:59:50 INFO BlockManager: Found block rdd_18_41 locally\n",
      "25/11/13 14:59:50 INFO Executor: Finished task 41.0 in stage 14.0 (TID 196). 4336 bytes result sent to driver\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Starting task 43.0 in stage 14.0 (TID 198) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 43, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:50 INFO Executor: Running task 43.0 in stage 14.0 (TID 198)\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Finished task 41.0 in stage 14.0 (TID 196) in 82 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (42/50)\n",
      "25/11/13 14:59:50 INFO BlockManager: Found block rdd_18_42 locally\n",
      "25/11/13 14:59:50 INFO Executor: Finished task 42.0 in stage 14.0 (TID 197). 4293 bytes result sent to driver\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Starting task 44.0 in stage 14.0 (TID 199) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 44, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:50 INFO TaskSetManager: Finished task 42.0 in stage 14.0 (TID 197) in 50 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (43/50)\n",
      "25/11/13 14:59:50 INFO Executor: Running task 44.0 in stage 14.0 (TID 199)\n",
      "25/11/13 14:59:50 INFO BlockManager: Found block rdd_18_43 locally\n",
      "25/11/13 14:59:50 INFO Executor: Finished task 43.0 in stage 14.0 (TID 198). 4293 bytes result sent to driver\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Starting task 45.0 in stage 14.0 (TID 200) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 45, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:50 INFO Executor: Running task 45.0 in stage 14.0 (TID 200)\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Finished task 43.0 in stage 14.0 (TID 198) in 65 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (44/50)\n",
      "25/11/13 14:59:50 INFO BlockManager: Found block rdd_18_44 locally\n",
      "25/11/13 14:59:50 INFO Executor: Finished task 44.0 in stage 14.0 (TID 199). 4293 bytes result sent to driver\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Starting task 46.0 in stage 14.0 (TID 201) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 46, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:50 INFO TaskSetManager: Finished task 44.0 in stage 14.0 (TID 199) in 36 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (45/50)\n",
      "25/11/13 14:59:50 INFO Executor: Running task 46.0 in stage 14.0 (TID 201)\n",
      "25/11/13 14:59:50 INFO BlockManager: Found block rdd_18_45 locally\n",
      "25/11/13 14:59:50 INFO Executor: Finished task 45.0 in stage 14.0 (TID 200). 4293 bytes result sent to driver\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Starting task 47.0 in stage 14.0 (TID 202) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 47, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:50 INFO Executor: Running task 47.0 in stage 14.0 (TID 202)\n",
      "25/11/13 14:59:50 INFO TaskSetManager: Finished task 45.0 in stage 14.0 (TID 200) in 22 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (46/50)\n",
      "25/11/13 14:59:51 INFO BlockManager: Found block rdd_18_46 locally\n",
      "25/11/13 14:59:51 INFO Executor: Finished task 46.0 in stage 14.0 (TID 201). 4293 bytes result sent to driver\n",
      "25/11/13 14:59:51 INFO TaskSetManager: Starting task 48.0 in stage 14.0 (TID 203) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 48, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:51 INFO Executor: Running task 48.0 in stage 14.0 (TID 203)\n",
      "25/11/13 14:59:51 INFO TaskSetManager: Finished task 46.0 in stage 14.0 (TID 201) in 55 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (47/50)\n",
      "25/11/13 14:59:51 INFO BlockManager: Found block rdd_18_47 locally\n",
      "25/11/13 14:59:51 INFO Executor: Finished task 47.0 in stage 14.0 (TID 202). 4293 bytes result sent to driver\n",
      "25/11/13 14:59:51 INFO TaskSetManager: Starting task 49.0 in stage 14.0 (TID 204) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 49, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 14:59:51 INFO Executor: Running task 49.0 in stage 14.0 (TID 204)\n",
      "25/11/13 14:59:51 INFO TaskSetManager: Finished task 47.0 in stage 14.0 (TID 202) in 53 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (48/50)\n",
      "25/11/13 14:59:51 INFO BlockManager: Found block rdd_18_48 locally\n",
      "25/11/13 14:59:51 INFO Executor: Finished task 48.0 in stage 14.0 (TID 203). 4293 bytes result sent to driver\n",
      "25/11/13 14:59:51 INFO TaskSetManager: Finished task 48.0 in stage 14.0 (TID 203) in 39 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (49/50)\n",
      "25/11/13 14:59:51 INFO BlockManager: Found block rdd_18_49 locally\n",
      "25/11/13 14:59:51 INFO Executor: Finished task 49.0 in stage 14.0 (TID 204). 4293 bytes result sent to driver\n",
      "25/11/13 14:59:51 INFO TaskSetManager: Finished task 49.0 in stage 14.0 (TID 204) in 37 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (50/50)\n",
      "25/11/13 14:59:51 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool \n",
      "25/11/13 14:59:51 INFO DAGScheduler: ResultStage 14 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 1.323 s\n",
      "25/11/13 14:59:51 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/11/13 14:59:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished\n",
      "25/11/13 14:59:51 INFO DAGScheduler: Job 8 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 1.336125 s\n",
      "25/11/13 14:59:51 INFO FileSourceStrategy: Pushed Filters:                      \n",
      "25/11/13 14:59:51 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/11/13 14:59:51 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 206.2 KiB, free 1045.9 MiB)\n",
      "25/11/13 14:59:51 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 36.6 KiB, free 1045.9 MiB)\n",
      "25/11/13 14:59:51 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 36.6 KiB, free: 1048.3 MiB)\n",
      "25/11/13 14:59:51 INFO BlockManagerInfo: Removed broadcast_13_piece0 on jupyter-spark-758b7c86d8-7j77n:43517 in memory (size: 163.1 KiB, free: 1048.5 MiB)\n",
      "25/11/13 14:59:51 INFO SparkContext: Created broadcast 14 from showString at NativeMethodAccessorImpl.java:0\n",
      "25/11/13 14:59:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 15790468 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/11/13 14:59:51 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "25/11/13 14:59:51 INFO DAGScheduler: Got job 9 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/11/13 14:59:51 INFO DAGScheduler: Final stage: ResultStage 15 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/11/13 14:59:51 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/11/13 14:59:51 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 14:59:51 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[42] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/11/13 14:59:51 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 30.5 KiB, free 1046.7 MiB)\n",
      "25/11/13 14:59:51 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 1046.7 MiB)\n",
      "25/11/13 14:59:51 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 10.8 KiB, free: 1048.4 MiB)\n",
      "25/11/13 14:59:51 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 14:59:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[42] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/11/13 14:59:51 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0\n",
      "25/11/13 14:59:51 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 205) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 9672 bytes) \n",
      "25/11/13 14:59:51 INFO Executor: Running task 0.0 in stage 15.0 (TID 205)\n",
      "25/11/13 14:59:51 INFO FileScanRDD: Reading File path: s3a://nau-local-analytics-bronze/auth_user/part-00000-328279f1-d4eb-469c-bf96-b8fd585b9f62-c000.snappy.parquet, range: 0-15790468, partition values: [empty row]\n",
      "25/11/13 14:59:51 INFO S3AInputStream: Switching to Random IO seek policy\n",
      "[Stage 15:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-----------------------------+----------+---------+---------+--------+------------+---------+--------------------------+----------+--------------------------+-----------+----------------------------------------------------------------+\n",
      "|user_id|username         |email                        |first_name|last_name|full_name|is_staff|is_superuser|is_active|date_joined               |last_login|ingestion_date            |source_name|user_hash                                                       |\n",
      "+-------+-----------------+-----------------------------+----------+---------+---------+--------+------------+---------+--------------------------+----------+--------------------------+-----------+----------------------------------------------------------------+\n",
      "|1      |enterprise_worker|enterprise_worker@example.com|          |         |         |true    |false       |true     |2018-08-29 18:34:26.488188|NULL      |2025-11-04 18:26:56.116039|auth_user  |5292211e07d3eae558e746efeaae281a3208c83e6a78601c8a5ed4dce565fe66|\n",
      "|2      |veda_service_user|veda_service_user@example.com|          |         |         |true    |false       |true     |2018-08-29 18:34:34.18119 |NULL      |2025-11-04 18:26:56.116039|auth_user  |84136b8498e880143cde64d5badcc17ec16fd795ec7e04a4e78ccc076433892e|\n",
      "|3      |ecommerce_worker |ecommerce_worker@example.com |          |         |         |true    |true        |true     |2018-08-29 18:34:42       |NULL      |2025-11-04 18:26:56.116039|auth_user  |ea9522b2b1762f784b79624827c141c93254384bc8ad1fecd59fba5c0c0f63bb|\n",
      "|4      |discovery_worker |discovery_worker@example.com |          |         |         |true    |false       |true     |2018-08-29 18:34:50.609274|NULL      |2025-11-04 18:26:56.116039|auth_user  |cc7c9c19587681bac8b622b4f5a00e61d7ce138732e64c24460e7e8bce53688c|\n",
      "|6      |insights_worker  |insights_worker@example.com  |          |         |         |true    |false       |true     |2018-08-29 18:34:58.792988|NULL      |2025-11-04 18:26:56.116039|auth_user  |369017097638c15933633841f9ceea5c595c121001f9cb95efbb986d94cdb983|\n",
      "+-------+-----------------+-----------------------------+----------+---------+---------+--------+------------+---------+--------------------------+----------+--------------------------+-----------+----------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/13 14:59:52 INFO Executor: Finished task 0.0 in stage 15.0 (TID 205). 2882 bytes result sent to driver\n",
      "25/11/13 14:59:52 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 205) in 781 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/1)\n",
      "25/11/13 14:59:52 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool \n",
      "25/11/13 14:59:52 INFO DAGScheduler: ResultStage 15 (showString at NativeMethodAccessorImpl.java:0) finished in 0.789 s\n",
      "25/11/13 14:59:52 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/11/13 14:59:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished\n",
      "25/11/13 14:59:52 INFO DAGScheduler: Job 9 finished: showString at NativeMethodAccessorImpl.java:0, took 0.799894 s\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_users_source.printSchema()\n",
    "df_users_source.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b873a3c-67e5-40bc-9033-570e232a8d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/13 15:02:57 INFO DelegatingLogStore: LogStore `LogStoreAdapter(io.delta.storage.S3SingleDriverLogStore)` is used for scheme `s3a`\n",
      "25/11/13 15:02:57 INFO DeltaLog: Creating initial snapshot without metadata, because the directory is empty\n",
      "25/11/13 15:02:57 INFO InitialSnapshot: [tableId=820d73db-afa2-4dc8-b034-00ffe2e842dd] Created snapshot InitialSnapshot(path=s3a://nau-local-analytics-silver/dim_user/_delta_log, version=-1, metadata=Metadata(7e108e2b-ae36-44bb-bec6-cb875e1593a8,null,null,Format(parquet,Map()),null,List(),Map(),Some(1763046177235)), logSegment=LogSegment(s3a://nau-local-analytics-silver/dim_user/_delta_log,-1,List(),org.apache.spark.sql.delta.EmptyCheckpointProvider$@65a2ce0d,-1), checksumOpt=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> [dim_user] Silver Delta table does not exist yet (first load).\n",
      ">> [dim_user] Preview of df_users_silver (with user_sk):\n",
      "root\n",
      " |-- user_sk: integer (nullable = false)\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- username: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- full_name: string (nullable = false)\n",
      " |-- is_staff: boolean (nullable = true)\n",
      " |-- is_superuser: boolean (nullable = true)\n",
      " |-- is_active: boolean (nullable = true)\n",
      " |-- date_joined: timestamp (nullable = true)\n",
      " |-- last_login: timestamp (nullable = true)\n",
      " |-- user_hash: string (nullable = true)\n",
      " |-- ingestion_date: timestamp (nullable = true)\n",
      " |-- source_name: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/13 15:02:58 INFO PrepareDeltaScan: DELTA: Filtering files for query\n",
      "25/11/13 15:02:58 INFO CodeGenerator: Code generated in 187.546877 ms\n",
      "25/11/13 15:02:58 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128\n",
      "25/11/13 15:02:58 INFO DAGScheduler: Got job 10 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions\n",
      "25/11/13 15:02:58 INFO DAGScheduler: Final stage: ResultStage 17 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)\n",
      "25/11/13 15:02:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)\n",
      "25/11/13 15:02:58 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 15:02:58 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[44] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents\n",
      "25/11/13 15:02:58 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 684.9 KiB, free 1047.7 MiB)\n",
      "25/11/13 15:02:58 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 154.5 KiB, free 1047.5 MiB)\n",
      "25/11/13 15:02:58 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 154.5 KiB, free: 1048.6 MiB)\n",
      "25/11/13 15:02:58 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 15:02:58 INFO DAGScheduler: Submitting 50 missing tasks from ResultStage 17 (MapPartitionsRDD[44] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n",
      "25/11/13 15:02:58 INFO TaskSchedulerImpl: Adding task set 17.0 with 50 tasks resource profile 0\n",
      "25/11/13 15:02:58 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 206) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:02:58 INFO TaskSetManager: Starting task 1.0 in stage 17.0 (TID 207) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 1, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:02:58 INFO Executor: Running task 1.0 in stage 17.0 (TID 207)\n",
      "25/11/13 15:02:58 INFO Executor: Running task 0.0 in stage 17.0 (TID 206)\n",
      "25/11/13 15:02:58 INFO BlockManager: Found block rdd_14_0 locally\n",
      "25/11/13 15:02:58 INFO BlockManager: Found block rdd_14_1 locally\n",
      "25/11/13 15:02:59 INFO CodeGenerator: Code generated in 219.878456 ms\n",
      "25/11/13 15:02:59 INFO Executor: Finished task 0.0 in stage 17.0 (TID 206). 4224 bytes result sent to driver\n",
      "25/11/13 15:02:59 INFO Executor: Finished task 1.0 in stage 17.0 (TID 207). 4224 bytes result sent to driver\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Starting task 2.0 in stage 17.0 (TID 208) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 2, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:02:59 INFO Executor: Running task 2.0 in stage 17.0 (TID 208)\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Starting task 3.0 in stage 17.0 (TID 209) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 3, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:02:59 INFO Executor: Running task 3.0 in stage 17.0 (TID 209)\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Finished task 1.0 in stage 17.0 (TID 207) in 281 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/50)\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 206) in 281 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (2/50)\n",
      "25/11/13 15:02:59 INFO BlockManager: Found block rdd_14_3 locally\n",
      "25/11/13 15:02:59 INFO BlockManager: Found block rdd_14_2 locally\n",
      "25/11/13 15:02:59 INFO Executor: Finished task 3.0 in stage 17.0 (TID 209). 4181 bytes result sent to driver\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Starting task 4.0 in stage 17.0 (TID 210) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 4, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:02:59 INFO Executor: Finished task 2.0 in stage 17.0 (TID 208). 4181 bytes result sent to driver\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Starting task 5.0 in stage 17.0 (TID 211) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 5, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:02:59 INFO Executor: Running task 4.0 in stage 17.0 (TID 210)\n",
      "25/11/13 15:02:59 INFO Executor: Running task 5.0 in stage 17.0 (TID 211)\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Finished task 3.0 in stage 17.0 (TID 209) in 49 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (3/50)\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Finished task 2.0 in stage 17.0 (TID 208) in 51 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (4/50)\n",
      "25/11/13 15:02:59 INFO BlockManager: Found block rdd_14_4 locally\n",
      "25/11/13 15:02:59 INFO BlockManager: Found block rdd_14_5 locally\n",
      "25/11/13 15:02:59 INFO Executor: Finished task 4.0 in stage 17.0 (TID 210). 4181 bytes result sent to driver\n",
      "25/11/13 15:02:59 INFO Executor: Finished task 5.0 in stage 17.0 (TID 211). 4181 bytes result sent to driver\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Starting task 6.0 in stage 17.0 (TID 212) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 6, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:02:59 INFO Executor: Running task 6.0 in stage 17.0 (TID 212)\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Starting task 7.0 in stage 17.0 (TID 213) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 7, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:02:59 INFO TaskSetManager: Finished task 4.0 in stage 17.0 (TID 210) in 27 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (5/50)\n",
      "25/11/13 15:02:59 INFO Executor: Running task 7.0 in stage 17.0 (TID 213)\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Finished task 5.0 in stage 17.0 (TID 211) in 26 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (6/50)\n",
      "25/11/13 15:02:59 INFO BlockManager: Found block rdd_14_7 locally\n",
      "25/11/13 15:02:59 INFO BlockManager: Found block rdd_14_6 locally\n",
      "25/11/13 15:02:59 INFO Executor: Finished task 6.0 in stage 17.0 (TID 212). 4224 bytes result sent to driver\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Starting task 8.0 in stage 17.0 (TID 214) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 8, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:02:59 INFO Executor: Finished task 7.0 in stage 17.0 (TID 213). 4392 bytes result sent to driver\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Finished task 6.0 in stage 17.0 (TID 212) in 76 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (7/50)\n",
      "25/11/13 15:02:59 INFO Executor: Running task 8.0 in stage 17.0 (TID 214)\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Starting task 9.0 in stage 17.0 (TID 215) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 9, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:02:59 INFO TaskSetManager: Finished task 7.0 in stage 17.0 (TID 213) in 77 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (8/50)\n",
      "25/11/13 15:02:59 INFO Executor: Running task 9.0 in stage 17.0 (TID 215)\n",
      "25/11/13 15:02:59 INFO BlockManager: Found block rdd_14_8 locally\n",
      "25/11/13 15:02:59 INFO BlockManager: Found block rdd_14_9 locally\n",
      "25/11/13 15:02:59 INFO Executor: Finished task 8.0 in stage 17.0 (TID 214). 4224 bytes result sent to driver\n",
      "25/11/13 15:02:59 INFO Executor: Finished task 9.0 in stage 17.0 (TID 215). 4267 bytes result sent to driver\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Starting task 10.0 in stage 17.0 (TID 216) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 10, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:02:59 INFO Executor: Running task 10.0 in stage 17.0 (TID 216)\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Starting task 11.0 in stage 17.0 (TID 217) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 11, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:02:59 INFO TaskSetManager: Finished task 8.0 in stage 17.0 (TID 214) in 65 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (9/50)\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Finished task 9.0 in stage 17.0 (TID 215) in 63 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (10/50)\n",
      "25/11/13 15:02:59 INFO Executor: Running task 11.0 in stage 17.0 (TID 217)\n",
      "25/11/13 15:02:59 INFO BlockManager: Found block rdd_14_10 locally\n",
      "25/11/13 15:02:59 INFO Executor: Finished task 10.0 in stage 17.0 (TID 216). 4181 bytes result sent to driver\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Starting task 12.0 in stage 17.0 (TID 218) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 12, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:02:59 INFO Executor: Running task 12.0 in stage 17.0 (TID 218)\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Finished task 10.0 in stage 17.0 (TID 216) in 48 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (11/50)\n",
      "25/11/13 15:02:59 INFO BlockManager: Found block rdd_14_11 locally\n",
      "25/11/13 15:02:59 INFO Executor: Finished task 11.0 in stage 17.0 (TID 217). 4181 bytes result sent to driver\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Starting task 13.0 in stage 17.0 (TID 219) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 13, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:02:59 INFO Executor: Running task 13.0 in stage 17.0 (TID 219)\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Finished task 11.0 in stage 17.0 (TID 217) in 53 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (12/50)\n",
      "25/11/13 15:02:59 INFO BlockManager: Found block rdd_14_12 locally\n",
      "25/11/13 15:02:59 INFO Executor: Finished task 12.0 in stage 17.0 (TID 218). 4181 bytes result sent to driver\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Starting task 14.0 in stage 17.0 (TID 220) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 14, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:02:59 INFO Executor: Running task 14.0 in stage 17.0 (TID 220)\n",
      "25/11/13 15:02:59 INFO BlockManager: Found block rdd_14_13 locally\n",
      "25/11/13 15:02:59 INFO Executor: Finished task 13.0 in stage 17.0 (TID 219). 4181 bytes result sent to driver\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Starting task 15.0 in stage 17.0 (TID 221) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 15, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:02:59 INFO TaskSetManager: Finished task 12.0 in stage 17.0 (TID 218) in 90 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (13/50)\n",
      "25/11/13 15:02:59 INFO Executor: Running task 15.0 in stage 17.0 (TID 221)\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Finished task 13.0 in stage 17.0 (TID 219) in 85 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (14/50)\n",
      "25/11/13 15:02:59 INFO BlockManager: Found block rdd_14_14 locally\n",
      "25/11/13 15:02:59 INFO Executor: Finished task 14.0 in stage 17.0 (TID 220). 4181 bytes result sent to driver\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Starting task 16.0 in stage 17.0 (TID 222) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 16, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:02:59 INFO Executor: Running task 16.0 in stage 17.0 (TID 222)\n",
      "25/11/13 15:02:59 INFO BlockManager: Found block rdd_14_15 locally\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Finished task 14.0 in stage 17.0 (TID 220) in 47 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (15/50)\n",
      "25/11/13 15:02:59 INFO Executor: Finished task 15.0 in stage 17.0 (TID 221). 4181 bytes result sent to driver\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Starting task 17.0 in stage 17.0 (TID 223) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 17, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:02:59 INFO TaskSetManager: Finished task 15.0 in stage 17.0 (TID 221) in 66 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (16/50)\n",
      "25/11/13 15:02:59 INFO Executor: Running task 17.0 in stage 17.0 (TID 223)\n",
      "25/11/13 15:02:59 INFO BlockManager: Found block rdd_14_17 locally\n",
      "25/11/13 15:02:59 INFO Executor: Finished task 17.0 in stage 17.0 (TID 223). 4181 bytes result sent to driver\n",
      "25/11/13 15:02:59 INFO BlockManager: Found block rdd_14_16 locally\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Starting task 18.0 in stage 17.0 (TID 224) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 18, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:02:59 INFO Executor: Finished task 16.0 in stage 17.0 (TID 222). 4181 bytes result sent to driver\n",
      "25/11/13 15:02:59 INFO Executor: Running task 18.0 in stage 17.0 (TID 224)\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Finished task 17.0 in stage 17.0 (TID 223) in 91 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (17/50)\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Starting task 19.0 in stage 17.0 (TID 225) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 19, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:02:59 INFO TaskSetManager: Finished task 16.0 in stage 17.0 (TID 222) in 97 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (18/50)\n",
      "25/11/13 15:02:59 INFO Executor: Running task 19.0 in stage 17.0 (TID 225)\n",
      "25/11/13 15:02:59 INFO BlockManager: Found block rdd_14_19 locally\n",
      "25/11/13 15:02:59 INFO Executor: Finished task 19.0 in stage 17.0 (TID 225). 4224 bytes result sent to driver\n",
      "25/11/13 15:02:59 INFO BlockManager: Found block rdd_14_18 locally\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Starting task 20.0 in stage 17.0 (TID 226) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 20, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:02:59 INFO Executor: Finished task 18.0 in stage 17.0 (TID 224). 4181 bytes result sent to driver\n",
      "25/11/13 15:02:59 INFO Executor: Running task 20.0 in stage 17.0 (TID 226)\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Starting task 21.0 in stage 17.0 (TID 227) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 21, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:02:59 INFO TaskSetManager: Finished task 19.0 in stage 17.0 (TID 225) in 87 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (19/50)\n",
      "25/11/13 15:02:59 INFO Executor: Running task 21.0 in stage 17.0 (TID 227)\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Finished task 18.0 in stage 17.0 (TID 224) in 92 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (20/50)\n",
      "25/11/13 15:02:59 INFO BlockManager: Found block rdd_14_20 locally\n",
      "25/11/13 15:02:59 INFO Executor: Finished task 20.0 in stage 17.0 (TID 226). 4181 bytes result sent to driver\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Starting task 22.0 in stage 17.0 (TID 228) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 22, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:02:59 INFO Executor: Running task 22.0 in stage 17.0 (TID 228)\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Finished task 20.0 in stage 17.0 (TID 226) in 44 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (21/50)\n",
      "25/11/13 15:02:59 INFO BlockManager: Found block rdd_14_21 locally\n",
      "25/11/13 15:02:59 INFO Executor: Finished task 21.0 in stage 17.0 (TID 227). 4181 bytes result sent to driver\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Starting task 23.0 in stage 17.0 (TID 229) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 23, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:02:59 INFO Executor: Running task 23.0 in stage 17.0 (TID 229)\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Finished task 21.0 in stage 17.0 (TID 227) in 63 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (22/50)\n",
      "25/11/13 15:02:59 INFO BlockManager: Found block rdd_14_22 locally\n",
      "25/11/13 15:02:59 INFO Executor: Finished task 22.0 in stage 17.0 (TID 228). 4224 bytes result sent to driver\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Starting task 24.0 in stage 17.0 (TID 230) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 24, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:02:59 INFO Executor: Running task 24.0 in stage 17.0 (TID 230)\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Finished task 22.0 in stage 17.0 (TID 228) in 86 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (23/50)\n",
      "25/11/13 15:02:59 INFO BlockManager: Found block rdd_14_23 locally\n",
      "25/11/13 15:02:59 INFO Executor: Finished task 23.0 in stage 17.0 (TID 229). 4224 bytes result sent to driver\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Starting task 25.0 in stage 17.0 (TID 231) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 25, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:02:59 INFO TaskSetManager: Finished task 23.0 in stage 17.0 (TID 229) in 49 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (24/50)\n",
      "25/11/13 15:02:59 INFO Executor: Running task 25.0 in stage 17.0 (TID 231)\n",
      "25/11/13 15:02:59 INFO BlockManager: Found block rdd_14_24 locally\n",
      "25/11/13 15:02:59 INFO Executor: Finished task 24.0 in stage 17.0 (TID 230). 4224 bytes result sent to driver\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Starting task 26.0 in stage 17.0 (TID 232) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 26, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:02:59 INFO TaskSetManager: Finished task 24.0 in stage 17.0 (TID 230) in 120 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (25/50)\n",
      "25/11/13 15:02:59 INFO Executor: Running task 26.0 in stage 17.0 (TID 232)\n",
      "25/11/13 15:02:59 INFO BlockManager: Found block rdd_14_25 locally(24 + 3) / 50]\n",
      "25/11/13 15:02:59 INFO Executor: Finished task 25.0 in stage 17.0 (TID 231). 4224 bytes result sent to driver\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Starting task 27.0 in stage 17.0 (TID 233) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 27, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:02:59 INFO Executor: Running task 27.0 in stage 17.0 (TID 233)\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Finished task 25.0 in stage 17.0 (TID 231) in 163 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (26/50)\n",
      "25/11/13 15:02:59 INFO BlockManager: Found block rdd_14_26 locally\n",
      "25/11/13 15:02:59 INFO BlockManager: Found block rdd_14_27 locally\n",
      "25/11/13 15:02:59 INFO Executor: Finished task 26.0 in stage 17.0 (TID 232). 4181 bytes result sent to driver\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Starting task 28.0 in stage 17.0 (TID 234) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 28, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:02:59 INFO Executor: Finished task 27.0 in stage 17.0 (TID 233). 4224 bytes result sent to driver\n",
      "25/11/13 15:02:59 INFO Executor: Running task 28.0 in stage 17.0 (TID 234)\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Starting task 29.0 in stage 17.0 (TID 235) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 29, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:02:59 INFO TaskSetManager: Finished task 26.0 in stage 17.0 (TID 232) in 99 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (27/50)\n",
      "25/11/13 15:02:59 INFO TaskSetManager: Finished task 27.0 in stage 17.0 (TID 233) in 52 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (28/50)\n",
      "25/11/13 15:02:59 INFO Executor: Running task 29.0 in stage 17.0 (TID 235)\n",
      "25/11/13 15:03:00 INFO BlockManager: Found block rdd_14_29 locally\n",
      "25/11/13 15:03:00 INFO BlockManager: Found block rdd_14_28 locally\n",
      "25/11/13 15:03:00 INFO Executor: Finished task 29.0 in stage 17.0 (TID 235). 4224 bytes result sent to driver\n",
      "25/11/13 15:03:00 INFO TaskSetManager: Starting task 30.0 in stage 17.0 (TID 236) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 30, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:00 INFO TaskSetManager: Finished task 29.0 in stage 17.0 (TID 235) in 109 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (29/50)\n",
      "25/11/13 15:03:00 INFO Executor: Running task 30.0 in stage 17.0 (TID 236)\n",
      "25/11/13 15:03:00 INFO Executor: Finished task 28.0 in stage 17.0 (TID 234). 4224 bytes result sent to driver\n",
      "25/11/13 15:03:00 INFO TaskSetManager: Starting task 31.0 in stage 17.0 (TID 237) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 31, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:00 INFO Executor: Running task 31.0 in stage 17.0 (TID 237)\n",
      "25/11/13 15:03:00 INFO TaskSetManager: Finished task 28.0 in stage 17.0 (TID 234) in 154 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (30/50)\n",
      "25/11/13 15:03:00 INFO BlockManager: Found block rdd_14_30 locally\n",
      "25/11/13 15:03:00 INFO BlockManager: Found block rdd_14_31 locally\n",
      "25/11/13 15:03:00 INFO Executor: Finished task 30.0 in stage 17.0 (TID 236). 4224 bytes result sent to driver\n",
      "25/11/13 15:03:00 INFO TaskSetManager: Starting task 32.0 in stage 17.0 (TID 238) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 32, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:00 INFO TaskSetManager: Finished task 30.0 in stage 17.0 (TID 236) in 96 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (31/50)\n",
      "25/11/13 15:03:00 INFO Executor: Finished task 31.0 in stage 17.0 (TID 237). 4224 bytes result sent to driver\n",
      "25/11/13 15:03:00 INFO Executor: Running task 32.0 in stage 17.0 (TID 238)\n",
      "25/11/13 15:03:00 INFO TaskSetManager: Starting task 33.0 in stage 17.0 (TID 239) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 33, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:00 INFO TaskSetManager: Finished task 31.0 in stage 17.0 (TID 237) in 61 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (32/50)\n",
      "25/11/13 15:03:00 INFO Executor: Running task 33.0 in stage 17.0 (TID 239)\n",
      "25/11/13 15:03:00 INFO BlockManager: Found block rdd_14_32 locally\n",
      "25/11/13 15:03:00 INFO Executor: Finished task 32.0 in stage 17.0 (TID 238). 4224 bytes result sent to driver\n",
      "25/11/13 15:03:00 INFO BlockManager: Found block rdd_14_33 locally\n",
      "25/11/13 15:03:00 INFO TaskSetManager: Starting task 34.0 in stage 17.0 (TID 240) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 34, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:00 INFO Executor: Running task 34.0 in stage 17.0 (TID 240)\n",
      "25/11/13 15:03:00 INFO TaskSetManager: Finished task 32.0 in stage 17.0 (TID 238) in 99 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (33/50)\n",
      "25/11/13 15:03:00 INFO Executor: Finished task 33.0 in stage 17.0 (TID 239). 4224 bytes result sent to driver\n",
      "25/11/13 15:03:00 INFO TaskSetManager: Starting task 35.0 in stage 17.0 (TID 241) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 35, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:00 INFO TaskSetManager: Finished task 33.0 in stage 17.0 (TID 239) in 97 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (34/50)\n",
      "25/11/13 15:03:00 INFO Executor: Running task 35.0 in stage 17.0 (TID 241)\n",
      "25/11/13 15:03:00 INFO BlockManager: Found block rdd_14_34 locally(34 + 2) / 50]\n",
      "25/11/13 15:03:00 INFO Executor: Finished task 34.0 in stage 17.0 (TID 240). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:00 INFO TaskSetManager: Starting task 36.0 in stage 17.0 (TID 242) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 36, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:00 INFO Executor: Running task 36.0 in stage 17.0 (TID 242)\n",
      "25/11/13 15:03:00 INFO TaskSetManager: Finished task 34.0 in stage 17.0 (TID 240) in 51 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (35/50)\n",
      "25/11/13 15:03:00 INFO BlockManager: Found block rdd_14_35 locally\n",
      "25/11/13 15:03:00 INFO Executor: Finished task 35.0 in stage 17.0 (TID 241). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:00 INFO TaskSetManager: Starting task 37.0 in stage 17.0 (TID 243) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 37, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:00 INFO Executor: Running task 37.0 in stage 17.0 (TID 243)\n",
      "25/11/13 15:03:00 INFO TaskSetManager: Finished task 35.0 in stage 17.0 (TID 241) in 78 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (36/50)\n",
      "25/11/13 15:03:00 INFO BlockManager: Found block rdd_14_36 locally\n",
      "25/11/13 15:03:00 INFO Executor: Finished task 36.0 in stage 17.0 (TID 242). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:00 INFO TaskSetManager: Starting task 38.0 in stage 17.0 (TID 244) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 38, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:00 INFO Executor: Running task 38.0 in stage 17.0 (TID 244)\n",
      "25/11/13 15:03:00 INFO TaskSetManager: Finished task 36.0 in stage 17.0 (TID 242) in 43 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (37/50)\n",
      "25/11/13 15:03:00 INFO BlockManager: Found block rdd_14_37 locally\n",
      "25/11/13 15:03:00 INFO BlockManager: Found block rdd_14_38 locally\n",
      "25/11/13 15:03:00 INFO Executor: Finished task 37.0 in stage 17.0 (TID 243). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:00 INFO TaskSetManager: Starting task 39.0 in stage 17.0 (TID 245) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 39, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:00 INFO Executor: Running task 39.0 in stage 17.0 (TID 245)\n",
      "25/11/13 15:03:00 INFO Executor: Finished task 38.0 in stage 17.0 (TID 244). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:00 INFO TaskSetManager: Finished task 37.0 in stage 17.0 (TID 243) in 25 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (38/50)\n",
      "25/11/13 15:03:00 INFO TaskSetManager: Starting task 40.0 in stage 17.0 (TID 246) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 40, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:00 INFO Executor: Running task 40.0 in stage 17.0 (TID 246)\n",
      "25/11/13 15:03:00 INFO TaskSetManager: Finished task 38.0 in stage 17.0 (TID 244) in 56 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (39/50)\n",
      "25/11/13 15:03:00 INFO BlockManager: Found block rdd_14_40 locally\n",
      "25/11/13 15:03:00 INFO Executor: Finished task 40.0 in stage 17.0 (TID 246). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:00 INFO BlockManager: Found block rdd_14_39 locally\n",
      "25/11/13 15:03:00 INFO TaskSetManager: Starting task 41.0 in stage 17.0 (TID 247) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 41, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:00 INFO TaskSetManager: Finished task 40.0 in stage 17.0 (TID 246) in 91 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (40/50)\n",
      "25/11/13 15:03:00 INFO Executor: Finished task 39.0 in stage 17.0 (TID 245). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:00 INFO Executor: Running task 41.0 in stage 17.0 (TID 247)\n",
      "25/11/13 15:03:00 INFO TaskSetManager: Starting task 42.0 in stage 17.0 (TID 248) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 42, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:00 INFO Executor: Running task 42.0 in stage 17.0 (TID 248)\n",
      "25/11/13 15:03:00 INFO TaskSetManager: Finished task 39.0 in stage 17.0 (TID 245) in 100 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (41/50)\n",
      "25/11/13 15:03:00 INFO BlockManager: Found block rdd_14_41 locally(41 + 2) / 50]\n",
      "25/11/13 15:03:00 INFO Executor: Finished task 41.0 in stage 17.0 (TID 247). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:00 INFO TaskSetManager: Starting task 43.0 in stage 17.0 (TID 249) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 43, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:00 INFO TaskSetManager: Finished task 41.0 in stage 17.0 (TID 247) in 84 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (42/50)\n",
      "25/11/13 15:03:00 INFO Executor: Running task 43.0 in stage 17.0 (TID 249)\n",
      "25/11/13 15:03:00 INFO BlockManager: Found block rdd_14_42 locally\n",
      "25/11/13 15:03:00 INFO Executor: Finished task 42.0 in stage 17.0 (TID 248). 4224 bytes result sent to driver\n",
      "25/11/13 15:03:00 INFO TaskSetManager: Starting task 44.0 in stage 17.0 (TID 250) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 44, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:00 INFO TaskSetManager: Finished task 42.0 in stage 17.0 (TID 248) in 94 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (43/50)\n",
      "25/11/13 15:03:00 INFO Executor: Running task 44.0 in stage 17.0 (TID 250)\n",
      "25/11/13 15:03:00 INFO BlockManager: Found block rdd_14_43 locally\n",
      "25/11/13 15:03:00 INFO Executor: Finished task 43.0 in stage 17.0 (TID 249). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:00 INFO TaskSetManager: Starting task 45.0 in stage 17.0 (TID 251) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 45, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:00 INFO Executor: Running task 45.0 in stage 17.0 (TID 251)\n",
      "25/11/13 15:03:00 INFO TaskSetManager: Finished task 43.0 in stage 17.0 (TID 249) in 87 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (44/50)\n",
      "25/11/13 15:03:00 INFO BlockManager: Found block rdd_14_44 locally\n",
      "25/11/13 15:03:00 INFO Executor: Finished task 44.0 in stage 17.0 (TID 250). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:00 INFO TaskSetManager: Starting task 46.0 in stage 17.0 (TID 252) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 46, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:00 INFO Executor: Running task 46.0 in stage 17.0 (TID 252)\n",
      "25/11/13 15:03:00 INFO TaskSetManager: Finished task 44.0 in stage 17.0 (TID 250) in 94 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (45/50)\n",
      "25/11/13 15:03:00 INFO BlockManager: Found block rdd_14_45 locally\n",
      "25/11/13 15:03:00 INFO Executor: Finished task 45.0 in stage 17.0 (TID 251). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:00 INFO TaskSetManager: Starting task 47.0 in stage 17.0 (TID 253) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 47, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:00 INFO Executor: Running task 47.0 in stage 17.0 (TID 253)\n",
      "25/11/13 15:03:00 INFO TaskSetManager: Finished task 45.0 in stage 17.0 (TID 251) in 92 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (46/50)\n",
      "25/11/13 15:03:00 INFO BlockManager: Found block rdd_14_46 locally\n",
      "25/11/13 15:03:00 INFO Executor: Finished task 46.0 in stage 17.0 (TID 252). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:00 INFO TaskSetManager: Starting task 48.0 in stage 17.0 (TID 254) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 48, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:00 INFO Executor: Running task 48.0 in stage 17.0 (TID 254)\n",
      "25/11/13 15:03:00 INFO TaskSetManager: Finished task 46.0 in stage 17.0 (TID 252) in 89 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (47/50)\n",
      "25/11/13 15:03:00 INFO BlockManager: Found block rdd_14_47 locally\n",
      "25/11/13 15:03:00 INFO Executor: Finished task 47.0 in stage 17.0 (TID 253). 4224 bytes result sent to driver\n",
      "25/11/13 15:03:00 INFO TaskSetManager: Starting task 49.0 in stage 17.0 (TID 255) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 49, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:00 INFO Executor: Running task 49.0 in stage 17.0 (TID 255)\n",
      "25/11/13 15:03:00 INFO TaskSetManager: Finished task 47.0 in stage 17.0 (TID 253) in 186 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (48/50)\n",
      "25/11/13 15:03:00 INFO BlockManager: Found block rdd_14_48 locally\n",
      "25/11/13 15:03:00 INFO Executor: Finished task 48.0 in stage 17.0 (TID 254). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:00 INFO TaskSetManager: Finished task 48.0 in stage 17.0 (TID 254) in 184 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (49/50)\n",
      "25/11/13 15:03:00 INFO BlockManager: Found block rdd_14_49 locally\n",
      "25/11/13 15:03:00 INFO Executor: Finished task 49.0 in stage 17.0 (TID 255). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:00 INFO TaskSetManager: Finished task 49.0 in stage 17.0 (TID 255) in 33 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (50/50)\n",
      "25/11/13 15:03:00 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool \n",
      "25/11/13 15:03:00 INFO DAGScheduler: ResultStage 17 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 2.079 s\n",
      "25/11/13 15:03:00 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/11/13 15:03:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished\n",
      "25/11/13 15:03:00 INFO DAGScheduler: Job 10 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 2.092735 s\n",
      "25/11/13 15:03:00 INFO CodeGenerator: Code generated in 40.197251 ms            \n",
      "25/11/13 15:03:00 INFO PrepareDeltaScan: DELTA: Done\n",
      "25/11/13 15:03:01 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/11/13 15:03:01 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/11/13 15:03:01 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/11/13 15:03:01 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/11/13 15:03:01 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/11/13 15:03:01 INFO CodeGenerator: Code generated in 45.896268 ms\n",
      "25/11/13 15:03:01 INFO CodeGenerator: Code generated in 17.266101 ms\n",
      "25/11/13 15:03:01 INFO CodeGenerator: Code generated in 20.898947 ms\n",
      "25/11/13 15:03:01 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 206.2 KiB, free 1047.3 MiB)\n",
      "25/11/13 15:03:01 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 36.6 KiB, free 1047.3 MiB)\n",
      "25/11/13 15:03:01 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 36.6 KiB, free: 1048.5 MiB)\n",
      "25/11/13 15:03:01 INFO SparkContext: Created broadcast 17 from showString at NativeMethodAccessorImpl.java:0\n",
      "25/11/13 15:03:01 INFO FileSourceScanExec: Planning scan with bin packing, max size: 15790468 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/11/13 15:03:01 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "25/11/13 15:03:01 INFO DAGScheduler: Registering RDD 49 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 2\n",
      "25/11/13 15:03:01 INFO DAGScheduler: Got job 11 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/11/13 15:03:01 INFO DAGScheduler: Final stage: ResultStage 19 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/11/13 15:03:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)\n",
      "25/11/13 15:03:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 18)\n",
      "25/11/13 15:03:01 INFO DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[49] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/11/13 15:03:01 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 48.6 KiB, free 1047.2 MiB)\n",
      "25/11/13 15:03:01 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 19.6 KiB, free 1047.2 MiB)\n",
      "25/11/13 15:03:01 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 19.6 KiB, free: 1048.5 MiB)\n",
      "25/11/13 15:03:01 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 15:03:01 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[49] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))\n",
      "25/11/13 15:03:01 INFO TaskSchedulerImpl: Adding task set 18.0 with 2 tasks resource profile 0\n",
      "25/11/13 15:03:01 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 256) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 9661 bytes) \n",
      "25/11/13 15:03:01 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 257) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 1, PROCESS_LOCAL, 9661 bytes) \n",
      "25/11/13 15:03:01 INFO Executor: Running task 1.0 in stage 18.0 (TID 257)\n",
      "25/11/13 15:03:01 INFO Executor: Running task 0.0 in stage 18.0 (TID 256)\n",
      "25/11/13 15:03:01 INFO CodeGenerator: Code generated in 9.935386 ms\n",
      "25/11/13 15:03:01 INFO BlockManagerInfo: Removed broadcast_16_piece0 on jupyter-spark-758b7c86d8-7j77n:43517 in memory (size: 154.5 KiB, free: 1048.7 MiB)\n",
      "25/11/13 15:03:01 INFO CodeGenerator: Code generated in 126.344658 ms\n",
      "25/11/13 15:03:01 INFO FileScanRDD: Reading File path: s3a://nau-local-analytics-bronze/auth_user/part-00000-328279f1-d4eb-469c-bf96-b8fd585b9f62-c000.snappy.parquet, range: 15790468-27386633, partition values: [empty row]\n",
      "25/11/13 15:03:01 INFO FileScanRDD: Reading File path: s3a://nau-local-analytics-bronze/auth_user/part-00000-328279f1-d4eb-469c-bf96-b8fd585b9f62-c000.snappy.parquet, range: 0-15790468, partition values: [empty row]\n",
      "25/11/13 15:03:01 INFO S3AInputStream: Switching to Random IO seek policy\n",
      "25/11/13 15:03:01 INFO S3AInputStream: Switching to Random IO seek policy\n",
      "25/11/13 15:03:01 INFO Executor: Finished task 1.0 in stage 18.0 (TID 257). 3401 bytes result sent to driver\n",
      "25/11/13 15:03:01 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 257) in 463 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/2)\n",
      "25/11/13 15:03:06 INFO Executor: Finished task 0.0 in stage 18.0 (TID 256). 3616 bytes result sent to driver\n",
      "25/11/13 15:03:06 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 256) in 4918 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (2/2)\n",
      "25/11/13 15:03:06 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool \n",
      "25/11/13 15:03:06 INFO DAGScheduler: ShuffleMapStage 18 (showString at NativeMethodAccessorImpl.java:0) finished in 4.929 s\n",
      "25/11/13 15:03:06 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/11/13 15:03:06 INFO DAGScheduler: running: Set()\n",
      "25/11/13 15:03:06 INFO DAGScheduler: waiting: Set(ResultStage 19)\n",
      "25/11/13 15:03:06 INFO DAGScheduler: failed: Set()\n",
      "25/11/13 15:03:06 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[54] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/11/13 15:03:06 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 48.3 KiB, free 1048.0 MiB)\n",
      "25/11/13 15:03:06 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 20.6 KiB, free 1048.0 MiB)\n",
      "25/11/13 15:03:06 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 20.6 KiB, free: 1048.6 MiB)\n",
      "25/11/13 15:03:06 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 15:03:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[54] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/11/13 15:03:06 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0\n",
      "25/11/13 15:03:06 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 258) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, NODE_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:06 INFO Executor: Running task 0.0 in stage 19.0 (TID 258)\n",
      "25/11/13 15:03:06 INFO ShuffleBlockFetcherIterator: Getting 1 (1862.0 B) non-empty blocks including 1 (1862.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:03:06 INFO CodeGenerator: Code generated in 9.986272 ms\n",
      "25/11/13 15:03:06 INFO CodeGenerator: Code generated in 5.887435 ms\n",
      "25/11/13 15:03:06 INFO CodeGenerator: Code generated in 5.575976 ms\n",
      "25/11/13 15:03:06 INFO CodeGenerator: Code generated in 5.344091 ms\n",
      "25/11/13 15:03:06 INFO CodeGenerator: Code generated in 10.167989 ms\n",
      "25/11/13 15:03:06 INFO Executor: Finished task 0.0 in stage 19.0 (TID 258). 6597 bytes result sent to driver\n",
      "25/11/13 15:03:06 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 258) in 157 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/1)\n",
      "25/11/13 15:03:06 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool \n",
      "25/11/13 15:03:06 INFO DAGScheduler: ResultStage 19 (showString at NativeMethodAccessorImpl.java:0) finished in 0.168 s\n",
      "25/11/13 15:03:06 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/11/13 15:03:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished\n",
      "25/11/13 15:03:06 INFO DAGScheduler: Job 11 finished: showString at NativeMethodAccessorImpl.java:0, took 5.127780 s\n",
      "25/11/13 15:03:06 INFO CodeGenerator: Code generated in 11.218647 ms            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----------------+----------------------------------+-------------+---------+-----------------+--------+------------+---------+--------------------------+--------------------------+----------------------------------------------------------------+--------------------------+-----------+\n",
      "|user_sk|user_id|username         |email                             |first_name   |last_name|full_name        |is_staff|is_superuser|is_active|date_joined               |last_login                |user_hash                                                       |ingestion_date            |source_name|\n",
      "+-------+-------+-----------------+----------------------------------+-------------+---------+-----------------+--------+------------+---------+--------------------------+--------------------------+----------------------------------------------------------------+--------------------------+-----------+\n",
      "|1      |1      |enterprise_worker|enterprise_worker@example.com     |             |         |                 |true    |false       |true     |2018-08-29 18:34:26.488188|NULL                      |5292211e07d3eae558e746efeaae281a3208c83e6a78601c8a5ed4dce565fe66|2025-11-04 18:26:56.116039|auth_user  |\n",
      "|2      |2      |veda_service_user|veda_service_user@example.com     |             |         |                 |true    |false       |true     |2018-08-29 18:34:34.18119 |NULL                      |84136b8498e880143cde64d5badcc17ec16fd795ec7e04a4e78ccc076433892e|2025-11-04 18:26:56.116039|auth_user  |\n",
      "|3      |3      |ecommerce_worker |ecommerce_worker@example.com      |             |         |                 |true    |true        |true     |2018-08-29 18:34:42       |NULL                      |ea9522b2b1762f784b79624827c141c93254384bc8ad1fecd59fba5c0c0f63bb|2025-11-04 18:26:56.116039|auth_user  |\n",
      "|4      |4      |discovery_worker |discovery_worker@example.com      |             |         |                 |true    |false       |true     |2018-08-29 18:34:50.609274|NULL                      |cc7c9c19587681bac8b622b4f5a00e61d7ce138732e64c24460e7e8bce53688c|2025-11-04 18:26:56.116039|auth_user  |\n",
      "|5      |6      |insights_worker  |insights_worker@example.com       |             |         |                 |true    |false       |true     |2018-08-29 18:34:58.792988|NULL                      |369017097638c15933633841f9ceea5c595c121001f9cb95efbb986d94cdb983|2025-11-04 18:26:56.116039|auth_user  |\n",
      "|6      |7      |technical_edunext|technical@edunext.co              |             |         |                 |true    |true        |true     |2018-09-10 20:10:50       |2025-10-22 22:28:28.638619|58bdae2dd037b7ac57f77f911ccf65eebaef25f30513cce738e6a45c28a897ee|2025-11-04 18:26:56.116039|auth_user  |\n",
      "|7      |8      |admin            |alertas@nau.edu.pt                |Administrador|NAU      |Administrador NAU|true    |true        |true     |2018-09-14 16:58:50       |2025-03-19 14:45:20.856742|d16562f4a3eed876be3c58d0306d900fd2c877b022c61455b442acfbfa6254e5|2025-11-04 18:26:56.116039|auth_user  |\n",
      "|8      |10     |staff            |naudevel+prod-staff@gmail.com     |             |         |                 |true    |false       |true     |2018-09-14 17:01:45       |NULL                      |ed5ee83b9ce56077772d5fcbf38d722f461b50bb04a24abe5ce9bf1caf33e396|2025-11-04 18:26:56.116039|auth_user  |\n",
      "|9      |11     |instructor       |naudevel+prod-instructor@gmail.com|             |         |                 |false   |false       |true     |2018-09-14 17:02:46       |NULL                      |24f32f2da2d94fe0de6f50f93412df1590cb777ccbcd257aea3de07cd77342e8|2025-11-04 18:26:56.116039|auth_user  |\n",
      "|10     |12     |student          |naudevel+prod-student@gmail.com   |             |         |                 |false   |false       |true     |2018-09-14 17:03:38       |NULL                      |f97142e3119d5f94acb9c3f673b2b502028dda45d2e047de0b5d2aa5bb9cd5dc|2025-11-04 18:26:56.116039|auth_user  |\n",
      "+-------+-------+-----------------+----------------------------------+-------------+---------+-----------------+--------+------------+---------+--------------------------+--------------------------+----------------------------------------------------------------+--------------------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n",
      ">> [dim_user] Writing initial Silver Delta table (overwrite).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/13 15:03:06 INFO DeltaLog: Creating initial snapshot without metadata, because the directory is empty\n",
      "25/11/13 15:03:06 INFO InitialSnapshot: [tableId=7e108e2b-ae36-44bb-bec6-cb875e1593a8] Created snapshot InitialSnapshot(path=s3a://nau-local-analytics-silver/dim_user/_delta_log, version=-1, metadata=Metadata(1c188fdf-4b2c-4f32-8cf2-0835b9075d7a,null,null,Format(parquet,Map()),null,List(),Map(),Some(1763046186784)), logSegment=LogSegment(s3a://nau-local-analytics-silver/dim_user/_delta_log,-1,List(),org.apache.spark.sql.delta.EmptyCheckpointProvider$@65a2ce0d,-1), checksumOpt=None)\n",
      "25/11/13 15:03:06 INFO OptimisticTransaction: [tableId=1c188fdf,txnId=75bac33c] Updated metadata from - to Metadata(d97aed6f-8e73-4258-85f1-83735790c6dc,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"user_sk\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"user_id\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"username\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(150)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"email\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(254)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"first_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(150)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"last_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(150)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"full_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"is_staff\",\"type\":\"boolean\",\"nullable\":true,\"metadata\":{\"isSigned\":false,\"scale\":0}},{\"name\":\"is_superuser\",\"type\":\"boolean\",\"nullable\":true,\"metadata\":{\"isSigned\":false,\"scale\":0}},{\"name\":\"is_active\",\"type\":\"boolean\",\"nullable\":true,\"metadata\":{\"isSigned\":false,\"scale\":0}},{\"name\":\"date_joined\",\"type\":\"timestamp\",\"nullable\":true,\"metadata\":{\"isSigned\":false,\"scale\":0}},{\"name\":\"last_login\",\"type\":\"timestamp\",\"nullable\":true,\"metadata\":{\"isSigned\":false,\"scale\":0}},{\"name\":\"user_hash\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"ingestion_date\",\"type\":\"timestamp\",\"nullable\":true,\"metadata\":{}},{\"name\":\"source_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1763046186814))\n",
      "25/11/13 15:03:07 INFO PrepareDeltaScan: DELTA: Filtering files for query\n",
      "25/11/13 15:03:07 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128\n",
      "25/11/13 15:03:07 INFO DAGScheduler: Got job 12 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions\n",
      "25/11/13 15:03:07 INFO DAGScheduler: Final stage: ResultStage 21 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)\n",
      "25/11/13 15:03:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)\n",
      "25/11/13 15:03:07 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 15:03:07 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[56] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents\n",
      "25/11/13 15:03:07 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 684.9 KiB, free 1047.3 MiB)\n",
      "25/11/13 15:03:07 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 154.5 KiB, free 1047.1 MiB)\n",
      "25/11/13 15:03:07 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 154.5 KiB, free: 1048.5 MiB)\n",
      "25/11/13 15:03:07 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 15:03:07 INFO DAGScheduler: Submitting 50 missing tasks from ResultStage 21 (MapPartitionsRDD[56] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n",
      "25/11/13 15:03:07 INFO TaskSchedulerImpl: Adding task set 21.0 with 50 tasks resource profile 0\n",
      "25/11/13 15:03:07 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 259) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:07 INFO TaskSetManager: Starting task 1.0 in stage 21.0 (TID 260) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 1, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:07 INFO Executor: Running task 0.0 in stage 21.0 (TID 259)\n",
      "25/11/13 15:03:07 INFO Executor: Running task 1.0 in stage 21.0 (TID 260)\n",
      "25/11/13 15:03:07 INFO BlockManager: Found block rdd_14_0 locally\n",
      "25/11/13 15:03:07 INFO Executor: Finished task 0.0 in stage 21.0 (TID 259). 4224 bytes result sent to driver\n",
      "25/11/13 15:03:07 INFO TaskSetManager: Starting task 2.0 in stage 21.0 (TID 261) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 2, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:07 INFO Executor: Running task 2.0 in stage 21.0 (TID 261)\n",
      "25/11/13 15:03:07 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 259) in 55 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/50)\n",
      "25/11/13 15:03:07 INFO BlockManager: Found block rdd_14_1 locally\n",
      "25/11/13 15:03:07 INFO Executor: Finished task 1.0 in stage 21.0 (TID 260). 4224 bytes result sent to driver\n",
      "25/11/13 15:03:07 INFO TaskSetManager: Starting task 3.0 in stage 21.0 (TID 262) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 3, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:07 INFO Executor: Running task 3.0 in stage 21.0 (TID 262)\n",
      "25/11/13 15:03:07 INFO TaskSetManager: Finished task 1.0 in stage 21.0 (TID 260) in 64 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (2/50)\n",
      "25/11/13 15:03:07 INFO BlockManager: Found block rdd_14_2 locally\n",
      "25/11/13 15:03:07 INFO Executor: Finished task 2.0 in stage 21.0 (TID 261). 4224 bytes result sent to driver\n",
      "25/11/13 15:03:07 INFO TaskSetManager: Starting task 4.0 in stage 21.0 (TID 263) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 4, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:07 INFO TaskSetManager: Finished task 2.0 in stage 21.0 (TID 261) in 52 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (3/50)\n",
      "25/11/13 15:03:07 INFO Executor: Running task 4.0 in stage 21.0 (TID 263)\n",
      "25/11/13 15:03:07 INFO BlockManager: Found block rdd_14_3 locally\n",
      "25/11/13 15:03:07 INFO Executor: Finished task 3.0 in stage 21.0 (TID 262). 4224 bytes result sent to driver\n",
      "25/11/13 15:03:07 INFO TaskSetManager: Starting task 5.0 in stage 21.0 (TID 264) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 5, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:07 INFO Executor: Running task 5.0 in stage 21.0 (TID 264)\n",
      "25/11/13 15:03:07 INFO TaskSetManager: Finished task 3.0 in stage 21.0 (TID 262) in 52 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (4/50)\n",
      "25/11/13 15:03:07 INFO BlockManagerInfo: Removed broadcast_19_piece0 on jupyter-spark-758b7c86d8-7j77n:43517 in memory (size: 20.6 KiB, free: 1048.5 MiB)\n",
      "25/11/13 15:03:07 INFO BlockManager: Found block rdd_14_4 locally\n",
      "25/11/13 15:03:07 INFO Executor: Finished task 4.0 in stage 21.0 (TID 263). 4224 bytes result sent to driver\n",
      "25/11/13 15:03:07 INFO TaskSetManager: Starting task 6.0 in stage 21.0 (TID 265) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 6, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:07 INFO Executor: Running task 6.0 in stage 21.0 (TID 265)\n",
      "25/11/13 15:03:07 INFO TaskSetManager: Finished task 4.0 in stage 21.0 (TID 263) in 103 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (5/50)\n",
      "25/11/13 15:03:08 INFO BlockManager: Found block rdd_14_5 locally\n",
      "25/11/13 15:03:08 INFO Executor: Finished task 5.0 in stage 21.0 (TID 264). 4224 bytes result sent to driver\n",
      "25/11/13 15:03:08 INFO TaskSetManager: Starting task 7.0 in stage 21.0 (TID 266) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 7, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:08 INFO TaskSetManager: Finished task 5.0 in stage 21.0 (TID 264) in 144 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (6/50)\n",
      "25/11/13 15:03:08 INFO Executor: Running task 7.0 in stage 21.0 (TID 266)\n",
      "25/11/13 15:03:08 INFO BlockManager: Found block rdd_14_6 locally\n",
      "25/11/13 15:03:08 INFO Executor: Finished task 6.0 in stage 21.0 (TID 265). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:08 INFO TaskSetManager: Starting task 8.0 in stage 21.0 (TID 267) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 8, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:08 INFO TaskSetManager: Finished task 6.0 in stage 21.0 (TID 265) in 82 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (7/50)\n",
      "25/11/13 15:03:08 INFO Executor: Running task 8.0 in stage 21.0 (TID 267)\n",
      "25/11/13 15:03:08 INFO BlockManager: Found block rdd_14_7 locally\n",
      "25/11/13 15:03:08 INFO Executor: Finished task 7.0 in stage 21.0 (TID 266). 4349 bytes result sent to driver\n",
      "25/11/13 15:03:08 INFO TaskSetManager: Starting task 9.0 in stage 21.0 (TID 268) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 9, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:08 INFO Executor: Running task 9.0 in stage 21.0 (TID 268)\n",
      "25/11/13 15:03:08 INFO TaskSetManager: Finished task 7.0 in stage 21.0 (TID 266) in 100 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (8/50)\n",
      "25/11/13 15:03:08 INFO BlockManager: Found block rdd_14_8 locally\n",
      "25/11/13 15:03:08 INFO Executor: Finished task 8.0 in stage 21.0 (TID 267). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:08 INFO TaskSetManager: Starting task 10.0 in stage 21.0 (TID 269) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 10, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:08 INFO TaskSetManager: Finished task 8.0 in stage 21.0 (TID 267) in 100 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (9/50)\n",
      "25/11/13 15:03:08 INFO Executor: Running task 10.0 in stage 21.0 (TID 269)\n",
      "25/11/13 15:03:08 INFO BlockManager: Found block rdd_14_9 locally\n",
      "25/11/13 15:03:08 INFO Executor: Finished task 9.0 in stage 21.0 (TID 268). 4224 bytes result sent to driver\n",
      "25/11/13 15:03:08 INFO TaskSetManager: Starting task 11.0 in stage 21.0 (TID 270) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 11, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:08 INFO Executor: Running task 11.0 in stage 21.0 (TID 270)\n",
      "25/11/13 15:03:08 INFO TaskSetManager: Finished task 9.0 in stage 21.0 (TID 268) in 62 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (10/50)\n",
      "25/11/13 15:03:08 INFO BlockManager: Found block rdd_14_10 locally\n",
      "25/11/13 15:03:08 INFO Executor: Finished task 10.0 in stage 21.0 (TID 269). 4224 bytes result sent to driver\n",
      "25/11/13 15:03:08 INFO TaskSetManager: Starting task 12.0 in stage 21.0 (TID 271) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 12, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:08 INFO TaskSetManager: Finished task 10.0 in stage 21.0 (TID 269) in 126 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (11/50)\n",
      "25/11/13 15:03:08 INFO Executor: Running task 12.0 in stage 21.0 (TID 271)\n",
      "25/11/13 15:03:08 INFO BlockManager: Found block rdd_14_11 locally\n",
      "25/11/13 15:03:08 INFO Executor: Finished task 11.0 in stage 21.0 (TID 270). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:08 INFO TaskSetManager: Starting task 13.0 in stage 21.0 (TID 272) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 13, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:08 INFO TaskSetManager: Finished task 11.0 in stage 21.0 (TID 270) in 96 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (12/50)\n",
      "25/11/13 15:03:08 INFO Executor: Running task 13.0 in stage 21.0 (TID 272)\n",
      "25/11/13 15:03:08 INFO BlockManager: Found block rdd_14_12 locally\n",
      "25/11/13 15:03:08 INFO Executor: Finished task 12.0 in stage 21.0 (TID 271). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:08 INFO TaskSetManager: Starting task 14.0 in stage 21.0 (TID 273) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 14, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:08 INFO TaskSetManager: Finished task 12.0 in stage 21.0 (TID 271) in 100 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (13/50)\n",
      "25/11/13 15:03:08 INFO Executor: Running task 14.0 in stage 21.0 (TID 273)\n",
      "25/11/13 15:03:08 INFO BlockManager: Found block rdd_14_13 locally(13 + 2) / 50]\n",
      "25/11/13 15:03:08 INFO Executor: Finished task 13.0 in stage 21.0 (TID 272). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:08 INFO TaskSetManager: Starting task 15.0 in stage 21.0 (TID 274) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 15, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:08 INFO Executor: Running task 15.0 in stage 21.0 (TID 274)\n",
      "25/11/13 15:03:08 INFO TaskSetManager: Finished task 13.0 in stage 21.0 (TID 272) in 100 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (14/50)\n",
      "25/11/13 15:03:08 INFO BlockManagerInfo: Removed broadcast_17_piece0 on jupyter-spark-758b7c86d8-7j77n:43517 in memory (size: 36.6 KiB, free: 1048.6 MiB)\n",
      "25/11/13 15:03:08 INFO BlockManager: Found block rdd_14_14 locally\n",
      "25/11/13 15:03:08 INFO BlockManagerInfo: Removed broadcast_18_piece0 on jupyter-spark-758b7c86d8-7j77n:43517 in memory (size: 19.6 KiB, free: 1048.6 MiB)\n",
      "25/11/13 15:03:08 INFO Executor: Finished task 14.0 in stage 21.0 (TID 273). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:08 INFO TaskSetManager: Starting task 16.0 in stage 21.0 (TID 275) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 16, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:08 INFO TaskSetManager: Finished task 14.0 in stage 21.0 (TID 273) in 241 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (15/50)\n",
      "25/11/13 15:03:08 INFO Executor: Running task 16.0 in stage 21.0 (TID 275)\n",
      "25/11/13 15:03:08 INFO BlockManager: Found block rdd_14_15 locally\n",
      "25/11/13 15:03:08 INFO Executor: Finished task 15.0 in stage 21.0 (TID 274). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:08 INFO TaskSetManager: Starting task 17.0 in stage 21.0 (TID 276) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 17, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:08 INFO Executor: Running task 17.0 in stage 21.0 (TID 276)\n",
      "25/11/13 15:03:08 INFO TaskSetManager: Finished task 15.0 in stage 21.0 (TID 274) in 251 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (16/50)\n",
      "25/11/13 15:03:08 INFO BlockManager: Found block rdd_14_16 locally\n",
      "25/11/13 15:03:08 INFO Executor: Finished task 16.0 in stage 21.0 (TID 275). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:08 INFO TaskSetManager: Starting task 18.0 in stage 21.0 (TID 277) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 18, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:08 INFO Executor: Running task 18.0 in stage 21.0 (TID 277)\n",
      "25/11/13 15:03:08 INFO TaskSetManager: Finished task 16.0 in stage 21.0 (TID 275) in 108 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (17/50)\n",
      "25/11/13 15:03:08 INFO BlockManager: Found block rdd_14_17 locally\n",
      "25/11/13 15:03:08 INFO Executor: Finished task 17.0 in stage 21.0 (TID 276). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:08 INFO TaskSetManager: Starting task 19.0 in stage 21.0 (TID 278) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 19, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:08 INFO TaskSetManager: Finished task 17.0 in stage 21.0 (TID 276) in 107 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (18/50)\n",
      "25/11/13 15:03:08 INFO Executor: Running task 19.0 in stage 21.0 (TID 278)\n",
      "25/11/13 15:03:08 INFO BlockManager: Found block rdd_14_18 locally(18 + 2) / 50]\n",
      "25/11/13 15:03:08 INFO Executor: Finished task 18.0 in stage 21.0 (TID 277). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:08 INFO TaskSetManager: Starting task 20.0 in stage 21.0 (TID 279) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 20, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:08 INFO TaskSetManager: Finished task 18.0 in stage 21.0 (TID 277) in 98 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (19/50)\n",
      "25/11/13 15:03:08 INFO Executor: Running task 20.0 in stage 21.0 (TID 279)\n",
      "25/11/13 15:03:08 INFO BlockManager: Found block rdd_14_19 locally\n",
      "25/11/13 15:03:08 INFO Executor: Finished task 19.0 in stage 21.0 (TID 278). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:08 INFO TaskSetManager: Starting task 21.0 in stage 21.0 (TID 280) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 21, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:08 INFO Executor: Running task 21.0 in stage 21.0 (TID 280)\n",
      "25/11/13 15:03:08 INFO TaskSetManager: Finished task 19.0 in stage 21.0 (TID 278) in 99 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (20/50)\n",
      "25/11/13 15:03:08 INFO BlockManager: Found block rdd_14_20 locally\n",
      "25/11/13 15:03:08 INFO Executor: Finished task 20.0 in stage 21.0 (TID 279). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:08 INFO BlockManager: Found block rdd_14_21 locally\n",
      "25/11/13 15:03:08 INFO TaskSetManager: Starting task 22.0 in stage 21.0 (TID 281) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 22, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:08 INFO Executor: Running task 22.0 in stage 21.0 (TID 281)\n",
      "25/11/13 15:03:08 INFO TaskSetManager: Finished task 20.0 in stage 21.0 (TID 279) in 108 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (21/50)\n",
      "25/11/13 15:03:08 INFO Executor: Finished task 21.0 in stage 21.0 (TID 280). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:08 INFO TaskSetManager: Starting task 23.0 in stage 21.0 (TID 282) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 23, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:08 INFO TaskSetManager: Finished task 21.0 in stage 21.0 (TID 280) in 58 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (22/50)\n",
      "25/11/13 15:03:08 INFO Executor: Running task 23.0 in stage 21.0 (TID 282)\n",
      "25/11/13 15:03:08 INFO BlockManager: Found block rdd_14_22 locally\n",
      "25/11/13 15:03:08 INFO Executor: Finished task 22.0 in stage 21.0 (TID 281). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:08 INFO TaskSetManager: Starting task 24.0 in stage 21.0 (TID 283) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 24, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:08 INFO TaskSetManager: Finished task 22.0 in stage 21.0 (TID 281) in 56 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (23/50)\n",
      "25/11/13 15:03:08 INFO Executor: Running task 24.0 in stage 21.0 (TID 283)\n",
      "25/11/13 15:03:08 INFO BlockManager: Found block rdd_14_23 locally\n",
      "25/11/13 15:03:08 INFO Executor: Finished task 23.0 in stage 21.0 (TID 282). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:08 INFO TaskSetManager: Starting task 25.0 in stage 21.0 (TID 284) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 25, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:08 INFO TaskSetManager: Finished task 23.0 in stage 21.0 (TID 282) in 77 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (24/50)\n",
      "25/11/13 15:03:08 INFO Executor: Running task 25.0 in stage 21.0 (TID 284)\n",
      "25/11/13 15:03:08 INFO BlockManager: Found block rdd_14_24 locally\n",
      "25/11/13 15:03:08 INFO Executor: Finished task 24.0 in stage 21.0 (TID 283). 4267 bytes result sent to driver\n",
      "25/11/13 15:03:08 INFO TaskSetManager: Starting task 26.0 in stage 21.0 (TID 285) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 26, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:08 INFO Executor: Running task 26.0 in stage 21.0 (TID 285)\n",
      "25/11/13 15:03:08 INFO TaskSetManager: Finished task 24.0 in stage 21.0 (TID 283) in 54 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (25/50)\n",
      "25/11/13 15:03:09 INFO BlockManager: Found block rdd_14_25 locally\n",
      "25/11/13 15:03:09 INFO Executor: Finished task 25.0 in stage 21.0 (TID 284). 4224 bytes result sent to driver\n",
      "25/11/13 15:03:09 INFO TaskSetManager: Starting task 27.0 in stage 21.0 (TID 286) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 27, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:09 INFO TaskSetManager: Finished task 25.0 in stage 21.0 (TID 284) in 77 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (26/50)\n",
      "25/11/13 15:03:09 INFO Executor: Running task 27.0 in stage 21.0 (TID 286)\n",
      "25/11/13 15:03:09 INFO BlockManager: Found block rdd_14_26 locally\n",
      "25/11/13 15:03:09 INFO Executor: Finished task 26.0 in stage 21.0 (TID 285). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:09 INFO TaskSetManager: Starting task 28.0 in stage 21.0 (TID 287) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 28, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:09 INFO Executor: Running task 28.0 in stage 21.0 (TID 287)\n",
      "25/11/13 15:03:09 INFO TaskSetManager: Finished task 26.0 in stage 21.0 (TID 285) in 73 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (27/50)\n",
      "25/11/13 15:03:09 INFO BlockManager: Found block rdd_14_27 locally\n",
      "25/11/13 15:03:09 INFO Executor: Finished task 27.0 in stage 21.0 (TID 286). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:09 INFO TaskSetManager: Starting task 29.0 in stage 21.0 (TID 288) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 29, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:09 INFO Executor: Running task 29.0 in stage 21.0 (TID 288)\n",
      "25/11/13 15:03:09 INFO TaskSetManager: Finished task 27.0 in stage 21.0 (TID 286) in 40 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (28/50)\n",
      "25/11/13 15:03:09 INFO BlockManager: Found block rdd_14_28 locally\n",
      "25/11/13 15:03:09 INFO Executor: Finished task 28.0 in stage 21.0 (TID 287). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:09 INFO TaskSetManager: Starting task 30.0 in stage 21.0 (TID 289) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 30, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:09 INFO Executor: Running task 30.0 in stage 21.0 (TID 289)\n",
      "25/11/13 15:03:09 INFO TaskSetManager: Finished task 28.0 in stage 21.0 (TID 287) in 25 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (29/50)\n",
      "25/11/13 15:03:09 INFO BlockManager: Found block rdd_14_29 locally\n",
      "25/11/13 15:03:09 INFO Executor: Finished task 29.0 in stage 21.0 (TID 288). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:09 INFO TaskSetManager: Starting task 31.0 in stage 21.0 (TID 290) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 31, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:09 INFO TaskSetManager: Finished task 29.0 in stage 21.0 (TID 288) in 79 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (30/50)\n",
      "25/11/13 15:03:09 INFO Executor: Running task 31.0 in stage 21.0 (TID 290)\n",
      "25/11/13 15:03:09 INFO BlockManager: Found block rdd_14_30 locally\n",
      "25/11/13 15:03:09 INFO Executor: Finished task 30.0 in stage 21.0 (TID 289). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:09 INFO TaskSetManager: Starting task 32.0 in stage 21.0 (TID 291) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 32, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:09 INFO TaskSetManager: Finished task 30.0 in stage 21.0 (TID 289) in 80 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (31/50)\n",
      "25/11/13 15:03:09 INFO Executor: Running task 32.0 in stage 21.0 (TID 291)\n",
      "25/11/13 15:03:09 INFO BlockManager: Found block rdd_14_31 locally\n",
      "25/11/13 15:03:09 INFO Executor: Finished task 31.0 in stage 21.0 (TID 290). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:09 INFO TaskSetManager: Starting task 33.0 in stage 21.0 (TID 292) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 33, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:09 INFO Executor: Running task 33.0 in stage 21.0 (TID 292)\n",
      "25/11/13 15:03:09 INFO TaskSetManager: Finished task 31.0 in stage 21.0 (TID 290) in 46 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (32/50)\n",
      "25/11/13 15:03:09 INFO BlockManager: Found block rdd_14_32 locally(31 + 3) / 50]\n",
      "25/11/13 15:03:09 INFO Executor: Finished task 32.0 in stage 21.0 (TID 291). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:09 INFO TaskSetManager: Starting task 34.0 in stage 21.0 (TID 293) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 34, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:09 INFO Executor: Running task 34.0 in stage 21.0 (TID 293)\n",
      "25/11/13 15:03:09 INFO TaskSetManager: Finished task 32.0 in stage 21.0 (TID 291) in 61 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (33/50)\n",
      "25/11/13 15:03:09 INFO BlockManager: Found block rdd_14_33 locally\n",
      "25/11/13 15:03:09 INFO Executor: Finished task 33.0 in stage 21.0 (TID 292). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:09 INFO TaskSetManager: Starting task 35.0 in stage 21.0 (TID 294) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 35, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:09 INFO TaskSetManager: Finished task 33.0 in stage 21.0 (TID 292) in 81 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (34/50)\n",
      "25/11/13 15:03:09 INFO Executor: Running task 35.0 in stage 21.0 (TID 294)\n",
      "25/11/13 15:03:09 INFO BlockManager: Found block rdd_14_34 locally\n",
      "25/11/13 15:03:09 INFO Executor: Finished task 34.0 in stage 21.0 (TID 293). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:09 INFO TaskSetManager: Starting task 36.0 in stage 21.0 (TID 295) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 36, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:09 INFO TaskSetManager: Finished task 34.0 in stage 21.0 (TID 293) in 42 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (35/50)\n",
      "25/11/13 15:03:09 INFO Executor: Running task 36.0 in stage 21.0 (TID 295)\n",
      "25/11/13 15:03:09 INFO BlockManager: Found block rdd_14_35 locally\n",
      "25/11/13 15:03:09 INFO Executor: Finished task 35.0 in stage 21.0 (TID 294). 4224 bytes result sent to driver\n",
      "25/11/13 15:03:09 INFO TaskSetManager: Starting task 37.0 in stage 21.0 (TID 296) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 37, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:09 INFO Executor: Running task 37.0 in stage 21.0 (TID 296)\n",
      "25/11/13 15:03:09 INFO TaskSetManager: Finished task 35.0 in stage 21.0 (TID 294) in 61 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (36/50)\n",
      "25/11/13 15:03:09 INFO BlockManager: Found block rdd_14_36 locally\n",
      "25/11/13 15:03:09 INFO Executor: Finished task 36.0 in stage 21.0 (TID 295). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:09 INFO TaskSetManager: Starting task 38.0 in stage 21.0 (TID 297) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 38, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:09 INFO Executor: Running task 38.0 in stage 21.0 (TID 297)\n",
      "25/11/13 15:03:09 INFO TaskSetManager: Finished task 36.0 in stage 21.0 (TID 295) in 89 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (37/50)\n",
      "25/11/13 15:03:09 INFO BlockManager: Found block rdd_14_37 locally\n",
      "25/11/13 15:03:09 INFO Executor: Finished task 37.0 in stage 21.0 (TID 296). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:09 INFO TaskSetManager: Starting task 39.0 in stage 21.0 (TID 298) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 39, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:09 INFO TaskSetManager: Finished task 37.0 in stage 21.0 (TID 296) in 47 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (38/50)\n",
      "25/11/13 15:03:09 INFO Executor: Running task 39.0 in stage 21.0 (TID 298)\n",
      "25/11/13 15:03:09 INFO BlockManager: Found block rdd_14_38 locally\n",
      "25/11/13 15:03:09 INFO Executor: Finished task 38.0 in stage 21.0 (TID 297). 4224 bytes result sent to driver\n",
      "25/11/13 15:03:09 INFO TaskSetManager: Starting task 40.0 in stage 21.0 (TID 299) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 40, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:09 INFO TaskSetManager: Finished task 38.0 in stage 21.0 (TID 297) in 46 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (39/50)\n",
      "25/11/13 15:03:09 INFO Executor: Running task 40.0 in stage 21.0 (TID 299)\n",
      "25/11/13 15:03:09 INFO BlockManager: Found block rdd_14_39 locally(39 + 2) / 50]\n",
      "25/11/13 15:03:09 INFO Executor: Finished task 39.0 in stage 21.0 (TID 298). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:09 INFO TaskSetManager: Starting task 41.0 in stage 21.0 (TID 300) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 41, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:09 INFO Executor: Running task 41.0 in stage 21.0 (TID 300)\n",
      "25/11/13 15:03:09 INFO TaskSetManager: Finished task 39.0 in stage 21.0 (TID 298) in 61 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (40/50)\n",
      "25/11/13 15:03:09 INFO BlockManager: Found block rdd_14_40 locally\n",
      "25/11/13 15:03:09 INFO Executor: Finished task 40.0 in stage 21.0 (TID 299). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:09 INFO TaskSetManager: Starting task 42.0 in stage 21.0 (TID 301) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 42, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:09 INFO Executor: Running task 42.0 in stage 21.0 (TID 301)\n",
      "25/11/13 15:03:09 INFO TaskSetManager: Finished task 40.0 in stage 21.0 (TID 299) in 83 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (41/50)\n",
      "25/11/13 15:03:09 INFO BlockManager: Found block rdd_14_41 locally\n",
      "25/11/13 15:03:09 INFO Executor: Finished task 41.0 in stage 21.0 (TID 300). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:09 INFO TaskSetManager: Starting task 43.0 in stage 21.0 (TID 302) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 43, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:09 INFO Executor: Running task 43.0 in stage 21.0 (TID 302)\n",
      "25/11/13 15:03:09 INFO TaskSetManager: Finished task 41.0 in stage 21.0 (TID 300) in 41 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (42/50)\n",
      "25/11/13 15:03:09 INFO BlockManager: Found block rdd_14_42 locally\n",
      "25/11/13 15:03:09 INFO Executor: Finished task 42.0 in stage 21.0 (TID 301). 4224 bytes result sent to driver\n",
      "25/11/13 15:03:09 INFO TaskSetManager: Starting task 44.0 in stage 21.0 (TID 303) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 44, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:09 INFO Executor: Running task 44.0 in stage 21.0 (TID 303)\n",
      "25/11/13 15:03:09 INFO TaskSetManager: Finished task 42.0 in stage 21.0 (TID 301) in 121 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (43/50)\n",
      "25/11/13 15:03:09 INFO BlockManager: Found block rdd_14_43 locally\n",
      "25/11/13 15:03:09 INFO Executor: Finished task 43.0 in stage 21.0 (TID 302). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:09 INFO TaskSetManager: Starting task 45.0 in stage 21.0 (TID 304) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 45, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:09 INFO TaskSetManager: Finished task 43.0 in stage 21.0 (TID 302) in 120 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (44/50)\n",
      "25/11/13 15:03:09 INFO Executor: Running task 45.0 in stage 21.0 (TID 304)\n",
      "25/11/13 15:03:09 INFO BlockManager: Found block rdd_14_44 locally\n",
      "25/11/13 15:03:09 INFO Executor: Finished task 44.0 in stage 21.0 (TID 303). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:09 INFO TaskSetManager: Starting task 46.0 in stage 21.0 (TID 305) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 46, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:09 INFO Executor: Running task 46.0 in stage 21.0 (TID 305) / 50]\n",
      "25/11/13 15:03:09 INFO TaskSetManager: Finished task 44.0 in stage 21.0 (TID 303) in 143 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (45/50)\n",
      "25/11/13 15:03:09 INFO BlockManager: Found block rdd_14_45 locally\n",
      "25/11/13 15:03:09 INFO Executor: Finished task 45.0 in stage 21.0 (TID 304). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:09 INFO TaskSetManager: Starting task 47.0 in stage 21.0 (TID 306) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 47, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:09 INFO TaskSetManager: Finished task 45.0 in stage 21.0 (TID 304) in 71 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (46/50)\n",
      "25/11/13 15:03:09 INFO Executor: Running task 47.0 in stage 21.0 (TID 306)\n",
      "25/11/13 15:03:09 INFO BlockManager: Found block rdd_14_46 locally\n",
      "25/11/13 15:03:09 INFO Executor: Finished task 46.0 in stage 21.0 (TID 305). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:09 INFO TaskSetManager: Starting task 48.0 in stage 21.0 (TID 307) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 48, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:09 INFO Executor: Running task 48.0 in stage 21.0 (TID 307)\n",
      "25/11/13 15:03:09 INFO TaskSetManager: Finished task 46.0 in stage 21.0 (TID 305) in 42 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (47/50)\n",
      "25/11/13 15:03:09 INFO BlockManager: Found block rdd_14_47 locally\n",
      "25/11/13 15:03:09 INFO BlockManager: Found block rdd_14_48 locally\n",
      "25/11/13 15:03:09 INFO Executor: Finished task 47.0 in stage 21.0 (TID 306). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:09 INFO TaskSetManager: Starting task 49.0 in stage 21.0 (TID 308) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 49, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:09 INFO Executor: Running task 49.0 in stage 21.0 (TID 308)\n",
      "25/11/13 15:03:09 INFO TaskSetManager: Finished task 47.0 in stage 21.0 (TID 306) in 87 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (48/50)\n",
      "25/11/13 15:03:09 INFO Executor: Finished task 48.0 in stage 21.0 (TID 307). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:09 INFO TaskSetManager: Finished task 48.0 in stage 21.0 (TID 307) in 63 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (49/50)\n",
      "25/11/13 15:03:09 INFO BlockManager: Found block rdd_14_49 locally\n",
      "25/11/13 15:03:09 INFO Executor: Finished task 49.0 in stage 21.0 (TID 308). 4181 bytes result sent to driver\n",
      "25/11/13 15:03:09 INFO TaskSetManager: Finished task 49.0 in stage 21.0 (TID 308) in 41 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (50/50)\n",
      "25/11/13 15:03:09 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool \n",
      "25/11/13 15:03:09 INFO DAGScheduler: ResultStage 21 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 2.022 s\n",
      "25/11/13 15:03:09 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/11/13 15:03:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 21: Stage finished\n",
      "25/11/13 15:03:09 INFO DAGScheduler: Job 12 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 2.030558 s\n",
      "25/11/13 15:03:09 INFO PrepareDeltaScan: DELTA: Done                            \n",
      "25/11/13 15:03:09 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/11/13 15:03:09 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/11/13 15:03:09 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/11/13 15:03:09 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/11/13 15:03:09 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/11/13 15:03:09 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "25/11/13 15:03:10 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 206.2 KiB, free 1047.3 MiB)\n",
      "25/11/13 15:03:10 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 36.6 KiB, free 1047.3 MiB)\n",
      "25/11/13 15:03:10 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 36.6 KiB, free: 1048.5 MiB)\n",
      "25/11/13 15:03:10 INFO BlockManagerInfo: Removed broadcast_20_piece0 on jupyter-spark-758b7c86d8-7j77n:43517 in memory (size: 154.5 KiB, free: 1048.7 MiB)\n",
      "25/11/13 15:03:10 INFO SparkContext: Created broadcast 21 from save at NativeMethodAccessorImpl.java:0\n",
      "25/11/13 15:03:10 INFO FileSourceScanExec: Planning scan with bin packing, max size: 15790468 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/11/13 15:03:10 INFO DAGScheduler: Registering RDD 60 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 3\n",
      "25/11/13 15:03:10 INFO DAGScheduler: Got map stage job 13 (save at NativeMethodAccessorImpl.java:0) with 2 output partitions\n",
      "25/11/13 15:03:10 INFO DAGScheduler: Final stage: ShuffleMapStage 22 (save at NativeMethodAccessorImpl.java:0)\n",
      "25/11/13 15:03:10 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/11/13 15:03:10 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 15:03:10 INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[60] at save at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/11/13 15:03:10 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 32.3 KiB, free 1048.1 MiB)\n",
      "25/11/13 15:03:10 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 12.0 KiB, free 1048.0 MiB)\n",
      "25/11/13 15:03:10 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 12.0 KiB, free: 1048.7 MiB)\n",
      "25/11/13 15:03:10 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 15:03:10 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[60] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))\n",
      "25/11/13 15:03:10 INFO TaskSchedulerImpl: Adding task set 22.0 with 2 tasks resource profile 0\n",
      "25/11/13 15:03:10 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 309) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 9661 bytes) \n",
      "25/11/13 15:03:10 INFO TaskSetManager: Starting task 1.0 in stage 22.0 (TID 310) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 1, PROCESS_LOCAL, 9661 bytes) \n",
      "25/11/13 15:03:10 INFO Executor: Running task 0.0 in stage 22.0 (TID 309)\n",
      "25/11/13 15:03:10 INFO Executor: Running task 1.0 in stage 22.0 (TID 310)\n",
      "25/11/13 15:03:10 INFO FileScanRDD: Reading File path: s3a://nau-local-analytics-bronze/auth_user/part-00000-328279f1-d4eb-469c-bf96-b8fd585b9f62-c000.snappy.parquet, range: 0-15790468, partition values: [empty row]\n",
      "25/11/13 15:03:10 INFO FileScanRDD: Reading File path: s3a://nau-local-analytics-bronze/auth_user/part-00000-328279f1-d4eb-469c-bf96-b8fd585b9f62-c000.snappy.parquet, range: 15790468-27386633, partition values: [empty row]\n",
      "25/11/13 15:03:10 INFO S3AInputStream: Switching to Random IO seek policy\n",
      "25/11/13 15:03:10 INFO S3AInputStream: Switching to Random IO seek policy\n",
      "25/11/13 15:03:10 INFO Executor: Finished task 1.0 in stage 22.0 (TID 310). 1841 bytes result sent to driver\n",
      "25/11/13 15:03:10 INFO TaskSetManager: Finished task 1.0 in stage 22.0 (TID 310) in 215 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/2)\n",
      "25/11/13 15:03:15 INFO Executor: Finished task 0.0 in stage 22.0 (TID 309). 2056 bytes result sent to driver\n",
      "25/11/13 15:03:15 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 309) in 5414 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (2/2)\n",
      "25/11/13 15:03:15 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool \n",
      "25/11/13 15:03:15 INFO DAGScheduler: ShuffleMapStage 22 (save at NativeMethodAccessorImpl.java:0) finished in 5.430 s\n",
      "25/11/13 15:03:15 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/11/13 15:03:15 INFO DAGScheduler: running: Set()\n",
      "25/11/13 15:03:15 INFO DAGScheduler: waiting: Set()\n",
      "25/11/13 15:03:15 INFO DAGScheduler: failed: Set()\n",
      "25/11/13 15:03:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/11/13 15:03:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/11/13 15:03:15 INFO CodeGenerator: Code generated in 14.830116 ms\n",
      "25/11/13 15:03:15 INFO CodeGenerator: Code generated in 12.142232 ms\n",
      "25/11/13 15:03:15 INFO SparkContext: Starting job: save at NativeMethodAccessorImpl.java:0\n",
      "25/11/13 15:03:15 INFO DAGScheduler: Got job 14 (save at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/11/13 15:03:15 INFO DAGScheduler: Final stage: ResultStage 24 (save at NativeMethodAccessorImpl.java:0)\n",
      "25/11/13 15:03:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 23)\n",
      "25/11/13 15:03:15 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 15:03:15 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[65] at save at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/11/13 15:03:15 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 383.5 KiB, free 1047.7 MiB)\n",
      "25/11/13 15:03:15 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 138.3 KiB, free 1047.5 MiB)\n",
      "25/11/13 15:03:15 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 138.3 KiB, free: 1048.5 MiB)\n",
      "25/11/13 15:03:16 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 15:03:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[65] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/11/13 15:03:16 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks resource profile 0\n",
      "25/11/13 15:03:16 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 311) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, NODE_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:16 INFO Executor: Running task 0.0 in stage 24.0 (TID 311)\n",
      "25/11/13 15:03:16 INFO ShuffleBlockFetcherIterator: Getting 1 (84.5 MiB) non-empty blocks including 1 (84.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:03:16 INFO CodeGenerator: Code generated in 16.303448 ms\n",
      "25/11/13 15:03:16 INFO CodeGenerator: Code generated in 7.843625 ms\n",
      "25/11/13 15:03:16 INFO BlockManagerInfo: Removed broadcast_22_piece0 on jupyter-spark-758b7c86d8-7j77n:43517 in memory (size: 12.0 KiB, free: 1048.6 MiB)\n",
      "25/11/13 15:03:17 INFO CodeGenerator: Code generated in 13.261452 ms\n",
      "25/11/13 15:03:17 INFO CodeGenerator: Code generated in 189.66659 ms\n",
      "25/11/13 15:03:17 INFO CodeGenerator: Code generated in 38.022151 ms\n",
      "25/11/13 15:03:18 INFO CodeGenerator: Code generated in 62.779365 ms\n",
      "25/11/13 15:03:18 INFO CodeGenerator: Code generated in 6.563698 ms\n",
      "25/11/13 15:03:18 INFO CodecConfig: Compression: SNAPPY\n",
      "25/11/13 15:03:18 INFO CodecConfig: Compression: SNAPPY\n",
      "25/11/13 15:03:18 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]\n",
      "25/11/13 15:03:18 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"user_sk\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"user_id\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"username\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(150)\",\n",
      "      \"isSigned\" : false,\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"email\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(254)\",\n",
      "      \"isSigned\" : false,\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"first_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(150)\",\n",
      "      \"isSigned\" : false,\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"last_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(150)\",\n",
      "      \"isSigned\" : false,\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"full_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"is_staff\",\n",
      "    \"type\" : \"boolean\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"isSigned\" : false,\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"is_superuser\",\n",
      "    \"type\" : \"boolean\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"isSigned\" : false,\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"is_active\",\n",
      "    \"type\" : \"boolean\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"isSigned\" : false,\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"date_joined\",\n",
      "    \"type\" : \"timestamp\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"isSigned\" : false,\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"last_login\",\n",
      "    \"type\" : \"timestamp\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"isSigned\" : false,\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"user_hash\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ingestion_date\",\n",
      "    \"type\" : \"timestamp\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"source_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional int32 user_sk;\n",
      "  optional int32 user_id;\n",
      "  optional binary username (STRING);\n",
      "  optional binary email (STRING);\n",
      "  optional binary first_name (STRING);\n",
      "  optional binary last_name (STRING);\n",
      "  optional binary full_name (STRING);\n",
      "  optional boolean is_staff;\n",
      "  optional boolean is_superuser;\n",
      "  optional boolean is_active;\n",
      "  optional int96 date_joined;\n",
      "  optional int96 last_login;\n",
      "  optional binary user_hash (STRING);\n",
      "  optional int96 ingestion_date;\n",
      "  optional binary source_name (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "25/11/13 15:03:18 INFO CodecPool: Got brand-new compressor [.snappy]\n",
      "25/11/13 15:03:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter\n",
      "25/11/13 15:03:32 INFO Executor: Finished task 0.0 in stage 24.0 (TID 311). 7696 bytes result sent to driver\n",
      "25/11/13 15:03:32 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 311) in 16542 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/1)\n",
      "25/11/13 15:03:32 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool \n",
      "25/11/13 15:03:32 INFO DAGScheduler: ResultStage 24 (save at NativeMethodAccessorImpl.java:0) finished in 16.642 s\n",
      "25/11/13 15:03:32 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/11/13 15:03:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 24: Stage finished\n",
      "25/11/13 15:03:32 INFO DAGScheduler: Job 14 finished: save at NativeMethodAccessorImpl.java:0, took 16.653682 s\n",
      "25/11/13 15:03:32 INFO DeltaFileFormatWriter: Start to commit write Job 2454d9ae-df4f-43f1-83ec-67c43639dd06.\n",
      "25/11/13 15:03:32 INFO DeltaFileFormatWriter: Write Job 2454d9ae-df4f-43f1-83ec-67c43639dd06 committed. Elapsed time: 2 ms.\n",
      "25/11/13 15:03:32 INFO DeltaFileFormatWriter: Finished processing stats for write job 2454d9ae-df4f-43f1-83ec-67c43639dd06.\n",
      "25/11/13 15:03:33 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128\n",
      "25/11/13 15:03:33 INFO DAGScheduler: Job 15 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.000416 s\n",
      "25/11/13 15:03:33 INFO OptimisticTransaction: [tableId=1c188fdf,txnId=75bac33c] Attempting to commit version 0 with 4 actions with Serializable isolation level\n",
      "25/11/13 15:03:34 INFO DeltaLog: Creating a new snapshot v0 for commit version 0\n",
      "25/11/13 15:03:34 INFO DeltaLog: Loading version 0.\n",
      "25/11/13 15:03:34 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(JSON, numFilesInSegment: 1, totalFileSize: 3603)\n",
      "25/11/13 15:03:34 INFO DataSourceStrategy: Pruning directories with: \n",
      "25/11/13 15:03:34 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/11/13 15:03:34 INFO FileSourceStrategy: Post-Scan Filters: ((isnotnull(protocol#2083.minReaderVersion) OR isnotnull(metaData#2082.id)) OR (isnotnull(commitInfo#2084.inCommitTimestamp) AND (version#2085L = 0)))\n",
      "25/11/13 15:03:34 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 202.9 KiB, free 1047.4 MiB)\n",
      "25/11/13 15:03:34 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 35.5 KiB, free 1047.3 MiB)\n",
      "25/11/13 15:03:34 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 35.5 KiB, free: 1048.5 MiB)\n",
      "25/11/13 15:03:34 INFO SparkContext: Created broadcast 24 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128\n",
      "25/11/13 15:03:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/11/13 15:03:34 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128\n",
      "25/11/13 15:03:34 INFO DAGScheduler: Got job 16 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions\n",
      "25/11/13 15:03:34 INFO DAGScheduler: Final stage: ResultStage 25 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)\n",
      "25/11/13 15:03:34 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/11/13 15:03:34 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 15:03:34 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[73] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents\n",
      "25/11/13 15:03:34 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 55.2 KiB, free 1047.3 MiB)\n",
      "25/11/13 15:03:34 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1047.3 MiB)\n",
      "25/11/13 15:03:34 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 17.1 KiB, free: 1048.5 MiB)\n",
      "25/11/13 15:03:34 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 15:03:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[73] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))\n",
      "25/11/13 15:03:34 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks resource profile 0\n",
      "25/11/13 15:03:34 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 312) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 9691 bytes) \n",
      "25/11/13 15:03:34 INFO Executor: Running task 0.0 in stage 25.0 (TID 312)\n",
      "25/11/13 15:03:34 INFO FileScanRDD: Reading File path: s3a://nau-local-analytics-silver/dim_user/_delta_log/00000000000000000000.json, range: 0-3603, partition values: [0]\n",
      "25/11/13 15:03:34 INFO Executor: Finished task 0.0 in stage 25.0 (TID 312). 2152 bytes result sent to driver\n",
      "25/11/13 15:03:34 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 312) in 70 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/1)\n",
      "25/11/13 15:03:34 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool \n",
      "25/11/13 15:03:34 INFO DAGScheduler: ResultStage 25 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.082 s\n",
      "25/11/13 15:03:34 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/11/13 15:03:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 25: Stage finished\n",
      "25/11/13 15:03:34 INFO DAGScheduler: Job 16 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.095774 s\n",
      "25/11/13 15:03:34 INFO Snapshot: [tableId=1c188fdf-4b2c-4f32-8cf2-0835b9075d7a] Created snapshot Snapshot(path=s3a://nau-local-analytics-silver/dim_user/_delta_log, version=0, metadata=Metadata(d97aed6f-8e73-4258-85f1-83735790c6dc,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"user_sk\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"user_id\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"username\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(150)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"email\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(254)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"first_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(150)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"last_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(150)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"full_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"is_staff\",\"type\":\"boolean\",\"nullable\":true,\"metadata\":{\"isSigned\":false,\"scale\":0}},{\"name\":\"is_superuser\",\"type\":\"boolean\",\"nullable\":true,\"metadata\":{\"isSigned\":false,\"scale\":0}},{\"name\":\"is_active\",\"type\":\"boolean\",\"nullable\":true,\"metadata\":{\"isSigned\":false,\"scale\":0}},{\"name\":\"date_joined\",\"type\":\"timestamp\",\"nullable\":true,\"metadata\":{\"isSigned\":false,\"scale\":0}},{\"name\":\"last_login\",\"type\":\"timestamp\",\"nullable\":true,\"metadata\":{\"isSigned\":false,\"scale\":0}},{\"name\":\"user_hash\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"ingestion_date\",\"type\":\"timestamp\",\"nullable\":true,\"metadata\":{}},{\"name\":\"source_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1763046186814)), logSegment=LogSegment(s3a://nau-local-analytics-silver/dim_user/_delta_log,0,List(S3AFileStatus{path=s3a://nau-local-analytics-silver/dim_user/_delta_log/00000000000000000000.json; isDirectory=false; length=3603; replication=1; blocksize=33554432; modification_time=1763046214000; access_time=0; owner=spark; group=spark; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=c281f4db384829085eea0acce4c7d3f0 versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@65a2ce0d,1763046214000), checksumOpt=None)\n",
      "25/11/13 15:03:34 INFO DeltaLog: Updated snapshot to Snapshot(path=s3a://nau-local-analytics-silver/dim_user/_delta_log, version=0, metadata=Metadata(d97aed6f-8e73-4258-85f1-83735790c6dc,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"user_sk\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"user_id\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"username\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(150)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"email\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(254)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"first_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(150)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"last_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(150)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"full_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"is_staff\",\"type\":\"boolean\",\"nullable\":true,\"metadata\":{\"isSigned\":false,\"scale\":0}},{\"name\":\"is_superuser\",\"type\":\"boolean\",\"nullable\":true,\"metadata\":{\"isSigned\":false,\"scale\":0}},{\"name\":\"is_active\",\"type\":\"boolean\",\"nullable\":true,\"metadata\":{\"isSigned\":false,\"scale\":0}},{\"name\":\"date_joined\",\"type\":\"timestamp\",\"nullable\":true,\"metadata\":{\"isSigned\":false,\"scale\":0}},{\"name\":\"last_login\",\"type\":\"timestamp\",\"nullable\":true,\"metadata\":{\"isSigned\":false,\"scale\":0}},{\"name\":\"user_hash\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"ingestion_date\",\"type\":\"timestamp\",\"nullable\":true,\"metadata\":{}},{\"name\":\"source_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1763046186814)), logSegment=LogSegment(s3a://nau-local-analytics-silver/dim_user/_delta_log,0,List(S3AFileStatus{path=s3a://nau-local-analytics-silver/dim_user/_delta_log/00000000000000000000.json; isDirectory=false; length=3603; replication=1; blocksize=33554432; modification_time=1763046214000; access_time=0; owner=spark; group=spark; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=c281f4db384829085eea0acce4c7d3f0 versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@65a2ce0d,1763046214000), checksumOpt=None)\n",
      "25/11/13 15:03:34 INFO OptimisticTransaction: [tableId=1c188fdf,txnId=75bac33c] Committed delta #0 to s3a://nau-local-analytics-silver/dim_user/_delta_log\n",
      "25/11/13 15:03:35 INFO DeltaLog: Loading version 0.\n",
      "25/11/13 15:03:35 INFO DeltaLogFileIndex: Created DeltaLogFileIndex(JSON, numFilesInSegment: 1, totalFileSize: 3603)\n",
      "25/11/13 15:03:35 INFO BlockManagerInfo: Removed broadcast_25_piece0 on jupyter-spark-758b7c86d8-7j77n:43517 in memory (size: 17.1 KiB, free: 1048.5 MiB)\n",
      "25/11/13 15:03:35 INFO BlockManagerInfo: Removed broadcast_24_piece0 on jupyter-spark-758b7c86d8-7j77n:43517 in memory (size: 35.5 KiB, free: 1048.6 MiB)\n",
      "25/11/13 15:03:35 INFO DataSourceStrategy: Pruning directories with: \n",
      "25/11/13 15:03:35 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/11/13 15:03:35 INFO FileSourceStrategy: Post-Scan Filters: ((isnotnull(protocol#2128.minReaderVersion) OR isnotnull(metaData#2127.id)) OR (isnotnull(commitInfo#2129.inCommitTimestamp) AND (version#2130L = 0)))\n",
      "25/11/13 15:03:35 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 202.9 KiB, free 1047.4 MiB)\n",
      "25/11/13 15:03:35 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 35.5 KiB, free 1047.3 MiB)\n",
      "25/11/13 15:03:35 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 35.5 KiB, free: 1048.5 MiB)\n",
      "25/11/13 15:03:35 INFO SparkContext: Created broadcast 26 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128\n",
      "25/11/13 15:03:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/11/13 15:03:35 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128\n",
      "25/11/13 15:03:35 INFO DAGScheduler: Got job 17 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions\n",
      "25/11/13 15:03:35 INFO DAGScheduler: Final stage: ResultStage 26 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)\n",
      "25/11/13 15:03:35 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/11/13 15:03:35 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 15:03:35 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[77] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents\n",
      "25/11/13 15:03:35 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 55.2 KiB, free 1047.3 MiB)\n",
      "25/11/13 15:03:35 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1047.3 MiB)\n",
      "25/11/13 15:03:35 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 17.1 KiB, free: 1048.5 MiB)\n",
      "25/11/13 15:03:35 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 15:03:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[77] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))\n",
      "25/11/13 15:03:35 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks resource profile 0\n",
      "25/11/13 15:03:35 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 313) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 9691 bytes) \n",
      "25/11/13 15:03:35 INFO Executor: Running task 0.0 in stage 26.0 (TID 313)\n",
      "25/11/13 15:03:35 INFO FileScanRDD: Reading File path: s3a://nau-local-analytics-silver/dim_user/_delta_log/00000000000000000000.json, range: 0-3603, partition values: [0]\n",
      "25/11/13 15:03:35 INFO Executor: Finished task 0.0 in stage 26.0 (TID 313). 2152 bytes result sent to driver\n",
      "25/11/13 15:03:35 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 313) in 106 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/1)\n",
      "25/11/13 15:03:35 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool \n",
      "25/11/13 15:03:35 INFO DAGScheduler: ResultStage 26 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.131 s\n",
      "25/11/13 15:03:35 INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/11/13 15:03:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 26: Stage finished\n",
      "25/11/13 15:03:35 INFO DAGScheduler: Job 17 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.136652 s\n",
      "25/11/13 15:03:35 INFO Snapshot: [tableId=d97aed6f-8e73-4258-85f1-83735790c6dc] Created snapshot Snapshot(path=s3a://nau-local-analytics-silver/dim_user/_delta_log, version=0, metadata=Metadata(d97aed6f-8e73-4258-85f1-83735790c6dc,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"user_sk\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"user_id\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"username\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(150)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"email\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(254)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"first_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(150)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"last_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(150)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"full_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"is_staff\",\"type\":\"boolean\",\"nullable\":true,\"metadata\":{\"isSigned\":false,\"scale\":0}},{\"name\":\"is_superuser\",\"type\":\"boolean\",\"nullable\":true,\"metadata\":{\"isSigned\":false,\"scale\":0}},{\"name\":\"is_active\",\"type\":\"boolean\",\"nullable\":true,\"metadata\":{\"isSigned\":false,\"scale\":0}},{\"name\":\"date_joined\",\"type\":\"timestamp\",\"nullable\":true,\"metadata\":{\"isSigned\":false,\"scale\":0}},{\"name\":\"last_login\",\"type\":\"timestamp\",\"nullable\":true,\"metadata\":{\"isSigned\":false,\"scale\":0}},{\"name\":\"user_hash\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"ingestion_date\",\"type\":\"timestamp\",\"nullable\":true,\"metadata\":{}},{\"name\":\"source_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1763046186814)), logSegment=LogSegment(s3a://nau-local-analytics-silver/dim_user/_delta_log,0,WrappedArray(S3AFileStatus{path=s3a://nau-local-analytics-silver/dim_user/_delta_log/00000000000000000000.json; isDirectory=false; length=3603; replication=1; blocksize=33554432; modification_time=1763046214182; access_time=0; owner=spark; group=spark; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=c281f4db384829085eea0acce4c7d3f0 versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@65a2ce0d,1763046214182), checksumOpt=None)\n",
      "25/11/13 15:03:35 INFO DeltaLog: Updated snapshot to Snapshot(path=s3a://nau-local-analytics-silver/dim_user/_delta_log, version=0, metadata=Metadata(d97aed6f-8e73-4258-85f1-83735790c6dc,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"user_sk\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"user_id\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"username\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(150)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"email\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(254)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"first_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(150)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"last_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"__CHAR_VARCHAR_TYPE_STRING\":\"varchar(150)\",\"isSigned\":false,\"scale\":0}},{\"name\":\"full_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"is_staff\",\"type\":\"boolean\",\"nullable\":true,\"metadata\":{\"isSigned\":false,\"scale\":0}},{\"name\":\"is_superuser\",\"type\":\"boolean\",\"nullable\":true,\"metadata\":{\"isSigned\":false,\"scale\":0}},{\"name\":\"is_active\",\"type\":\"boolean\",\"nullable\":true,\"metadata\":{\"isSigned\":false,\"scale\":0}},{\"name\":\"date_joined\",\"type\":\"timestamp\",\"nullable\":true,\"metadata\":{\"isSigned\":false,\"scale\":0}},{\"name\":\"last_login\",\"type\":\"timestamp\",\"nullable\":true,\"metadata\":{\"isSigned\":false,\"scale\":0}},{\"name\":\"user_hash\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"ingestion_date\",\"type\":\"timestamp\",\"nullable\":true,\"metadata\":{}},{\"name\":\"source_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1763046186814)), logSegment=LogSegment(s3a://nau-local-analytics-silver/dim_user/_delta_log,0,WrappedArray(S3AFileStatus{path=s3a://nau-local-analytics-silver/dim_user/_delta_log/00000000000000000000.json; isDirectory=false; length=3603; replication=1; blocksize=33554432; modification_time=1763046214182; access_time=0; owner=spark; group=spark; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=true; isErasureCoded=false} isEmptyDirectory=FALSE eTag=c281f4db384829085eea0acce4c7d3f0 versionId=null),org.apache.spark.sql.delta.EmptyCheckpointProvider$@65a2ce0d,1763046214182), checksumOpt=None)\n",
      "25/11/13 15:03:35 INFO CreateDeltaTableCommand: Table is path-based table: false. Update catalog with mode: Create\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> [dim_user] Load/MERGE finished. Quick validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/13 15:03:35 INFO BlockManagerInfo: Removed broadcast_23_piece0 on jupyter-spark-758b7c86d8-7j77n:43517 in memory (size: 138.3 KiB, free: 1048.6 MiB)\n",
      "25/11/13 15:03:35 INFO BlockManagerInfo: Removed broadcast_21_piece0 on jupyter-spark-758b7c86d8-7j77n:43517 in memory (size: 36.6 KiB, free: 1048.7 MiB)\n",
      "25/11/13 15:03:35 INFO PrepareDeltaScan: DELTA: Filtering files for query\n",
      "25/11/13 15:03:35 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 202.5 KiB, free 1047.8 MiB)\n",
      "25/11/13 15:03:35 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 1047.8 MiB)\n",
      "25/11/13 15:03:35 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 35.4 KiB, free: 1048.6 MiB)\n",
      "25/11/13 15:03:35 INFO SparkContext: Created broadcast 28 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128\n",
      "25/11/13 15:03:36 INFO DataSourceStrategy: Pruning directories with: \n",
      "25/11/13 15:03:36 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/11/13 15:03:36 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/11/13 15:03:36 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 202.9 KiB, free 1047.6 MiB)\n",
      "25/11/13 15:03:36 INFO BlockManagerInfo: Removed broadcast_27_piece0 on jupyter-spark-758b7c86d8-7j77n:43517 in memory (size: 17.1 KiB, free: 1048.7 MiB)\n",
      "25/11/13 15:03:36 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 35.5 KiB, free 1047.9 MiB)\n",
      "25/11/13 15:03:36 INFO BlockManagerInfo: Removed broadcast_26_piece0 on jupyter-spark-758b7c86d8-7j77n:43517 in memory (size: 35.5 KiB, free: 1048.7 MiB)\n",
      "25/11/13 15:03:36 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 35.5 KiB, free: 1048.7 MiB)\n",
      "25/11/13 15:03:36 INFO SparkContext: Created broadcast 29 from $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128\n",
      "25/11/13 15:03:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/11/13 15:03:36 INFO DAGScheduler: Registering RDD 81 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 4\n",
      "25/11/13 15:03:36 INFO DAGScheduler: Got map stage job 18 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions\n",
      "25/11/13 15:03:36 INFO DAGScheduler: Final stage: ShuffleMapStage 27 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)\n",
      "25/11/13 15:03:36 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/11/13 15:03:36 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 15:03:36 INFO DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[81] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents\n",
      "25/11/13 15:03:36 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 105.9 KiB, free 1047.8 MiB)\n",
      "25/11/13 15:03:36 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 32.7 KiB, free 1047.7 MiB)\n",
      "25/11/13 15:03:36 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 32.7 KiB, free: 1048.6 MiB)\n",
      "25/11/13 15:03:36 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 15:03:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[81] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))\n",
      "25/11/13 15:03:36 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks resource profile 0\n",
      "25/11/13 15:03:36 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 314) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 9680 bytes) \n",
      "25/11/13 15:03:36 INFO Executor: Running task 0.0 in stage 27.0 (TID 314)\n",
      "25/11/13 15:03:36 INFO FileScanRDD: Reading File path: s3a://nau-local-analytics-silver/dim_user/_delta_log/00000000000000000000.json, range: 0-3603, partition values: [0]\n",
      "25/11/13 15:03:36 INFO Executor: Finished task 0.0 in stage 27.0 (TID 314). 1854 bytes result sent to driver\n",
      "25/11/13 15:03:36 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 314) in 167 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/1)\n",
      "25/11/13 15:03:36 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool \n",
      "25/11/13 15:03:36 INFO DAGScheduler: ShuffleMapStage 27 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.199 s\n",
      "25/11/13 15:03:36 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/11/13 15:03:36 INFO DAGScheduler: running: Set()\n",
      "25/11/13 15:03:36 INFO DAGScheduler: waiting: Set()\n",
      "25/11/13 15:03:36 INFO DAGScheduler: failed: Set()\n",
      "25/11/13 15:03:37 INFO BlockManagerInfo: Removed broadcast_30_piece0 on jupyter-spark-758b7c86d8-7j77n:43517 in memory (size: 32.7 KiB, free: 1048.7 MiB)\n",
      "25/11/13 15:03:38 INFO CodeGenerator: Code generated in 55.012935 ms\n",
      "25/11/13 15:03:38 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128\n",
      "25/11/13 15:03:38 INFO DAGScheduler: Got job 19 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions\n",
      "25/11/13 15:03:38 INFO DAGScheduler: Final stage: ResultStage 29 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)\n",
      "25/11/13 15:03:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)\n",
      "25/11/13 15:03:38 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 15:03:38 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[94] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents\n",
      "25/11/13 15:03:38 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 717.2 KiB, free 1047.2 MiB)\n",
      "25/11/13 15:03:38 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 163.6 KiB, free 1047.0 MiB)\n",
      "25/11/13 15:03:38 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 163.6 KiB, free: 1048.5 MiB)\n",
      "25/11/13 15:03:38 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 15:03:38 INFO DAGScheduler: Submitting 50 missing tasks from ResultStage 29 (MapPartitionsRDD[94] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n",
      "25/11/13 15:03:38 INFO TaskSchedulerImpl: Adding task set 29.0 with 50 tasks resource profile 0\n",
      "25/11/13 15:03:38 INFO TaskSetManager: Starting task 26.0 in stage 29.0 (TID 315) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 26, NODE_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:38 INFO TaskSetManager: Starting task 42.0 in stage 29.0 (TID 316) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 42, NODE_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:38 INFO Executor: Running task 26.0 in stage 29.0 (TID 315)\n",
      "25/11/13 15:03:38 INFO Executor: Running task 42.0 in stage 29.0 (TID 316)\n",
      "25/11/13 15:03:38 INFO ShuffleBlockFetcherIterator: Getting 1 (868.0 B) non-empty blocks including 1 (868.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:03:38 INFO ShuffleBlockFetcherIterator: Getting 1 (1051.0 B) non-empty blocks including 1 (1051.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/11/13 15:03:38 INFO MemoryStore: Block rdd_88_26 stored as values in memory (estimated size 920.0 B, free 1046.9 MiB)\n",
      "25/11/13 15:03:38 INFO BlockManagerInfo: Added rdd_88_26 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 920.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:38 INFO MemoryStore: Block rdd_88_42 stored as values in memory (estimated size 749.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:38 INFO BlockManagerInfo: Added rdd_88_42 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 749.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:38 INFO CodeGenerator: Code generated in 160.965737 ms + 2) / 50]\n",
      "25/11/13 15:03:38 INFO MemoryStore: Block rdd_92_42 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:38 INFO BlockManagerInfo: Added rdd_92_42 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:38 INFO MemoryStore: Block rdd_92_26 stored as values in memory (estimated size 676.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:38 INFO BlockManagerInfo: Added rdd_92_26 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 676.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:38 INFO CodeGenerator: Code generated in 83.423307 ms\n",
      "25/11/13 15:03:38 INFO Executor: Finished task 26.0 in stage 29.0 (TID 315). 5176 bytes result sent to driver\n",
      "25/11/13 15:03:38 INFO Executor: Finished task 42.0 in stage 29.0 (TID 316). 5024 bytes result sent to driver\n",
      "25/11/13 15:03:38 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 317) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:38 INFO Executor: Running task 0.0 in stage 29.0 (TID 317)\n",
      "25/11/13 15:03:38 INFO TaskSetManager: Starting task 1.0 in stage 29.0 (TID 318) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 1, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:38 INFO Executor: Running task 1.0 in stage 29.0 (TID 318)\n",
      "25/11/13 15:03:38 INFO TaskSetManager: Finished task 26.0 in stage 29.0 (TID 315) in 615 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/50)\n",
      "25/11/13 15:03:38 INFO TaskSetManager: Finished task 42.0 in stage 29.0 (TID 316) in 616 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (2/50)\n",
      "25/11/13 15:03:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "25/11/13 15:03:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms\n",
      "25/11/13 15:03:39 INFO MemoryStore: Block rdd_88_0 stored as values in memory (estimated size 46.0 B, free 1046.9 MiB)\n",
      "25/11/13 15:03:39 INFO BlockManagerInfo: Added rdd_88_0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:39 INFO MemoryStore: Block rdd_88_1 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:39 INFO BlockManagerInfo: Added rdd_88_1 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:39 INFO MemoryStore: Block rdd_92_0 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:39 INFO BlockManagerInfo: Added rdd_92_0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:39 INFO Executor: Finished task 0.0 in stage 29.0 (TID 317). 5067 bytes result sent to driver\n",
      "25/11/13 15:03:39 INFO TaskSetManager: Starting task 2.0 in stage 29.0 (TID 319) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 2, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:39 INFO Executor: Running task 2.0 in stage 29.0 (TID 319)\n",
      "25/11/13 15:03:39 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 317) in 318 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (3/50)\n",
      "25/11/13 15:03:39 INFO MemoryStore: Block rdd_92_1 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:39 INFO BlockManagerInfo: Added rdd_92_1 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:39 INFO Executor: Finished task 1.0 in stage 29.0 (TID 318). 5067 bytes result sent to driver\n",
      "25/11/13 15:03:39 INFO TaskSetManager: Starting task 3.0 in stage 29.0 (TID 320) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 3, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:39 INFO TaskSetManager: Finished task 1.0 in stage 29.0 (TID 318) in 342 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (4/50)\n",
      "25/11/13 15:03:39 INFO Executor: Running task 3.0 in stage 29.0 (TID 320)\n",
      "25/11/13 15:03:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "25/11/13 15:03:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:03:39 INFO MemoryStore: Block rdd_88_2 stored as values in memory (estimated size 46.0 B, free 1046.9 MiB)\n",
      "25/11/13 15:03:39 INFO BlockManagerInfo: Added rdd_88_2 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:39 INFO MemoryStore: Block rdd_88_3 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:39 INFO BlockManagerInfo: Added rdd_88_3 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:39 INFO MemoryStore: Block rdd_92_2 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:39 INFO BlockManagerInfo: Added rdd_92_2 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:39 INFO Executor: Finished task 2.0 in stage 29.0 (TID 319). 5024 bytes result sent to driver\n",
      "25/11/13 15:03:39 INFO MemoryStore: Block rdd_92_3 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:39 INFO BlockManagerInfo: Added rdd_92_3 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:39 INFO TaskSetManager: Starting task 4.0 in stage 29.0 (TID 321) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 4, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:39 INFO TaskSetManager: Finished task 2.0 in stage 29.0 (TID 319) in 260 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (5/50)\n",
      "25/11/13 15:03:39 INFO Executor: Running task 4.0 in stage 29.0 (TID 321)\n",
      "25/11/13 15:03:39 INFO Executor: Finished task 3.0 in stage 29.0 (TID 320). 5024 bytes result sent to driver\n",
      "25/11/13 15:03:39 INFO TaskSetManager: Starting task 5.0 in stage 29.0 (TID 322) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 5, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:39 INFO Executor: Running task 5.0 in stage 29.0 (TID 322)\n",
      "25/11/13 15:03:39 INFO TaskSetManager: Finished task 3.0 in stage 29.0 (TID 320) in 239 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (6/50)\n",
      "25/11/13 15:03:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:03:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:03:39 INFO MemoryStore: Block rdd_88_4 stored as values in memory (estimated size 46.0 B, free 1046.9 MiB)\n",
      "25/11/13 15:03:39 INFO BlockManagerInfo: Added rdd_88_4 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:39 INFO MemoryStore: Block rdd_88_5 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:39 INFO BlockManagerInfo: Added rdd_88_5 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:39 INFO MemoryStore: Block rdd_92_4 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:39 INFO BlockManagerInfo: Added rdd_92_4 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:39 INFO Executor: Finished task 4.0 in stage 29.0 (TID 321). 5024 bytes result sent to driver\n",
      "25/11/13 15:03:39 INFO TaskSetManager: Starting task 6.0 in stage 29.0 (TID 323) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 6, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:39 INFO TaskSetManager: Finished task 4.0 in stage 29.0 (TID 321) in 275 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (7/50)\n",
      "25/11/13 15:03:39 INFO MemoryStore: Block rdd_92_5 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:39 INFO BlockManagerInfo: Added rdd_92_5 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:39 INFO Executor: Running task 6.0 in stage 29.0 (TID 323)\n",
      "25/11/13 15:03:39 INFO Executor: Finished task 5.0 in stage 29.0 (TID 322). 5024 bytes result sent to driver\n",
      "25/11/13 15:03:39 INFO TaskSetManager: Starting task 7.0 in stage 29.0 (TID 324) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 7, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:39 INFO Executor: Running task 7.0 in stage 29.0 (TID 324)\n",
      "25/11/13 15:03:39 INFO TaskSetManager: Finished task 5.0 in stage 29.0 (TID 322) in 293 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (8/50)\n",
      "25/11/13 15:03:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:03:39 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:03:39 INFO MemoryStore: Block rdd_88_6 stored as values in memory (estimated size 46.0 B, free 1046.9 MiB)\n",
      "25/11/13 15:03:39 INFO BlockManagerInfo: Added rdd_88_6 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:39 INFO MemoryStore: Block rdd_88_7 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:39 INFO BlockManagerInfo: Added rdd_88_7 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:39 INFO MemoryStore: Block rdd_92_6 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:39 INFO BlockManagerInfo: Added rdd_92_6 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:39 INFO Executor: Finished task 6.0 in stage 29.0 (TID 323). 5024 bytes result sent to driver\n",
      "25/11/13 15:03:39 INFO TaskSetManager: Starting task 8.0 in stage 29.0 (TID 325) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 8, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:39 INFO Executor: Running task 8.0 in stage 29.0 (TID 325)\n",
      "25/11/13 15:03:39 INFO TaskSetManager: Finished task 6.0 in stage 29.0 (TID 323) in 237 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (9/50)\n",
      "25/11/13 15:03:39 INFO MemoryStore: Block rdd_92_7 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:39 INFO BlockManagerInfo: Added rdd_92_7 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:40 INFO Executor: Finished task 7.0 in stage 29.0 (TID 324). 5067 bytes result sent to driver\n",
      "25/11/13 15:03:40 INFO TaskSetManager: Starting task 9.0 in stage 29.0 (TID 326) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 9, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:40 INFO Executor: Running task 9.0 in stage 29.0 (TID 326)\n",
      "25/11/13 15:03:40 INFO TaskSetManager: Finished task 7.0 in stage 29.0 (TID 324) in 297 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (10/50)\n",
      "25/11/13 15:03:40 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:03:40 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:03:40 INFO MemoryStore: Block rdd_88_8 stored as values in memory (estimated size 46.0 B, free 1046.9 MiB)\n",
      "25/11/13 15:03:40 INFO BlockManagerInfo: Added rdd_88_8 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:40 INFO MemoryStore: Block rdd_92_8 stored as values in memory (estimated size 46.0 B, free 1046.9 MiB)\n",
      "25/11/13 15:03:40 INFO BlockManagerInfo: Added rdd_92_8 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:40 INFO Executor: Finished task 8.0 in stage 29.0 (TID 325). 5067 bytes result sent to driver\n",
      "25/11/13 15:03:40 INFO TaskSetManager: Starting task 10.0 in stage 29.0 (TID 327) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 10, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:40 INFO TaskSetManager: Finished task 8.0 in stage 29.0 (TID 325) in 213 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (11/50)\n",
      "25/11/13 15:03:40 INFO Executor: Running task 10.0 in stage 29.0 (TID 327)\n",
      "25/11/13 15:03:40 INFO MemoryStore: Block rdd_88_9 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:40 INFO BlockManagerInfo: Added rdd_88_9 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:40 INFO MemoryStore: Block rdd_92_9 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:40 INFO BlockManagerInfo: Added rdd_92_9 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:40 INFO Executor: Finished task 9.0 in stage 29.0 (TID 326). 5024 bytes result sent to driver\n",
      "25/11/13 15:03:40 INFO TaskSetManager: Starting task 11.0 in stage 29.0 (TID 328) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 11, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:40 INFO Executor: Running task 11.0 in stage 29.0 (TID 328)\n",
      "25/11/13 15:03:40 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/11/13 15:03:40 INFO TaskSetManager: Finished task 9.0 in stage 29.0 (TID 326) in 220 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (12/50)\n",
      "25/11/13 15:03:40 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 34 ms\n",
      "25/11/13 15:03:40 INFO MemoryStore: Block rdd_88_10 stored as values in memory (estimated size 46.0 B, free 1046.9 MiB)\n",
      "25/11/13 15:03:40 INFO BlockManagerInfo: Added rdd_88_10 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:40 INFO MemoryStore: Block rdd_88_11 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:40 INFO BlockManagerInfo: Added rdd_88_11 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:40 INFO MemoryStore: Block rdd_92_10 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:40 INFO BlockManagerInfo: Added rdd_92_10 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:40 INFO Executor: Finished task 10.0 in stage 29.0 (TID 327). 5024 bytes result sent to driver\n",
      "25/11/13 15:03:40 INFO TaskSetManager: Starting task 12.0 in stage 29.0 (TID 329) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 12, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:40 INFO TaskSetManager: Finished task 10.0 in stage 29.0 (TID 327) in 288 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (13/50)\n",
      "25/11/13 15:03:40 INFO Executor: Running task 12.0 in stage 29.0 (TID 329)\n",
      "25/11/13 15:03:40 INFO MemoryStore: Block rdd_92_11 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:40 INFO BlockManagerInfo: Added rdd_92_11 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:40 INFO Executor: Finished task 11.0 in stage 29.0 (TID 328). 5024 bytes result sent to driver\n",
      "25/11/13 15:03:40 INFO TaskSetManager: Starting task 13.0 in stage 29.0 (TID 330) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 13, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:40 INFO Executor: Running task 13.0 in stage 29.0 (TID 330)\n",
      "25/11/13 15:03:40 INFO TaskSetManager: Finished task 11.0 in stage 29.0 (TID 328) in 205 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (14/50)\n",
      "25/11/13 15:03:40 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:03:40 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:03:40 INFO MemoryStore: Block rdd_88_12 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:40 INFO MemoryStore: Block rdd_88_13 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:40 INFO BlockManagerInfo: Added rdd_88_12 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:40 INFO BlockManagerInfo: Added rdd_88_13 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:40 INFO MemoryStore: Block rdd_92_12 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:40 INFO MemoryStore: Block rdd_92_13 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:40 INFO BlockManagerInfo: Added rdd_92_12 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:40 INFO BlockManagerInfo: Added rdd_92_13 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:40 INFO Executor: Finished task 12.0 in stage 29.0 (TID 329). 5024 bytes result sent to driver\n",
      "25/11/13 15:03:40 INFO Executor: Finished task 13.0 in stage 29.0 (TID 330). 5024 bytes result sent to driver\n",
      "25/11/13 15:03:40 INFO TaskSetManager: Starting task 14.0 in stage 29.0 (TID 331) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 14, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:40 INFO Executor: Running task 14.0 in stage 29.0 (TID 331)\n",
      "25/11/13 15:03:40 INFO TaskSetManager: Starting task 15.0 in stage 29.0 (TID 332) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 15, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:40 INFO Executor: Running task 15.0 in stage 29.0 (TID 332)\n",
      "25/11/13 15:03:40 INFO TaskSetManager: Finished task 13.0 in stage 29.0 (TID 330) in 312 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (15/50)\n",
      "25/11/13 15:03:40 INFO TaskSetManager: Finished task 12.0 in stage 29.0 (TID 329) in 352 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (16/50)\n",
      "25/11/13 15:03:40 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:03:40 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "25/11/13 15:03:40 INFO MemoryStore: Block rdd_88_14 stored as values in memory (estimated size 46.0 B, free 1046.9 MiB)\n",
      "25/11/13 15:03:40 INFO BlockManagerInfo: Added rdd_88_14 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:40 INFO MemoryStore: Block rdd_88_15 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:40 INFO MemoryStore: Block rdd_92_14 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:40 INFO BlockManagerInfo: Added rdd_88_15 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:40 INFO BlockManagerInfo: Added rdd_92_14 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:40 INFO Executor: Finished task 14.0 in stage 29.0 (TID 331). 5024 bytes result sent to driver\n",
      "25/11/13 15:03:40 INFO TaskSetManager: Starting task 16.0 in stage 29.0 (TID 333) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 16, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:40 INFO Executor: Running task 16.0 in stage 29.0 (TID 333)\n",
      "25/11/13 15:03:40 INFO TaskSetManager: Finished task 14.0 in stage 29.0 (TID 331) in 210 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (17/50)\n",
      "25/11/13 15:03:41 INFO MemoryStore: Block rdd_92_15 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:41 INFO BlockManagerInfo: Added rdd_92_15 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:41 INFO Executor: Finished task 15.0 in stage 29.0 (TID 332). 5024 bytes result sent to driver\n",
      "25/11/13 15:03:41 INFO TaskSetManager: Starting task 17.0 in stage 29.0 (TID 334) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 17, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:41 INFO Executor: Running task 17.0 in stage 29.0 (TID 334)\n",
      "25/11/13 15:03:41 INFO TaskSetManager: Finished task 15.0 in stage 29.0 (TID 332) in 246 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (18/50)\n",
      "25/11/13 15:03:41 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:03:41 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:03:41 INFO MemoryStore: Block rdd_88_16 stored as values in memory (estimated size 46.0 B, free 1046.9 MiB)\n",
      "25/11/13 15:03:41 INFO BlockManagerInfo: Added rdd_88_16 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:41 INFO MemoryStore: Block rdd_92_16 stored as values in memory (estimated size 46.0 B, free 1046.9 MiB)\n",
      "25/11/13 15:03:41 INFO BlockManagerInfo: Added rdd_92_16 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:41 INFO MemoryStore: Block rdd_88_17 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:41 INFO BlockManagerInfo: Added rdd_88_17 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:41 INFO Executor: Finished task 16.0 in stage 29.0 (TID 333). 5067 bytes result sent to driver\n",
      "25/11/13 15:03:41 INFO TaskSetManager: Starting task 18.0 in stage 29.0 (TID 335) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 18, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:41 INFO Executor: Running task 18.0 in stage 29.0 (TID 335)\n",
      "25/11/13 15:03:41 INFO TaskSetManager: Finished task 16.0 in stage 29.0 (TID 333) in 247 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (19/50)\n",
      "25/11/13 15:03:41 INFO MemoryStore: Block rdd_92_17 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:41 INFO BlockManagerInfo: Added rdd_92_17 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:41 INFO Executor: Finished task 17.0 in stage 29.0 (TID 334). 5067 bytes result sent to driver\n",
      "25/11/13 15:03:41 INFO TaskSetManager: Starting task 19.0 in stage 29.0 (TID 336) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 19, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:41 INFO Executor: Running task 19.0 in stage 29.0 (TID 336)\n",
      "25/11/13 15:03:41 INFO TaskSetManager: Finished task 17.0 in stage 29.0 (TID 334) in 241 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (20/50)\n",
      "25/11/13 15:03:41 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:03:41 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:03:41 INFO MemoryStore: Block rdd_88_18 stored as values in memory (estimated size 46.0 B, free 1046.9 MiB)\n",
      "25/11/13 15:03:41 INFO BlockManagerInfo: Added rdd_88_18 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:41 INFO MemoryStore: Block rdd_88_19 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:41 INFO BlockManagerInfo: Added rdd_88_19 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:41 INFO MemoryStore: Block rdd_92_18 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:41 INFO BlockManagerInfo: Added rdd_92_18 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:41 INFO Executor: Finished task 18.0 in stage 29.0 (TID 335). 5024 bytes result sent to driver\n",
      "25/11/13 15:03:41 INFO TaskSetManager: Starting task 20.0 in stage 29.0 (TID 337) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 20, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:41 INFO TaskSetManager: Finished task 18.0 in stage 29.0 (TID 335) in 187 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (21/50)\n",
      "25/11/13 15:03:41 INFO Executor: Running task 20.0 in stage 29.0 (TID 337)\n",
      "25/11/13 15:03:41 INFO MemoryStore: Block rdd_92_19 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:41 INFO BlockManagerInfo: Added rdd_92_19 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:41 INFO Executor: Finished task 19.0 in stage 29.0 (TID 336). 5024 bytes result sent to driver\n",
      "25/11/13 15:03:41 INFO TaskSetManager: Starting task 21.0 in stage 29.0 (TID 338) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 21, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:41 INFO Executor: Running task 21.0 in stage 29.0 (TID 338)\n",
      "25/11/13 15:03:41 INFO TaskSetManager: Finished task 19.0 in stage 29.0 (TID 336) in 192 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (22/50)\n",
      "25/11/13 15:03:41 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:03:41 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:03:41 INFO MemoryStore: Block rdd_88_20 stored as values in memory (estimated size 46.0 B, free 1046.9 MiB)\n",
      "25/11/13 15:03:41 INFO BlockManagerInfo: Added rdd_88_20 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:41 INFO MemoryStore: Block rdd_92_20 stored as values in memory (estimated size 46.0 B, free 1046.9 MiB)\n",
      "25/11/13 15:03:41 INFO BlockManagerInfo: Added rdd_92_20 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:41 INFO Executor: Finished task 20.0 in stage 29.0 (TID 337). 5024 bytes result sent to driver\n",
      "25/11/13 15:03:41 INFO TaskSetManager: Starting task 22.0 in stage 29.0 (TID 339) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 22, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:41 INFO Executor: Running task 22.0 in stage 29.0 (TID 339)\n",
      "25/11/13 15:03:41 INFO TaskSetManager: Finished task 20.0 in stage 29.0 (TID 337) in 170 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (23/50)\n",
      "25/11/13 15:03:41 INFO MemoryStore: Block rdd_88_21 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:41 INFO BlockManagerInfo: Added rdd_88_21 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:41 INFO MemoryStore: Block rdd_92_21 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:41 INFO BlockManagerInfo: Added rdd_92_21 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:41 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:03:41 INFO Executor: Finished task 21.0 in stage 29.0 (TID 338). 5024 bytes result sent to driver\n",
      "25/11/13 15:03:41 INFO TaskSetManager: Starting task 23.0 in stage 29.0 (TID 340) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 23, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:41 INFO Executor: Running task 23.0 in stage 29.0 (TID 340)\n",
      "25/11/13 15:03:41 INFO TaskSetManager: Finished task 21.0 in stage 29.0 (TID 338) in 203 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (24/50)\n",
      "25/11/13 15:03:41 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:03:41 INFO MemoryStore: Block rdd_88_22 stored as values in memory (estimated size 46.0 B, free 1046.9 MiB)\n",
      "25/11/13 15:03:41 INFO BlockManagerInfo: Added rdd_88_22 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:41 INFO MemoryStore: Block rdd_92_22 stored as values in memory (estimated size 46.0 B, free 1046.9 MiB)\n",
      "25/11/13 15:03:41 INFO BlockManagerInfo: Added rdd_92_22 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:41 INFO Executor: Finished task 22.0 in stage 29.0 (TID 339). 5067 bytes result sent to driver\n",
      "25/11/13 15:03:41 INFO TaskSetManager: Starting task 24.0 in stage 29.0 (TID 341) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 24, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:41 INFO TaskSetManager: Finished task 22.0 in stage 29.0 (TID 339) in 203 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (25/50)\n",
      "25/11/13 15:03:41 INFO Executor: Running task 24.0 in stage 29.0 (TID 341)\n",
      "25/11/13 15:03:41 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:03:41 INFO MemoryStore: Block rdd_88_23 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:41 INFO BlockManagerInfo: Added rdd_88_23 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:41 INFO MemoryStore: Block rdd_92_23 stored as values in memory (estimated size 46.0 B, free 1046.9 MiB)\n",
      "25/11/13 15:03:41 INFO BlockManagerInfo: Added rdd_92_23 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:41 INFO Executor: Finished task 23.0 in stage 29.0 (TID 340). 5067 bytes result sent to driver\n",
      "25/11/13 15:03:41 INFO TaskSetManager: Starting task 25.0 in stage 29.0 (TID 342) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 25, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:41 INFO Executor: Running task 25.0 in stage 29.0 (TID 342)\n",
      "25/11/13 15:03:41 INFO TaskSetManager: Finished task 23.0 in stage 29.0 (TID 340) in 221 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (26/50)\n",
      "25/11/13 15:03:41 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 24 ms\n",
      "25/11/13 15:03:41 INFO MemoryStore: Block rdd_88_24 stored as values in memory (estimated size 46.0 B, free 1046.9 MiB)\n",
      "25/11/13 15:03:41 INFO BlockManagerInfo: Added rdd_88_24 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:41 INFO MemoryStore: Block rdd_92_24 stored as values in memory (estimated size 46.0 B, free 1046.9 MiB)\n",
      "25/11/13 15:03:41 INFO BlockManagerInfo: Added rdd_92_24 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:41 INFO Executor: Finished task 24.0 in stage 29.0 (TID 341). 5024 bytes result sent to driver\n",
      "25/11/13 15:03:41 INFO TaskSetManager: Starting task 27.0 in stage 29.0 (TID 343) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 27, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:41 INFO Executor: Running task 27.0 in stage 29.0 (TID 343)\n",
      "25/11/13 15:03:41 INFO TaskSetManager: Finished task 24.0 in stage 29.0 (TID 341) in 201 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (27/50)\n",
      "25/11/13 15:03:42 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:03:42 INFO MemoryStore: Block rdd_88_25 stored as values in memory (estimated size 46.0 B, free 1046.9 MiB)\n",
      "25/11/13 15:03:42 INFO BlockManagerInfo: Added rdd_88_25 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:42 INFO MemoryStore: Block rdd_92_25 stored as values in memory (estimated size 46.0 B, free 1046.9 MiB)\n",
      "25/11/13 15:03:42 INFO BlockManagerInfo: Added rdd_92_25 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:42 INFO Executor: Finished task 25.0 in stage 29.0 (TID 342). 5024 bytes result sent to driver\n",
      "25/11/13 15:03:42 INFO TaskSetManager: Starting task 28.0 in stage 29.0 (TID 344) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 28, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:42 INFO Executor: Running task 28.0 in stage 29.0 (TID 344)\n",
      "25/11/13 15:03:42 INFO TaskSetManager: Finished task 25.0 in stage 29.0 (TID 342) in 196 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (28/50)\n",
      "25/11/13 15:03:42 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/11/13 15:03:42 INFO MemoryStore: Block rdd_88_27 stored as values in memory (estimated size 46.0 B, free 1046.9 MiB)\n",
      "25/11/13 15:03:42 INFO BlockManagerInfo: Added rdd_88_27 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:42 INFO MemoryStore: Block rdd_92_27 stored as values in memory (estimated size 46.0 B, free 1046.9 MiB)\n",
      "25/11/13 15:03:42 INFO BlockManagerInfo: Added rdd_92_27 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:42 INFO Executor: Finished task 27.0 in stage 29.0 (TID 343). 5024 bytes result sent to driver\n",
      "25/11/13 15:03:42 INFO MemoryStore: Block rdd_88_28 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:42 INFO BlockManagerInfo: Added rdd_88_28 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:42 INFO TaskSetManager: Starting task 29.0 in stage 29.0 (TID 345) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 29, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:42 INFO TaskSetManager: Finished task 27.0 in stage 29.0 (TID 343) in 273 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (29/50)\n",
      "25/11/13 15:03:42 INFO Executor: Running task 29.0 in stage 29.0 (TID 345)\n",
      "25/11/13 15:03:42 INFO MemoryStore: Block rdd_92_28 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:42 INFO BlockManagerInfo: Added rdd_92_28 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:42 INFO Executor: Finished task 28.0 in stage 29.0 (TID 344). 5024 bytes result sent to driver\n",
      "25/11/13 15:03:42 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:42 INFO TaskSetManager: Starting task 30.0 in stage 29.0 (TID 346) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 30, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:03:42 INFO Executor: Running task 30.0 in stage 29.0 (TID 346)\n",
      "25/11/13 15:03:42 INFO TaskSetManager: Finished task 28.0 in stage 29.0 (TID 344) in 206 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (30/50)\n",
      "25/11/13 15:03:42 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:03:42 INFO MemoryStore: Block rdd_88_29 stored as values in memory (estimated size 46.0 B, free 1046.9 MiB)\n",
      "25/11/13 15:03:42 INFO BlockManagerInfo: Added rdd_88_29 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:42 INFO MemoryStore: Block rdd_92_29 stored as values in memory (estimated size 46.0 B, free 1046.9 MiB)\n",
      "25/11/13 15:03:42 INFO BlockManagerInfo: Added rdd_92_29 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:42 INFO Executor: Finished task 29.0 in stage 29.0 (TID 345). 5067 bytes result sent to driver\n",
      "25/11/13 15:03:42 INFO TaskSetManager: Starting task 31.0 in stage 29.0 (TID 347) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 31, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:42 INFO TaskSetManager: Finished task 29.0 in stage 29.0 (TID 345) in 205 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (31/50)\n",
      "25/11/13 15:03:42 INFO Executor: Running task 31.0 in stage 29.0 (TID 347)\n",
      "25/11/13 15:03:42 INFO MemoryStore: Block rdd_88_30 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:42 INFO BlockManagerInfo: Added rdd_88_30 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:42 INFO MemoryStore: Block rdd_92_30 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:42 INFO BlockManagerInfo: Added rdd_92_30 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:42 INFO Executor: Finished task 30.0 in stage 29.0 (TID 346). 5067 bytes result sent to driver\n",
      "25/11/13 15:03:42 INFO TaskSetManager: Starting task 32.0 in stage 29.0 (TID 348) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 32, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:42 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 26 ms\n",
      "25/11/13 15:03:42 INFO Executor: Running task 32.0 in stage 29.0 (TID 348)\n",
      "25/11/13 15:03:42 INFO TaskSetManager: Finished task 30.0 in stage 29.0 (TID 346) in 247 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (32/50)\n",
      "25/11/13 15:03:42 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:03:42 INFO MemoryStore: Block rdd_88_31 stored as values in memory (estimated size 46.0 B, free 1046.9 MiB)\n",
      "25/11/13 15:03:42 INFO BlockManagerInfo: Added rdd_88_31 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:42 INFO MemoryStore: Block rdd_92_31 stored as values in memory (estimated size 46.0 B, free 1046.9 MiB)\n",
      "25/11/13 15:03:42 INFO BlockManagerInfo: Added rdd_92_31 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:42 INFO Executor: Finished task 31.0 in stage 29.0 (TID 347). 5024 bytes result sent to driver\n",
      "25/11/13 15:03:42 INFO TaskSetManager: Starting task 33.0 in stage 29.0 (TID 349) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 33, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:42 INFO Executor: Running task 33.0 in stage 29.0 (TID 349)\n",
      "25/11/13 15:03:42 INFO TaskSetManager: Finished task 31.0 in stage 29.0 (TID 347) in 220 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (33/50)\n",
      "25/11/13 15:03:42 INFO MemoryStore: Block rdd_88_32 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:42 INFO BlockManagerInfo: Added rdd_88_32 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:42 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:03:42 INFO MemoryStore: Block rdd_92_32 stored as values in memory (estimated size 46.0 B, free 1046.9 MiB)\n",
      "25/11/13 15:03:42 INFO BlockManagerInfo: Added rdd_92_32 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:42 INFO Executor: Finished task 32.0 in stage 29.0 (TID 348). 5024 bytes result sent to driver\n",
      "25/11/13 15:03:42 INFO TaskSetManager: Starting task 34.0 in stage 29.0 (TID 350) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 34, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:42 INFO TaskSetManager: Finished task 32.0 in stage 29.0 (TID 348) in 268 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (34/50)\n",
      "25/11/13 15:03:42 INFO Executor: Running task 34.0 in stage 29.0 (TID 350)\n",
      "25/11/13 15:03:42 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:03:42 INFO MemoryStore: Block rdd_88_33 stored as values in memory (estimated size 46.0 B, free 1046.9 MiB)\n",
      "25/11/13 15:03:42 INFO BlockManagerInfo: Added rdd_88_33 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:42 INFO MemoryStore: Block rdd_92_33 stored as values in memory (estimated size 46.0 B, free 1046.9 MiB)\n",
      "25/11/13 15:03:42 INFO BlockManagerInfo: Added rdd_92_33 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:42 INFO Executor: Finished task 33.0 in stage 29.0 (TID 349). 5024 bytes result sent to driver\n",
      "25/11/13 15:03:42 INFO TaskSetManager: Starting task 35.0 in stage 29.0 (TID 351) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 35, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:42 INFO Executor: Running task 35.0 in stage 29.0 (TID 351)\n",
      "25/11/13 15:03:42 INFO TaskSetManager: Finished task 33.0 in stage 29.0 (TID 349) in 200 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (35/50)\n",
      "25/11/13 15:03:42 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:03:42 INFO MemoryStore: Block rdd_88_34 stored as values in memory (estimated size 46.0 B, free 1046.9 MiB)\n",
      "25/11/13 15:03:42 INFO BlockManagerInfo: Added rdd_88_34 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:42 INFO MemoryStore: Block rdd_92_34 stored as values in memory (estimated size 46.0 B, free 1046.9 MiB)\n",
      "25/11/13 15:03:42 INFO BlockManagerInfo: Added rdd_92_34 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:42 INFO Executor: Finished task 34.0 in stage 29.0 (TID 350). 5024 bytes result sent to driver\n",
      "25/11/13 15:03:42 INFO TaskSetManager: Starting task 36.0 in stage 29.0 (TID 352) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 36, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:42 INFO Executor: Running task 36.0 in stage 29.0 (TID 352)\n",
      "25/11/13 15:03:42 INFO TaskSetManager: Finished task 34.0 in stage 29.0 (TID 350) in 220 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (36/50)\n",
      "25/11/13 15:03:43 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:03:43 INFO MemoryStore: Block rdd_88_35 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:43 INFO BlockManagerInfo: Added rdd_88_35 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:43 INFO MemoryStore: Block rdd_92_35 stored as values in memory (estimated size 46.0 B, free 1046.9 MiB)\n",
      "25/11/13 15:03:43 INFO BlockManagerInfo: Added rdd_92_35 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:43 INFO Executor: Finished task 35.0 in stage 29.0 (TID 351). 5024 bytes result sent to driver\n",
      "25/11/13 15:03:43 INFO TaskSetManager: Starting task 37.0 in stage 29.0 (TID 353) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 37, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:43 INFO Executor: Running task 37.0 in stage 29.0 (TID 353)\n",
      "25/11/13 15:03:43 INFO TaskSetManager: Finished task 35.0 in stage 29.0 (TID 351) in 202 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (37/50)\n",
      "25/11/13 15:03:43 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:03:43 INFO MemoryStore: Block rdd_88_36 stored as values in memory (estimated size 46.0 B, free 1046.9 MiB)\n",
      "25/11/13 15:03:43 INFO BlockManagerInfo: Added rdd_88_36 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:43 INFO MemoryStore: Block rdd_92_36 stored as values in memory (estimated size 46.0 B, free 1046.9 MiB)\n",
      "25/11/13 15:03:43 INFO BlockManagerInfo: Added rdd_92_36 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:43 INFO Executor: Finished task 36.0 in stage 29.0 (TID 352). 5024 bytes result sent to driver\n",
      "25/11/13 15:03:43 INFO TaskSetManager: Starting task 38.0 in stage 29.0 (TID 354) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 38, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:43 INFO TaskSetManager: Finished task 36.0 in stage 29.0 (TID 352) in 209 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (38/50)\n",
      "25/11/13 15:03:43 INFO Executor: Running task 38.0 in stage 29.0 (TID 354)\n",
      "25/11/13 15:03:43 INFO MemoryStore: Block rdd_88_37 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:43 INFO BlockManagerInfo: Added rdd_88_37 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:43 INFO MemoryStore: Block rdd_92_37 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:43 INFO BlockManagerInfo: Added rdd_92_37 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:43 INFO Executor: Finished task 37.0 in stage 29.0 (TID 353). 5067 bytes result sent to driver\n",
      "25/11/13 15:03:43 INFO TaskSetManager: Starting task 39.0 in stage 29.0 (TID 355) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 39, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:43 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:43 INFO Executor: Running task 39.0 in stage 29.0 (TID 355)\n",
      "25/11/13 15:03:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:03:43 INFO TaskSetManager: Finished task 37.0 in stage 29.0 (TID 353) in 195 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (39/50)\n",
      "25/11/13 15:03:43 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:03:43 INFO MemoryStore: Block rdd_88_38 stored as values in memory (estimated size 46.0 B, free 1046.9 MiB)\n",
      "25/11/13 15:03:43 INFO BlockManagerInfo: Added rdd_88_38 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:43 INFO MemoryStore: Block rdd_92_38 stored as values in memory (estimated size 46.0 B, free 1046.9 MiB)\n",
      "25/11/13 15:03:43 INFO BlockManagerInfo: Added rdd_92_38 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:43 INFO MemoryStore: Block rdd_88_39 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:43 INFO BlockManagerInfo: Added rdd_88_39 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:43 INFO Executor: Finished task 38.0 in stage 29.0 (TID 354). 5067 bytes result sent to driver\n",
      "25/11/13 15:03:43 INFO TaskSetManager: Starting task 40.0 in stage 29.0 (TID 356) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 40, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:43 INFO Executor: Running task 40.0 in stage 29.0 (TID 356)\n",
      "25/11/13 15:03:43 INFO TaskSetManager: Finished task 38.0 in stage 29.0 (TID 354) in 207 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (40/50)\n",
      "25/11/13 15:03:43 INFO MemoryStore: Block rdd_92_39 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:43 INFO BlockManagerInfo: Added rdd_92_39 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:43 INFO Executor: Finished task 39.0 in stage 29.0 (TID 355). 5024 bytes result sent to driver\n",
      "25/11/13 15:03:43 INFO TaskSetManager: Starting task 41.0 in stage 29.0 (TID 357) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 41, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:43 INFO TaskSetManager: Finished task 39.0 in stage 29.0 (TID 355) in 157 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (41/50)\n",
      "25/11/13 15:03:43 INFO Executor: Running task 41.0 in stage 29.0 (TID 357)\n",
      "25/11/13 15:03:43 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:03:43 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:03:43 INFO MemoryStore: Block rdd_88_40 stored as values in memory (estimated size 46.0 B, free 1046.9 MiB)\n",
      "25/11/13 15:03:43 INFO BlockManagerInfo: Added rdd_88_40 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:43 INFO MemoryStore: Block rdd_88_41 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:43 INFO BlockManagerInfo: Added rdd_88_41 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:43 INFO MemoryStore: Block rdd_92_40 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:43 INFO BlockManagerInfo: Added rdd_92_40 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:43 INFO Executor: Finished task 40.0 in stage 29.0 (TID 356). 5024 bytes result sent to driver\n",
      "25/11/13 15:03:43 INFO TaskSetManager: Starting task 43.0 in stage 29.0 (TID 358) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 43, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:43 INFO Executor: Running task 43.0 in stage 29.0 (TID 358)\n",
      "25/11/13 15:03:43 INFO TaskSetManager: Finished task 40.0 in stage 29.0 (TID 356) in 179 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (42/50)\n",
      "25/11/13 15:03:43 INFO MemoryStore: Block rdd_92_41 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:43 INFO BlockManagerInfo: Added rdd_92_41 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:43 INFO Executor: Finished task 41.0 in stage 29.0 (TID 357). 5024 bytes result sent to driver\n",
      "25/11/13 15:03:43 INFO TaskSetManager: Starting task 44.0 in stage 29.0 (TID 359) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 44, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:43 INFO Executor: Running task 44.0 in stage 29.0 (TID 359)\n",
      "25/11/13 15:03:43 INFO TaskSetManager: Finished task 41.0 in stage 29.0 (TID 357) in 148 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (43/50)\n",
      "25/11/13 15:03:43 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:03:43 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:03:43 INFO MemoryStore: Block rdd_88_43 stored as values in memory (estimated size 46.0 B, free 1046.9 MiB)\n",
      "25/11/13 15:03:43 INFO BlockManagerInfo: Added rdd_88_43 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:43 INFO MemoryStore: Block rdd_88_44 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:43 INFO BlockManagerInfo: Added rdd_88_44 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:43 INFO MemoryStore: Block rdd_92_43 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:43 INFO BlockManagerInfo: Added rdd_92_43 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:43 INFO Executor: Finished task 43.0 in stage 29.0 (TID 358). 5024 bytes result sent to driver\n",
      "25/11/13 15:03:43 INFO MemoryStore: Block rdd_92_44 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:43 INFO TaskSetManager: Starting task 45.0 in stage 29.0 (TID 360) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 45, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:43 INFO BlockManagerInfo: Added rdd_92_44 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:43 INFO Executor: Running task 45.0 in stage 29.0 (TID 360)\n",
      "25/11/13 15:03:43 INFO TaskSetManager: Finished task 43.0 in stage 29.0 (TID 358) in 168 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (44/50)\n",
      "25/11/13 15:03:43 INFO Executor: Finished task 44.0 in stage 29.0 (TID 359). 5024 bytes result sent to driver\n",
      "25/11/13 15:03:43 INFO TaskSetManager: Starting task 46.0 in stage 29.0 (TID 361) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 46, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:43 INFO Executor: Running task 46.0 in stage 29.0 (TID 361)\n",
      "25/11/13 15:03:43 INFO TaskSetManager: Finished task 44.0 in stage 29.0 (TID 359) in 186 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (45/50)\n",
      "25/11/13 15:03:43 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:43 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:03:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:03:43 INFO MemoryStore: Block rdd_88_46 stored as values in memory (estimated size 46.0 B, free 1046.9 MiB)\n",
      "25/11/13 15:03:43 INFO BlockManagerInfo: Added rdd_88_46 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:43 INFO MemoryStore: Block rdd_88_45 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:43 INFO BlockManagerInfo: Added rdd_88_45 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:43 INFO MemoryStore: Block rdd_92_45 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:43 INFO MemoryStore: Block rdd_92_46 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:43 INFO BlockManagerInfo: Added rdd_92_45 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:43 INFO BlockManagerInfo: Added rdd_92_46 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:43 INFO Executor: Finished task 46.0 in stage 29.0 (TID 361). 5024 bytes result sent to driver\n",
      "25/11/13 15:03:43 INFO Executor: Finished task 45.0 in stage 29.0 (TID 360). 5024 bytes result sent to driver\n",
      "25/11/13 15:03:43 INFO TaskSetManager: Starting task 47.0 in stage 29.0 (TID 362) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 47, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:43 INFO Executor: Running task 47.0 in stage 29.0 (TID 362)\n",
      "25/11/13 15:03:43 INFO TaskSetManager: Starting task 48.0 in stage 29.0 (TID 363) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 48, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:43 INFO Executor: Running task 48.0 in stage 29.0 (TID 363)\n",
      "25/11/13 15:03:43 INFO TaskSetManager: Finished task 46.0 in stage 29.0 (TID 361) in 223 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (46/50)\n",
      "25/11/13 15:03:43 INFO TaskSetManager: Finished task 45.0 in stage 29.0 (TID 360) in 229 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (47/50)\n",
      "25/11/13 15:03:43 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:03:43 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/11/13 15:03:44 INFO MemoryStore: Block rdd_88_48 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:44 INFO MemoryStore: Block rdd_88_47 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:44 INFO BlockManagerInfo: Added rdd_88_47 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:44 INFO BlockManagerInfo: Added rdd_88_48 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:44 INFO MemoryStore: Block rdd_92_48 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:44 INFO BlockManagerInfo: Added rdd_92_48 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:44 INFO MemoryStore: Block rdd_92_47 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:44 INFO BlockManagerInfo: Added rdd_92_47 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:44 INFO Executor: Finished task 48.0 in stage 29.0 (TID 363). 5067 bytes result sent to driver\n",
      "25/11/13 15:03:44 INFO TaskSetManager: Starting task 49.0 in stage 29.0 (TID 364) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 49, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:44 INFO Executor: Running task 49.0 in stage 29.0 (TID 364)\n",
      "25/11/13 15:03:44 INFO Executor: Finished task 47.0 in stage 29.0 (TID 362). 5067 bytes result sent to driver\n",
      "25/11/13 15:03:44 INFO TaskSetManager: Finished task 48.0 in stage 29.0 (TID 363) in 174 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (48/50)\n",
      "25/11/13 15:03:44 INFO TaskSetManager: Finished task 47.0 in stage 29.0 (TID 362) in 177 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (49/50)\n",
      "25/11/13 15:03:44 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:03:44 INFO MemoryStore: Block rdd_88_49 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:44 INFO BlockManagerInfo: Added rdd_88_49 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:44 INFO MemoryStore: Block rdd_92_49 stored as values in memory (estimated size 46.0 B, free 1047.0 MiB)\n",
      "25/11/13 15:03:44 INFO BlockManagerInfo: Added rdd_92_49 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 46.0 B, free: 1048.5 MiB)\n",
      "25/11/13 15:03:44 INFO Executor: Finished task 49.0 in stage 29.0 (TID 364). 5024 bytes result sent to driver\n",
      "25/11/13 15:03:44 INFO TaskSetManager: Finished task 49.0 in stage 29.0 (TID 364) in 111 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (50/50)\n",
      "25/11/13 15:03:44 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool \n",
      "25/11/13 15:03:44 INFO DAGScheduler: ResultStage 29 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 6.005 s\n",
      "25/11/13 15:03:44 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/11/13 15:03:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 29: Stage finished\n",
      "25/11/13 15:03:44 INFO DAGScheduler: Job 19 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 6.017305 s\n",
      "25/11/13 15:03:44 INFO Snapshot: [tableId=d97aed6f-8e73-4258-85f1-83735790c6dc] DELTA: Compute snapshot for version: 0\n",
      "25/11/13 15:03:44 INFO DAGScheduler: Registering RDD 97 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) as input to shuffle 5\n",
      "25/11/13 15:03:44 INFO DAGScheduler: Got map stage job 20 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions\n",
      "25/11/13 15:03:44 INFO DAGScheduler: Final stage: ShuffleMapStage 31 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)\n",
      "25/11/13 15:03:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 30)\n",
      "25/11/13 15:03:44 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 15:03:44 INFO DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[97] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents\n",
      "25/11/13 15:03:44 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 603.2 KiB, free 1046.4 MiB)\n",
      "25/11/13 15:03:44 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 138.3 KiB, free 1046.3 MiB)\n",
      "25/11/13 15:03:44 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 138.3 KiB, free: 1048.4 MiB)\n",
      "25/11/13 15:03:44 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 15:03:44 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[97] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n",
      "25/11/13 15:03:44 INFO TaskSchedulerImpl: Adding task set 31.0 with 50 tasks resource profile 0\n",
      "25/11/13 15:03:44 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 365) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:44 INFO TaskSetManager: Starting task 1.0 in stage 31.0 (TID 366) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 1, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:44 INFO Executor: Running task 1.0 in stage 31.0 (TID 366)\n",
      "25/11/13 15:03:44 INFO Executor: Running task 0.0 in stage 31.0 (TID 365)\n",
      "25/11/13 15:03:44 INFO BlockManager: Found block rdd_88_1 locally\n",
      "25/11/13 15:03:44 INFO BlockManager: Found block rdd_88_0 locally\n",
      "25/11/13 15:03:44 INFO Executor: Finished task 0.0 in stage 31.0 (TID 365). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:44 INFO TaskSetManager: Starting task 2.0 in stage 31.0 (TID 367) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 2, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:44 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 365) in 78 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/50)\n",
      "25/11/13 15:03:44 INFO Executor: Running task 2.0 in stage 31.0 (TID 367)\n",
      "25/11/13 15:03:44 INFO Executor: Finished task 1.0 in stage 31.0 (TID 366). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:44 INFO TaskSetManager: Starting task 3.0 in stage 31.0 (TID 368) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 3, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:44 INFO Executor: Running task 3.0 in stage 31.0 (TID 368)\n",
      "25/11/13 15:03:44 INFO TaskSetManager: Finished task 1.0 in stage 31.0 (TID 366) in 85 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (2/50)\n",
      "25/11/13 15:03:44 INFO BlockManager: Found block rdd_88_2 locally\n",
      "25/11/13 15:03:44 INFO BlockManager: Found block rdd_88_3 locally\n",
      "25/11/13 15:03:44 INFO Executor: Finished task 3.0 in stage 31.0 (TID 368). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:44 INFO TaskSetManager: Starting task 4.0 in stage 31.0 (TID 369) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 4, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:44 INFO Executor: Running task 4.0 in stage 31.0 (TID 369)\n",
      "25/11/13 15:03:44 INFO TaskSetManager: Finished task 3.0 in stage 31.0 (TID 368) in 90 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (3/50)\n",
      "25/11/13 15:03:44 INFO Executor: Finished task 2.0 in stage 31.0 (TID 367). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:44 INFO TaskSetManager: Starting task 5.0 in stage 31.0 (TID 370) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 5, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:44 INFO Executor: Running task 5.0 in stage 31.0 (TID 370)\n",
      "25/11/13 15:03:44 INFO TaskSetManager: Finished task 2.0 in stage 31.0 (TID 367) in 105 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (4/50)\n",
      "25/11/13 15:03:44 INFO BlockManager: Found block rdd_88_4 locally\n",
      "25/11/13 15:03:44 INFO BlockManager: Found block rdd_88_5 locally\n",
      "25/11/13 15:03:44 INFO Executor: Finished task 4.0 in stage 31.0 (TID 369). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:44 INFO TaskSetManager: Starting task 6.0 in stage 31.0 (TID 371) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 6, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:44 INFO TaskSetManager: Finished task 4.0 in stage 31.0 (TID 369) in 98 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (5/50)\n",
      "25/11/13 15:03:44 INFO Executor: Running task 6.0 in stage 31.0 (TID 371)\n",
      "25/11/13 15:03:44 INFO Executor: Finished task 5.0 in stage 31.0 (TID 370). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:44 INFO TaskSetManager: Starting task 7.0 in stage 31.0 (TID 372) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 7, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:44 INFO Executor: Running task 7.0 in stage 31.0 (TID 372)\n",
      "25/11/13 15:03:44 INFO TaskSetManager: Finished task 5.0 in stage 31.0 (TID 370) in 95 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (6/50)\n",
      "25/11/13 15:03:44 INFO BlockManager: Found block rdd_88_6 locally\n",
      "25/11/13 15:03:44 INFO BlockManager: Found block rdd_88_7 locally\n",
      "25/11/13 15:03:44 INFO Executor: Finished task 6.0 in stage 31.0 (TID 371). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:44 INFO Executor: Finished task 7.0 in stage 31.0 (TID 372). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:44 INFO TaskSetManager: Starting task 8.0 in stage 31.0 (TID 373) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 8, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:44 INFO Executor: Running task 8.0 in stage 31.0 (TID 373)\n",
      "25/11/13 15:03:44 INFO TaskSetManager: Starting task 9.0 in stage 31.0 (TID 374) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 9, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:44 INFO Executor: Running task 9.0 in stage 31.0 (TID 374)\n",
      "25/11/13 15:03:44 INFO TaskSetManager: Finished task 7.0 in stage 31.0 (TID 372) in 91 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (7/50)\n",
      "25/11/13 15:03:44 INFO TaskSetManager: Finished task 6.0 in stage 31.0 (TID 371) in 95 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (8/50)\n",
      "25/11/13 15:03:44 INFO BlockManager: Found block rdd_88_8 locally\n",
      "25/11/13 15:03:44 INFO BlockManager: Found block rdd_88_9 locally\n",
      "25/11/13 15:03:44 INFO Executor: Finished task 8.0 in stage 31.0 (TID 373). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:44 INFO Executor: Finished task 9.0 in stage 31.0 (TID 374). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:44 INFO TaskSetManager: Starting task 10.0 in stage 31.0 (TID 375) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 10, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:44 INFO TaskSetManager: Finished task 8.0 in stage 31.0 (TID 373) in 103 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (9/50)\n",
      "25/11/13 15:03:44 INFO Executor: Running task 10.0 in stage 31.0 (TID 375)\n",
      "25/11/13 15:03:44 INFO TaskSetManager: Starting task 11.0 in stage 31.0 (TID 376) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 11, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:44 INFO Executor: Running task 11.0 in stage 31.0 (TID 376)\n",
      "25/11/13 15:03:44 INFO TaskSetManager: Finished task 9.0 in stage 31.0 (TID 374) in 105 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (10/50)\n",
      "25/11/13 15:03:44 INFO BlockManager: Found block rdd_88_10 locally\n",
      "25/11/13 15:03:44 INFO BlockManager: Found block rdd_88_11 locally\n",
      "25/11/13 15:03:45 INFO Executor: Finished task 10.0 in stage 31.0 (TID 375). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:45 INFO TaskSetManager: Starting task 12.0 in stage 31.0 (TID 377) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 12, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:45 INFO TaskSetManager: Finished task 10.0 in stage 31.0 (TID 375) in 100 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (11/50)\n",
      "25/11/13 15:03:45 INFO Executor: Running task 12.0 in stage 31.0 (TID 377)\n",
      "25/11/13 15:03:45 INFO Executor: Finished task 11.0 in stage 31.0 (TID 376). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:45 INFO TaskSetManager: Starting task 13.0 in stage 31.0 (TID 378) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 13, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:45 INFO Executor: Running task 13.0 in stage 31.0 (TID 378)\n",
      "25/11/13 15:03:45 INFO TaskSetManager: Finished task 11.0 in stage 31.0 (TID 376) in 104 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (12/50)\n",
      "25/11/13 15:03:45 INFO BlockManager: Found block rdd_88_13 locally\n",
      "25/11/13 15:03:45 INFO BlockManager: Found block rdd_88_12 locally\n",
      "25/11/13 15:03:45 INFO BlockManagerInfo: Removed broadcast_31_piece0 on jupyter-spark-758b7c86d8-7j77n:43517 in memory (size: 163.6 KiB, free: 1048.5 MiB)\n",
      "25/11/13 15:03:45 INFO Executor: Finished task 12.0 in stage 31.0 (TID 377). 4633 bytes result sent to driver\n",
      "25/11/13 15:03:45 INFO TaskSetManager: Finished task 12.0 in stage 31.0 (TID 377) in 119 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (13/50)\n",
      "25/11/13 15:03:45 INFO TaskSetManager: Starting task 14.0 in stage 31.0 (TID 379) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 14, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:45 INFO Executor: Running task 14.0 in stage 31.0 (TID 379)\n",
      "25/11/13 15:03:45 INFO Executor: Finished task 13.0 in stage 31.0 (TID 378). 4633 bytes result sent to driver\n",
      "25/11/13 15:03:45 INFO TaskSetManager: Starting task 15.0 in stage 31.0 (TID 380) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 15, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:45 INFO TaskSetManager: Finished task 13.0 in stage 31.0 (TID 378) in 124 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (14/50)\n",
      "25/11/13 15:03:45 INFO Executor: Running task 15.0 in stage 31.0 (TID 380)\n",
      "25/11/13 15:03:45 INFO BlockManager: Found block rdd_88_14 locally\n",
      "25/11/13 15:03:45 INFO BlockManager: Found block rdd_88_15 locally\n",
      "25/11/13 15:03:45 INFO Executor: Finished task 14.0 in stage 31.0 (TID 379). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:45 INFO TaskSetManager: Starting task 16.0 in stage 31.0 (TID 381) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 16, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:45 INFO Executor: Running task 16.0 in stage 31.0 (TID 381)\n",
      "25/11/13 15:03:45 INFO TaskSetManager: Finished task 14.0 in stage 31.0 (TID 379) in 99 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (15/50)\n",
      "25/11/13 15:03:45 INFO Executor: Finished task 15.0 in stage 31.0 (TID 380). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:45 INFO TaskSetManager: Starting task 17.0 in stage 31.0 (TID 382) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 17, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:45 INFO BlockManager: Found block rdd_88_16 locally\n",
      "25/11/13 15:03:45 INFO TaskSetManager: Finished task 15.0 in stage 31.0 (TID 380) in 132 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (16/50)\n",
      "25/11/13 15:03:45 INFO Executor: Running task 17.0 in stage 31.0 (TID 382)\n",
      "25/11/13 15:03:45 INFO BlockManager: Found block rdd_88_17 locally\n",
      "25/11/13 15:03:45 INFO Executor: Finished task 16.0 in stage 31.0 (TID 381). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:45 INFO TaskSetManager: Starting task 18.0 in stage 31.0 (TID 383) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 18, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:45 INFO Executor: Running task 18.0 in stage 31.0 (TID 383)\n",
      "25/11/13 15:03:45 INFO TaskSetManager: Finished task 16.0 in stage 31.0 (TID 381) in 101 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (17/50)\n",
      "25/11/13 15:03:45 INFO Executor: Finished task 17.0 in stage 31.0 (TID 382). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:45 INFO TaskSetManager: Starting task 19.0 in stage 31.0 (TID 384) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 19, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:45 INFO Executor: Running task 19.0 in stage 31.0 (TID 384)\n",
      "25/11/13 15:03:45 INFO TaskSetManager: Finished task 17.0 in stage 31.0 (TID 382) in 97 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (18/50)\n",
      "25/11/13 15:03:45 INFO BlockManager: Found block rdd_88_18 locally\n",
      "25/11/13 15:03:45 INFO BlockManager: Found block rdd_88_19 locally\n",
      "25/11/13 15:03:45 INFO Executor: Finished task 18.0 in stage 31.0 (TID 383). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:45 INFO TaskSetManager: Starting task 20.0 in stage 31.0 (TID 385) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 20, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:45 INFO TaskSetManager: Finished task 18.0 in stage 31.0 (TID 383) in 94 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (19/50)\n",
      "25/11/13 15:03:45 INFO Executor: Running task 20.0 in stage 31.0 (TID 385)\n",
      "25/11/13 15:03:45 INFO Executor: Finished task 19.0 in stage 31.0 (TID 384). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:45 INFO TaskSetManager: Starting task 21.0 in stage 31.0 (TID 386) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 21, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:45 INFO BlockManager: Found block rdd_88_20 locally\n",
      "25/11/13 15:03:45 INFO Executor: Running task 21.0 in stage 31.0 (TID 386)\n",
      "25/11/13 15:03:45 INFO TaskSetManager: Finished task 19.0 in stage 31.0 (TID 384) in 101 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (20/50)\n",
      "25/11/13 15:03:45 INFO BlockManager: Found block rdd_88_21 locally\n",
      "25/11/13 15:03:45 INFO Executor: Finished task 20.0 in stage 31.0 (TID 385). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:45 INFO TaskSetManager: Starting task 22.0 in stage 31.0 (TID 387) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 22, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:45 INFO Executor: Running task 22.0 in stage 31.0 (TID 387)\n",
      "25/11/13 15:03:45 INFO TaskSetManager: Finished task 20.0 in stage 31.0 (TID 385) in 110 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (21/50)\n",
      "25/11/13 15:03:45 INFO BlockManager: Found block rdd_88_22 locally\n",
      "25/11/13 15:03:45 INFO Executor: Finished task 21.0 in stage 31.0 (TID 386). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:45 INFO TaskSetManager: Starting task 23.0 in stage 31.0 (TID 388) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 23, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:45 INFO Executor: Running task 23.0 in stage 31.0 (TID 388)\n",
      "25/11/13 15:03:45 INFO TaskSetManager: Finished task 21.0 in stage 31.0 (TID 386) in 106 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (22/50)\n",
      "25/11/13 15:03:45 INFO BlockManager: Found block rdd_88_23 locally\n",
      "25/11/13 15:03:45 INFO Executor: Finished task 22.0 in stage 31.0 (TID 387). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:45 INFO TaskSetManager: Starting task 24.0 in stage 31.0 (TID 389) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 24, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:45 INFO Executor: Running task 24.0 in stage 31.0 (TID 389)\n",
      "25/11/13 15:03:45 INFO TaskSetManager: Finished task 22.0 in stage 31.0 (TID 387) in 92 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (23/50)\n",
      "25/11/13 15:03:45 INFO BlockManager: Found block rdd_88_24 locally\n",
      "25/11/13 15:03:45 INFO Executor: Finished task 23.0 in stage 31.0 (TID 388). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:45 INFO TaskSetManager: Starting task 25.0 in stage 31.0 (TID 390) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 25, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:45 INFO Executor: Running task 25.0 in stage 31.0 (TID 390)\n",
      "25/11/13 15:03:45 INFO TaskSetManager: Finished task 23.0 in stage 31.0 (TID 388) in 98 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (24/50)\n",
      "25/11/13 15:03:45 INFO BlockManager: Found block rdd_88_25 locally\n",
      "25/11/13 15:03:45 INFO Executor: Finished task 24.0 in stage 31.0 (TID 389). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:45 INFO TaskSetManager: Starting task 26.0 in stage 31.0 (TID 391) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 26, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:45 INFO Executor: Running task 26.0 in stage 31.0 (TID 391)\n",
      "25/11/13 15:03:45 INFO TaskSetManager: Finished task 24.0 in stage 31.0 (TID 389) in 99 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (25/50)\n",
      "25/11/13 15:03:45 INFO BlockManager: Found block rdd_88_26 locally\n",
      "25/11/13 15:03:45 INFO Executor: Finished task 25.0 in stage 31.0 (TID 390). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:45 INFO TaskSetManager: Starting task 27.0 in stage 31.0 (TID 392) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 27, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:45 INFO TaskSetManager: Finished task 25.0 in stage 31.0 (TID 390) in 99 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (26/50)\n",
      "25/11/13 15:03:45 INFO Executor: Running task 27.0 in stage 31.0 (TID 392)\n",
      "25/11/13 15:03:45 INFO BlockManager: Found block rdd_88_27 locally(26 + 2) / 50]\n",
      "25/11/13 15:03:45 INFO Executor: Finished task 26.0 in stage 31.0 (TID 391). 4633 bytes result sent to driver\n",
      "25/11/13 15:03:45 INFO TaskSetManager: Starting task 28.0 in stage 31.0 (TID 393) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 28, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:45 INFO TaskSetManager: Finished task 26.0 in stage 31.0 (TID 391) in 93 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (27/50)\n",
      "25/11/13 15:03:45 INFO Executor: Running task 28.0 in stage 31.0 (TID 393)\n",
      "25/11/13 15:03:45 INFO BlockManager: Found block rdd_88_28 locally\n",
      "25/11/13 15:03:45 INFO Executor: Finished task 27.0 in stage 31.0 (TID 392). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:45 INFO TaskSetManager: Starting task 29.0 in stage 31.0 (TID 394) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 29, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:45 INFO Executor: Running task 29.0 in stage 31.0 (TID 394)\n",
      "25/11/13 15:03:45 INFO TaskSetManager: Finished task 27.0 in stage 31.0 (TID 392) in 107 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (28/50)\n",
      "25/11/13 15:03:45 INFO BlockManager: Found block rdd_88_29 locally\n",
      "25/11/13 15:03:45 INFO Executor: Finished task 28.0 in stage 31.0 (TID 393). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:45 INFO TaskSetManager: Starting task 30.0 in stage 31.0 (TID 395) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 30, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:45 INFO Executor: Running task 30.0 in stage 31.0 (TID 395)\n",
      "25/11/13 15:03:45 INFO TaskSetManager: Finished task 28.0 in stage 31.0 (TID 393) in 101 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (29/50)\n",
      "25/11/13 15:03:45 INFO BlockManager: Found block rdd_88_30 locally\n",
      "25/11/13 15:03:46 INFO Executor: Finished task 29.0 in stage 31.0 (TID 394). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:46 INFO TaskSetManager: Starting task 31.0 in stage 31.0 (TID 396) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 31, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:46 INFO Executor: Running task 31.0 in stage 31.0 (TID 396)\n",
      "25/11/13 15:03:46 INFO TaskSetManager: Finished task 29.0 in stage 31.0 (TID 394) in 95 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (30/50)\n",
      "25/11/13 15:03:46 INFO BlockManager: Found block rdd_88_31 locally\n",
      "25/11/13 15:03:46 INFO Executor: Finished task 30.0 in stage 31.0 (TID 395). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:46 INFO TaskSetManager: Starting task 32.0 in stage 31.0 (TID 397) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 32, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:46 INFO TaskSetManager: Finished task 30.0 in stage 31.0 (TID 395) in 102 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (31/50)\n",
      "25/11/13 15:03:46 INFO Executor: Running task 32.0 in stage 31.0 (TID 397)\n",
      "25/11/13 15:03:46 INFO BlockManager: Found block rdd_88_32 locally\n",
      "25/11/13 15:03:46 INFO Executor: Finished task 31.0 in stage 31.0 (TID 396). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:46 INFO TaskSetManager: Starting task 33.0 in stage 31.0 (TID 398) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 33, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:46 INFO Executor: Running task 33.0 in stage 31.0 (TID 398)\n",
      "25/11/13 15:03:46 INFO TaskSetManager: Finished task 31.0 in stage 31.0 (TID 396) in 103 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (32/50)\n",
      "25/11/13 15:03:46 INFO BlockManager: Found block rdd_88_33 locally\n",
      "25/11/13 15:03:46 INFO Executor: Finished task 32.0 in stage 31.0 (TID 397). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:46 INFO TaskSetManager: Starting task 34.0 in stage 31.0 (TID 399) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 34, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:46 INFO Executor: Running task 34.0 in stage 31.0 (TID 399)\n",
      "25/11/13 15:03:46 INFO TaskSetManager: Finished task 32.0 in stage 31.0 (TID 397) in 107 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (33/50)\n",
      "25/11/13 15:03:46 INFO BlockManager: Found block rdd_88_34 locally\n",
      "25/11/13 15:03:46 INFO Executor: Finished task 33.0 in stage 31.0 (TID 398). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:46 INFO TaskSetManager: Starting task 35.0 in stage 31.0 (TID 400) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 35, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:46 INFO TaskSetManager: Finished task 33.0 in stage 31.0 (TID 398) in 98 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (34/50)\n",
      "25/11/13 15:03:46 INFO Executor: Running task 35.0 in stage 31.0 (TID 400)\n",
      "25/11/13 15:03:46 INFO BlockManager: Found block rdd_88_35 locally\n",
      "25/11/13 15:03:46 INFO Executor: Finished task 34.0 in stage 31.0 (TID 399). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:46 INFO TaskSetManager: Starting task 36.0 in stage 31.0 (TID 401) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 36, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:46 INFO Executor: Running task 36.0 in stage 31.0 (TID 401)\n",
      "25/11/13 15:03:46 INFO TaskSetManager: Finished task 34.0 in stage 31.0 (TID 399) in 109 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (35/50)\n",
      "25/11/13 15:03:46 INFO Executor: Finished task 35.0 in stage 31.0 (TID 400). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:46 INFO BlockManager: Found block rdd_88_36 locally\n",
      "25/11/13 15:03:46 INFO TaskSetManager: Starting task 37.0 in stage 31.0 (TID 402) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 37, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:46 INFO Executor: Running task 37.0 in stage 31.0 (TID 402)\n",
      "25/11/13 15:03:46 INFO TaskSetManager: Finished task 35.0 in stage 31.0 (TID 400) in 104 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (36/50)\n",
      "25/11/13 15:03:46 INFO BlockManager: Found block rdd_88_37 locally\n",
      "25/11/13 15:03:46 INFO Executor: Finished task 36.0 in stage 31.0 (TID 401). 4633 bytes result sent to driver\n",
      "25/11/13 15:03:46 INFO TaskSetManager: Starting task 38.0 in stage 31.0 (TID 403) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 38, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:46 INFO Executor: Running task 38.0 in stage 31.0 (TID 403)\n",
      "25/11/13 15:03:46 INFO TaskSetManager: Finished task 36.0 in stage 31.0 (TID 401) in 114 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (37/50)\n",
      "25/11/13 15:03:46 INFO Executor: Finished task 37.0 in stage 31.0 (TID 402). 4633 bytes result sent to driver\n",
      "25/11/13 15:03:46 INFO BlockManager: Found block rdd_88_38 locally\n",
      "25/11/13 15:03:46 INFO TaskSetManager: Starting task 39.0 in stage 31.0 (TID 404) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 39, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:46 INFO TaskSetManager: Finished task 37.0 in stage 31.0 (TID 402) in 114 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (38/50)\n",
      "25/11/13 15:03:46 INFO Executor: Running task 39.0 in stage 31.0 (TID 404)\n",
      "25/11/13 15:03:46 INFO BlockManager: Found block rdd_88_39 locally(38 + 2) / 50]\n",
      "25/11/13 15:03:46 INFO Executor: Finished task 38.0 in stage 31.0 (TID 403). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:46 INFO TaskSetManager: Starting task 40.0 in stage 31.0 (TID 405) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 40, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:46 INFO TaskSetManager: Finished task 38.0 in stage 31.0 (TID 403) in 93 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (39/50)\n",
      "25/11/13 15:03:46 INFO Executor: Running task 40.0 in stage 31.0 (TID 405)\n",
      "25/11/13 15:03:46 INFO Executor: Finished task 39.0 in stage 31.0 (TID 404). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:46 INFO TaskSetManager: Starting task 41.0 in stage 31.0 (TID 406) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 41, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:46 INFO TaskSetManager: Finished task 39.0 in stage 31.0 (TID 404) in 100 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (40/50)\n",
      "25/11/13 15:03:46 INFO BlockManager: Found block rdd_88_40 locally\n",
      "25/11/13 15:03:46 INFO Executor: Running task 41.0 in stage 31.0 (TID 406)\n",
      "25/11/13 15:03:46 INFO BlockManager: Found block rdd_88_41 locally\n",
      "25/11/13 15:03:46 INFO Executor: Finished task 40.0 in stage 31.0 (TID 405). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:46 INFO TaskSetManager: Starting task 42.0 in stage 31.0 (TID 407) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 42, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:46 INFO Executor: Running task 42.0 in stage 31.0 (TID 407)\n",
      "25/11/13 15:03:46 INFO TaskSetManager: Finished task 40.0 in stage 31.0 (TID 405) in 107 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (41/50)\n",
      "25/11/13 15:03:46 INFO BlockManager: Found block rdd_88_42 locally\n",
      "25/11/13 15:03:46 INFO Executor: Finished task 41.0 in stage 31.0 (TID 406). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:46 INFO TaskSetManager: Starting task 43.0 in stage 31.0 (TID 408) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 43, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:46 INFO TaskSetManager: Finished task 41.0 in stage 31.0 (TID 406) in 101 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (42/50)\n",
      "25/11/13 15:03:46 INFO Executor: Running task 43.0 in stage 31.0 (TID 408)\n",
      "25/11/13 15:03:46 INFO BlockManager: Found block rdd_88_43 locally(42 + 2) / 50]\n",
      "25/11/13 15:03:46 INFO Executor: Finished task 42.0 in stage 31.0 (TID 407). 4633 bytes result sent to driver\n",
      "25/11/13 15:03:46 INFO TaskSetManager: Starting task 44.0 in stage 31.0 (TID 409) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 44, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:46 INFO TaskSetManager: Finished task 42.0 in stage 31.0 (TID 407) in 99 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (43/50)\n",
      "25/11/13 15:03:46 INFO Executor: Running task 44.0 in stage 31.0 (TID 409)\n",
      "25/11/13 15:03:46 INFO BlockManager: Found block rdd_88_44 locally\n",
      "25/11/13 15:03:46 INFO Executor: Finished task 43.0 in stage 31.0 (TID 408). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:46 INFO TaskSetManager: Starting task 45.0 in stage 31.0 (TID 410) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 45, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:46 INFO Executor: Running task 45.0 in stage 31.0 (TID 410)\n",
      "25/11/13 15:03:46 INFO TaskSetManager: Finished task 43.0 in stage 31.0 (TID 408) in 102 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (44/50)\n",
      "25/11/13 15:03:46 INFO BlockManager: Found block rdd_88_45 locally\n",
      "25/11/13 15:03:46 INFO Executor: Finished task 44.0 in stage 31.0 (TID 409). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:46 INFO TaskSetManager: Starting task 46.0 in stage 31.0 (TID 411) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 46, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:46 INFO Executor: Running task 46.0 in stage 31.0 (TID 411)\n",
      "25/11/13 15:03:46 INFO TaskSetManager: Finished task 44.0 in stage 31.0 (TID 409) in 101 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (45/50)\n",
      "25/11/13 15:03:46 INFO Executor: Finished task 45.0 in stage 31.0 (TID 410). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:46 INFO TaskSetManager: Starting task 47.0 in stage 31.0 (TID 412) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 47, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:46 INFO Executor: Running task 47.0 in stage 31.0 (TID 412)\n",
      "25/11/13 15:03:46 INFO TaskSetManager: Finished task 45.0 in stage 31.0 (TID 410) in 85 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (46/50)\n",
      "25/11/13 15:03:46 INFO BlockManager: Found block rdd_88_46 locally\n",
      "25/11/13 15:03:46 INFO BlockManager: Found block rdd_88_47 locally\n",
      "25/11/13 15:03:46 INFO Executor: Finished task 46.0 in stage 31.0 (TID 411). 4633 bytes result sent to driver\n",
      "25/11/13 15:03:46 INFO TaskSetManager: Starting task 48.0 in stage 31.0 (TID 413) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 48, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:46 INFO Executor: Running task 48.0 in stage 31.0 (TID 413)\n",
      "25/11/13 15:03:46 INFO TaskSetManager: Finished task 46.0 in stage 31.0 (TID 411) in 96 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (47/50)\n",
      "25/11/13 15:03:46 INFO Executor: Finished task 47.0 in stage 31.0 (TID 412). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:46 INFO TaskSetManager: Starting task 49.0 in stage 31.0 (TID 414) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 49, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:03:46 INFO Executor: Running task 49.0 in stage 31.0 (TID 414)\n",
      "25/11/13 15:03:46 INFO TaskSetManager: Finished task 47.0 in stage 31.0 (TID 412) in 97 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (48/50)\n",
      "25/11/13 15:03:46 INFO BlockManager: Found block rdd_88_48 locally\n",
      "25/11/13 15:03:46 INFO BlockManager: Found block rdd_88_49 locally\n",
      "25/11/13 15:03:46 INFO Executor: Finished task 48.0 in stage 31.0 (TID 413). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:46 INFO Executor: Finished task 49.0 in stage 31.0 (TID 414). 4590 bytes result sent to driver\n",
      "25/11/13 15:03:46 INFO TaskSetManager: Finished task 48.0 in stage 31.0 (TID 413) in 100 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (49/50)\n",
      "25/11/13 15:03:46 INFO TaskSetManager: Finished task 49.0 in stage 31.0 (TID 414) in 95 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (50/50)\n",
      "25/11/13 15:03:46 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool \n",
      "25/11/13 15:03:46 INFO DAGScheduler: ShuffleMapStage 31 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 2.530 s\n",
      "25/11/13 15:03:46 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/11/13 15:03:46 INFO DAGScheduler: running: Set()\n",
      "25/11/13 15:03:46 INFO DAGScheduler: waiting: Set()\n",
      "25/11/13 15:03:46 INFO DAGScheduler: failed: Set()\n",
      "25/11/13 15:03:47 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128\n",
      "25/11/13 15:03:47 INFO DAGScheduler: Got job 21 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 1 output partitions\n",
      "25/11/13 15:03:47 INFO DAGScheduler: Final stage: ResultStage 34 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)\n",
      "25/11/13 15:03:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 33)\n",
      "25/11/13 15:03:47 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 15:03:47 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[100] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents\n",
      "25/11/13 15:03:47 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 534.4 KiB, free 1046.6 MiB)\n",
      "25/11/13 15:03:47 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 124.9 KiB, free 1046.5 MiB)\n",
      "25/11/13 15:03:47 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 124.9 KiB, free: 1048.4 MiB)\n",
      "25/11/13 15:03:47 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 15:03:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[100] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0))\n",
      "25/11/13 15:03:47 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks resource profile 0\n",
      "25/11/13 15:03:47 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 415) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, NODE_LOCAL, 8999 bytes) \n",
      "25/11/13 15:03:47 INFO Executor: Running task 0.0 in stage 34.0 (TID 415)\n",
      "25/11/13 15:03:47 INFO ShuffleBlockFetcherIterator: Getting 50 (4.9 KiB) non-empty blocks including 50 (4.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:03:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/11/13 15:03:47 INFO Executor: Finished task 0.0 in stage 34.0 (TID 415). 7136 bytes result sent to driver\n",
      "25/11/13 15:03:47 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 415) in 76 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/1)\n",
      "25/11/13 15:03:47 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool \n",
      "25/11/13 15:03:47 INFO DAGScheduler: ResultStage 34 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.104 s\n",
      "25/11/13 15:03:47 INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/11/13 15:03:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 34: Stage finished\n",
      "25/11/13 15:03:47 INFO DAGScheduler: Job 21 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.112750 s\n",
      "25/11/13 15:03:47 INFO Snapshot: [tableId=d97aed6f-8e73-4258-85f1-83735790c6dc] DELTA: Done\n",
      "25/11/13 15:03:47 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/11/13 15:03:47 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/11/13 15:03:47 INFO CodeGenerator: Code generated in 30.158649 ms\n",
      "25/11/13 15:03:47 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 207.0 KiB, free 1046.3 MiB)\n",
      "25/11/13 15:03:47 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 1046.3 MiB)\n",
      "25/11/13 15:03:47 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 36.8 KiB, free: 1048.4 MiB)\n",
      "25/11/13 15:03:47 INFO SparkContext: Created broadcast 34 from showString at NativeMethodAccessorImpl.java:0\n",
      "25/11/13 15:03:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 34852989 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/11/13 15:03:47 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "25/11/13 15:03:47 INFO DAGScheduler: Got job 22 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/11/13 15:03:47 INFO DAGScheduler: Final stage: ResultStage 35 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/11/13 15:03:47 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/11/13 15:03:47 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 15:03:47 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[104] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/11/13 15:03:47 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 29.7 KiB, free 1046.2 MiB)\n",
      "25/11/13 15:03:47 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 10.1 KiB, free 1046.2 MiB)\n",
      "25/11/13 15:03:47 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 10.1 KiB, free: 1048.3 MiB)\n",
      "25/11/13 15:03:47 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 15:03:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[104] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/11/13 15:03:47 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks resource profile 0\n",
      "25/11/13 15:03:47 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 416) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 9671 bytes) \n",
      "25/11/13 15:03:47 INFO Executor: Running task 0.0 in stage 35.0 (TID 416)\n",
      "25/11/13 15:03:47 INFO CodeGenerator: Code generated in 20.056897 ms\n",
      "25/11/13 15:03:47 INFO FileScanRDD: Reading File path: s3a://nau-local-analytics-silver/dim_user/part-00000-1e2cb7c2-be16-4592-9fd6-87e16bfa900b-c000.snappy.parquet, range: 0-34852989, partition values: [empty row]\n",
      "25/11/13 15:03:47 INFO S3AInputStream: Switching to Random IO seek policy\n",
      "25/11/13 15:03:47 INFO BlockManagerInfo: Removed broadcast_33_piece0 on jupyter-spark-758b7c86d8-7j77n:43517 in memory (size: 124.9 KiB, free: 1048.5 MiB)\n",
      "25/11/13 15:03:47 INFO BlockManagerInfo: Removed broadcast_32_piece0 on jupyter-spark-758b7c86d8-7j77n:43517 in memory (size: 138.3 KiB, free: 1048.6 MiB)\n",
      "[Stage 35:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----------------+----------------------------------+-------------+---------+-----------------+--------+------------+---------+--------------------------+--------------------------+----------------------------------------------------------------+--------------------------+-----------+\n",
      "|user_sk|user_id|username         |email                             |first_name   |last_name|full_name        |is_staff|is_superuser|is_active|date_joined               |last_login                |user_hash                                                       |ingestion_date            |source_name|\n",
      "+-------+-------+-----------------+----------------------------------+-------------+---------+-----------------+--------+------------+---------+--------------------------+--------------------------+----------------------------------------------------------------+--------------------------+-----------+\n",
      "|1      |1      |enterprise_worker|enterprise_worker@example.com     |             |         |                 |true    |false       |true     |2018-08-29 18:34:26.488188|NULL                      |5292211e07d3eae558e746efeaae281a3208c83e6a78601c8a5ed4dce565fe66|2025-11-04 18:26:56.116039|auth_user  |\n",
      "|2      |2      |veda_service_user|veda_service_user@example.com     |             |         |                 |true    |false       |true     |2018-08-29 18:34:34.18119 |NULL                      |84136b8498e880143cde64d5badcc17ec16fd795ec7e04a4e78ccc076433892e|2025-11-04 18:26:56.116039|auth_user  |\n",
      "|3      |3      |ecommerce_worker |ecommerce_worker@example.com      |             |         |                 |true    |true        |true     |2018-08-29 18:34:42       |NULL                      |ea9522b2b1762f784b79624827c141c93254384bc8ad1fecd59fba5c0c0f63bb|2025-11-04 18:26:56.116039|auth_user  |\n",
      "|4      |4      |discovery_worker |discovery_worker@example.com      |             |         |                 |true    |false       |true     |2018-08-29 18:34:50.609274|NULL                      |cc7c9c19587681bac8b622b4f5a00e61d7ce138732e64c24460e7e8bce53688c|2025-11-04 18:26:56.116039|auth_user  |\n",
      "|5      |6      |insights_worker  |insights_worker@example.com       |             |         |                 |true    |false       |true     |2018-08-29 18:34:58.792988|NULL                      |369017097638c15933633841f9ceea5c595c121001f9cb95efbb986d94cdb983|2025-11-04 18:26:56.116039|auth_user  |\n",
      "|6      |7      |technical_edunext|technical@edunext.co              |             |         |                 |true    |true        |true     |2018-09-10 20:10:50       |2025-10-22 22:28:28.638619|58bdae2dd037b7ac57f77f911ccf65eebaef25f30513cce738e6a45c28a897ee|2025-11-04 18:26:56.116039|auth_user  |\n",
      "|7      |8      |admin            |alertas@nau.edu.pt                |Administrador|NAU      |Administrador NAU|true    |true        |true     |2018-09-14 16:58:50       |2025-03-19 14:45:20.856742|d16562f4a3eed876be3c58d0306d900fd2c877b022c61455b442acfbfa6254e5|2025-11-04 18:26:56.116039|auth_user  |\n",
      "|8      |10     |staff            |naudevel+prod-staff@gmail.com     |             |         |                 |true    |false       |true     |2018-09-14 17:01:45       |NULL                      |ed5ee83b9ce56077772d5fcbf38d722f461b50bb04a24abe5ce9bf1caf33e396|2025-11-04 18:26:56.116039|auth_user  |\n",
      "|9      |11     |instructor       |naudevel+prod-instructor@gmail.com|             |         |                 |false   |false       |true     |2018-09-14 17:02:46       |NULL                      |24f32f2da2d94fe0de6f50f93412df1590cb777ccbcd257aea3de07cd77342e8|2025-11-04 18:26:56.116039|auth_user  |\n",
      "|10     |12     |student          |naudevel+prod-student@gmail.com   |             |         |                 |false   |false       |true     |2018-09-14 17:03:38       |NULL                      |f97142e3119d5f94acb9c3f673b2b502028dda45d2e047de0b5d2aa5bb9cd5dc|2025-11-04 18:26:56.116039|auth_user  |\n",
      "+-------+-------+-----------------+----------------------------------+-------------+---------+-----------------+--------+------------+---------+--------------------------+--------------------------+----------------------------------------------------------------+--------------------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/13 15:03:48 INFO Executor: Finished task 0.0 in stage 35.0 (TID 416). 3911 bytes result sent to driver\n",
      "25/11/13 15:03:48 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 416) in 1063 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/1)\n",
      "25/11/13 15:03:48 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool \n",
      "25/11/13 15:03:48 INFO DAGScheduler: ResultStage 35 (showString at NativeMethodAccessorImpl.java:0) finished in 1.075 s\n",
      "25/11/13 15:03:48 INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/11/13 15:03:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 35: Stage finished\n",
      "25/11/13 15:03:48 INFO DAGScheduler: Job 22 finished: showString at NativeMethodAccessorImpl.java:0, took 1.081294 s\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "\n",
    "# ============================================================\n",
    "# Configuration\n",
    "# ============================================================\n",
    "silver_path = \"s3a://nau-local-analytics-silver/dim_user\"\n",
    "dim_table_name = \"dim_user\"\n",
    "\n",
    "BUSINESS_COLUMNS = [\n",
    "    \"user_id\",\n",
    "    \"username\",\n",
    "    \"email\",\n",
    "    \"first_name\",\n",
    "    \"last_name\",\n",
    "    \"full_name\",\n",
    "    \"is_staff\",\n",
    "    \"is_superuser\",\n",
    "    \"is_active\",\n",
    "    \"date_joined\",\n",
    "    \"last_login\",\n",
    "    \"user_hash\",\n",
    "    \"ingestion_date\",\n",
    "    \"source_name\",\n",
    "]\n",
    "\n",
    "# ============================================================\n",
    "# 1. Check if the Silver Delta table already exists\n",
    "# ============================================================\n",
    "try:\n",
    "    df_dim_user_current = (\n",
    "        spark.read\n",
    "             .format(\"delta\")\n",
    "             .load(silver_path)\n",
    "             .select(\"user_id\", \"user_sk\")\n",
    "    )\n",
    "    dim_user_exists = True\n",
    "    print(\">> [dim_user] Existing Silver Delta table found.\")\n",
    "except AnalysisException:\n",
    "    dim_user_exists = False\n",
    "    df_dim_user_current = None\n",
    "    print(\">> [dim_user] Silver Delta table does not exist yet (first load).\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. Build df_users_silver with a stable surrogate key (user_sk)\n",
    "# ============================================================\n",
    "if dim_user_exists:\n",
    "    # Get current max SK to keep the sequence\n",
    "    max_sk = df_dim_user_current.agg(F.max(\"user_sk\")).collect()[0][0]\n",
    "    max_sk = max_sk if max_sk is not None else 0\n",
    "\n",
    "    # Join Bronze source with existing SKs from Silver by natural key (user_id)\n",
    "    df_joined = (\n",
    "        df_users_source.alias(\"s\")\n",
    "        .join(\n",
    "            df_dim_user_current.alias(\"t\"),\n",
    "            on=\"user_id\",\n",
    "            how=\"left\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Existing users -> reuse user_sk\n",
    "    df_existing = (\n",
    "        df_joined\n",
    "        .filter(F.col(\"t.user_sk\").isNotNull())\n",
    "        .select(\n",
    "            F.col(\"t.user_sk\").alias(\"user_sk\"),\n",
    "            *[F.col(f\"s.{c}\").alias(c) for c in BUSINESS_COLUMNS]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # New users -> generate new SKs sequentially after max_sk\n",
    "    df_new = df_joined.filter(F.col(\"t.user_sk\").isNull())\n",
    "\n",
    "    w_new_users = Window.orderBy(F.col(\"s.user_id\"))\n",
    "\n",
    "    df_new_with_sk = (\n",
    "        df_new\n",
    "        .withColumn(\n",
    "            \"user_sk\",\n",
    "            F.row_number().over(w_new_users) + F.lit(max_sk)\n",
    "        )\n",
    "        .select(\n",
    "            F.col(\"user_sk\"),\n",
    "            *[F.col(f\"s.{c}\").alias(c) for c in BUSINESS_COLUMNS]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Final dataframe for Silver\n",
    "    df_users_silver = df_existing.unionByName(df_new_with_sk)\n",
    "\n",
    "else:\n",
    "    # First load: generate SKs from scratch\n",
    "    w_initial_load = Window.orderBy(\"user_id\")\n",
    "\n",
    "    df_users_silver = (\n",
    "        df_users_source\n",
    "        .withColumn(\"user_sk\", F.row_number().over(w_initial_load))\n",
    "        .select(\n",
    "            \"user_sk\",\n",
    "            *BUSINESS_COLUMNS\n",
    "        )\n",
    "    )\n",
    "\n",
    "print(\">> [dim_user] Preview of df_users_silver (with user_sk):\")\n",
    "df_users_silver.printSchema()\n",
    "df_users_silver.show(10, truncate=False)\n",
    "\n",
    "# ============================================================\n",
    "# 3. Upsert into Silver using Delta MERGE (SQL)\n",
    "# ============================================================\n",
    "\n",
    "if dim_user_exists:\n",
    "    print(\">> [dim_user] Registering staging view and running MERGE...\")\n",
    "\n",
    "    # Staging view for the current run\n",
    "    df_users_silver.createOrReplaceTempView(\"stg_dim_user\")\n",
    "\n",
    "    # Make sure the Delta table is registered in the catalog\n",
    "    spark.sql(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {dim_table_name}\n",
    "        USING delta\n",
    "        LOCATION '{silver_path}'\n",
    "    \"\"\")\n",
    "\n",
    "    spark.sql(f\"\"\"\n",
    "        MERGE INTO {dim_table_name} AS t\n",
    "        USING stg_dim_user AS s\n",
    "        ON t.user_id = s.user_id\n",
    "        WHEN MATCHED THEN UPDATE SET\n",
    "            t.username       = s.username,\n",
    "            t.email          = s.email,\n",
    "            t.first_name     = s.first_name,\n",
    "            t.last_name      = s.last_name,\n",
    "            t.full_name      = s.full_name,\n",
    "            t.is_staff       = s.is_staff,\n",
    "            t.is_superuser   = s.is_superuser,\n",
    "            t.is_active      = s.is_active,\n",
    "            t.date_joined    = s.date_joined,\n",
    "            t.last_login     = s.last_login,\n",
    "            t.user_hash      = s.user_hash,\n",
    "            t.ingestion_date = s.ingestion_date,\n",
    "            t.source_name    = s.source_name\n",
    "        WHEN NOT MATCHED THEN INSERT (\n",
    "            user_sk,\n",
    "            user_id,\n",
    "            username,\n",
    "            email,\n",
    "            first_name,\n",
    "            last_name,\n",
    "            full_name,\n",
    "            is_staff,\n",
    "            is_superuser,\n",
    "            is_active,\n",
    "            date_joined,\n",
    "            last_login,\n",
    "            user_hash,\n",
    "            ingestion_date,\n",
    "            source_name\n",
    "        )\n",
    "        VALUES (\n",
    "            s.user_sk,\n",
    "            s.user_id,\n",
    "            s.username,\n",
    "            s.email,\n",
    "            s.first_name,\n",
    "            s.last_name,\n",
    "            s.full_name,\n",
    "            s.is_staff,\n",
    "            s.is_superuser,\n",
    "            s.is_active,\n",
    "            s.date_joined,\n",
    "            s.last_login,\n",
    "            s.user_hash,\n",
    "            s.ingestion_date,\n",
    "            s.source_name\n",
    "        )\n",
    "    \"\"\")\n",
    "else:\n",
    "    print(\">> [dim_user] Writing initial Silver Delta table (overwrite).\")\n",
    "\n",
    "    (\n",
    "        df_users_silver\n",
    "            .write\n",
    "            .format(\"delta\")\n",
    "            .mode(\"overwrite\")\n",
    "            .option(\"overwriteSchema\", \"true\")\n",
    "            .save(silver_path)\n",
    "    )\n",
    "\n",
    "    # Optionally register it in the metastore\n",
    "    spark.sql(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {dim_table_name}\n",
    "        USING delta\n",
    "        LOCATION '{silver_path}'\n",
    "    \"\"\")\n",
    "\n",
    "print(\">> [dim_user] Load/MERGE finished. Quick validation:\")\n",
    "\n",
    "df_dim_user_check = spark.read.format(\"delta\").load(silver_path)\n",
    "df_dim_user_check.show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3dff7b30-b6ec-4044-9e66-995ab9490df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> [dim_user] Reading Silver Delta table from path:\n",
      "   s3a://nau-local-analytics-silver/dim_user\n",
      "\n",
      ">> [dim_user] Schema:\n",
      "root\n",
      " |-- user_sk: integer (nullable = true)\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- username: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- full_name: string (nullable = true)\n",
      " |-- is_staff: boolean (nullable = true)\n",
      " |-- is_superuser: boolean (nullable = true)\n",
      " |-- is_active: boolean (nullable = true)\n",
      " |-- date_joined: timestamp (nullable = true)\n",
      " |-- last_login: timestamp (nullable = true)\n",
      " |-- user_hash: string (nullable = true)\n",
      " |-- ingestion_date: timestamp (nullable = true)\n",
      " |-- source_name: string (nullable = true)\n",
      "\n",
      ">> [dim_user] Sample rows:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/13 15:06:35 INFO PrepareDeltaScan: DELTA: Filtering files for query\n",
      "25/11/13 15:06:35 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128\n",
      "25/11/13 15:06:35 INFO DAGScheduler: Got job 23 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions\n",
      "25/11/13 15:06:35 INFO DAGScheduler: Final stage: ResultStage 37 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)\n",
      "25/11/13 15:06:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 36)\n",
      "25/11/13 15:06:35 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 15:06:35 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[106] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents\n",
      "25/11/13 15:06:35 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 684.9 KiB, free 1046.9 MiB)\n",
      "25/11/13 15:06:35 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 154.6 KiB, free 1046.8 MiB)\n",
      "25/11/13 15:06:35 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 154.6 KiB, free: 1048.5 MiB)\n",
      "25/11/13 15:06:35 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 15:06:35 INFO DAGScheduler: Submitting 50 missing tasks from ResultStage 37 (MapPartitionsRDD[106] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n",
      "25/11/13 15:06:35 INFO TaskSchedulerImpl: Adding task set 37.0 with 50 tasks resource profile 0\n",
      "25/11/13 15:06:35 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 417) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:35 INFO TaskSetManager: Starting task 1.0 in stage 37.0 (TID 418) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 1, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:35 INFO Executor: Running task 1.0 in stage 37.0 (TID 418)\n",
      "25/11/13 15:06:35 INFO Executor: Running task 0.0 in stage 37.0 (TID 417)\n",
      "25/11/13 15:06:35 INFO BlockManagerInfo: Removed broadcast_35_piece0 on jupyter-spark-758b7c86d8-7j77n:43517 in memory (size: 10.1 KiB, free: 1048.5 MiB)\n",
      "25/11/13 15:06:35 INFO BlockManager: Found block rdd_88_0 locally\n",
      "25/11/13 15:06:35 INFO BlockManager: Found block rdd_88_1 locally\n",
      "25/11/13 15:06:35 INFO Executor: Finished task 0.0 in stage 37.0 (TID 417). 4267 bytes result sent to driver\n",
      "25/11/13 15:06:35 INFO Executor: Finished task 1.0 in stage 37.0 (TID 418). 4267 bytes result sent to driver\n",
      "25/11/13 15:06:35 INFO TaskSetManager: Starting task 2.0 in stage 37.0 (TID 419) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 2, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:35 INFO Executor: Running task 2.0 in stage 37.0 (TID 419)\n",
      "25/11/13 15:06:35 INFO TaskSetManager: Starting task 3.0 in stage 37.0 (TID 420) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 3, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:35 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 417) in 94 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/50)\n",
      "25/11/13 15:06:35 INFO Executor: Running task 3.0 in stage 37.0 (TID 420)\n",
      "25/11/13 15:06:35 INFO TaskSetManager: Finished task 1.0 in stage 37.0 (TID 418) in 94 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (2/50)\n",
      "25/11/13 15:06:35 INFO BlockManager: Found block rdd_88_3 locally\n",
      "25/11/13 15:06:35 INFO BlockManager: Found block rdd_88_2 locally\n",
      "25/11/13 15:06:35 INFO Executor: Finished task 3.0 in stage 37.0 (TID 420). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:35 INFO TaskSetManager: Starting task 4.0 in stage 37.0 (TID 421) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 4, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:35 INFO Executor: Running task 4.0 in stage 37.0 (TID 421)\n",
      "25/11/13 15:06:35 INFO Executor: Finished task 2.0 in stage 37.0 (TID 419). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:35 INFO TaskSetManager: Finished task 3.0 in stage 37.0 (TID 420) in 37 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (3/50)\n",
      "25/11/13 15:06:35 INFO TaskSetManager: Starting task 5.0 in stage 37.0 (TID 422) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 5, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:35 INFO Executor: Running task 5.0 in stage 37.0 (TID 422)\n",
      "25/11/13 15:06:35 INFO TaskSetManager: Finished task 2.0 in stage 37.0 (TID 419) in 39 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (4/50)\n",
      "25/11/13 15:06:35 INFO BlockManager: Found block rdd_88_4 locally\n",
      "25/11/13 15:06:35 INFO BlockManager: Found block rdd_88_5 locally\n",
      "25/11/13 15:06:35 INFO Executor: Finished task 4.0 in stage 37.0 (TID 421). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:35 INFO TaskSetManager: Starting task 6.0 in stage 37.0 (TID 423) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 6, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:35 INFO Executor: Running task 6.0 in stage 37.0 (TID 423)\n",
      "25/11/13 15:06:35 INFO Executor: Finished task 5.0 in stage 37.0 (TID 422). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:35 INFO TaskSetManager: Starting task 7.0 in stage 37.0 (TID 424) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 7, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:35 INFO Executor: Running task 7.0 in stage 37.0 (TID 424)\n",
      "25/11/13 15:06:35 INFO TaskSetManager: Finished task 4.0 in stage 37.0 (TID 421) in 48 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (5/50)\n",
      "25/11/13 15:06:35 INFO TaskSetManager: Finished task 5.0 in stage 37.0 (TID 422) in 47 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (6/50)\n",
      "25/11/13 15:06:35 INFO BlockManager: Found block rdd_88_6 locally\n",
      "25/11/13 15:06:35 INFO Executor: Finished task 6.0 in stage 37.0 (TID 423). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:35 INFO TaskSetManager: Starting task 8.0 in stage 37.0 (TID 425) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 8, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:35 INFO TaskSetManager: Finished task 6.0 in stage 37.0 (TID 423) in 44 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (7/50)\n",
      "25/11/13 15:06:35 INFO Executor: Running task 8.0 in stage 37.0 (TID 425)\n",
      "25/11/13 15:06:35 INFO BlockManager: Found block rdd_88_7 locally\n",
      "25/11/13 15:06:35 INFO Executor: Finished task 7.0 in stage 37.0 (TID 424). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:35 INFO TaskSetManager: Starting task 9.0 in stage 37.0 (TID 426) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 9, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:35 INFO Executor: Running task 9.0 in stage 37.0 (TID 426)\n",
      "25/11/13 15:06:35 INFO TaskSetManager: Finished task 7.0 in stage 37.0 (TID 424) in 68 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (8/50)\n",
      "25/11/13 15:06:35 INFO BlockManager: Found block rdd_88_8 locally\n",
      "25/11/13 15:06:35 INFO Executor: Finished task 8.0 in stage 37.0 (TID 425). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:35 INFO TaskSetManager: Starting task 10.0 in stage 37.0 (TID 427) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 10, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:35 INFO BlockManager: Found block rdd_88_9 locally\n",
      "25/11/13 15:06:35 INFO TaskSetManager: Finished task 8.0 in stage 37.0 (TID 425) in 42 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (9/50)\n",
      "25/11/13 15:06:35 INFO Executor: Running task 10.0 in stage 37.0 (TID 427)\n",
      "25/11/13 15:06:35 INFO Executor: Finished task 9.0 in stage 37.0 (TID 426). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:35 INFO TaskSetManager: Starting task 11.0 in stage 37.0 (TID 428) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 11, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:35 INFO Executor: Running task 11.0 in stage 37.0 (TID 428)\n",
      "25/11/13 15:06:35 INFO TaskSetManager: Finished task 9.0 in stage 37.0 (TID 426) in 21 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (10/50)\n",
      "25/11/13 15:06:35 INFO BlockManager: Found block rdd_88_11 locally\n",
      "25/11/13 15:06:35 INFO BlockManager: Found block rdd_88_10 locally\n",
      "25/11/13 15:06:35 INFO Executor: Finished task 11.0 in stage 37.0 (TID 428). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:35 INFO TaskSetManager: Starting task 12.0 in stage 37.0 (TID 429) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 12, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:35 INFO Executor: Finished task 10.0 in stage 37.0 (TID 427). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:35 INFO Executor: Running task 12.0 in stage 37.0 (TID 429)\n",
      "25/11/13 15:06:35 INFO TaskSetManager: Starting task 13.0 in stage 37.0 (TID 430) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 13, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:35 INFO Executor: Running task 13.0 in stage 37.0 (TID 430)\n",
      "25/11/13 15:06:35 INFO TaskSetManager: Finished task 11.0 in stage 37.0 (TID 428) in 51 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (11/50)\n",
      "25/11/13 15:06:35 INFO TaskSetManager: Finished task 10.0 in stage 37.0 (TID 427) in 56 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (12/50)\n",
      "25/11/13 15:06:35 INFO BlockManager: Found block rdd_88_12 locally\n",
      "25/11/13 15:06:35 INFO Executor: Finished task 12.0 in stage 37.0 (TID 429). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:35 INFO BlockManager: Found block rdd_88_13 locally\n",
      "25/11/13 15:06:35 INFO TaskSetManager: Starting task 14.0 in stage 37.0 (TID 431) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 14, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:35 INFO Executor: Running task 14.0 in stage 37.0 (TID 431)\n",
      "25/11/13 15:06:35 INFO TaskSetManager: Finished task 12.0 in stage 37.0 (TID 429) in 36 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (13/50)\n",
      "25/11/13 15:06:35 INFO Executor: Finished task 13.0 in stage 37.0 (TID 430). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:35 INFO TaskSetManager: Starting task 15.0 in stage 37.0 (TID 432) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 15, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:35 INFO TaskSetManager: Finished task 13.0 in stage 37.0 (TID 430) in 39 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (14/50)\n",
      "25/11/13 15:06:35 INFO Executor: Running task 15.0 in stage 37.0 (TID 432)\n",
      "25/11/13 15:06:35 INFO BlockManager: Found block rdd_88_14 locally\n",
      "25/11/13 15:06:35 INFO Executor: Finished task 14.0 in stage 37.0 (TID 431). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:35 INFO TaskSetManager: Starting task 16.0 in stage 37.0 (TID 433) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 16, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:35 INFO TaskSetManager: Finished task 14.0 in stage 37.0 (TID 431) in 22 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (15/50)\n",
      "25/11/13 15:06:35 INFO Executor: Running task 16.0 in stage 37.0 (TID 433)\n",
      "25/11/13 15:06:36 INFO BlockManager: Found block rdd_88_15 locally\n",
      "25/11/13 15:06:36 INFO Executor: Finished task 15.0 in stage 37.0 (TID 432). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Starting task 17.0 in stage 37.0 (TID 434) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 17, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:36 INFO Executor: Running task 17.0 in stage 37.0 (TID 434)\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Finished task 15.0 in stage 37.0 (TID 432) in 58 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (16/50)\n",
      "25/11/13 15:06:36 INFO BlockManager: Found block rdd_88_16 locally\n",
      "25/11/13 15:06:36 INFO Executor: Finished task 16.0 in stage 37.0 (TID 433). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Starting task 18.0 in stage 37.0 (TID 435) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 18, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:36 INFO BlockManager: Found block rdd_88_17 locally\n",
      "25/11/13 15:06:36 INFO Executor: Running task 18.0 in stage 37.0 (TID 435)\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Finished task 16.0 in stage 37.0 (TID 433) in 72 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (17/50)\n",
      "25/11/13 15:06:36 INFO Executor: Finished task 17.0 in stage 37.0 (TID 434). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Starting task 19.0 in stage 37.0 (TID 436) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 19, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:36 INFO Executor: Running task 19.0 in stage 37.0 (TID 436)\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Finished task 17.0 in stage 37.0 (TID 434) in 38 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (18/50)\n",
      "25/11/13 15:06:36 INFO BlockManager: Found block rdd_88_18 locally\n",
      "25/11/13 15:06:36 INFO Executor: Finished task 18.0 in stage 37.0 (TID 435). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Starting task 20.0 in stage 37.0 (TID 437) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 20, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:36 INFO Executor: Running task 20.0 in stage 37.0 (TID 437)\n",
      "25/11/13 15:06:36 INFO BlockManager: Found block rdd_88_19 locally\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Finished task 18.0 in stage 37.0 (TID 435) in 22 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (19/50)\n",
      "25/11/13 15:06:36 INFO Executor: Finished task 19.0 in stage 37.0 (TID 436). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Starting task 21.0 in stage 37.0 (TID 438) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 21, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:36 INFO Executor: Running task 21.0 in stage 37.0 (TID 438)\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Finished task 19.0 in stage 37.0 (TID 436) in 23 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (20/50)\n",
      "25/11/13 15:06:36 INFO BlockManager: Found block rdd_88_20 locally\n",
      "25/11/13 15:06:36 INFO Executor: Finished task 20.0 in stage 37.0 (TID 437). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Starting task 22.0 in stage 37.0 (TID 439) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 22, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:36 INFO TaskSetManager: Finished task 20.0 in stage 37.0 (TID 437) in 50 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (21/50)\n",
      "25/11/13 15:06:36 INFO Executor: Running task 22.0 in stage 37.0 (TID 439)\n",
      "25/11/13 15:06:36 INFO BlockManager: Found block rdd_88_21 locally\n",
      "25/11/13 15:06:36 INFO Executor: Finished task 21.0 in stage 37.0 (TID 438). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Starting task 23.0 in stage 37.0 (TID 440) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 23, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:36 INFO Executor: Running task 23.0 in stage 37.0 (TID 440)\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Finished task 21.0 in stage 37.0 (TID 438) in 50 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (22/50)\n",
      "25/11/13 15:06:36 INFO BlockManager: Found block rdd_88_22 locally\n",
      "25/11/13 15:06:36 INFO Executor: Finished task 22.0 in stage 37.0 (TID 439). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:36 INFO BlockManager: Found block rdd_88_23 locally\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Starting task 24.0 in stage 37.0 (TID 441) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 24, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:36 INFO Executor: Running task 24.0 in stage 37.0 (TID 441)\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Finished task 22.0 in stage 37.0 (TID 439) in 37 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (23/50)\n",
      "25/11/13 15:06:36 INFO Executor: Finished task 23.0 in stage 37.0 (TID 440). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Starting task 25.0 in stage 37.0 (TID 442) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 25, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:36 INFO Executor: Running task 25.0 in stage 37.0 (TID 442)\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Finished task 23.0 in stage 37.0 (TID 440) in 36 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (24/50)\n",
      "25/11/13 15:06:36 INFO BlockManager: Found block rdd_88_24 locally\n",
      "25/11/13 15:06:36 INFO BlockManager: Found block rdd_88_25 locally\n",
      "25/11/13 15:06:36 INFO Executor: Finished task 24.0 in stage 37.0 (TID 441). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Starting task 26.0 in stage 37.0 (TID 443) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 26, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:36 INFO Executor: Running task 26.0 in stage 37.0 (TID 443)\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Finished task 24.0 in stage 37.0 (TID 441) in 21 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (25/50)\n",
      "25/11/13 15:06:36 INFO Executor: Finished task 25.0 in stage 37.0 (TID 442). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Starting task 27.0 in stage 37.0 (TID 444) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 27, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:36 INFO Executor: Running task 27.0 in stage 37.0 (TID 444)\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Finished task 25.0 in stage 37.0 (TID 442) in 20 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (26/50)\n",
      "25/11/13 15:06:36 INFO BlockManager: Found block rdd_88_26 locally\n",
      "25/11/13 15:06:36 INFO Executor: Finished task 26.0 in stage 37.0 (TID 443). 4393 bytes result sent to driver\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Starting task 28.0 in stage 37.0 (TID 445) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 28, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:36 INFO Executor: Running task 28.0 in stage 37.0 (TID 445)\n",
      "25/11/13 15:06:36 INFO BlockManager: Found block rdd_88_27 locally\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Finished task 26.0 in stage 37.0 (TID 443) in 87 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (27/50)\n",
      "25/11/13 15:06:36 INFO Executor: Finished task 27.0 in stage 37.0 (TID 444). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Starting task 29.0 in stage 37.0 (TID 446) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 29, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:36 INFO Executor: Running task 29.0 in stage 37.0 (TID 446)\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Finished task 27.0 in stage 37.0 (TID 444) in 87 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (28/50)\n",
      "25/11/13 15:06:36 INFO BlockManager: Found block rdd_88_28 locally\n",
      "25/11/13 15:06:36 INFO Executor: Finished task 28.0 in stage 37.0 (TID 445). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:36 INFO BlockManager: Found block rdd_88_29 locally\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Starting task 30.0 in stage 37.0 (TID 447) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 30, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:36 INFO Executor: Running task 30.0 in stage 37.0 (TID 447) / 50]\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Finished task 28.0 in stage 37.0 (TID 445) in 50 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (29/50)\n",
      "25/11/13 15:06:36 INFO Executor: Finished task 29.0 in stage 37.0 (TID 446). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Starting task 31.0 in stage 37.0 (TID 448) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 31, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:36 INFO TaskSetManager: Finished task 29.0 in stage 37.0 (TID 446) in 49 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (30/50)\n",
      "25/11/13 15:06:36 INFO Executor: Running task 31.0 in stage 37.0 (TID 448)\n",
      "25/11/13 15:06:36 INFO BlockManager: Found block rdd_88_30 locally\n",
      "25/11/13 15:06:36 INFO Executor: Finished task 30.0 in stage 37.0 (TID 447). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Starting task 32.0 in stage 37.0 (TID 449) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 32, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:36 INFO Executor: Running task 32.0 in stage 37.0 (TID 449)\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Finished task 30.0 in stage 37.0 (TID 447) in 36 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (31/50)\n",
      "25/11/13 15:06:36 INFO BlockManager: Found block rdd_88_31 locally\n",
      "25/11/13 15:06:36 INFO Executor: Finished task 31.0 in stage 37.0 (TID 448). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Starting task 33.0 in stage 37.0 (TID 450) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 33, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:36 INFO TaskSetManager: Finished task 31.0 in stage 37.0 (TID 448) in 42 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (32/50)\n",
      "25/11/13 15:06:36 INFO Executor: Running task 33.0 in stage 37.0 (TID 450)\n",
      "25/11/13 15:06:36 INFO BlockManager: Found block rdd_88_32 locally\n",
      "25/11/13 15:06:36 INFO Executor: Finished task 32.0 in stage 37.0 (TID 449). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Starting task 34.0 in stage 37.0 (TID 451) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 34, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:36 INFO Executor: Running task 34.0 in stage 37.0 (TID 451)\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Finished task 32.0 in stage 37.0 (TID 449) in 22 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (33/50)\n",
      "25/11/13 15:06:36 INFO BlockManager: Found block rdd_88_33 locally\n",
      "25/11/13 15:06:36 INFO Executor: Finished task 33.0 in stage 37.0 (TID 450). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Starting task 35.0 in stage 37.0 (TID 452) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 35, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:36 INFO TaskSetManager: Finished task 33.0 in stage 37.0 (TID 450) in 58 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (34/50)\n",
      "25/11/13 15:06:36 INFO Executor: Running task 35.0 in stage 37.0 (TID 452)\n",
      "25/11/13 15:06:36 INFO BlockManager: Found block rdd_88_34 locally\n",
      "25/11/13 15:06:36 INFO Executor: Finished task 34.0 in stage 37.0 (TID 451). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Starting task 36.0 in stage 37.0 (TID 453) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 36, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:36 INFO Executor: Running task 36.0 in stage 37.0 (TID 453)\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Finished task 34.0 in stage 37.0 (TID 451) in 79 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (35/50)\n",
      "25/11/13 15:06:36 INFO BlockManager: Found block rdd_88_35 locally\n",
      "25/11/13 15:06:36 INFO Executor: Finished task 35.0 in stage 37.0 (TID 452). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Starting task 37.0 in stage 37.0 (TID 454) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 37, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:36 INFO TaskSetManager: Finished task 35.0 in stage 37.0 (TID 452) in 47 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (36/50)\n",
      "25/11/13 15:06:36 INFO Executor: Running task 37.0 in stage 37.0 (TID 454)\n",
      "25/11/13 15:06:36 INFO BlockManager: Found block rdd_88_36 locally\n",
      "25/11/13 15:06:36 INFO Executor: Finished task 36.0 in stage 37.0 (TID 453). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Starting task 38.0 in stage 37.0 (TID 455) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 38, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:36 INFO Executor: Running task 38.0 in stage 37.0 (TID 455)\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Finished task 36.0 in stage 37.0 (TID 453) in 41 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (37/50)\n",
      "25/11/13 15:06:36 INFO BlockManager: Found block rdd_88_37 locally(37 + 2) / 50]\n",
      "25/11/13 15:06:36 INFO Executor: Finished task 37.0 in stage 37.0 (TID 454). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Starting task 39.0 in stage 37.0 (TID 456) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 39, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:36 INFO Executor: Running task 39.0 in stage 37.0 (TID 456)\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Finished task 37.0 in stage 37.0 (TID 454) in 62 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (38/50)\n",
      "25/11/13 15:06:36 INFO BlockManager: Found block rdd_88_38 locally\n",
      "25/11/13 15:06:36 INFO Executor: Finished task 38.0 in stage 37.0 (TID 455). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Starting task 40.0 in stage 37.0 (TID 457) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 40, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:36 INFO Executor: Running task 40.0 in stage 37.0 (TID 457)\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Finished task 38.0 in stage 37.0 (TID 455) in 88 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (39/50)\n",
      "25/11/13 15:06:36 INFO BlockManager: Found block rdd_88_39 locally\n",
      "25/11/13 15:06:36 INFO Executor: Finished task 39.0 in stage 37.0 (TID 456). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Starting task 41.0 in stage 37.0 (TID 458) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 41, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:36 INFO Executor: Running task 41.0 in stage 37.0 (TID 458)\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Finished task 39.0 in stage 37.0 (TID 456) in 49 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (40/50)\n",
      "25/11/13 15:06:36 INFO BlockManager: Found block rdd_88_40 locally\n",
      "25/11/13 15:06:36 INFO Executor: Finished task 40.0 in stage 37.0 (TID 457). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Starting task 42.0 in stage 37.0 (TID 459) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 42, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:36 INFO TaskSetManager: Finished task 40.0 in stage 37.0 (TID 457) in 60 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (41/50)\n",
      "25/11/13 15:06:36 INFO Executor: Running task 42.0 in stage 37.0 (TID 459)\n",
      "25/11/13 15:06:36 INFO BlockManager: Found block rdd_88_41 locally\n",
      "25/11/13 15:06:36 INFO Executor: Finished task 41.0 in stage 37.0 (TID 458). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Starting task 43.0 in stage 37.0 (TID 460) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 43, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:36 INFO Executor: Running task 43.0 in stage 37.0 (TID 460)\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Finished task 41.0 in stage 37.0 (TID 458) in 55 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (42/50)\n",
      "25/11/13 15:06:36 INFO BlockManager: Found block rdd_88_42 locally\n",
      "25/11/13 15:06:36 INFO Executor: Finished task 42.0 in stage 37.0 (TID 459). 4267 bytes result sent to driver\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Starting task 44.0 in stage 37.0 (TID 461) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 44, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:36 INFO Executor: Running task 44.0 in stage 37.0 (TID 461)\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Finished task 42.0 in stage 37.0 (TID 459) in 45 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (43/50)\n",
      "25/11/13 15:06:36 INFO BlockManager: Found block rdd_88_43 locally\n",
      "25/11/13 15:06:36 INFO Executor: Finished task 43.0 in stage 37.0 (TID 460). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Starting task 45.0 in stage 37.0 (TID 462) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 45, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:36 INFO Executor: Running task 45.0 in stage 37.0 (TID 462)\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Finished task 43.0 in stage 37.0 (TID 460) in 44 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (44/50)\n",
      "25/11/13 15:06:36 INFO BlockManager: Found block rdd_88_44 locally\n",
      "25/11/13 15:06:36 INFO Executor: Finished task 44.0 in stage 37.0 (TID 461). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Starting task 46.0 in stage 37.0 (TID 463) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 46, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:36 INFO Executor: Running task 46.0 in stage 37.0 (TID 463) / 50]\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Finished task 44.0 in stage 37.0 (TID 461) in 57 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (45/50)\n",
      "25/11/13 15:06:36 INFO BlockManager: Found block rdd_88_45 locally\n",
      "25/11/13 15:06:36 INFO Executor: Finished task 45.0 in stage 37.0 (TID 462). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Starting task 47.0 in stage 37.0 (TID 464) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 47, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:36 INFO TaskSetManager: Finished task 45.0 in stage 37.0 (TID 462) in 55 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (46/50)\n",
      "25/11/13 15:06:36 INFO Executor: Running task 47.0 in stage 37.0 (TID 464)\n",
      "25/11/13 15:06:36 INFO BlockManager: Found block rdd_88_46 locally\n",
      "25/11/13 15:06:36 INFO BlockManager: Found block rdd_88_47 locally\n",
      "25/11/13 15:06:36 INFO Executor: Finished task 46.0 in stage 37.0 (TID 463). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:36 INFO Executor: Finished task 47.0 in stage 37.0 (TID 464). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Starting task 48.0 in stage 37.0 (TID 465) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 48, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:36 INFO Executor: Running task 48.0 in stage 37.0 (TID 465)\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Starting task 49.0 in stage 37.0 (TID 466) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 49, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:36 INFO TaskSetManager: Finished task 46.0 in stage 37.0 (TID 463) in 50 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (47/50)\n",
      "25/11/13 15:06:36 INFO Executor: Running task 49.0 in stage 37.0 (TID 466)\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Finished task 47.0 in stage 37.0 (TID 464) in 43 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (48/50)\n",
      "25/11/13 15:06:36 INFO BlockManager: Found block rdd_88_48 locally\n",
      "25/11/13 15:06:36 INFO Executor: Finished task 48.0 in stage 37.0 (TID 465). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:36 INFO BlockManager: Found block rdd_88_49 locally\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Finished task 48.0 in stage 37.0 (TID 465) in 53 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (49/50)\n",
      "25/11/13 15:06:36 INFO Executor: Finished task 49.0 in stage 37.0 (TID 466). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:36 INFO TaskSetManager: Finished task 49.0 in stage 37.0 (TID 466) in 57 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (50/50)\n",
      "25/11/13 15:06:36 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool \n",
      "25/11/13 15:06:36 INFO DAGScheduler: ResultStage 37 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 1.209 s\n",
      "25/11/13 15:06:36 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/11/13 15:06:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 37: Stage finished\n",
      "25/11/13 15:06:36 INFO DAGScheduler: Job 23 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 1.231389 s\n",
      "25/11/13 15:06:36 INFO PrepareDeltaScan: DELTA: Done                            \n",
      "25/11/13 15:06:36 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/11/13 15:06:36 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/11/13 15:06:37 INFO CodeGenerator: Code generated in 42.778751 ms\n",
      "25/11/13 15:06:37 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 207.0 KiB, free 1046.6 MiB)\n",
      "25/11/13 15:06:37 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 1046.6 MiB)\n",
      "25/11/13 15:06:37 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 36.8 KiB, free: 1048.4 MiB)\n",
      "25/11/13 15:06:37 INFO SparkContext: Created broadcast 37 from showString at NativeMethodAccessorImpl.java:0\n",
      "25/11/13 15:06:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 34852989 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/11/13 15:06:37 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "25/11/13 15:06:37 INFO DAGScheduler: Got job 24 (showString at NativeMethodAccessorImpl.java:0) with 2 output partitions\n",
      "25/11/13 15:06:37 INFO DAGScheduler: Final stage: ResultStage 38 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/11/13 15:06:37 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/11/13 15:06:37 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 15:06:37 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[111] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/11/13 15:06:37 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 30.0 KiB, free 1046.5 MiB)\n",
      "25/11/13 15:06:37 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 10.4 KiB, free 1046.5 MiB)\n",
      "25/11/13 15:06:37 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 10.4 KiB, free: 1048.4 MiB)\n",
      "25/11/13 15:06:37 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 15:06:37 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 38 (MapPartitionsRDD[111] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))\n",
      "25/11/13 15:06:37 INFO TaskSchedulerImpl: Adding task set 38.0 with 2 tasks resource profile 0\n",
      "25/11/13 15:06:37 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 467) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 9671 bytes) \n",
      "25/11/13 15:06:37 INFO TaskSetManager: Starting task 1.0 in stage 38.0 (TID 468) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 1, PROCESS_LOCAL, 9671 bytes) \n",
      "25/11/13 15:06:37 INFO Executor: Running task 1.0 in stage 38.0 (TID 468)\n",
      "25/11/13 15:06:37 INFO Executor: Running task 0.0 in stage 38.0 (TID 467)\n",
      "25/11/13 15:06:37 INFO CodeGenerator: Code generated in 37.661652 ms\n",
      "25/11/13 15:06:37 INFO FileScanRDD: Reading File path: s3a://nau-local-analytics-silver/dim_user/part-00000-1e2cb7c2-be16-4592-9fd6-87e16bfa900b-c000.snappy.parquet, range: 0-34852989, partition values: [empty row]\n",
      "25/11/13 15:06:37 INFO FileScanRDD: Reading File path: s3a://nau-local-analytics-silver/dim_user/part-00000-1e2cb7c2-be16-4592-9fd6-87e16bfa900b-c000.snappy.parquet, range: 34852989-65511675, partition values: [empty row]\n",
      "25/11/13 15:06:37 INFO S3AInputStream: Switching to Random IO seek policy\n",
      "25/11/13 15:06:37 INFO S3AInputStream: Switching to Random IO seek policy\n",
      "25/11/13 15:06:37 INFO BlockManagerInfo: Removed broadcast_36_piece0 on jupyter-spark-758b7c86d8-7j77n:43517 in memory (size: 154.6 KiB, free: 1048.6 MiB)\n",
      "25/11/13 15:06:37 INFO BlockManagerInfo: Removed broadcast_34_piece0 on jupyter-spark-758b7c86d8-7j77n:43517 in memory (size: 36.8 KiB, free: 1048.6 MiB)\n",
      "25/11/13 15:06:37 INFO Executor: Finished task 1.0 in stage 38.0 (TID 468). 1496 bytes result sent to driver\n",
      "25/11/13 15:06:37 INFO TaskSetManager: Finished task 1.0 in stage 38.0 (TID 468) in 294 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/2)\n",
      "25/11/13 15:06:40 INFO Executor: Finished task 0.0 in stage 38.0 (TID 467). 4916 bytes result sent to driver\n",
      "25/11/13 15:06:40 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 467) in 2881 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (2/2)\n",
      "25/11/13 15:06:40 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool \n",
      "25/11/13 15:06:40 INFO DAGScheduler: ResultStage 38 (showString at NativeMethodAccessorImpl.java:0) finished in 2.895 s\n",
      "25/11/13 15:06:40 INFO DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/11/13 15:06:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 38: Stage finished\n",
      "25/11/13 15:06:40 INFO DAGScheduler: Job 24 finished: showString at NativeMethodAccessorImpl.java:0, took 2.900973 s\n",
      "25/11/13 15:06:40 INFO CodeGenerator: Code generated in 15.747455 ms            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----------------+----------------------------------+-------------+---------+-----------------+--------+------------+---------+--------------------------+--------------------------+----------------------------------------------------------------+--------------------------+-----------+\n",
      "|user_sk|user_id|username         |email                             |first_name   |last_name|full_name        |is_staff|is_superuser|is_active|date_joined               |last_login                |user_hash                                                       |ingestion_date            |source_name|\n",
      "+-------+-------+-----------------+----------------------------------+-------------+---------+-----------------+--------+------------+---------+--------------------------+--------------------------+----------------------------------------------------------------+--------------------------+-----------+\n",
      "|1      |1      |enterprise_worker|enterprise_worker@example.com     |             |         |                 |true    |false       |true     |2018-08-29 18:34:26.488188|NULL                      |5292211e07d3eae558e746efeaae281a3208c83e6a78601c8a5ed4dce565fe66|2025-11-04 18:26:56.116039|auth_user  |\n",
      "|2      |2      |veda_service_user|veda_service_user@example.com     |             |         |                 |true    |false       |true     |2018-08-29 18:34:34.18119 |NULL                      |84136b8498e880143cde64d5badcc17ec16fd795ec7e04a4e78ccc076433892e|2025-11-04 18:26:56.116039|auth_user  |\n",
      "|3      |3      |ecommerce_worker |ecommerce_worker@example.com      |             |         |                 |true    |true        |true     |2018-08-29 18:34:42       |NULL                      |ea9522b2b1762f784b79624827c141c93254384bc8ad1fecd59fba5c0c0f63bb|2025-11-04 18:26:56.116039|auth_user  |\n",
      "|4      |4      |discovery_worker |discovery_worker@example.com      |             |         |                 |true    |false       |true     |2018-08-29 18:34:50.609274|NULL                      |cc7c9c19587681bac8b622b4f5a00e61d7ce138732e64c24460e7e8bce53688c|2025-11-04 18:26:56.116039|auth_user  |\n",
      "|5      |6      |insights_worker  |insights_worker@example.com       |             |         |                 |true    |false       |true     |2018-08-29 18:34:58.792988|NULL                      |369017097638c15933633841f9ceea5c595c121001f9cb95efbb986d94cdb983|2025-11-04 18:26:56.116039|auth_user  |\n",
      "|6      |7      |technical_edunext|technical@edunext.co              |             |         |                 |true    |true        |true     |2018-09-10 20:10:50       |2025-10-22 22:28:28.638619|58bdae2dd037b7ac57f77f911ccf65eebaef25f30513cce738e6a45c28a897ee|2025-11-04 18:26:56.116039|auth_user  |\n",
      "|7      |8      |admin            |alertas@nau.edu.pt                |Administrador|NAU      |Administrador NAU|true    |true        |true     |2018-09-14 16:58:50       |2025-03-19 14:45:20.856742|d16562f4a3eed876be3c58d0306d900fd2c877b022c61455b442acfbfa6254e5|2025-11-04 18:26:56.116039|auth_user  |\n",
      "|8      |10     |staff            |naudevel+prod-staff@gmail.com     |             |         |                 |true    |false       |true     |2018-09-14 17:01:45       |NULL                      |ed5ee83b9ce56077772d5fcbf38d722f461b50bb04a24abe5ce9bf1caf33e396|2025-11-04 18:26:56.116039|auth_user  |\n",
      "|9      |11     |instructor       |naudevel+prod-instructor@gmail.com|             |         |                 |false   |false       |true     |2018-09-14 17:02:46       |NULL                      |24f32f2da2d94fe0de6f50f93412df1590cb777ccbcd257aea3de07cd77342e8|2025-11-04 18:26:56.116039|auth_user  |\n",
      "|10     |12     |student          |naudevel+prod-student@gmail.com   |             |         |                 |false   |false       |true     |2018-09-14 17:03:38       |NULL                      |f97142e3119d5f94acb9c3f673b2b502028dda45d2e047de0b5d2aa5bb9cd5dc|2025-11-04 18:26:56.116039|auth_user  |\n",
      "+-------+-------+-----------------+----------------------------------+-------------+---------+-----------------+--------+------------+---------+--------------------------+--------------------------+----------------------------------------------------------------+--------------------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/13 15:06:40 INFO CodeGenerator: Code generated in 29.375328 ms\n",
      "25/11/13 15:06:40 INFO DAGScheduler: Registering RDD 113 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 6\n",
      "25/11/13 15:06:40 INFO DAGScheduler: Got map stage job 25 (count at NativeMethodAccessorImpl.java:0) with 50 output partitions\n",
      "25/11/13 15:06:40 INFO DAGScheduler: Final stage: ShuffleMapStage 40 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/11/13 15:06:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 39)\n",
      "25/11/13 15:06:40 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 15:06:40 INFO DAGScheduler: Submitting ShuffleMapStage 40 (MapPartitionsRDD[113] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/11/13 15:06:40 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 710.4 KiB, free 1046.9 MiB)\n",
      "25/11/13 15:06:40 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 162.5 KiB, free 1046.7 MiB)\n",
      "25/11/13 15:06:40 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 162.5 KiB, free: 1048.4 MiB)\n",
      "25/11/13 15:06:40 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 15:06:40 INFO DAGScheduler: Submitting 50 missing tasks from ShuffleMapStage 40 (MapPartitionsRDD[113] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n",
      "25/11/13 15:06:40 INFO TaskSchedulerImpl: Adding task set 40.0 with 50 tasks resource profile 0\n",
      "25/11/13 15:06:40 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 469) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:40 INFO TaskSetManager: Starting task 1.0 in stage 40.0 (TID 470) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 1, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:40 INFO Executor: Running task 0.0 in stage 40.0 (TID 469)\n",
      "25/11/13 15:06:40 INFO Executor: Running task 1.0 in stage 40.0 (TID 470)\n",
      "25/11/13 15:06:40 INFO BlockManager: Found block rdd_92_0 locally\n",
      "25/11/13 15:06:40 INFO BlockManager: Found block rdd_92_1 locally\n",
      "25/11/13 15:06:40 INFO CodeGenerator: Code generated in 41.260554 ms\n",
      "25/11/13 15:06:40 INFO Executor: Finished task 0.0 in stage 40.0 (TID 469). 4613 bytes result sent to driver\n",
      "25/11/13 15:06:40 INFO TaskSetManager: Starting task 2.0 in stage 40.0 (TID 471) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 2, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:40 INFO Executor: Running task 2.0 in stage 40.0 (TID 471)\n",
      "25/11/13 15:06:40 INFO Executor: Finished task 1.0 in stage 40.0 (TID 470). 4613 bytes result sent to driver\n",
      "25/11/13 15:06:40 INFO TaskSetManager: Starting task 3.0 in stage 40.0 (TID 472) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 3, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:40 INFO TaskSetManager: Finished task 1.0 in stage 40.0 (TID 470) in 83 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/50)\n",
      "25/11/13 15:06:40 INFO Executor: Running task 3.0 in stage 40.0 (TID 472)\n",
      "25/11/13 15:06:40 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 469) in 86 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (2/50)\n",
      "25/11/13 15:06:40 INFO BlockManager: Found block rdd_92_3 locally\n",
      "25/11/13 15:06:40 INFO BlockManager: Found block rdd_92_2 locally\n",
      "25/11/13 15:06:40 INFO Executor: Finished task 2.0 in stage 40.0 (TID 471). 4613 bytes result sent to driver\n",
      "25/11/13 15:06:40 INFO TaskSetManager: Starting task 4.0 in stage 40.0 (TID 473) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 4, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:40 INFO Executor: Running task 4.0 in stage 40.0 (TID 473)\n",
      "25/11/13 15:06:40 INFO TaskSetManager: Finished task 2.0 in stage 40.0 (TID 471) in 22 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (3/50)\n",
      "25/11/13 15:06:40 INFO Executor: Finished task 3.0 in stage 40.0 (TID 472). 4613 bytes result sent to driver\n",
      "25/11/13 15:06:40 INFO TaskSetManager: Starting task 5.0 in stage 40.0 (TID 474) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 5, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:40 INFO TaskSetManager: Finished task 3.0 in stage 40.0 (TID 472) in 34 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (4/50)\n",
      "25/11/13 15:06:40 INFO Executor: Running task 5.0 in stage 40.0 (TID 474)\n",
      "25/11/13 15:06:40 INFO BlockManager: Found block rdd_92_5 locally\n",
      "25/11/13 15:06:40 INFO Executor: Finished task 5.0 in stage 40.0 (TID 474). 4656 bytes result sent to driver\n",
      "25/11/13 15:06:40 INFO TaskSetManager: Starting task 6.0 in stage 40.0 (TID 475) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 6, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:40 INFO TaskSetManager: Finished task 5.0 in stage 40.0 (TID 474) in 36 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (5/50)\n",
      "25/11/13 15:06:40 INFO Executor: Running task 6.0 in stage 40.0 (TID 475)\n",
      "25/11/13 15:06:40 INFO BlockManager: Found block rdd_92_4 locally\n",
      "25/11/13 15:06:40 INFO Executor: Finished task 4.0 in stage 40.0 (TID 473). 4656 bytes result sent to driver\n",
      "25/11/13 15:06:40 INFO TaskSetManager: Starting task 7.0 in stage 40.0 (TID 476) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 7, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:40 INFO Executor: Running task 7.0 in stage 40.0 (TID 476)\n",
      "25/11/13 15:06:40 INFO TaskSetManager: Finished task 4.0 in stage 40.0 (TID 473) in 62 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (6/50)\n",
      "25/11/13 15:06:40 INFO BlockManager: Found block rdd_92_6 locally\n",
      "25/11/13 15:06:40 INFO BlockManager: Found block rdd_92_7 locally\n",
      "25/11/13 15:06:40 INFO Executor: Finished task 6.0 in stage 40.0 (TID 475). 4613 bytes result sent to driver\n",
      "25/11/13 15:06:40 INFO TaskSetManager: Starting task 8.0 in stage 40.0 (TID 477) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 8, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:40 INFO Executor: Running task 8.0 in stage 40.0 (TID 477)\n",
      "25/11/13 15:06:40 INFO TaskSetManager: Finished task 6.0 in stage 40.0 (TID 475) in 23 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (7/50)\n",
      "25/11/13 15:06:40 INFO Executor: Finished task 7.0 in stage 40.0 (TID 476). 4613 bytes result sent to driver\n",
      "25/11/13 15:06:40 INFO TaskSetManager: Starting task 9.0 in stage 40.0 (TID 478) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 9, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:40 INFO Executor: Running task 9.0 in stage 40.0 (TID 478)\n",
      "25/11/13 15:06:40 INFO TaskSetManager: Finished task 7.0 in stage 40.0 (TID 476) in 15 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (8/50)\n",
      "25/11/13 15:06:40 INFO BlockManager: Found block rdd_92_8 locally\n",
      "25/11/13 15:06:40 INFO Executor: Finished task 8.0 in stage 40.0 (TID 477). 4613 bytes result sent to driver\n",
      "25/11/13 15:06:40 INFO TaskSetManager: Starting task 10.0 in stage 40.0 (TID 479) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 10, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:40 INFO TaskSetManager: Finished task 8.0 in stage 40.0 (TID 477) in 50 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (9/50)\n",
      "25/11/13 15:06:40 INFO Executor: Running task 10.0 in stage 40.0 (TID 479)\n",
      "25/11/13 15:06:40 INFO BlockManager: Found block rdd_92_9 locally\n",
      "25/11/13 15:06:40 INFO Executor: Finished task 9.0 in stage 40.0 (TID 478). 4656 bytes result sent to driver\n",
      "25/11/13 15:06:40 INFO TaskSetManager: Starting task 11.0 in stage 40.0 (TID 480) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 11, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:40 INFO Executor: Running task 11.0 in stage 40.0 (TID 480)\n",
      "25/11/13 15:06:40 INFO BlockManager: Found block rdd_92_10 locally\n",
      "25/11/13 15:06:40 INFO TaskSetManager: Finished task 9.0 in stage 40.0 (TID 478) in 84 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (10/50)\n",
      "25/11/13 15:06:40 INFO Executor: Finished task 10.0 in stage 40.0 (TID 479). 4613 bytes result sent to driver\n",
      "25/11/13 15:06:40 INFO TaskSetManager: Starting task 12.0 in stage 40.0 (TID 481) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 12, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:40 INFO Executor: Running task 12.0 in stage 40.0 (TID 481)\n",
      "25/11/13 15:06:40 INFO TaskSetManager: Finished task 10.0 in stage 40.0 (TID 479) in 41 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (11/50)\n",
      "25/11/13 15:06:40 INFO BlockManager: Found block rdd_92_11 locally\n",
      "25/11/13 15:06:40 INFO Executor: Finished task 11.0 in stage 40.0 (TID 480). 4613 bytes result sent to driver\n",
      "25/11/13 15:06:40 INFO TaskSetManager: Starting task 13.0 in stage 40.0 (TID 482) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 13, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:40 INFO TaskSetManager: Finished task 11.0 in stage 40.0 (TID 480) in 19 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (12/50)\n",
      "25/11/13 15:06:40 INFO Executor: Running task 13.0 in stage 40.0 (TID 482)\n",
      "25/11/13 15:06:40 INFO BlockManager: Found block rdd_92_12 locally\n",
      "25/11/13 15:06:40 INFO Executor: Finished task 12.0 in stage 40.0 (TID 481). 4656 bytes result sent to driver\n",
      "25/11/13 15:06:40 INFO TaskSetManager: Starting task 14.0 in stage 40.0 (TID 483) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 14, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:40 INFO TaskSetManager: Finished task 12.0 in stage 40.0 (TID 481) in 24 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (13/50)\n",
      "25/11/13 15:06:40 INFO Executor: Running task 14.0 in stage 40.0 (TID 483)\n",
      "25/11/13 15:06:40 INFO BlockManager: Found block rdd_92_13 locally\n",
      "25/11/13 15:06:40 INFO Executor: Finished task 13.0 in stage 40.0 (TID 482). 4613 bytes result sent to driver\n",
      "25/11/13 15:06:40 INFO TaskSetManager: Starting task 15.0 in stage 40.0 (TID 484) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 15, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:40 INFO TaskSetManager: Finished task 13.0 in stage 40.0 (TID 482) in 46 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (14/50)\n",
      "25/11/13 15:06:40 INFO Executor: Running task 15.0 in stage 40.0 (TID 484)\n",
      "25/11/13 15:06:40 INFO BlockManager: Found block rdd_92_14 locally\n",
      "25/11/13 15:06:40 INFO Executor: Finished task 14.0 in stage 40.0 (TID 483). 4613 bytes result sent to driver\n",
      "25/11/13 15:06:40 INFO TaskSetManager: Starting task 16.0 in stage 40.0 (TID 485) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 16, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:40 INFO TaskSetManager: Finished task 14.0 in stage 40.0 (TID 483) in 63 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (15/50)\n",
      "25/11/13 15:06:40 INFO Executor: Running task 16.0 in stage 40.0 (TID 485)\n",
      "25/11/13 15:06:40 INFO BlockManager: Found block rdd_92_15 locally\n",
      "25/11/13 15:06:40 INFO Executor: Finished task 15.0 in stage 40.0 (TID 484). 4613 bytes result sent to driver\n",
      "25/11/13 15:06:40 INFO TaskSetManager: Starting task 17.0 in stage 40.0 (TID 486) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 17, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:40 INFO Executor: Running task 17.0 in stage 40.0 (TID 486)\n",
      "25/11/13 15:06:40 INFO TaskSetManager: Finished task 15.0 in stage 40.0 (TID 484) in 42 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (16/50)\n",
      "25/11/13 15:06:40 INFO BlockManager: Found block rdd_92_16 locally\n",
      "25/11/13 15:06:40 INFO Executor: Finished task 16.0 in stage 40.0 (TID 485). 4699 bytes result sent to driver\n",
      "25/11/13 15:06:40 INFO TaskSetManager: Starting task 18.0 in stage 40.0 (TID 487) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 18, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:40 INFO TaskSetManager: Finished task 16.0 in stage 40.0 (TID 485) in 61 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (17/50)\n",
      "25/11/13 15:06:40 INFO Executor: Running task 18.0 in stage 40.0 (TID 487)\n",
      "25/11/13 15:06:40 INFO BlockManager: Found block rdd_92_17 locally\n",
      "25/11/13 15:06:40 INFO Executor: Finished task 17.0 in stage 40.0 (TID 486). 4656 bytes result sent to driver\n",
      "25/11/13 15:06:40 INFO BlockManager: Found block rdd_92_18 locally\n",
      "25/11/13 15:06:40 INFO TaskSetManager: Starting task 19.0 in stage 40.0 (TID 488) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 19, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:40 INFO TaskSetManager: Finished task 17.0 in stage 40.0 (TID 486) in 89 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (18/50)\n",
      "25/11/13 15:06:40 INFO Executor: Running task 19.0 in stage 40.0 (TID 488)\n",
      "25/11/13 15:06:40 INFO Executor: Finished task 18.0 in stage 40.0 (TID 487). 4613 bytes result sent to driver\n",
      "25/11/13 15:06:40 INFO TaskSetManager: Starting task 20.0 in stage 40.0 (TID 489) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 20, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:40 INFO TaskSetManager: Finished task 18.0 in stage 40.0 (TID 487) in 61 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (19/50)\n",
      "25/11/13 15:06:40 INFO Executor: Running task 20.0 in stage 40.0 (TID 489)\n",
      "25/11/13 15:06:40 INFO BlockManager: Found block rdd_92_19 locally\n",
      "25/11/13 15:06:40 INFO Executor: Finished task 19.0 in stage 40.0 (TID 488). 4613 bytes result sent to driver\n",
      "25/11/13 15:06:40 INFO TaskSetManager: Starting task 21.0 in stage 40.0 (TID 490) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 21, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:40 INFO TaskSetManager: Finished task 19.0 in stage 40.0 (TID 488) in 21 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (20/50)\n",
      "25/11/13 15:06:40 INFO Executor: Running task 21.0 in stage 40.0 (TID 490)\n",
      "25/11/13 15:06:40 INFO BlockManager: Found block rdd_92_20 locally\n",
      "25/11/13 15:06:40 INFO Executor: Finished task 20.0 in stage 40.0 (TID 489). 4613 bytes result sent to driver\n",
      "25/11/13 15:06:40 INFO TaskSetManager: Starting task 22.0 in stage 40.0 (TID 491) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 22, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:40 INFO Executor: Running task 22.0 in stage 40.0 (TID 491)\n",
      "25/11/13 15:06:40 INFO TaskSetManager: Finished task 20.0 in stage 40.0 (TID 489) in 23 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (21/50)\n",
      "25/11/13 15:06:40 INFO BlockManager: Found block rdd_92_22 locally\n",
      "25/11/13 15:06:40 INFO BlockManager: Found block rdd_92_21 locally\n",
      "25/11/13 15:06:40 INFO Executor: Finished task 22.0 in stage 40.0 (TID 491). 4613 bytes result sent to driver\n",
      "25/11/13 15:06:40 INFO TaskSetManager: Starting task 23.0 in stage 40.0 (TID 492) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 23, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:40 INFO Executor: Finished task 21.0 in stage 40.0 (TID 490). 4613 bytes result sent to driver\n",
      "25/11/13 15:06:40 INFO Executor: Running task 23.0 in stage 40.0 (TID 492)\n",
      "25/11/13 15:06:40 INFO TaskSetManager: Starting task 24.0 in stage 40.0 (TID 493) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 24, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:40 INFO TaskSetManager: Finished task 21.0 in stage 40.0 (TID 490) in 81 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (22/50)\n",
      "25/11/13 15:06:40 INFO Executor: Running task 24.0 in stage 40.0 (TID 493)\n",
      "25/11/13 15:06:40 INFO TaskSetManager: Finished task 22.0 in stage 40.0 (TID 491) in 77 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (23/50)\n",
      "25/11/13 15:06:40 INFO BlockManager: Found block rdd_92_23 locally(23 + 2) / 50]\n",
      "25/11/13 15:06:40 INFO Executor: Finished task 23.0 in stage 40.0 (TID 492). 4613 bytes result sent to driver\n",
      "25/11/13 15:06:40 INFO TaskSetManager: Starting task 25.0 in stage 40.0 (TID 494) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 25, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:40 INFO Executor: Running task 25.0 in stage 40.0 (TID 494)\n",
      "25/11/13 15:06:40 INFO TaskSetManager: Finished task 23.0 in stage 40.0 (TID 492) in 44 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (24/50)\n",
      "25/11/13 15:06:40 INFO BlockManager: Found block rdd_92_24 locally\n",
      "25/11/13 15:06:40 INFO Executor: Finished task 24.0 in stage 40.0 (TID 493). 4613 bytes result sent to driver\n",
      "25/11/13 15:06:40 INFO TaskSetManager: Starting task 26.0 in stage 40.0 (TID 495) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 26, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:40 INFO Executor: Running task 26.0 in stage 40.0 (TID 495)\n",
      "25/11/13 15:06:40 INFO TaskSetManager: Finished task 24.0 in stage 40.0 (TID 493) in 24 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (25/50)\n",
      "25/11/13 15:06:41 INFO BlockManager: Found block rdd_92_26 locally\n",
      "25/11/13 15:06:41 INFO Executor: Finished task 26.0 in stage 40.0 (TID 495). 4656 bytes result sent to driver\n",
      "25/11/13 15:06:41 INFO TaskSetManager: Starting task 27.0 in stage 40.0 (TID 496) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 27, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:41 INFO TaskSetManager: Finished task 26.0 in stage 40.0 (TID 495) in 55 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (26/50)\n",
      "25/11/13 15:06:41 INFO Executor: Running task 27.0 in stage 40.0 (TID 496)\n",
      "25/11/13 15:06:41 INFO BlockManager: Found block rdd_92_25 locally\n",
      "25/11/13 15:06:41 INFO Executor: Finished task 25.0 in stage 40.0 (TID 494). 4613 bytes result sent to driver\n",
      "25/11/13 15:06:41 INFO TaskSetManager: Starting task 28.0 in stage 40.0 (TID 497) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 28, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:41 INFO TaskSetManager: Finished task 25.0 in stage 40.0 (TID 494) in 84 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (27/50)\n",
      "25/11/13 15:06:41 INFO Executor: Running task 28.0 in stage 40.0 (TID 497)\n",
      "25/11/13 15:06:41 INFO BlockManager: Found block rdd_92_27 locally\n",
      "25/11/13 15:06:41 INFO BlockManager: Found block rdd_92_28 locally\n",
      "25/11/13 15:06:41 INFO Executor: Finished task 27.0 in stage 40.0 (TID 496). 4613 bytes result sent to driver\n",
      "25/11/13 15:06:41 INFO TaskSetManager: Starting task 29.0 in stage 40.0 (TID 498) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 29, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:41 INFO Executor: Running task 29.0 in stage 40.0 (TID 498)\n",
      "25/11/13 15:06:41 INFO TaskSetManager: Finished task 27.0 in stage 40.0 (TID 496) in 41 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (28/50)\n",
      "25/11/13 15:06:41 INFO Executor: Finished task 28.0 in stage 40.0 (TID 497). 4613 bytes result sent to driver\n",
      "25/11/13 15:06:41 INFO TaskSetManager: Starting task 30.0 in stage 40.0 (TID 499) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 30, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:41 INFO TaskSetManager: Finished task 28.0 in stage 40.0 (TID 497) in 17 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (29/50)\n",
      "25/11/13 15:06:41 INFO Executor: Running task 30.0 in stage 40.0 (TID 499)\n",
      "25/11/13 15:06:41 INFO BlockManager: Found block rdd_92_29 locally\n",
      "25/11/13 15:06:41 INFO BlockManager: Found block rdd_92_30 locally\n",
      "25/11/13 15:06:41 INFO Executor: Finished task 30.0 in stage 40.0 (TID 499). 4613 bytes result sent to driver\n",
      "25/11/13 15:06:41 INFO TaskSetManager: Starting task 31.0 in stage 40.0 (TID 500) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 31, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:41 INFO Executor: Running task 31.0 in stage 40.0 (TID 500)\n",
      "25/11/13 15:06:41 INFO TaskSetManager: Finished task 30.0 in stage 40.0 (TID 499) in 82 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (30/50)\n",
      "25/11/13 15:06:41 INFO Executor: Finished task 29.0 in stage 40.0 (TID 498). 4656 bytes result sent to driver\n",
      "25/11/13 15:06:41 INFO TaskSetManager: Starting task 32.0 in stage 40.0 (TID 501) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 32, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:41 INFO Executor: Running task 32.0 in stage 40.0 (TID 501)\n",
      "25/11/13 15:06:41 INFO TaskSetManager: Finished task 29.0 in stage 40.0 (TID 498) in 88 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (31/50)\n",
      "25/11/13 15:06:41 INFO BlockManager: Found block rdd_92_31 locally(31 + 2) / 50]\n",
      "25/11/13 15:06:41 INFO Executor: Finished task 31.0 in stage 40.0 (TID 500). 4613 bytes result sent to driver\n",
      "25/11/13 15:06:41 INFO TaskSetManager: Starting task 33.0 in stage 40.0 (TID 502) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 33, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:41 INFO Executor: Running task 33.0 in stage 40.0 (TID 502)\n",
      "25/11/13 15:06:41 INFO TaskSetManager: Finished task 31.0 in stage 40.0 (TID 500) in 23 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (32/50)\n",
      "25/11/13 15:06:41 INFO BlockManager: Found block rdd_92_32 locally\n",
      "25/11/13 15:06:41 INFO Executor: Finished task 32.0 in stage 40.0 (TID 501). 4613 bytes result sent to driver\n",
      "25/11/13 15:06:41 INFO TaskSetManager: Starting task 34.0 in stage 40.0 (TID 503) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 34, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:41 INFO TaskSetManager: Finished task 32.0 in stage 40.0 (TID 501) in 24 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (33/50)\n",
      "25/11/13 15:06:41 INFO Executor: Running task 34.0 in stage 40.0 (TID 503)\n",
      "25/11/13 15:06:41 INFO BlockManager: Found block rdd_92_34 locally\n",
      "25/11/13 15:06:41 INFO BlockManager: Found block rdd_92_33 locally\n",
      "25/11/13 15:06:41 INFO Executor: Finished task 34.0 in stage 40.0 (TID 503). 4613 bytes result sent to driver\n",
      "25/11/13 15:06:41 INFO TaskSetManager: Starting task 35.0 in stage 40.0 (TID 504) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 35, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:41 INFO Executor: Running task 35.0 in stage 40.0 (TID 504)\n",
      "25/11/13 15:06:41 INFO Executor: Finished task 33.0 in stage 40.0 (TID 502). 4613 bytes result sent to driver\n",
      "25/11/13 15:06:41 INFO TaskSetManager: Starting task 36.0 in stage 40.0 (TID 505) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 36, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:41 INFO Executor: Running task 36.0 in stage 40.0 (TID 505)\n",
      "25/11/13 15:06:41 INFO TaskSetManager: Finished task 33.0 in stage 40.0 (TID 502) in 81 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (34/50)\n",
      "25/11/13 15:06:41 INFO TaskSetManager: Finished task 34.0 in stage 40.0 (TID 503) in 77 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (35/50)\n",
      "25/11/13 15:06:41 INFO BlockManager: Found block rdd_92_35 locally\n",
      "25/11/13 15:06:41 INFO Executor: Finished task 35.0 in stage 40.0 (TID 504). 4613 bytes result sent to driver\n",
      "25/11/13 15:06:41 INFO BlockManager: Found block rdd_92_36 locally\n",
      "25/11/13 15:06:41 INFO TaskSetManager: Starting task 37.0 in stage 40.0 (TID 506) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 37, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:41 INFO TaskSetManager: Finished task 35.0 in stage 40.0 (TID 504) in 42 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (36/50)\n",
      "25/11/13 15:06:41 INFO Executor: Running task 37.0 in stage 40.0 (TID 506)\n",
      "25/11/13 15:06:41 INFO Executor: Finished task 36.0 in stage 40.0 (TID 505). 4613 bytes result sent to driver\n",
      "25/11/13 15:06:41 INFO TaskSetManager: Starting task 38.0 in stage 40.0 (TID 507) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 38, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:41 INFO TaskSetManager: Finished task 36.0 in stage 40.0 (TID 505) in 23 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (37/50)\n",
      "25/11/13 15:06:41 INFO Executor: Running task 38.0 in stage 40.0 (TID 507)\n",
      "25/11/13 15:06:41 INFO BlockManager: Found block rdd_92_37 locally\n",
      "25/11/13 15:06:41 INFO BlockManager: Found block rdd_92_38 locally\n",
      "25/11/13 15:06:41 INFO Executor: Finished task 37.0 in stage 40.0 (TID 506). 4656 bytes result sent to driver\n",
      "25/11/13 15:06:41 INFO TaskSetManager: Starting task 39.0 in stage 40.0 (TID 508) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 39, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:41 INFO Executor: Running task 39.0 in stage 40.0 (TID 508)\n",
      "25/11/13 15:06:41 INFO TaskSetManager: Finished task 37.0 in stage 40.0 (TID 506) in 83 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (38/50)\n",
      "25/11/13 15:06:41 INFO Executor: Finished task 38.0 in stage 40.0 (TID 507). 4656 bytes result sent to driver\n",
      "25/11/13 15:06:41 INFO TaskSetManager: Starting task 40.0 in stage 40.0 (TID 509) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 40, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:41 INFO TaskSetManager: Finished task 38.0 in stage 40.0 (TID 507) in 81 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (39/50)\n",
      "25/11/13 15:06:41 INFO Executor: Running task 40.0 in stage 40.0 (TID 509)\n",
      "25/11/13 15:06:41 INFO BlockManagerInfo: Removed broadcast_38_piece0 on jupyter-spark-758b7c86d8-7j77n:43517 in memory (size: 10.4 KiB, free: 1048.5 MiB)\n",
      "25/11/13 15:06:41 INFO BlockManagerInfo: Removed broadcast_37_piece0 on jupyter-spark-758b7c86d8-7j77n:43517 in memory (size: 36.8 KiB, free: 1048.5 MiB)\n",
      "25/11/13 15:06:41 INFO BlockManager: Found block rdd_92_40 locally\n",
      "25/11/13 15:06:41 INFO BlockManager: Found block rdd_92_39 locally\n",
      "25/11/13 15:06:41 INFO Executor: Finished task 40.0 in stage 40.0 (TID 509). 4656 bytes result sent to driver\n",
      "25/11/13 15:06:41 INFO TaskSetManager: Starting task 41.0 in stage 40.0 (TID 510) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 41, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:41 INFO Executor: Finished task 39.0 in stage 40.0 (TID 508). 4613 bytes result sent to driver\n",
      "25/11/13 15:06:41 INFO Executor: Running task 41.0 in stage 40.0 (TID 510)\n",
      "25/11/13 15:06:41 INFO TaskSetManager: Finished task 40.0 in stage 40.0 (TID 509) in 199 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (40/50)\n",
      "25/11/13 15:06:41 INFO TaskSetManager: Starting task 42.0 in stage 40.0 (TID 511) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 42, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:41 INFO TaskSetManager: Finished task 39.0 in stage 40.0 (TID 508) in 204 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (41/50)\n",
      "25/11/13 15:06:41 INFO Executor: Running task 42.0 in stage 40.0 (TID 511)\n",
      "25/11/13 15:06:41 INFO BlockManager: Found block rdd_92_42 locally\n",
      "25/11/13 15:06:41 INFO BlockManager: Found block rdd_92_41 locally\n",
      "25/11/13 15:06:41 INFO Executor: Finished task 42.0 in stage 40.0 (TID 511). 4613 bytes result sent to driver\n",
      "25/11/13 15:06:41 INFO TaskSetManager: Starting task 43.0 in stage 40.0 (TID 512) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 43, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:41 INFO Executor: Finished task 41.0 in stage 40.0 (TID 510). 4613 bytes result sent to driver\n",
      "25/11/13 15:06:41 INFO Executor: Running task 43.0 in stage 40.0 (TID 512)\n",
      "25/11/13 15:06:41 INFO TaskSetManager: Starting task 44.0 in stage 40.0 (TID 513) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 44, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:41 INFO Executor: Running task 44.0 in stage 40.0 (TID 513)\n",
      "25/11/13 15:06:41 INFO TaskSetManager: Finished task 42.0 in stage 40.0 (TID 511) in 22 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (42/50)\n",
      "25/11/13 15:06:41 INFO TaskSetManager: Finished task 41.0 in stage 40.0 (TID 510) in 63 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (43/50)\n",
      "25/11/13 15:06:41 INFO BlockManager: Found block rdd_92_44 locally\n",
      "25/11/13 15:06:41 INFO Executor: Finished task 44.0 in stage 40.0 (TID 513). 4613 bytes result sent to driver\n",
      "25/11/13 15:06:41 INFO BlockManager: Found block rdd_92_43 locally\n",
      "25/11/13 15:06:41 INFO TaskSetManager: Starting task 45.0 in stage 40.0 (TID 514) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 45, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:41 INFO Executor: Running task 45.0 in stage 40.0 (TID 514)\n",
      "25/11/13 15:06:41 INFO TaskSetManager: Finished task 44.0 in stage 40.0 (TID 513) in 86 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (44/50)\n",
      "25/11/13 15:06:41 INFO Executor: Finished task 43.0 in stage 40.0 (TID 512). 4613 bytes result sent to driver\n",
      "25/11/13 15:06:41 INFO TaskSetManager: Starting task 46.0 in stage 40.0 (TID 515) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 46, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:41 INFO TaskSetManager: Finished task 43.0 in stage 40.0 (TID 512) in 90 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (45/50)\n",
      "25/11/13 15:06:41 INFO Executor: Running task 46.0 in stage 40.0 (TID 515)\n",
      "25/11/13 15:06:41 INFO BlockManager: Found block rdd_92_45 locally\n",
      "25/11/13 15:06:41 INFO BlockManager: Found block rdd_92_46 locally(45 + 2) / 50]\n",
      "25/11/13 15:06:41 INFO Executor: Finished task 45.0 in stage 40.0 (TID 514). 4613 bytes result sent to driver\n",
      "25/11/13 15:06:41 INFO TaskSetManager: Starting task 47.0 in stage 40.0 (TID 516) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 47, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:41 INFO TaskSetManager: Finished task 45.0 in stage 40.0 (TID 514) in 62 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (46/50)\n",
      "25/11/13 15:06:41 INFO Executor: Running task 47.0 in stage 40.0 (TID 516)\n",
      "25/11/13 15:06:41 INFO Executor: Finished task 46.0 in stage 40.0 (TID 515). 4613 bytes result sent to driver\n",
      "25/11/13 15:06:41 INFO TaskSetManager: Starting task 48.0 in stage 40.0 (TID 517) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 48, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:41 INFO Executor: Running task 48.0 in stage 40.0 (TID 517)\n",
      "25/11/13 15:06:41 INFO TaskSetManager: Finished task 46.0 in stage 40.0 (TID 515) in 89 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (47/50)\n",
      "25/11/13 15:06:41 INFO BlockManager: Found block rdd_92_47 locally\n",
      "25/11/13 15:06:41 INFO Executor: Finished task 47.0 in stage 40.0 (TID 516). 4613 bytes result sent to driver\n",
      "25/11/13 15:06:41 INFO TaskSetManager: Starting task 49.0 in stage 40.0 (TID 518) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 49, PROCESS_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:41 INFO TaskSetManager: Finished task 47.0 in stage 40.0 (TID 516) in 47 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (48/50)\n",
      "25/11/13 15:06:41 INFO Executor: Running task 49.0 in stage 40.0 (TID 518)\n",
      "25/11/13 15:06:41 INFO BlockManager: Found block rdd_92_48 locally\n",
      "25/11/13 15:06:41 INFO Executor: Finished task 48.0 in stage 40.0 (TID 517). 4613 bytes result sent to driver\n",
      "25/11/13 15:06:41 INFO TaskSetManager: Finished task 48.0 in stage 40.0 (TID 517) in 21 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (49/50)\n",
      "25/11/13 15:06:41 INFO BlockManager: Found block rdd_92_49 locally\n",
      "25/11/13 15:06:41 INFO Executor: Finished task 49.0 in stage 40.0 (TID 518). 4656 bytes result sent to driver\n",
      "25/11/13 15:06:41 INFO TaskSetManager: Finished task 49.0 in stage 40.0 (TID 518) in 86 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (50/50)\n",
      "25/11/13 15:06:41 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool \n",
      "25/11/13 15:06:41 INFO DAGScheduler: ShuffleMapStage 40 (count at NativeMethodAccessorImpl.java:0) finished in 1.475 s\n",
      "25/11/13 15:06:41 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/11/13 15:06:41 INFO DAGScheduler: running: Set()\n",
      "25/11/13 15:06:41 INFO DAGScheduler: waiting: Set()\n",
      "25/11/13 15:06:41 INFO DAGScheduler: failed: Set()\n",
      "25/11/13 15:06:41 INFO CodeGenerator: Code generated in 47.843107 ms\n",
      "25/11/13 15:06:41 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0\n",
      "25/11/13 15:06:41 INFO DAGScheduler: Got job 26 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/11/13 15:06:41 INFO DAGScheduler: Final stage: ResultStage 43 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/11/13 15:06:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 42)\n",
      "25/11/13 15:06:41 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 15:06:41 INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[116] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/11/13 15:06:41 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 14.9 KiB, free 1047.0 MiB)\n",
      "25/11/13 15:06:41 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 1047.0 MiB)\n",
      "25/11/13 15:06:41 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 6.7 KiB, free: 1048.5 MiB)\n",
      "25/11/13 15:06:41 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 15:06:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[116] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/11/13 15:06:41 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks resource profile 0\n",
      "25/11/13 15:06:41 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 519) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, NODE_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:41 INFO Executor: Running task 0.0 in stage 43.0 (TID 519)\n",
      "25/11/13 15:06:41 INFO ShuffleBlockFetcherIterator: Getting 50 (2.9 KiB) non-empty blocks including 50 (2.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:06:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/11/13 15:06:42 INFO CodeGenerator: Code generated in 13.503232 ms\n",
      "25/11/13 15:06:42 INFO Executor: Finished task 0.0 in stage 43.0 (TID 519). 4004 bytes result sent to driver\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 519) in 58 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/1)\n",
      "25/11/13 15:06:42 INFO DAGScheduler: ResultStage 43 (count at NativeMethodAccessorImpl.java:0) finished in 0.068 s\n",
      "25/11/13 15:06:42 INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/11/13 15:06:42 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool \n",
      "25/11/13 15:06:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 43: Stage finished\n",
      "25/11/13 15:06:42 INFO DAGScheduler: Job 26 finished: count at NativeMethodAccessorImpl.java:0, took 0.076380 s\n",
      "25/11/13 15:06:42 INFO CodeGenerator: Code generated in 11.62947 ms             \n",
      "25/11/13 15:06:42 INFO CodeGenerator: Code generated in 5.455203 ms\n",
      "25/11/13 15:06:42 INFO PrepareDeltaScan: DELTA: Filtering files for query\n",
      "25/11/13 15:06:42 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128\n",
      "25/11/13 15:06:42 INFO DAGScheduler: Got job 27 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions\n",
      "25/11/13 15:06:42 INFO DAGScheduler: Final stage: ResultStage 45 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)\n",
      "25/11/13 15:06:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 44)\n",
      "25/11/13 15:06:42 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 15:06:42 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[118] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents\n",
      "25/11/13 15:06:42 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 684.9 KiB, free 1046.3 MiB)\n",
      "25/11/13 15:06:42 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 154.6 KiB, free 1046.2 MiB)\n",
      "25/11/13 15:06:42 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 154.6 KiB, free: 1048.3 MiB)\n",
      "25/11/13 15:06:42 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 15:06:42 INFO DAGScheduler: Submitting 50 missing tasks from ResultStage 45 (MapPartitionsRDD[118] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n",
      "25/11/13 15:06:42 INFO TaskSchedulerImpl: Adding task set 45.0 with 50 tasks resource profile 0\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 520) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:42 INFO TaskSetManager: Starting task 1.0 in stage 45.0 (TID 521) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 1, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:42 INFO Executor: Running task 0.0 in stage 45.0 (TID 520)\n",
      "25/11/13 15:06:42 INFO Executor: Running task 1.0 in stage 45.0 (TID 521)\n",
      "25/11/13 15:06:42 INFO BlockManagerInfo: Removed broadcast_39_piece0 on jupyter-spark-758b7c86d8-7j77n:43517 in memory (size: 162.5 KiB, free: 1048.5 MiB)\n",
      "25/11/13 15:06:42 INFO BlockManager: Found block rdd_88_0 locally\n",
      "25/11/13 15:06:42 INFO Executor: Finished task 0.0 in stage 45.0 (TID 520). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Starting task 2.0 in stage 45.0 (TID 522) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 2, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:42 INFO Executor: Running task 2.0 in stage 45.0 (TID 522)\n",
      "25/11/13 15:06:42 INFO BlockManagerInfo: Removed broadcast_40_piece0 on jupyter-spark-758b7c86d8-7j77n:43517 in memory (size: 6.7 KiB, free: 1048.5 MiB)\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 520) in 48 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/50)\n",
      "25/11/13 15:06:42 INFO BlockManager: Found block rdd_88_1 locally\n",
      "25/11/13 15:06:42 INFO Executor: Finished task 1.0 in stage 45.0 (TID 521). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Starting task 3.0 in stage 45.0 (TID 523) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 3, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:42 INFO TaskSetManager: Finished task 1.0 in stage 45.0 (TID 521) in 53 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (2/50)\n",
      "25/11/13 15:06:42 INFO Executor: Running task 3.0 in stage 45.0 (TID 523)\n",
      "25/11/13 15:06:42 INFO BlockManager: Found block rdd_88_2 locally\n",
      "25/11/13 15:06:42 INFO Executor: Finished task 2.0 in stage 45.0 (TID 522). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Starting task 4.0 in stage 45.0 (TID 524) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 4, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:42 INFO TaskSetManager: Finished task 2.0 in stage 45.0 (TID 522) in 18 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (3/50)\n",
      "25/11/13 15:06:42 INFO Executor: Running task 4.0 in stage 45.0 (TID 524)\n",
      "25/11/13 15:06:42 INFO BlockManager: Found block rdd_88_3 locally\n",
      "25/11/13 15:06:42 INFO Executor: Finished task 3.0 in stage 45.0 (TID 523). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Starting task 5.0 in stage 45.0 (TID 525) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 5, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:42 INFO Executor: Running task 5.0 in stage 45.0 (TID 525)\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Finished task 3.0 in stage 45.0 (TID 523) in 18 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (4/50)\n",
      "25/11/13 15:06:42 INFO BlockManager: Found block rdd_88_4 locally\n",
      "25/11/13 15:06:42 INFO Executor: Finished task 4.0 in stage 45.0 (TID 524). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Starting task 6.0 in stage 45.0 (TID 526) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 6, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:42 INFO TaskSetManager: Finished task 4.0 in stage 45.0 (TID 524) in 50 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (5/50)\n",
      "25/11/13 15:06:42 INFO Executor: Running task 6.0 in stage 45.0 (TID 526)\n",
      "25/11/13 15:06:42 INFO BlockManager: Found block rdd_88_5 locally\n",
      "25/11/13 15:06:42 INFO Executor: Finished task 5.0 in stage 45.0 (TID 525). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Starting task 7.0 in stage 45.0 (TID 527) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 7, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:42 INFO Executor: Running task 7.0 in stage 45.0 (TID 527)\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Finished task 5.0 in stage 45.0 (TID 525) in 49 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (6/50)\n",
      "25/11/13 15:06:42 INFO BlockManager: Found block rdd_88_7 locally\n",
      "25/11/13 15:06:42 INFO BlockManager: Found block rdd_88_6 locally\n",
      "25/11/13 15:06:42 INFO Executor: Finished task 7.0 in stage 45.0 (TID 527). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:42 INFO Executor: Finished task 6.0 in stage 45.0 (TID 526). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Starting task 8.0 in stage 45.0 (TID 528) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 8, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:42 INFO Executor: Running task 8.0 in stage 45.0 (TID 528)\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Starting task 9.0 in stage 45.0 (TID 529) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 9, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:42 INFO Executor: Running task 9.0 in stage 45.0 (TID 529)\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Finished task 6.0 in stage 45.0 (TID 526) in 40 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (7/50)\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Finished task 7.0 in stage 45.0 (TID 527) in 36 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (8/50)\n",
      "25/11/13 15:06:42 INFO BlockManager: Found block rdd_88_8 locally\n",
      "25/11/13 15:06:42 INFO BlockManager: Found block rdd_88_9 locally\n",
      "25/11/13 15:06:42 INFO Executor: Finished task 8.0 in stage 45.0 (TID 528). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:42 INFO Executor: Finished task 9.0 in stage 45.0 (TID 529). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Starting task 10.0 in stage 45.0 (TID 530) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 10, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:42 INFO Executor: Running task 10.0 in stage 45.0 (TID 530)\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Starting task 11.0 in stage 45.0 (TID 531) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 11, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:42 INFO TaskSetManager: Finished task 8.0 in stage 45.0 (TID 528) in 18 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (9/50)\n",
      "25/11/13 15:06:42 INFO Executor: Running task 11.0 in stage 45.0 (TID 531)\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Finished task 9.0 in stage 45.0 (TID 529) in 19 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (10/50)\n",
      "25/11/13 15:06:42 INFO BlockManager: Found block rdd_88_11 locally\n",
      "25/11/13 15:06:42 INFO BlockManager: Found block rdd_88_10 locally\n",
      "25/11/13 15:06:42 INFO Executor: Finished task 10.0 in stage 45.0 (TID 530). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:42 INFO Executor: Finished task 11.0 in stage 45.0 (TID 531). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Starting task 12.0 in stage 45.0 (TID 532) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 12, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:42 INFO Executor: Running task 12.0 in stage 45.0 (TID 532)\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Starting task 13.0 in stage 45.0 (TID 533) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 13, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:42 INFO Executor: Running task 13.0 in stage 45.0 (TID 533)\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Finished task 11.0 in stage 45.0 (TID 531) in 77 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (11/50)\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Finished task 10.0 in stage 45.0 (TID 530) in 77 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (12/50)\n",
      "25/11/13 15:06:42 INFO BlockManager: Found block rdd_88_12 locally\n",
      "25/11/13 15:06:42 INFO Executor: Finished task 12.0 in stage 45.0 (TID 532). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Starting task 14.0 in stage 45.0 (TID 534) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 14, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:42 INFO TaskSetManager: Finished task 12.0 in stage 45.0 (TID 532) in 40 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (13/50)\n",
      "25/11/13 15:06:42 INFO Executor: Running task 14.0 in stage 45.0 (TID 534)\n",
      "25/11/13 15:06:42 INFO BlockManager: Found block rdd_88_13 locally\n",
      "25/11/13 15:06:42 INFO Executor: Finished task 13.0 in stage 45.0 (TID 533). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Starting task 15.0 in stage 45.0 (TID 535) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 15, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:42 INFO Executor: Running task 15.0 in stage 45.0 (TID 535)\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Finished task 13.0 in stage 45.0 (TID 533) in 47 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (14/50)\n",
      "25/11/13 15:06:42 INFO BlockManager: Found block rdd_88_14 locally\n",
      "25/11/13 15:06:42 INFO Executor: Finished task 14.0 in stage 45.0 (TID 534). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Starting task 16.0 in stage 45.0 (TID 536) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 16, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:42 INFO Executor: Running task 16.0 in stage 45.0 (TID 536)\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Finished task 14.0 in stage 45.0 (TID 534) in 23 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (15/50)\n",
      "25/11/13 15:06:42 INFO BlockManager: Found block rdd_88_15 locally\n",
      "25/11/13 15:06:42 INFO Executor: Finished task 15.0 in stage 45.0 (TID 535). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Starting task 17.0 in stage 45.0 (TID 537) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 17, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:42 INFO Executor: Running task 17.0 in stage 45.0 (TID 537)\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Finished task 15.0 in stage 45.0 (TID 535) in 52 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (16/50)\n",
      "25/11/13 15:06:42 INFO BlockManager: Found block rdd_88_16 locally\n",
      "25/11/13 15:06:42 INFO Executor: Finished task 16.0 in stage 45.0 (TID 536). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Starting task 18.0 in stage 45.0 (TID 538) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 18, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:42 INFO Executor: Running task 18.0 in stage 45.0 (TID 538)\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Finished task 16.0 in stage 45.0 (TID 536) in 67 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (17/50)\n",
      "25/11/13 15:06:42 INFO BlockManager: Found block rdd_88_17 locally\n",
      "25/11/13 15:06:42 INFO Executor: Finished task 17.0 in stage 45.0 (TID 537). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Starting task 19.0 in stage 45.0 (TID 539) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 19, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:42 INFO TaskSetManager: Finished task 17.0 in stage 45.0 (TID 537) in 40 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (18/50)\n",
      "25/11/13 15:06:42 INFO Executor: Running task 19.0 in stage 45.0 (TID 539)\n",
      "25/11/13 15:06:42 INFO BlockManager: Found block rdd_88_18 locally\n",
      "25/11/13 15:06:42 INFO Executor: Finished task 18.0 in stage 45.0 (TID 538). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Starting task 20.0 in stage 45.0 (TID 540) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 20, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:42 INFO TaskSetManager: Finished task 18.0 in stage 45.0 (TID 538) in 15 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (19/50)\n",
      "25/11/13 15:06:42 INFO Executor: Running task 20.0 in stage 45.0 (TID 540)\n",
      "25/11/13 15:06:42 INFO BlockManager: Found block rdd_88_20 locally\n",
      "25/11/13 15:06:42 INFO BlockManager: Found block rdd_88_19 locally\n",
      "25/11/13 15:06:42 INFO Executor: Finished task 20.0 in stage 45.0 (TID 540). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:42 INFO Executor: Finished task 19.0 in stage 45.0 (TID 539). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Starting task 21.0 in stage 45.0 (TID 541) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 21, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:42 INFO Executor: Running task 21.0 in stage 45.0 (TID 541)\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Starting task 22.0 in stage 45.0 (TID 542) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 22, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:42 INFO Executor: Running task 22.0 in stage 45.0 (TID 542)\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Finished task 19.0 in stage 45.0 (TID 539) in 20 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (20/50)\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Finished task 20.0 in stage 45.0 (TID 540) in 16 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (21/50)\n",
      "25/11/13 15:06:42 INFO BlockManager: Found block rdd_88_21 locally\n",
      "25/11/13 15:06:42 INFO BlockManager: Found block rdd_88_22 locally\n",
      "25/11/13 15:06:42 INFO Executor: Finished task 21.0 in stage 45.0 (TID 541). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:42 INFO Executor: Finished task 22.0 in stage 45.0 (TID 542). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Starting task 23.0 in stage 45.0 (TID 543) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 23, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:42 INFO Executor: Running task 23.0 in stage 45.0 (TID 543)\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Starting task 24.0 in stage 45.0 (TID 544) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 24, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:42 INFO TaskSetManager: Finished task 21.0 in stage 45.0 (TID 541) in 43 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (22/50)\n",
      "25/11/13 15:06:42 INFO Executor: Running task 24.0 in stage 45.0 (TID 544)\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Finished task 22.0 in stage 45.0 (TID 542) in 42 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (23/50)\n",
      "25/11/13 15:06:42 INFO BlockManager: Found block rdd_88_23 locally\n",
      "25/11/13 15:06:42 INFO Executor: Finished task 23.0 in stage 45.0 (TID 543). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Starting task 25.0 in stage 45.0 (TID 545) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 25, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:42 INFO Executor: Running task 25.0 in stage 45.0 (TID 545)\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Finished task 23.0 in stage 45.0 (TID 543) in 35 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (24/50)\n",
      "25/11/13 15:06:42 INFO BlockManager: Found block rdd_88_24 locally\n",
      "25/11/13 15:06:42 INFO Executor: Finished task 24.0 in stage 45.0 (TID 544). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Starting task 26.0 in stage 45.0 (TID 546) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 26, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:42 INFO TaskSetManager: Finished task 24.0 in stage 45.0 (TID 544) in 40 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (25/50)\n",
      "25/11/13 15:06:42 INFO Executor: Running task 26.0 in stage 45.0 (TID 546)\n",
      "25/11/13 15:06:42 INFO BlockManager: Found block rdd_88_25 locally\n",
      "25/11/13 15:06:42 INFO Executor: Finished task 25.0 in stage 45.0 (TID 545). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Starting task 27.0 in stage 45.0 (TID 547) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 27, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:42 INFO Executor: Running task 27.0 in stage 45.0 (TID 547)\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Finished task 25.0 in stage 45.0 (TID 545) in 18 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (26/50)\n",
      "25/11/13 15:06:42 INFO BlockManager: Found block rdd_88_26 locally\n",
      "25/11/13 15:06:42 INFO Executor: Finished task 26.0 in stage 45.0 (TID 546). 4393 bytes result sent to driver\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Starting task 28.0 in stage 45.0 (TID 548) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 28, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:42 INFO Executor: Running task 28.0 in stage 45.0 (TID 548)\n",
      "25/11/13 15:06:42 INFO TaskSetManager: Finished task 26.0 in stage 45.0 (TID 546) in 19 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (27/50)\n",
      "25/11/13 15:06:42 INFO BlockManager: Found block rdd_88_27 locally\n",
      "25/11/13 15:06:42 INFO Executor: Finished task 27.0 in stage 45.0 (TID 547). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:43 INFO TaskSetManager: Starting task 29.0 in stage 45.0 (TID 549) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 29, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:43 INFO TaskSetManager: Finished task 27.0 in stage 45.0 (TID 547) in 21 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (28/50)\n",
      "25/11/13 15:06:43 INFO Executor: Running task 29.0 in stage 45.0 (TID 549)\n",
      "25/11/13 15:06:43 INFO BlockManager: Found block rdd_88_28 locally\n",
      "25/11/13 15:06:43 INFO Executor: Finished task 28.0 in stage 45.0 (TID 548). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:43 INFO TaskSetManager: Starting task 30.0 in stage 45.0 (TID 550) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 30, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:43 INFO TaskSetManager: Finished task 28.0 in stage 45.0 (TID 548) in 45 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (29/50)\n",
      "25/11/13 15:06:43 INFO Executor: Running task 30.0 in stage 45.0 (TID 550)\n",
      "25/11/13 15:06:43 INFO BlockManager: Found block rdd_88_29 locally\n",
      "25/11/13 15:06:43 INFO Executor: Finished task 29.0 in stage 45.0 (TID 549). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:43 INFO TaskSetManager: Starting task 31.0 in stage 45.0 (TID 551) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 31, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:43 INFO TaskSetManager: Finished task 29.0 in stage 45.0 (TID 549) in 63 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (30/50)\n",
      "25/11/13 15:06:43 INFO Executor: Running task 31.0 in stage 45.0 (TID 551)\n",
      "25/11/13 15:06:43 INFO BlockManager: Found block rdd_88_30 locally\n",
      "25/11/13 15:06:43 INFO Executor: Finished task 30.0 in stage 45.0 (TID 550). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:43 INFO TaskSetManager: Starting task 32.0 in stage 45.0 (TID 552) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 32, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:43 INFO Executor: Running task 32.0 in stage 45.0 (TID 552)\n",
      "25/11/13 15:06:43 INFO TaskSetManager: Finished task 30.0 in stage 45.0 (TID 550) in 40 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (31/50)\n",
      "25/11/13 15:06:43 INFO BlockManager: Found block rdd_88_31 locally\n",
      "25/11/13 15:06:43 INFO Executor: Finished task 31.0 in stage 45.0 (TID 551). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:43 INFO TaskSetManager: Starting task 33.0 in stage 45.0 (TID 553) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 33, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:43 INFO Executor: Running task 33.0 in stage 45.0 (TID 553)\n",
      "25/11/13 15:06:43 INFO TaskSetManager: Finished task 31.0 in stage 45.0 (TID 551) in 23 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (32/50)\n",
      "25/11/13 15:06:43 INFO BlockManager: Found block rdd_88_32 locally\n",
      "25/11/13 15:06:43 INFO Executor: Finished task 32.0 in stage 45.0 (TID 552). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:43 INFO TaskSetManager: Starting task 34.0 in stage 45.0 (TID 554) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 34, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:43 INFO Executor: Running task 34.0 in stage 45.0 (TID 554)\n",
      "25/11/13 15:06:43 INFO TaskSetManager: Finished task 32.0 in stage 45.0 (TID 552) in 21 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (33/50)\n",
      "25/11/13 15:06:43 INFO BlockManager: Found block rdd_88_33 locally\n",
      "25/11/13 15:06:43 INFO Executor: Finished task 33.0 in stage 45.0 (TID 553). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:43 INFO TaskSetManager: Starting task 35.0 in stage 45.0 (TID 555) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 35, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:43 INFO Executor: Running task 35.0 in stage 45.0 (TID 555)\n",
      "25/11/13 15:06:43 INFO TaskSetManager: Finished task 33.0 in stage 45.0 (TID 553) in 49 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (34/50)\n",
      "25/11/13 15:06:43 INFO BlockManager: Found block rdd_88_34 locally\n",
      "25/11/13 15:06:43 INFO Executor: Finished task 34.0 in stage 45.0 (TID 554). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:43 INFO TaskSetManager: Starting task 36.0 in stage 45.0 (TID 556) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 36, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:43 INFO Executor: Running task 36.0 in stage 45.0 (TID 556)\n",
      "25/11/13 15:06:43 INFO TaskSetManager: Finished task 34.0 in stage 45.0 (TID 554) in 72 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (35/50)\n",
      "25/11/13 15:06:43 INFO BlockManager: Found block rdd_88_35 locally\n",
      "25/11/13 15:06:43 INFO Executor: Finished task 35.0 in stage 45.0 (TID 555). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:43 INFO BlockManager: Found block rdd_88_36 locally\n",
      "25/11/13 15:06:43 INFO TaskSetManager: Starting task 37.0 in stage 45.0 (TID 557) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 37, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:43 INFO Executor: Running task 37.0 in stage 45.0 (TID 557)\n",
      "25/11/13 15:06:43 INFO TaskSetManager: Finished task 35.0 in stage 45.0 (TID 555) in 46 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (36/50)\n",
      "25/11/13 15:06:43 INFO Executor: Finished task 36.0 in stage 45.0 (TID 556). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:43 INFO TaskSetManager: Starting task 38.0 in stage 45.0 (TID 558) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 38, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:43 INFO TaskSetManager: Finished task 36.0 in stage 45.0 (TID 556) in 22 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (37/50)\n",
      "25/11/13 15:06:43 INFO Executor: Running task 38.0 in stage 45.0 (TID 558)\n",
      "25/11/13 15:06:43 INFO BlockManager: Found block rdd_88_37 locally\n",
      "25/11/13 15:06:43 INFO BlockManager: Found block rdd_88_38 locally\n",
      "25/11/13 15:06:43 INFO Executor: Finished task 37.0 in stage 45.0 (TID 557). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:43 INFO Executor: Finished task 38.0 in stage 45.0 (TID 558). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:43 INFO TaskSetManager: Starting task 39.0 in stage 45.0 (TID 559) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 39, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:43 INFO Executor: Running task 39.0 in stage 45.0 (TID 559)\n",
      "25/11/13 15:06:43 INFO TaskSetManager: Starting task 40.0 in stage 45.0 (TID 560) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 40, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:43 INFO TaskSetManager: Finished task 37.0 in stage 45.0 (TID 557) in 86 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (38/50)\n",
      "25/11/13 15:06:43 INFO Executor: Running task 40.0 in stage 45.0 (TID 560)\n",
      "25/11/13 15:06:43 INFO TaskSetManager: Finished task 38.0 in stage 45.0 (TID 558) in 82 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (39/50)\n",
      "25/11/13 15:06:43 INFO BlockManager: Found block rdd_88_39 locally\n",
      "25/11/13 15:06:43 INFO Executor: Finished task 39.0 in stage 45.0 (TID 559). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:43 INFO TaskSetManager: Starting task 41.0 in stage 45.0 (TID 561) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 41, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:43 INFO Executor: Running task 41.0 in stage 45.0 (TID 561)\n",
      "25/11/13 15:06:43 INFO TaskSetManager: Finished task 39.0 in stage 45.0 (TID 559) in 34 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (40/50)\n",
      "25/11/13 15:06:43 INFO BlockManager: Found block rdd_88_40 locally\n",
      "25/11/13 15:06:43 INFO Executor: Finished task 40.0 in stage 45.0 (TID 560). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:43 INFO TaskSetManager: Starting task 42.0 in stage 45.0 (TID 562) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 42, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:43 INFO TaskSetManager: Finished task 40.0 in stage 45.0 (TID 560) in 63 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (41/50)\n",
      "25/11/13 15:06:43 INFO Executor: Running task 42.0 in stage 45.0 (TID 562)\n",
      "25/11/13 15:06:43 INFO BlockManager: Found block rdd_88_41 locally\n",
      "25/11/13 15:06:43 INFO Executor: Finished task 41.0 in stage 45.0 (TID 561). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:43 INFO TaskSetManager: Starting task 43.0 in stage 45.0 (TID 563) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 43, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:43 INFO TaskSetManager: Finished task 41.0 in stage 45.0 (TID 561) in 54 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (42/50)\n",
      "25/11/13 15:06:43 INFO Executor: Running task 43.0 in stage 45.0 (TID 563)\n",
      "25/11/13 15:06:43 INFO BlockManager: Found block rdd_88_42 locally(42 + 2) / 50]\n",
      "25/11/13 15:06:43 INFO BlockManager: Found block rdd_88_43 locally\n",
      "25/11/13 15:06:43 INFO Executor: Finished task 42.0 in stage 45.0 (TID 562). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:43 INFO TaskSetManager: Starting task 44.0 in stage 45.0 (TID 564) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 44, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:43 INFO Executor: Finished task 43.0 in stage 45.0 (TID 563). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:43 INFO Executor: Running task 44.0 in stage 45.0 (TID 564)\n",
      "25/11/13 15:06:43 INFO TaskSetManager: Starting task 45.0 in stage 45.0 (TID 565) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 45, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:43 INFO Executor: Running task 45.0 in stage 45.0 (TID 565)\n",
      "25/11/13 15:06:43 INFO TaskSetManager: Finished task 42.0 in stage 45.0 (TID 562) in 88 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (43/50)\n",
      "25/11/13 15:06:43 INFO TaskSetManager: Finished task 43.0 in stage 45.0 (TID 563) in 43 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (44/50)\n",
      "25/11/13 15:06:43 INFO BlockManager: Found block rdd_88_45 locally\n",
      "25/11/13 15:06:43 INFO BlockManager: Found block rdd_88_44 locally\n",
      "25/11/13 15:06:43 INFO Executor: Finished task 45.0 in stage 45.0 (TID 565). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:43 INFO Executor: Finished task 44.0 in stage 45.0 (TID 564). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:43 INFO TaskSetManager: Starting task 46.0 in stage 45.0 (TID 566) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 46, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:43 INFO TaskSetManager: Finished task 45.0 in stage 45.0 (TID 565) in 16 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (45/50)\n",
      "25/11/13 15:06:43 INFO Executor: Running task 46.0 in stage 45.0 (TID 566)\n",
      "25/11/13 15:06:43 INFO TaskSetManager: Starting task 47.0 in stage 45.0 (TID 567) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 47, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:43 INFO Executor: Running task 47.0 in stage 45.0 (TID 567)\n",
      "25/11/13 15:06:43 INFO TaskSetManager: Finished task 44.0 in stage 45.0 (TID 564) in 19 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (46/50)\n",
      "25/11/13 15:06:43 INFO BlockManager: Found block rdd_88_46 locally\n",
      "25/11/13 15:06:43 INFO Executor: Finished task 46.0 in stage 45.0 (TID 566). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:43 INFO BlockManager: Found block rdd_88_47 locally\n",
      "25/11/13 15:06:43 INFO TaskSetManager: Starting task 48.0 in stage 45.0 (TID 568) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 48, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:43 INFO Executor: Running task 48.0 in stage 45.0 (TID 568)\n",
      "25/11/13 15:06:43 INFO TaskSetManager: Finished task 46.0 in stage 45.0 (TID 566) in 77 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (47/50)\n",
      "25/11/13 15:06:43 INFO Executor: Finished task 47.0 in stage 45.0 (TID 567). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:43 INFO TaskSetManager: Starting task 49.0 in stage 45.0 (TID 569) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 49, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:43 INFO Executor: Running task 49.0 in stage 45.0 (TID 569)\n",
      "25/11/13 15:06:43 INFO TaskSetManager: Finished task 47.0 in stage 45.0 (TID 567) in 78 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (48/50)\n",
      "25/11/13 15:06:43 INFO BlockManager: Found block rdd_88_49 locally\n",
      "25/11/13 15:06:43 INFO BlockManager: Found block rdd_88_48 locally\n",
      "25/11/13 15:06:43 INFO Executor: Finished task 49.0 in stage 45.0 (TID 569). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:43 INFO Executor: Finished task 48.0 in stage 45.0 (TID 568). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:43 INFO TaskSetManager: Finished task 49.0 in stage 45.0 (TID 569) in 17 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (49/50)\n",
      "25/11/13 15:06:43 INFO TaskSetManager: Finished task 48.0 in stage 45.0 (TID 568) in 22 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (50/50)\n",
      "25/11/13 15:06:43 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool \n",
      "25/11/13 15:06:43 INFO DAGScheduler: ResultStage 45 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 0.987 s\n",
      "25/11/13 15:06:43 INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/11/13 15:06:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 45: Stage finished\n",
      "25/11/13 15:06:43 INFO DAGScheduler: Job 27 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 0.994844 s\n",
      "25/11/13 15:06:43 INFO PrepareDeltaScan: DELTA: Done                            \n",
      "25/11/13 15:06:43 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/11/13 15:06:43 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/11/13 15:06:43 INFO CodeGenerator: Code generated in 346.466404 ms\n",
      "25/11/13 15:06:43 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 204.3 KiB, free 1046.8 MiB)\n",
      "25/11/13 15:06:44 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 36.1 KiB, free 1046.8 MiB)\n",
      "25/11/13 15:06:44 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 36.1 KiB, free: 1048.5 MiB)\n",
      "25/11/13 15:06:44 INFO SparkContext: Created broadcast 42 from count at NativeMethodAccessorImpl.java:0\n",
      "25/11/13 15:06:44 INFO FileSourceScanExec: Planning scan with bin packing, max size: 34852989 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/11/13 15:06:44 INFO DAGScheduler: Registering RDD 122 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 7\n",
      "25/11/13 15:06:44 INFO DAGScheduler: Got map stage job 28 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions\n",
      "25/11/13 15:06:44 INFO DAGScheduler: Final stage: ShuffleMapStage 46 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/11/13 15:06:44 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/11/13 15:06:44 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 15:06:44 INFO DAGScheduler: Submitting ShuffleMapStage 46 (MapPartitionsRDD[122] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/11/13 15:06:44 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 34.0 KiB, free 1046.8 MiB)\n",
      "25/11/13 15:06:44 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 1046.8 MiB)\n",
      "25/11/13 15:06:44 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 14.8 KiB, free: 1048.4 MiB)\n",
      "25/11/13 15:06:44 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 15:06:44 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 46 (MapPartitionsRDD[122] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))\n",
      "25/11/13 15:06:44 INFO TaskSchedulerImpl: Adding task set 46.0 with 2 tasks resource profile 0\n",
      "25/11/13 15:06:44 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 570) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 9660 bytes) \n",
      "25/11/13 15:06:44 INFO TaskSetManager: Starting task 1.0 in stage 46.0 (TID 571) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 1, PROCESS_LOCAL, 9660 bytes) \n",
      "25/11/13 15:06:44 INFO Executor: Running task 1.0 in stage 46.0 (TID 571)\n",
      "25/11/13 15:06:44 INFO Executor: Running task 0.0 in stage 46.0 (TID 570)\n",
      "25/11/13 15:06:44 INFO CodeGenerator: Code generated in 44.893045 ms\n",
      "25/11/13 15:06:44 INFO CodeGenerator: Code generated in 12.199172 ms\n",
      "25/11/13 15:06:44 INFO CodeGenerator: Code generated in 7.254528 ms\n",
      "25/11/13 15:06:44 INFO FileScanRDD: Reading File path: s3a://nau-local-analytics-silver/dim_user/part-00000-1e2cb7c2-be16-4592-9fd6-87e16bfa900b-c000.snappy.parquet, range: 0-34852989, partition values: [empty row]\n",
      "25/11/13 15:06:44 INFO FileScanRDD: Reading File path: s3a://nau-local-analytics-silver/dim_user/part-00000-1e2cb7c2-be16-4592-9fd6-87e16bfa900b-c000.snappy.parquet, range: 34852989-65511675, partition values: [empty row]\n",
      "25/11/13 15:06:44 INFO S3AInputStream: Switching to Random IO seek policy\n",
      "25/11/13 15:06:44 INFO S3AInputStream: Switching to Random IO seek policy\n",
      "25/11/13 15:06:44 INFO Executor: Finished task 1.0 in stage 46.0 (TID 571). 2779 bytes result sent to driver\n",
      "25/11/13 15:06:44 INFO TaskSetManager: Finished task 1.0 in stage 46.0 (TID 571) in 241 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/2)\n",
      "25/11/13 15:06:45 INFO Executor: Finished task 0.0 in stage 46.0 (TID 570). 2994 bytes result sent to driver\n",
      "25/11/13 15:06:45 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 570) in 1420 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (2/2)\n",
      "25/11/13 15:06:45 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool \n",
      "25/11/13 15:06:45 INFO DAGScheduler: ShuffleMapStage 46 (count at NativeMethodAccessorImpl.java:0) finished in 1.433 s\n",
      "25/11/13 15:06:45 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/11/13 15:06:45 INFO DAGScheduler: running: Set()\n",
      "25/11/13 15:06:45 INFO DAGScheduler: waiting: Set()\n",
      "25/11/13 15:06:45 INFO DAGScheduler: failed: Set()\n",
      "25/11/13 15:06:45 INFO ShufflePartitionsUtil: For shuffle(7), advisory target size: 67108864, actual target size 1408441, minimum partition size: 1048576\n",
      "25/11/13 15:06:45 INFO CodeGenerator: Code generated in 22.855835 ms\n",
      "25/11/13 15:06:45 INFO DAGScheduler: Registering RDD 125 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 8\n",
      "25/11/13 15:06:45 INFO DAGScheduler: Got map stage job 29 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions\n",
      "25/11/13 15:06:45 INFO DAGScheduler: Final stage: ShuffleMapStage 48 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/11/13 15:06:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 47)\n",
      "25/11/13 15:06:45 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 15:06:45 INFO DAGScheduler: Submitting ShuffleMapStage 48 (MapPartitionsRDD[125] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/11/13 15:06:45 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 49.0 KiB, free 1046.7 MiB)\n",
      "25/11/13 15:06:45 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 21.9 KiB, free 1046.7 MiB)\n",
      "25/11/13 15:06:45 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 21.9 KiB, free: 1048.4 MiB)\n",
      "25/11/13 15:06:45 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 15:06:45 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 48 (MapPartitionsRDD[125] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))\n",
      "25/11/13 15:06:45 INFO TaskSchedulerImpl: Adding task set 48.0 with 2 tasks resource profile 0\n",
      "25/11/13 15:06:45 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 572) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, NODE_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:45 INFO TaskSetManager: Starting task 1.0 in stage 48.0 (TID 573) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 1, NODE_LOCAL, 8988 bytes) \n",
      "25/11/13 15:06:45 INFO Executor: Running task 0.0 in stage 48.0 (TID 572)\n",
      "25/11/13 15:06:45 INFO Executor: Running task 1.0 in stage 48.0 (TID 573)\n",
      "25/11/13 15:06:45 INFO ShuffleBlockFetcherIterator: Getting 1 (1371.4 KiB) non-empty blocks including 1 (1371.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:06:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "25/11/13 15:06:45 INFO ShuffleBlockFetcherIterator: Getting 1 (1379.5 KiB) non-empty blocks including 1 (1379.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:06:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/11/13 15:06:45 INFO CodeGenerator: Code generated in 31.957819 ms\n",
      "25/11/13 15:06:45 INFO BlockManagerInfo: Removed broadcast_43_piece0 on jupyter-spark-758b7c86d8-7j77n:43517 in memory (size: 14.8 KiB, free: 1048.4 MiB)\n",
      "25/11/13 15:06:45 INFO BlockManagerInfo: Removed broadcast_41_piece0 on jupyter-spark-758b7c86d8-7j77n:43517 in memory (size: 154.6 KiB, free: 1048.6 MiB)\n",
      "25/11/13 15:06:47 INFO Executor: Finished task 1.0 in stage 48.0 (TID 573). 5907 bytes result sent to driver\n",
      "25/11/13 15:06:47 INFO TaskSetManager: Finished task 1.0 in stage 48.0 (TID 573) in 1462 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/2)\n",
      "25/11/13 15:06:47 INFO Executor: Finished task 0.0 in stage 48.0 (TID 572). 5864 bytes result sent to driver\n",
      "25/11/13 15:06:47 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 572) in 1492 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (2/2)\n",
      "25/11/13 15:06:47 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool \n",
      "25/11/13 15:06:47 INFO DAGScheduler: ShuffleMapStage 48 (count at NativeMethodAccessorImpl.java:0) finished in 1.506 s\n",
      "25/11/13 15:06:47 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/11/13 15:06:47 INFO DAGScheduler: running: Set()\n",
      "25/11/13 15:06:47 INFO DAGScheduler: waiting: Set()\n",
      "25/11/13 15:06:47 INFO DAGScheduler: failed: Set()\n",
      "25/11/13 15:06:47 INFO CodeGenerator: Code generated in 16.833057 ms\n",
      "25/11/13 15:06:47 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0\n",
      "25/11/13 15:06:47 INFO DAGScheduler: Got job 30 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/11/13 15:06:47 INFO DAGScheduler: Final stage: ResultStage 51 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/11/13 15:06:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 50)\n",
      "25/11/13 15:06:47 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 15:06:47 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[128] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/11/13 15:06:47 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 12.5 KiB, free 1047.5 MiB)\n",
      "25/11/13 15:06:47 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 1047.5 MiB)\n",
      "25/11/13 15:06:47 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 5.9 KiB, free: 1048.6 MiB)\n",
      "25/11/13 15:06:47 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 15:06:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[128] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/11/13 15:06:47 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks resource profile 0\n",
      "25/11/13 15:06:47 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 574) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, NODE_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:47 INFO Executor: Running task 0.0 in stage 51.0 (TID 574)\n",
      "25/11/13 15:06:47 INFO ShuffleBlockFetcherIterator: Getting 2 (120.0 B) non-empty blocks including 2 (120.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/11/13 15:06:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/11/13 15:06:47 INFO CodeGenerator: Code generated in 22.359503 ms\n",
      "25/11/13 15:06:47 INFO Executor: Finished task 0.0 in stage 51.0 (TID 574). 3995 bytes result sent to driver\n",
      "25/11/13 15:06:47 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 574) in 34 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/1)\n",
      "25/11/13 15:06:47 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool \n",
      "25/11/13 15:06:47 INFO DAGScheduler: ResultStage 51 (count at NativeMethodAccessorImpl.java:0) finished in 0.046 s\n",
      "25/11/13 15:06:47 INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/11/13 15:06:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 51: Stage finished\n",
      "25/11/13 15:06:47 INFO DAGScheduler: Job 30 finished: count at NativeMethodAccessorImpl.java:0, took 0.077788 s\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> [dim_user] Total rows in Silver: 494033\n",
      ">> [dim_user] Distinct user_id in Silver: 494033\n",
      "\n",
      ">> [dim_user] Checking if table is available in the catalog (if created):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/13 15:06:47 INFO CodeGenerator: Code generated in 47.417128 ms\n",
      "25/11/13 15:06:47 INFO CodeGenerator: Code generated in 83.128085 ms\n",
      "25/11/13 15:06:47 INFO CodeGenerator: Code generated in 5.98119 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "|default  |dim_user |false      |\n",
      "+---------+---------+-----------+\n",
      "\n",
      "\n",
      ">> [dim_user] Preview via SQL (if table is registered):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/13 15:06:47 INFO PrepareDeltaScan: DELTA: Filtering files for query\n",
      "25/11/13 15:06:48 INFO BlockManagerInfo: Removed broadcast_45_piece0 on jupyter-spark-758b7c86d8-7j77n:43517 in memory (size: 5.9 KiB, free: 1048.6 MiB)\n",
      "25/11/13 15:06:48 INFO BlockManagerInfo: Removed broadcast_44_piece0 on jupyter-spark-758b7c86d8-7j77n:43517 in memory (size: 21.9 KiB, free: 1048.6 MiB)\n",
      "25/11/13 15:06:48 INFO SparkContext: Starting job: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128\n",
      "25/11/13 15:06:48 INFO DAGScheduler: Got job 31 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) with 50 output partitions\n",
      "25/11/13 15:06:48 INFO DAGScheduler: Final stage: ResultStage 53 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128)\n",
      "25/11/13 15:06:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 52)\n",
      "25/11/13 15:06:48 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 15:06:48 INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[130] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128), which has no missing parents\n",
      "25/11/13 15:06:48 INFO BlockManagerInfo: Removed broadcast_42_piece0 on jupyter-spark-758b7c86d8-7j77n:43517 in memory (size: 36.1 KiB, free: 1048.6 MiB)\n",
      "25/11/13 15:06:48 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 684.9 KiB, free 1047.2 MiB)\n",
      "25/11/13 15:06:48 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 154.6 KiB, free 1047.0 MiB)\n",
      "25/11/13 15:06:48 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 154.6 KiB, free: 1048.5 MiB)\n",
      "25/11/13 15:06:48 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 15:06:48 INFO DAGScheduler: Submitting 50 missing tasks from ResultStage 53 (MapPartitionsRDD[130] at $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n",
      "25/11/13 15:06:48 INFO TaskSchedulerImpl: Adding task set 53.0 with 50 tasks resource profile 0\n",
      "25/11/13 15:06:48 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 575) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:48 INFO TaskSetManager: Starting task 1.0 in stage 53.0 (TID 576) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 1, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:48 INFO Executor: Running task 0.0 in stage 53.0 (TID 575)\n",
      "25/11/13 15:06:48 INFO Executor: Running task 1.0 in stage 53.0 (TID 576)\n",
      "25/11/13 15:06:48 INFO BlockManager: Found block rdd_88_1 locally\n",
      "25/11/13 15:06:48 INFO BlockManager: Found block rdd_88_0 locally\n",
      "25/11/13 15:06:48 INFO Executor: Finished task 1.0 in stage 53.0 (TID 576). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:48 INFO TaskSetManager: Starting task 2.0 in stage 53.0 (TID 577) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 2, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:48 INFO TaskSetManager: Finished task 1.0 in stage 53.0 (TID 576) in 20 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/50)\n",
      "25/11/13 15:06:48 INFO Executor: Running task 2.0 in stage 53.0 (TID 577)\n",
      "25/11/13 15:06:48 INFO Executor: Finished task 0.0 in stage 53.0 (TID 575). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:48 INFO TaskSetManager: Starting task 3.0 in stage 53.0 (TID 578) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 3, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:48 INFO Executor: Running task 3.0 in stage 53.0 (TID 578)\n",
      "25/11/13 15:06:48 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 575) in 23 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (2/50)\n",
      "25/11/13 15:06:48 INFO BlockManager: Found block rdd_88_2 locally\n",
      "25/11/13 15:06:48 INFO Executor: Finished task 2.0 in stage 53.0 (TID 577). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:48 INFO TaskSetManager: Starting task 4.0 in stage 53.0 (TID 579) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 4, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:48 INFO Executor: Running task 4.0 in stage 53.0 (TID 579)\n",
      "25/11/13 15:06:48 INFO TaskSetManager: Finished task 2.0 in stage 53.0 (TID 577) in 70 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (3/50)\n",
      "25/11/13 15:06:48 INFO BlockManager: Found block rdd_88_3 locally\n",
      "25/11/13 15:06:48 INFO Executor: Finished task 3.0 in stage 53.0 (TID 578). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:48 INFO TaskSetManager: Starting task 5.0 in stage 53.0 (TID 580) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 5, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:48 INFO Executor: Running task 5.0 in stage 53.0 (TID 580)\n",
      "25/11/13 15:06:48 INFO TaskSetManager: Finished task 3.0 in stage 53.0 (TID 578) in 72 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (4/50)\n",
      "25/11/13 15:06:48 INFO BlockManager: Found block rdd_88_4 locally\n",
      "25/11/13 15:06:48 INFO Executor: Finished task 4.0 in stage 53.0 (TID 579). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:48 INFO TaskSetManager: Starting task 6.0 in stage 53.0 (TID 581) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 6, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:48 INFO Executor: Running task 6.0 in stage 53.0 (TID 581)\n",
      "25/11/13 15:06:48 INFO BlockManager: Found block rdd_88_5 locally\n",
      "25/11/13 15:06:48 INFO TaskSetManager: Finished task 4.0 in stage 53.0 (TID 579) in 21 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (5/50)\n",
      "25/11/13 15:06:48 INFO Executor: Finished task 5.0 in stage 53.0 (TID 580). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:48 INFO TaskSetManager: Starting task 7.0 in stage 53.0 (TID 582) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 7, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:48 INFO Executor: Running task 7.0 in stage 53.0 (TID 582)\n",
      "25/11/13 15:06:48 INFO TaskSetManager: Finished task 5.0 in stage 53.0 (TID 580) in 19 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (6/50)\n",
      "25/11/13 15:06:48 INFO BlockManager: Found block rdd_88_6 locally\n",
      "25/11/13 15:06:48 INFO Executor: Finished task 6.0 in stage 53.0 (TID 581). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:48 INFO TaskSetManager: Starting task 8.0 in stage 53.0 (TID 583) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 8, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:48 INFO Executor: Running task 8.0 in stage 53.0 (TID 583)\n",
      "25/11/13 15:06:48 INFO TaskSetManager: Finished task 6.0 in stage 53.0 (TID 581) in 53 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (7/50)\n",
      "25/11/13 15:06:48 INFO BlockManager: Found block rdd_88_7 locally\n",
      "25/11/13 15:06:48 INFO Executor: Finished task 7.0 in stage 53.0 (TID 582). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:48 INFO TaskSetManager: Starting task 9.0 in stage 53.0 (TID 584) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 9, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:48 INFO Executor: Running task 9.0 in stage 53.0 (TID 584)\n",
      "25/11/13 15:06:48 INFO TaskSetManager: Finished task 7.0 in stage 53.0 (TID 582) in 78 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (8/50)\n",
      "25/11/13 15:06:48 INFO BlockManager: Found block rdd_88_8 locally\n",
      "25/11/13 15:06:48 INFO Executor: Finished task 8.0 in stage 53.0 (TID 583). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:48 INFO TaskSetManager: Starting task 10.0 in stage 53.0 (TID 585) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 10, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:48 INFO Executor: Running task 10.0 in stage 53.0 (TID 585)\n",
      "25/11/13 15:06:48 INFO BlockManager: Found block rdd_88_9 locally\n",
      "25/11/13 15:06:48 INFO Executor: Finished task 9.0 in stage 53.0 (TID 584). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:48 INFO TaskSetManager: Starting task 11.0 in stage 53.0 (TID 586) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 11, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:48 INFO Executor: Running task 11.0 in stage 53.0 (TID 586)\n",
      "25/11/13 15:06:48 INFO TaskSetManager: Finished task 8.0 in stage 53.0 (TID 583) in 47 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (9/50)\n",
      "25/11/13 15:06:48 INFO TaskSetManager: Finished task 9.0 in stage 53.0 (TID 584) in 18 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (10/50)\n",
      "25/11/13 15:06:48 INFO BlockManager: Found block rdd_88_10 locally\n",
      "25/11/13 15:06:48 INFO Executor: Finished task 10.0 in stage 53.0 (TID 585). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:48 INFO TaskSetManager: Starting task 12.0 in stage 53.0 (TID 587) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 12, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:48 INFO Executor: Running task 12.0 in stage 53.0 (TID 587)\n",
      "25/11/13 15:06:48 INFO TaskSetManager: Finished task 10.0 in stage 53.0 (TID 585) in 51 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (11/50)\n",
      "25/11/13 15:06:48 INFO BlockManager: Found block rdd_88_11 locally\n",
      "25/11/13 15:06:48 INFO Executor: Finished task 11.0 in stage 53.0 (TID 586). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:48 INFO TaskSetManager: Starting task 13.0 in stage 53.0 (TID 588) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 13, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:48 INFO Executor: Running task 13.0 in stage 53.0 (TID 588)\n",
      "25/11/13 15:06:48 INFO TaskSetManager: Finished task 11.0 in stage 53.0 (TID 586) in 56 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (12/50)\n",
      "25/11/13 15:06:48 INFO BlockManager: Found block rdd_88_12 locally\n",
      "25/11/13 15:06:48 INFO Executor: Finished task 12.0 in stage 53.0 (TID 587). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:48 INFO TaskSetManager: Starting task 14.0 in stage 53.0 (TID 589) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 14, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:48 INFO TaskSetManager: Finished task 12.0 in stage 53.0 (TID 587) in 80 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (13/50)\n",
      "25/11/13 15:06:48 INFO Executor: Running task 14.0 in stage 53.0 (TID 589)\n",
      "25/11/13 15:06:48 INFO BlockManager: Found block rdd_88_13 locally\n",
      "25/11/13 15:06:48 INFO Executor: Finished task 13.0 in stage 53.0 (TID 588). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:48 INFO TaskSetManager: Starting task 15.0 in stage 53.0 (TID 590) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 15, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:48 INFO Executor: Running task 15.0 in stage 53.0 (TID 590)\n",
      "25/11/13 15:06:48 INFO TaskSetManager: Finished task 13.0 in stage 53.0 (TID 588) in 54 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (14/50)\n",
      "25/11/13 15:06:48 INFO BlockManager: Found block rdd_88_14 locally\n",
      "25/11/13 15:06:48 INFO Executor: Finished task 14.0 in stage 53.0 (TID 589). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:48 INFO TaskSetManager: Starting task 16.0 in stage 53.0 (TID 591) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 16, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:48 INFO Executor: Running task 16.0 in stage 53.0 (TID 591)\n",
      "25/11/13 15:06:48 INFO TaskSetManager: Finished task 14.0 in stage 53.0 (TID 589) in 52 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (15/50)\n",
      "25/11/13 15:06:48 INFO BlockManager: Found block rdd_88_15 locally\n",
      "25/11/13 15:06:48 INFO BlockManager: Found block rdd_88_16 locally\n",
      "25/11/13 15:06:48 INFO Executor: Finished task 15.0 in stage 53.0 (TID 590). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:48 INFO TaskSetManager: Starting task 17.0 in stage 53.0 (TID 592) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 17, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:48 INFO Executor: Finished task 16.0 in stage 53.0 (TID 591). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:48 INFO Executor: Running task 17.0 in stage 53.0 (TID 592)\n",
      "25/11/13 15:06:48 INFO TaskSetManager: Finished task 15.0 in stage 53.0 (TID 590) in 86 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (16/50)\n",
      "25/11/13 15:06:48 INFO TaskSetManager: Starting task 18.0 in stage 53.0 (TID 593) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 18, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:48 INFO Executor: Running task 18.0 in stage 53.0 (TID 593)\n",
      "25/11/13 15:06:48 INFO TaskSetManager: Finished task 16.0 in stage 53.0 (TID 591) in 81 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (17/50)\n",
      "25/11/13 15:06:48 INFO BlockManager: Found block rdd_88_17 locally\n",
      "25/11/13 15:06:48 INFO BlockManager: Found block rdd_88_18 locally\n",
      "25/11/13 15:06:48 INFO Executor: Finished task 17.0 in stage 53.0 (TID 592). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:48 INFO TaskSetManager: Starting task 19.0 in stage 53.0 (TID 594) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 19, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:48 INFO TaskSetManager: Finished task 17.0 in stage 53.0 (TID 592) in 154 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (18/50)\n",
      "25/11/13 15:06:48 INFO Executor: Running task 19.0 in stage 53.0 (TID 594)\n",
      "25/11/13 15:06:48 INFO Executor: Finished task 18.0 in stage 53.0 (TID 593). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:48 INFO TaskSetManager: Starting task 20.0 in stage 53.0 (TID 595) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 20, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:48 INFO Executor: Running task 20.0 in stage 53.0 (TID 595)\n",
      "25/11/13 15:06:48 INFO TaskSetManager: Finished task 18.0 in stage 53.0 (TID 593) in 156 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (19/50)\n",
      "25/11/13 15:06:48 INFO BlockManager: Found block rdd_88_19 locally\n",
      "25/11/13 15:06:48 INFO Executor: Finished task 19.0 in stage 53.0 (TID 594). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:48 INFO BlockManager: Found block rdd_88_20 locally\n",
      "25/11/13 15:06:48 INFO TaskSetManager: Starting task 21.0 in stage 53.0 (TID 596) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 21, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:48 INFO Executor: Running task 21.0 in stage 53.0 (TID 596)\n",
      "25/11/13 15:06:48 INFO TaskSetManager: Finished task 19.0 in stage 53.0 (TID 594) in 47 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (20/50)\n",
      "25/11/13 15:06:48 INFO Executor: Finished task 20.0 in stage 53.0 (TID 595). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:48 INFO TaskSetManager: Starting task 22.0 in stage 53.0 (TID 597) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 22, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:48 INFO Executor: Running task 22.0 in stage 53.0 (TID 597)\n",
      "25/11/13 15:06:48 INFO TaskSetManager: Finished task 20.0 in stage 53.0 (TID 595) in 46 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (21/50)\n",
      "25/11/13 15:06:48 INFO BlockManager: Found block rdd_88_21 locally\n",
      "25/11/13 15:06:48 INFO Executor: Finished task 21.0 in stage 53.0 (TID 596). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:48 INFO TaskSetManager: Starting task 23.0 in stage 53.0 (TID 598) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 23, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:48 INFO TaskSetManager: Finished task 21.0 in stage 53.0 (TID 596) in 20 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (22/50)\n",
      "25/11/13 15:06:48 INFO Executor: Running task 23.0 in stage 53.0 (TID 598)\n",
      "25/11/13 15:06:48 INFO BlockManager: Found block rdd_88_22 locally\n",
      "25/11/13 15:06:49 INFO Executor: Finished task 22.0 in stage 53.0 (TID 597). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Starting task 24.0 in stage 53.0 (TID 599) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 24, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:49 INFO Executor: Running task 24.0 in stage 53.0 (TID 599)\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Finished task 22.0 in stage 53.0 (TID 597) in 53 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (23/50)\n",
      "25/11/13 15:06:49 INFO BlockManager: Found block rdd_88_23 locally\n",
      "25/11/13 15:06:49 INFO BlockManager: Found block rdd_88_24 locally\n",
      "25/11/13 15:06:49 INFO Executor: Finished task 23.0 in stage 53.0 (TID 598). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Starting task 25.0 in stage 53.0 (TID 600) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 25, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:49 INFO Executor: Running task 25.0 in stage 53.0 (TID 600)\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Finished task 23.0 in stage 53.0 (TID 598) in 79 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (24/50)\n",
      "25/11/13 15:06:49 INFO Executor: Finished task 24.0 in stage 53.0 (TID 599). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Starting task 26.0 in stage 53.0 (TID 601) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 26, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:49 INFO Executor: Running task 26.0 in stage 53.0 (TID 601)\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Finished task 24.0 in stage 53.0 (TID 599) in 44 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (25/50)\n",
      "25/11/13 15:06:49 INFO BlockManager: Found block rdd_88_26 locally\n",
      "25/11/13 15:06:49 INFO Executor: Finished task 26.0 in stage 53.0 (TID 601). 4393 bytes result sent to driver\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Starting task 27.0 in stage 53.0 (TID 602) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 27, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:49 INFO Executor: Running task 27.0 in stage 53.0 (TID 602)\n",
      "25/11/13 15:06:49 INFO BlockManager: Found block rdd_88_25 locally\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Finished task 26.0 in stage 53.0 (TID 601) in 22 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (26/50)\n",
      "25/11/13 15:06:49 INFO Executor: Finished task 25.0 in stage 53.0 (TID 600). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Starting task 28.0 in stage 53.0 (TID 603) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 28, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:49 INFO Executor: Running task 28.0 in stage 53.0 (TID 603)\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Finished task 25.0 in stage 53.0 (TID 600) in 64 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (27/50)\n",
      "25/11/13 15:06:49 INFO BlockManager: Found block rdd_88_27 locally\n",
      "25/11/13 15:06:49 INFO Executor: Finished task 27.0 in stage 53.0 (TID 602). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Starting task 29.0 in stage 53.0 (TID 604) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 29, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:49 INFO Executor: Running task 29.0 in stage 53.0 (TID 604)\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Finished task 27.0 in stage 53.0 (TID 602) in 81 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (28/50)\n",
      "25/11/13 15:06:49 INFO BlockManager: Found block rdd_88_28 locally\n",
      "25/11/13 15:06:49 INFO Executor: Finished task 28.0 in stage 53.0 (TID 603). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Starting task 30.0 in stage 53.0 (TID 605) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 30, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:49 INFO Executor: Running task 30.0 in stage 53.0 (TID 605)\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Finished task 28.0 in stage 53.0 (TID 603) in 49 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (29/50)\n",
      "25/11/13 15:06:49 INFO BlockManager: Found block rdd_88_29 locally\n",
      "25/11/13 15:06:49 INFO Executor: Finished task 29.0 in stage 53.0 (TID 604). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Starting task 31.0 in stage 53.0 (TID 606) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 31, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:49 INFO TaskSetManager: Finished task 29.0 in stage 53.0 (TID 604) in 22 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (30/50)\n",
      "25/11/13 15:06:49 INFO Executor: Running task 31.0 in stage 53.0 (TID 606)\n",
      "25/11/13 15:06:49 INFO BlockManager: Found block rdd_88_30 locally\n",
      "25/11/13 15:06:49 INFO Executor: Finished task 30.0 in stage 53.0 (TID 605). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Starting task 32.0 in stage 53.0 (TID 607) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 32, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:49 INFO Executor: Running task 32.0 in stage 53.0 (TID 607)\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Finished task 30.0 in stage 53.0 (TID 605) in 98 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (31/50)\n",
      "25/11/13 15:06:49 INFO BlockManager: Found block rdd_88_31 locally\n",
      "25/11/13 15:06:49 INFO Executor: Finished task 31.0 in stage 53.0 (TID 606). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Starting task 33.0 in stage 53.0 (TID 608) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 33, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:49 INFO Executor: Running task 33.0 in stage 53.0 (TID 608)\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Finished task 31.0 in stage 53.0 (TID 606) in 101 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (32/50)\n",
      "25/11/13 15:06:49 INFO BlockManager: Found block rdd_88_32 locally\n",
      "25/11/13 15:06:49 INFO Executor: Finished task 32.0 in stage 53.0 (TID 607). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Starting task 34.0 in stage 53.0 (TID 609) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 34, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:49 INFO Executor: Running task 34.0 in stage 53.0 (TID 609)\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Finished task 32.0 in stage 53.0 (TID 607) in 20 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (33/50)\n",
      "25/11/13 15:06:49 INFO BlockManager: Found block rdd_88_33 locally(33 + 2) / 50]\n",
      "25/11/13 15:06:49 INFO Executor: Finished task 33.0 in stage 53.0 (TID 608). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Starting task 35.0 in stage 53.0 (TID 610) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 35, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:49 INFO BlockManager: Found block rdd_88_34 locally\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Finished task 33.0 in stage 53.0 (TID 608) in 73 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (34/50)\n",
      "25/11/13 15:06:49 INFO Executor: Running task 35.0 in stage 53.0 (TID 610)\n",
      "25/11/13 15:06:49 INFO Executor: Finished task 34.0 in stage 53.0 (TID 609). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Starting task 36.0 in stage 53.0 (TID 611) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 36, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:49 INFO Executor: Running task 36.0 in stage 53.0 (TID 611)\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Finished task 34.0 in stage 53.0 (TID 609) in 70 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (35/50)\n",
      "25/11/13 15:06:49 INFO BlockManager: Found block rdd_88_35 locally\n",
      "25/11/13 15:06:49 INFO Executor: Finished task 35.0 in stage 53.0 (TID 610). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Starting task 37.0 in stage 53.0 (TID 612) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 37, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:49 INFO BlockManager: Found block rdd_88_36 locally\n",
      "25/11/13 15:06:49 INFO Executor: Running task 37.0 in stage 53.0 (TID 612)\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Finished task 35.0 in stage 53.0 (TID 610) in 18 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (36/50)\n",
      "25/11/13 15:06:49 INFO Executor: Finished task 36.0 in stage 53.0 (TID 611). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Starting task 38.0 in stage 53.0 (TID 613) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 38, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:49 INFO Executor: Running task 38.0 in stage 53.0 (TID 613)\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Finished task 36.0 in stage 53.0 (TID 611) in 18 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (37/50)\n",
      "25/11/13 15:06:49 INFO BlockManager: Found block rdd_88_37 locally\n",
      "25/11/13 15:06:49 INFO Executor: Finished task 37.0 in stage 53.0 (TID 612). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Starting task 39.0 in stage 53.0 (TID 614) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 39, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:49 INFO Executor: Running task 39.0 in stage 53.0 (TID 614)\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Finished task 37.0 in stage 53.0 (TID 612) in 53 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (38/50)\n",
      "25/11/13 15:06:49 INFO BlockManager: Found block rdd_88_38 locally\n",
      "25/11/13 15:06:49 INFO Executor: Finished task 38.0 in stage 53.0 (TID 613). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Starting task 40.0 in stage 53.0 (TID 615) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 40, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:49 INFO Executor: Running task 40.0 in stage 53.0 (TID 615)\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Finished task 38.0 in stage 53.0 (TID 613) in 59 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (39/50)\n",
      "25/11/13 15:06:49 INFO BlockManager: Found block rdd_88_39 locally\n",
      "25/11/13 15:06:49 INFO Executor: Finished task 39.0 in stage 53.0 (TID 614). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Starting task 41.0 in stage 53.0 (TID 616) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 41, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:49 INFO TaskSetManager: Finished task 39.0 in stage 53.0 (TID 614) in 44 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (40/50)\n",
      "25/11/13 15:06:49 INFO Executor: Running task 41.0 in stage 53.0 (TID 616)\n",
      "25/11/13 15:06:49 INFO BlockManager: Found block rdd_88_40 locally\n",
      "25/11/13 15:06:49 INFO Executor: Finished task 40.0 in stage 53.0 (TID 615). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Starting task 42.0 in stage 53.0 (TID 617) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 42, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:49 INFO Executor: Running task 42.0 in stage 53.0 (TID 617)\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Finished task 40.0 in stage 53.0 (TID 615) in 40 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (41/50)\n",
      "25/11/13 15:06:49 INFO BlockManager: Found block rdd_88_41 locally\n",
      "25/11/13 15:06:49 INFO Executor: Finished task 41.0 in stage 53.0 (TID 616). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Starting task 43.0 in stage 53.0 (TID 618) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 43, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:49 INFO TaskSetManager: Finished task 41.0 in stage 53.0 (TID 616) in 21 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (42/50)\n",
      "25/11/13 15:06:49 INFO Executor: Running task 43.0 in stage 53.0 (TID 618)\n",
      "25/11/13 15:06:49 INFO BlockManager: Found block rdd_88_42 locally\n",
      "25/11/13 15:06:49 INFO Executor: Finished task 42.0 in stage 53.0 (TID 617). 4267 bytes result sent to driver\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Starting task 44.0 in stage 53.0 (TID 619) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 44, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:49 INFO Executor: Running task 44.0 in stage 53.0 (TID 619)\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Finished task 42.0 in stage 53.0 (TID 617) in 54 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (43/50)\n",
      "25/11/13 15:06:49 INFO BlockManager: Found block rdd_88_43 locally(42 + 3) / 50]\n",
      "25/11/13 15:06:49 INFO BlockManager: Found block rdd_88_44 locally\n",
      "25/11/13 15:06:49 INFO Executor: Finished task 44.0 in stage 53.0 (TID 619). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:49 INFO Executor: Finished task 43.0 in stage 53.0 (TID 618). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Starting task 45.0 in stage 53.0 (TID 620) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 45, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:49 INFO Executor: Running task 45.0 in stage 53.0 (TID 620)\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Finished task 44.0 in stage 53.0 (TID 619) in 45 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (44/50)\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Starting task 46.0 in stage 53.0 (TID 621) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 46, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:49 INFO TaskSetManager: Finished task 43.0 in stage 53.0 (TID 618) in 84 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (45/50)\n",
      "25/11/13 15:06:49 INFO Executor: Running task 46.0 in stage 53.0 (TID 621)\n",
      "25/11/13 15:06:49 INFO BlockManager: Found block rdd_88_45 locally\n",
      "25/11/13 15:06:49 INFO Executor: Finished task 45.0 in stage 53.0 (TID 620). 4224 bytes result sent to driver\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Starting task 47.0 in stage 53.0 (TID 622) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 47, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:49 INFO TaskSetManager: Finished task 45.0 in stage 53.0 (TID 620) in 23 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (46/50)\n",
      "25/11/13 15:06:49 INFO Executor: Running task 47.0 in stage 53.0 (TID 622)\n",
      "25/11/13 15:06:49 INFO BlockManager: Found block rdd_88_46 locally\n",
      "25/11/13 15:06:49 INFO Executor: Finished task 46.0 in stage 53.0 (TID 621). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Starting task 48.0 in stage 53.0 (TID 623) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 48, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:49 INFO Executor: Running task 48.0 in stage 53.0 (TID 623)\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Finished task 46.0 in stage 53.0 (TID 621) in 58 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (47/50)\n",
      "25/11/13 15:06:49 INFO BlockManager: Found block rdd_88_47 locally\n",
      "25/11/13 15:06:49 INFO BlockManager: Found block rdd_88_48 locally\n",
      "25/11/13 15:06:49 INFO Executor: Finished task 47.0 in stage 53.0 (TID 622). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Starting task 49.0 in stage 53.0 (TID 624) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 49, PROCESS_LOCAL, 8999 bytes) \n",
      "25/11/13 15:06:49 INFO Executor: Finished task 48.0 in stage 53.0 (TID 623). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:49 INFO Executor: Running task 49.0 in stage 53.0 (TID 624)\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Finished task 48.0 in stage 53.0 (TID 623) in 43 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (48/50)\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Finished task 47.0 in stage 53.0 (TID 622) in 78 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (49/50)\n",
      "25/11/13 15:06:49 INFO BlockManager: Found block rdd_88_49 locally\n",
      "25/11/13 15:06:49 INFO Executor: Finished task 49.0 in stage 53.0 (TID 624). 4181 bytes result sent to driver\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Finished task 49.0 in stage 53.0 (TID 624) in 22 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (50/50)\n",
      "25/11/13 15:06:49 INFO DAGScheduler: ResultStage 53 ($anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128) finished in 1.360 s\n",
      "25/11/13 15:06:49 INFO DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/11/13 15:06:49 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool \n",
      "25/11/13 15:06:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 53: Stage finished\n",
      "25/11/13 15:06:49 INFO DAGScheduler: Job 31 finished: $anonfun$recordDeltaOperationInternal$1 at DatabricksLogging.scala:128, took 1.399830 s\n",
      "25/11/13 15:06:49 INFO PrepareDeltaScan: DELTA: Done                            \n",
      "25/11/13 15:06:49 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/11/13 15:06:49 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/11/13 15:06:49 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 207.0 KiB, free 1046.8 MiB)\n",
      "25/11/13 15:06:49 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 36.8 KiB, free 1046.8 MiB)\n",
      "25/11/13 15:06:49 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 36.8 KiB, free: 1048.5 MiB)\n",
      "25/11/13 15:06:49 INFO SparkContext: Created broadcast 47 from showString at NativeMethodAccessorImpl.java:0\n",
      "25/11/13 15:06:49 INFO FileSourceScanExec: Planning scan with bin packing, max size: 34852989 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/11/13 15:06:49 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "25/11/13 15:06:49 INFO DAGScheduler: Got job 32 (showString at NativeMethodAccessorImpl.java:0) with 2 output partitions\n",
      "25/11/13 15:06:49 INFO DAGScheduler: Final stage: ResultStage 54 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/11/13 15:06:49 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/11/13 15:06:49 INFO DAGScheduler: Missing parents: List()\n",
      "25/11/13 15:06:49 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[135] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/11/13 15:06:49 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 30.0 KiB, free 1046.8 MiB)\n",
      "25/11/13 15:06:49 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 10.4 KiB, free 1046.8 MiB)\n",
      "25/11/13 15:06:49 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on jupyter-spark-758b7c86d8-7j77n:43517 (size: 10.4 KiB, free: 1048.5 MiB)\n",
      "25/11/13 15:06:49 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1611\n",
      "25/11/13 15:06:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 54 (MapPartitionsRDD[135] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))\n",
      "25/11/13 15:06:49 INFO TaskSchedulerImpl: Adding task set 54.0 with 2 tasks resource profile 0\n",
      "25/11/13 15:06:49 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 625) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 0, PROCESS_LOCAL, 9671 bytes) \n",
      "25/11/13 15:06:49 INFO TaskSetManager: Starting task 1.0 in stage 54.0 (TID 626) (jupyter-spark-758b7c86d8-7j77n, executor driver, partition 1, PROCESS_LOCAL, 9671 bytes) \n",
      "25/11/13 15:06:49 INFO Executor: Running task 0.0 in stage 54.0 (TID 625)\n",
      "25/11/13 15:06:49 INFO Executor: Running task 1.0 in stage 54.0 (TID 626)\n",
      "25/11/13 15:06:49 INFO FileScanRDD: Reading File path: s3a://nau-local-analytics-silver/dim_user/part-00000-1e2cb7c2-be16-4592-9fd6-87e16bfa900b-c000.snappy.parquet, range: 0-34852989, partition values: [empty row]\n",
      "25/11/13 15:06:49 INFO FileScanRDD: Reading File path: s3a://nau-local-analytics-silver/dim_user/part-00000-1e2cb7c2-be16-4592-9fd6-87e16bfa900b-c000.snappy.parquet, range: 34852989-65511675, partition values: [empty row]\n",
      "25/11/13 15:06:50 INFO S3AInputStream: Switching to Random IO seek policy\n",
      "25/11/13 15:06:50 INFO S3AInputStream: Switching to Random IO seek policy\n",
      "25/11/13 15:06:50 INFO Executor: Finished task 1.0 in stage 54.0 (TID 626). 1496 bytes result sent to driver\n",
      "25/11/13 15:06:50 INFO TaskSetManager: Finished task 1.0 in stage 54.0 (TID 626) in 202 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (1/2)\n",
      "25/11/13 15:06:50 INFO BlockManagerInfo: Removed broadcast_46_piece0 on jupyter-spark-758b7c86d8-7j77n:43517 in memory (size: 154.6 KiB, free: 1048.6 MiB)\n",
      "[Stage 54:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----------------+----------------------------------+-------------+---------+-----------------+--------+------------+---------+--------------------------+--------------------------+----------------------------------------------------------------+--------------------------+-----------+\n",
      "|user_sk|user_id|username         |email                             |first_name   |last_name|full_name        |is_staff|is_superuser|is_active|date_joined               |last_login                |user_hash                                                       |ingestion_date            |source_name|\n",
      "+-------+-------+-----------------+----------------------------------+-------------+---------+-----------------+--------+------------+---------+--------------------------+--------------------------+----------------------------------------------------------------+--------------------------+-----------+\n",
      "|1      |1      |enterprise_worker|enterprise_worker@example.com     |             |         |                 |true    |false       |true     |2018-08-29 18:34:26.488188|NULL                      |5292211e07d3eae558e746efeaae281a3208c83e6a78601c8a5ed4dce565fe66|2025-11-04 18:26:56.116039|auth_user  |\n",
      "|2      |2      |veda_service_user|veda_service_user@example.com     |             |         |                 |true    |false       |true     |2018-08-29 18:34:34.18119 |NULL                      |84136b8498e880143cde64d5badcc17ec16fd795ec7e04a4e78ccc076433892e|2025-11-04 18:26:56.116039|auth_user  |\n",
      "|3      |3      |ecommerce_worker |ecommerce_worker@example.com      |             |         |                 |true    |true        |true     |2018-08-29 18:34:42       |NULL                      |ea9522b2b1762f784b79624827c141c93254384bc8ad1fecd59fba5c0c0f63bb|2025-11-04 18:26:56.116039|auth_user  |\n",
      "|4      |4      |discovery_worker |discovery_worker@example.com      |             |         |                 |true    |false       |true     |2018-08-29 18:34:50.609274|NULL                      |cc7c9c19587681bac8b622b4f5a00e61d7ce138732e64c24460e7e8bce53688c|2025-11-04 18:26:56.116039|auth_user  |\n",
      "|5      |6      |insights_worker  |insights_worker@example.com       |             |         |                 |true    |false       |true     |2018-08-29 18:34:58.792988|NULL                      |369017097638c15933633841f9ceea5c595c121001f9cb95efbb986d94cdb983|2025-11-04 18:26:56.116039|auth_user  |\n",
      "|6      |7      |technical_edunext|technical@edunext.co              |             |         |                 |true    |true        |true     |2018-09-10 20:10:50       |2025-10-22 22:28:28.638619|58bdae2dd037b7ac57f77f911ccf65eebaef25f30513cce738e6a45c28a897ee|2025-11-04 18:26:56.116039|auth_user  |\n",
      "|7      |8      |admin            |alertas@nau.edu.pt                |Administrador|NAU      |Administrador NAU|true    |true        |true     |2018-09-14 16:58:50       |2025-03-19 14:45:20.856742|d16562f4a3eed876be3c58d0306d900fd2c877b022c61455b442acfbfa6254e5|2025-11-04 18:26:56.116039|auth_user  |\n",
      "|8      |10     |staff            |naudevel+prod-staff@gmail.com     |             |         |                 |true    |false       |true     |2018-09-14 17:01:45       |NULL                      |ed5ee83b9ce56077772d5fcbf38d722f461b50bb04a24abe5ce9bf1caf33e396|2025-11-04 18:26:56.116039|auth_user  |\n",
      "|9      |11     |instructor       |naudevel+prod-instructor@gmail.com|             |         |                 |false   |false       |true     |2018-09-14 17:02:46       |NULL                      |24f32f2da2d94fe0de6f50f93412df1590cb777ccbcd257aea3de07cd77342e8|2025-11-04 18:26:56.116039|auth_user  |\n",
      "|10     |12     |student          |naudevel+prod-student@gmail.com   |             |         |                 |false   |false       |true     |2018-09-14 17:03:38       |NULL                      |f97142e3119d5f94acb9c3f673b2b502028dda45d2e047de0b5d2aa5bb9cd5dc|2025-11-04 18:26:56.116039|auth_user  |\n",
      "+-------+-------+-----------------+----------------------------------+-------------+---------+-----------------+--------+------------+---------+--------------------------+--------------------------+----------------------------------------------------------------+--------------------------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/13 15:06:53 INFO Executor: Finished task 0.0 in stage 54.0 (TID 625). 4637 bytes result sent to driver\n",
      "25/11/13 15:06:53 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 625) in 3341 ms on jupyter-spark-758b7c86d8-7j77n (executor driver) (2/2)\n",
      "25/11/13 15:06:53 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool \n",
      "25/11/13 15:06:53 INFO DAGScheduler: ResultStage 54 (showString at NativeMethodAccessorImpl.java:0) finished in 3.350 s\n",
      "25/11/13 15:06:53 INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/11/13 15:06:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 54: Stage finished\n",
      "25/11/13 15:06:53 INFO DAGScheduler: Job 32 finished: showString at NativeMethodAccessorImpl.java:0, took 3.355308 s\n",
      "25/11/13 15:32:18 INFO SparkContext: Invoking stop() from shutdown hook         \n",
      "25/11/13 15:32:18 INFO SparkContext: SparkContext is stopping with exitCode 0.\n",
      "25/11/13 15:32:18 INFO SparkUI: Stopped Spark web UI at http://jupyter-spark-758b7c86d8-7j77n:4040\n",
      "25/11/13 15:32:18 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\n",
      "25/11/13 15:32:18 INFO MemoryStore: MemoryStore cleared\n",
      "25/11/13 15:32:18 INFO BlockManager: BlockManager stopped\n",
      "25/11/13 15:32:18 INFO BlockManagerMaster: BlockManagerMaster stopped\n",
      "25/11/13 15:32:18 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\n",
      "25/11/13 15:32:18 INFO SparkContext: Successfully stopped SparkContext\n",
      "25/11/13 15:32:18 INFO ShutdownHookManager: Shutdown hook called\n",
      "25/11/13 15:32:18 INFO ShutdownHookManager: Deleting directory /tmp/spark-c4b751d6-afc3-4fdc-b641-835f675e1e39/pyspark-2e659519-66f1-48fe-88d3-01823a38ae8e\n",
      "25/11/13 15:32:18 INFO ShutdownHookManager: Deleting directory /tmp/spark-c4b751d6-afc3-4fdc-b641-835f675e1e39\n",
      "25/11/13 15:32:18 INFO ShutdownHookManager: Deleting directory /tmp/spark-347d25c6-abba-4f33-a7f1-0b7164519088\n",
      "25/11/13 15:32:18 INFO MetricsSystemImpl: Stopping s3a-file-system metrics system...\n",
      "25/11/13 15:32:18 INFO MetricsSystemImpl: s3a-file-system metrics system stopped.\n",
      "25/11/13 15:32:18 INFO MetricsSystemImpl: s3a-file-system metrics system shutdown complete.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# ============================================\n",
    "# Simple validation for dim_user (Silver)\n",
    "# ============================================\n",
    "silver_path = \"s3a://nau-local-analytics-silver/dim_user\"\n",
    "dim_table_name = \"dim_user\"\n",
    "\n",
    "print(\">> [dim_user] Reading Silver Delta table from path:\")\n",
    "print(f\"   {silver_path}\\n\")\n",
    "\n",
    "df_dim_user = (\n",
    "    spark.read\n",
    "         .format(\"delta\")\n",
    "         .load(silver_path)\n",
    ")\n",
    "\n",
    "print(\">> [dim_user] Schema:\")\n",
    "df_dim_user.printSchema()\n",
    "\n",
    "print(\">> [dim_user] Sample rows:\")\n",
    "df_dim_user.orderBy(\"user_sk\").show(10, truncate=False)\n",
    "\n",
    "# Basic metrics\n",
    "total_rows = df_dim_user.count()\n",
    "distinct_users = df_dim_user.select(\"user_id\").distinct().count()\n",
    "\n",
    "print(f\">> [dim_user] Total rows in Silver: {total_rows}\")\n",
    "print(f\">> [dim_user] Distinct user_id in Silver: {distinct_users}\")\n",
    "\n",
    "# Optional: check if table is registered in the metastore\n",
    "print(\"\\n>> [dim_user] Checking if table is available in the catalog (if created):\")\n",
    "spark.sql(f\"SHOW TABLES LIKE '{dim_table_name}'\").show(truncate=False)\n",
    "\n",
    "# Optional: preview via SQL as well\n",
    "print(\"\\n>> [dim_user] Preview via SQL (if table is registered):\")\n",
    "spark.sql(f\"SELECT * FROM {dim_table_name} ORDER BY user_sk LIMIT 10\").show(truncate=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
